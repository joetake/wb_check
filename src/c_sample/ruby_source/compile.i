
typedef unsigned char __u_char;
typedef unsigned short int __u_short;
typedef unsigned int __u_int;
typedef unsigned long int __u_long;
typedef signed char __int8_t;
typedef unsigned char __uint8_t;
typedef signed short int __int16_t;
typedef unsigned short int __uint16_t;
typedef signed int __int32_t;
typedef unsigned int __uint32_t;
typedef signed long int __int64_t;
typedef unsigned long int __uint64_t;
typedef __int8_t __int_least8_t;
typedef __uint8_t __uint_least8_t;
typedef __int16_t __int_least16_t;
typedef __uint16_t __uint_least16_t;
typedef __int32_t __int_least32_t;
typedef __uint32_t __uint_least32_t;
typedef __int64_t __int_least64_t;
typedef __uint64_t __uint_least64_t;
typedef long int __quad_t;
typedef unsigned long int __u_quad_t;
typedef long int __intmax_t;
typedef unsigned long int __uintmax_t;
typedef unsigned long int __dev_t;
typedef unsigned int __uid_t;
typedef unsigned int __gid_t;
typedef unsigned long int __ino_t;
typedef unsigned long int __ino64_t;
typedef unsigned int __mode_t;
typedef unsigned long int __nlink_t;
typedef long int __off_t;
typedef long int __off64_t;
typedef int __pid_t;
typedef struct { int __val[2]; } __fsid_t;
typedef long int __clock_t;
typedef unsigned long int __rlim_t;
typedef unsigned long int __rlim64_t;
typedef unsigned int __id_t;
typedef long int __time_t;
typedef unsigned int __useconds_t;
typedef long int __suseconds_t;
typedef long int __suseconds64_t;
typedef int __daddr_t;
typedef int __key_t;
typedef int __clockid_t;
typedef void * __timer_t;
typedef long int __blksize_t;
typedef long int __blkcnt_t;
typedef long int __blkcnt64_t;
typedef unsigned long int __fsblkcnt_t;
typedef unsigned long int __fsblkcnt64_t;
typedef unsigned long int __fsfilcnt_t;
typedef unsigned long int __fsfilcnt64_t;
typedef long int __fsword_t;
typedef long int __ssize_t;
typedef long int __syscall_slong_t;
typedef unsigned long int __syscall_ulong_t;
typedef __off64_t __loff_t;
typedef char *__caddr_t;
typedef long int __intptr_t;
typedef unsigned int __socklen_t;
typedef int __sig_atomic_t;
typedef float float_t;
typedef double double_t;
enum
  {
    FP_INT_UPWARD =
      0,
    FP_INT_DOWNWARD =
      1,
    FP_INT_TOWARDZERO =
      2,
    FP_INT_TONEARESTFROMZERO =
      3,
    FP_INT_TONEAREST =
      4,
  };
extern int __fpclassify (double __value) __attribute__ ((__nothrow__ , __leaf__))
     __attribute__ ((__const__));
extern int __signbit (double __value) __attribute__ ((__nothrow__ , __leaf__))
     __attribute__ ((__const__));
extern int __isinf (double __value) __attribute__ ((__nothrow__ , __leaf__))
  __attribute__ ((__const__));
extern int __finite (double __value) __attribute__ ((__nothrow__ , __leaf__))
  __attribute__ ((__const__));
extern int __isnan (double __value) __attribute__ ((__nothrow__ , __leaf__))
  __attribute__ ((__const__));
extern int __iseqsig (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__));
extern int __issignaling (double __value) __attribute__ ((__nothrow__ , __leaf__))
     __attribute__ ((__const__));
 extern double acos (double __x) __attribute__ ((__nothrow__ , __leaf__)); extern double __acos (double __x) __attribute__ ((__nothrow__ , __leaf__));
 extern double asin (double __x) __attribute__ ((__nothrow__ , __leaf__)); extern double __asin (double __x) __attribute__ ((__nothrow__ , __leaf__));
 extern double atan (double __x) __attribute__ ((__nothrow__ , __leaf__)); extern double __atan (double __x) __attribute__ ((__nothrow__ , __leaf__));
 extern double atan2 (double __y, double __x) __attribute__ ((__nothrow__ , __leaf__)); extern double __atan2 (double __y, double __x) __attribute__ ((__nothrow__ , __leaf__));
 extern double cos (double __x) __attribute__ ((__nothrow__ , __leaf__)); extern double __cos (double __x) __attribute__ ((__nothrow__ , __leaf__));
 extern double sin (double __x) __attribute__ ((__nothrow__ , __leaf__)); extern double __sin (double __x) __attribute__ ((__nothrow__ , __leaf__));
 extern double tan (double __x) __attribute__ ((__nothrow__ , __leaf__)); extern double __tan (double __x) __attribute__ ((__nothrow__ , __leaf__));
 extern double cosh (double __x) __attribute__ ((__nothrow__ , __leaf__)); extern double __cosh (double __x) __attribute__ ((__nothrow__ , __leaf__));
 extern double sinh (double __x) __attribute__ ((__nothrow__ , __leaf__)); extern double __sinh (double __x) __attribute__ ((__nothrow__ , __leaf__));
 extern double tanh (double __x) __attribute__ ((__nothrow__ , __leaf__)); extern double __tanh (double __x) __attribute__ ((__nothrow__ , __leaf__));
 extern void sincos (double __x, double *__sinx, double *__cosx) __attribute__ ((__nothrow__ , __leaf__)); extern void __sincos (double __x, double *__sinx, double *__cosx) __attribute__ ((__nothrow__ , __leaf__));
 extern double acosh (double __x) __attribute__ ((__nothrow__ , __leaf__)); extern double __acosh (double __x) __attribute__ ((__nothrow__ , __leaf__));
 extern double asinh (double __x) __attribute__ ((__nothrow__ , __leaf__)); extern double __asinh (double __x) __attribute__ ((__nothrow__ , __leaf__));
 extern double atanh (double __x) __attribute__ ((__nothrow__ , __leaf__)); extern double __atanh (double __x) __attribute__ ((__nothrow__ , __leaf__));
 extern double exp (double __x) __attribute__ ((__nothrow__ , __leaf__)); extern double __exp (double __x) __attribute__ ((__nothrow__ , __leaf__));
extern double frexp (double __x, int *__exponent) __attribute__ ((__nothrow__ , __leaf__)); extern double __frexp (double __x, int *__exponent) __attribute__ ((__nothrow__ , __leaf__));
extern double ldexp (double __x, int __exponent) __attribute__ ((__nothrow__ , __leaf__)); extern double __ldexp (double __x, int __exponent) __attribute__ ((__nothrow__ , __leaf__));
 extern double log (double __x) __attribute__ ((__nothrow__ , __leaf__)); extern double __log (double __x) __attribute__ ((__nothrow__ , __leaf__));
 extern double log10 (double __x) __attribute__ ((__nothrow__ , __leaf__)); extern double __log10 (double __x) __attribute__ ((__nothrow__ , __leaf__));
extern double modf (double __x, double *__iptr) __attribute__ ((__nothrow__ , __leaf__)); extern double __modf (double __x, double *__iptr) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2)));
 extern double exp10 (double __x) __attribute__ ((__nothrow__ , __leaf__)); extern double __exp10 (double __x) __attribute__ ((__nothrow__ , __leaf__));
 extern double expm1 (double __x) __attribute__ ((__nothrow__ , __leaf__)); extern double __expm1 (double __x) __attribute__ ((__nothrow__ , __leaf__));
 extern double log1p (double __x) __attribute__ ((__nothrow__ , __leaf__)); extern double __log1p (double __x) __attribute__ ((__nothrow__ , __leaf__));
extern double logb (double __x) __attribute__ ((__nothrow__ , __leaf__)); extern double __logb (double __x) __attribute__ ((__nothrow__ , __leaf__));
 extern double exp2 (double __x) __attribute__ ((__nothrow__ , __leaf__)); extern double __exp2 (double __x) __attribute__ ((__nothrow__ , __leaf__));
 extern double log2 (double __x) __attribute__ ((__nothrow__ , __leaf__)); extern double __log2 (double __x) __attribute__ ((__nothrow__ , __leaf__));
 extern double pow (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__)); extern double __pow (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__));
extern double sqrt (double __x) __attribute__ ((__nothrow__ , __leaf__)); extern double __sqrt (double __x) __attribute__ ((__nothrow__ , __leaf__));
 extern double hypot (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__)); extern double __hypot (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__));
 extern double cbrt (double __x) __attribute__ ((__nothrow__ , __leaf__)); extern double __cbrt (double __x) __attribute__ ((__nothrow__ , __leaf__));
extern double ceil (double __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern double __ceil (double __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern double fabs (double __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern double __fabs (double __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern double floor (double __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern double __floor (double __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern double fmod (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__)); extern double __fmod (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__));
extern int isinf (double __value) __attribute__ ((__nothrow__ , __leaf__))
  __attribute__ ((__const__));
extern int finite (double __value) __attribute__ ((__nothrow__ , __leaf__))
  __attribute__ ((__const__));
extern double drem (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__)); extern double __drem (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__));
extern double significand (double __x) __attribute__ ((__nothrow__ , __leaf__)); extern double __significand (double __x) __attribute__ ((__nothrow__ , __leaf__));
extern double copysign (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern double __copysign (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern double nan (const char *__tagb) __attribute__ ((__nothrow__ , __leaf__)); extern double __nan (const char *__tagb) __attribute__ ((__nothrow__ , __leaf__));
extern int isnan (double __value) __attribute__ ((__nothrow__ , __leaf__))
  __attribute__ ((__const__));
extern double j0 (double) __attribute__ ((__nothrow__ , __leaf__)); extern double __j0 (double) __attribute__ ((__nothrow__ , __leaf__));
extern double j1 (double) __attribute__ ((__nothrow__ , __leaf__)); extern double __j1 (double) __attribute__ ((__nothrow__ , __leaf__));
extern double jn (int, double) __attribute__ ((__nothrow__ , __leaf__)); extern double __jn (int, double) __attribute__ ((__nothrow__ , __leaf__));
extern double y0 (double) __attribute__ ((__nothrow__ , __leaf__)); extern double __y0 (double) __attribute__ ((__nothrow__ , __leaf__));
extern double y1 (double) __attribute__ ((__nothrow__ , __leaf__)); extern double __y1 (double) __attribute__ ((__nothrow__ , __leaf__));
extern double yn (int, double) __attribute__ ((__nothrow__ , __leaf__)); extern double __yn (int, double) __attribute__ ((__nothrow__ , __leaf__));
 extern double erf (double) __attribute__ ((__nothrow__ , __leaf__)); extern double __erf (double) __attribute__ ((__nothrow__ , __leaf__));
 extern double erfc (double) __attribute__ ((__nothrow__ , __leaf__)); extern double __erfc (double) __attribute__ ((__nothrow__ , __leaf__));
extern double lgamma (double) __attribute__ ((__nothrow__ , __leaf__)); extern double __lgamma (double) __attribute__ ((__nothrow__ , __leaf__));
extern double tgamma (double) __attribute__ ((__nothrow__ , __leaf__)); extern double __tgamma (double) __attribute__ ((__nothrow__ , __leaf__));
extern double gamma (double) __attribute__ ((__nothrow__ , __leaf__)); extern double __gamma (double) __attribute__ ((__nothrow__ , __leaf__));
extern double lgamma_r (double, int *__signgamp) __attribute__ ((__nothrow__ , __leaf__)); extern double __lgamma_r (double, int *__signgamp) __attribute__ ((__nothrow__ , __leaf__));
extern double rint (double __x) __attribute__ ((__nothrow__ , __leaf__)); extern double __rint (double __x) __attribute__ ((__nothrow__ , __leaf__));
extern double nextafter (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__)); extern double __nextafter (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__));
extern double nexttoward (double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__)); extern double __nexttoward (double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__));
extern double nextdown (double __x) __attribute__ ((__nothrow__ , __leaf__)); extern double __nextdown (double __x) __attribute__ ((__nothrow__ , __leaf__));
extern double nextup (double __x) __attribute__ ((__nothrow__ , __leaf__)); extern double __nextup (double __x) __attribute__ ((__nothrow__ , __leaf__));
extern double remainder (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__)); extern double __remainder (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__));
extern double scalbn (double __x, int __n) __attribute__ ((__nothrow__ , __leaf__)); extern double __scalbn (double __x, int __n) __attribute__ ((__nothrow__ , __leaf__));
extern int ilogb (double __x) __attribute__ ((__nothrow__ , __leaf__)); extern int __ilogb (double __x) __attribute__ ((__nothrow__ , __leaf__));
extern long int llogb (double __x) __attribute__ ((__nothrow__ , __leaf__)); extern long int __llogb (double __x) __attribute__ ((__nothrow__ , __leaf__));
extern double scalbln (double __x, long int __n) __attribute__ ((__nothrow__ , __leaf__)); extern double __scalbln (double __x, long int __n) __attribute__ ((__nothrow__ , __leaf__));
extern double nearbyint (double __x) __attribute__ ((__nothrow__ , __leaf__)); extern double __nearbyint (double __x) __attribute__ ((__nothrow__ , __leaf__));
extern double round (double __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern double __round (double __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern double trunc (double __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern double __trunc (double __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern double remquo (double __x, double __y, int *__quo) __attribute__ ((__nothrow__ , __leaf__)); extern double __remquo (double __x, double __y, int *__quo) __attribute__ ((__nothrow__ , __leaf__));
extern long int lrint (double __x) __attribute__ ((__nothrow__ , __leaf__)); extern long int __lrint (double __x) __attribute__ ((__nothrow__ , __leaf__));
__extension__
extern long long int llrint (double __x) __attribute__ ((__nothrow__ , __leaf__)); extern long long int __llrint (double __x) __attribute__ ((__nothrow__ , __leaf__));
extern long int lround (double __x) __attribute__ ((__nothrow__ , __leaf__)); extern long int __lround (double __x) __attribute__ ((__nothrow__ , __leaf__));
__extension__
extern long long int llround (double __x) __attribute__ ((__nothrow__ , __leaf__)); extern long long int __llround (double __x) __attribute__ ((__nothrow__ , __leaf__));
extern double fdim (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__)); extern double __fdim (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__));
extern double fmax (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern double __fmax (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern double fmin (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern double __fmin (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern double fma (double __x, double __y, double __z) __attribute__ ((__nothrow__ , __leaf__)); extern double __fma (double __x, double __y, double __z) __attribute__ ((__nothrow__ , __leaf__));
extern double roundeven (double __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern double __roundeven (double __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern __intmax_t fromfp (double __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__)); extern __intmax_t __fromfp (double __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__));
extern __uintmax_t ufromfp (double __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__)); extern __uintmax_t __ufromfp (double __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__));
extern __intmax_t fromfpx (double __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__)); extern __intmax_t __fromfpx (double __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__));
extern __uintmax_t ufromfpx (double __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__)); extern __uintmax_t __ufromfpx (double __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__));
extern int canonicalize (double *__cx, const double *__x) __attribute__ ((__nothrow__ , __leaf__));
extern double fmaxmag (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern double __fmaxmag (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern double fminmag (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern double __fminmag (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern double fmaximum (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern double __fmaximum (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern double fminimum (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern double __fminimum (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern double fmaximum_num (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern double __fmaximum_num (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern double fminimum_num (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern double __fminimum_num (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern double fmaximum_mag (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern double __fmaximum_mag (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern double fminimum_mag (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern double __fminimum_mag (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern double fmaximum_mag_num (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern double __fmaximum_mag_num (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern double fminimum_mag_num (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern double __fminimum_mag_num (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern int totalorder (const double *__x, const double *__y) __attribute__ ((__nothrow__ , __leaf__))
     __attribute__ ((__pure__));
extern int totalordermag (const double *__x, const double *__y) __attribute__ ((__nothrow__ , __leaf__))
     __attribute__ ((__pure__));
extern double getpayload (const double *__x) __attribute__ ((__nothrow__ , __leaf__)); extern double __getpayload (const double *__x) __attribute__ ((__nothrow__ , __leaf__));
extern int setpayload (double *__x, double __payload) __attribute__ ((__nothrow__ , __leaf__));
extern int setpayloadsig (double *__x, double __payload) __attribute__ ((__nothrow__ , __leaf__));
extern double scalb (double __x, double __n) __attribute__ ((__nothrow__ , __leaf__)); extern double __scalb (double __x, double __n) __attribute__ ((__nothrow__ , __leaf__));
extern int __fpclassifyf (float __value) __attribute__ ((__nothrow__ , __leaf__))
     __attribute__ ((__const__));
extern int __signbitf (float __value) __attribute__ ((__nothrow__ , __leaf__))
     __attribute__ ((__const__));
extern int __isinff (float __value) __attribute__ ((__nothrow__ , __leaf__))
  __attribute__ ((__const__));
extern int __finitef (float __value) __attribute__ ((__nothrow__ , __leaf__))
  __attribute__ ((__const__));
extern int __isnanf (float __value) __attribute__ ((__nothrow__ , __leaf__))
  __attribute__ ((__const__));
extern int __iseqsigf (float __x, float __y) __attribute__ ((__nothrow__ , __leaf__));
extern int __issignalingf (float __value) __attribute__ ((__nothrow__ , __leaf__))
     __attribute__ ((__const__));
 extern float acosf (float __x) __attribute__ ((__nothrow__ , __leaf__)); extern float __acosf (float __x) __attribute__ ((__nothrow__ , __leaf__));
 extern float asinf (float __x) __attribute__ ((__nothrow__ , __leaf__)); extern float __asinf (float __x) __attribute__ ((__nothrow__ , __leaf__));
 extern float atanf (float __x) __attribute__ ((__nothrow__ , __leaf__)); extern float __atanf (float __x) __attribute__ ((__nothrow__ , __leaf__));
 extern float atan2f (float __y, float __x) __attribute__ ((__nothrow__ , __leaf__)); extern float __atan2f (float __y, float __x) __attribute__ ((__nothrow__ , __leaf__));
 extern float cosf (float __x) __attribute__ ((__nothrow__ , __leaf__)); extern float __cosf (float __x) __attribute__ ((__nothrow__ , __leaf__));
 extern float sinf (float __x) __attribute__ ((__nothrow__ , __leaf__)); extern float __sinf (float __x) __attribute__ ((__nothrow__ , __leaf__));
 extern float tanf (float __x) __attribute__ ((__nothrow__ , __leaf__)); extern float __tanf (float __x) __attribute__ ((__nothrow__ , __leaf__));
 extern float coshf (float __x) __attribute__ ((__nothrow__ , __leaf__)); extern float __coshf (float __x) __attribute__ ((__nothrow__ , __leaf__));
 extern float sinhf (float __x) __attribute__ ((__nothrow__ , __leaf__)); extern float __sinhf (float __x) __attribute__ ((__nothrow__ , __leaf__));
 extern float tanhf (float __x) __attribute__ ((__nothrow__ , __leaf__)); extern float __tanhf (float __x) __attribute__ ((__nothrow__ , __leaf__));
 extern void sincosf (float __x, float *__sinx, float *__cosx) __attribute__ ((__nothrow__ , __leaf__)); extern void __sincosf (float __x, float *__sinx, float *__cosx) __attribute__ ((__nothrow__ , __leaf__));
 extern float acoshf (float __x) __attribute__ ((__nothrow__ , __leaf__)); extern float __acoshf (float __x) __attribute__ ((__nothrow__ , __leaf__));
 extern float asinhf (float __x) __attribute__ ((__nothrow__ , __leaf__)); extern float __asinhf (float __x) __attribute__ ((__nothrow__ , __leaf__));
 extern float atanhf (float __x) __attribute__ ((__nothrow__ , __leaf__)); extern float __atanhf (float __x) __attribute__ ((__nothrow__ , __leaf__));
 extern float expf (float __x) __attribute__ ((__nothrow__ , __leaf__)); extern float __expf (float __x) __attribute__ ((__nothrow__ , __leaf__));
extern float frexpf (float __x, int *__exponent) __attribute__ ((__nothrow__ , __leaf__)); extern float __frexpf (float __x, int *__exponent) __attribute__ ((__nothrow__ , __leaf__));
extern float ldexpf (float __x, int __exponent) __attribute__ ((__nothrow__ , __leaf__)); extern float __ldexpf (float __x, int __exponent) __attribute__ ((__nothrow__ , __leaf__));
 extern float logf (float __x) __attribute__ ((__nothrow__ , __leaf__)); extern float __logf (float __x) __attribute__ ((__nothrow__ , __leaf__));
 extern float log10f (float __x) __attribute__ ((__nothrow__ , __leaf__)); extern float __log10f (float __x) __attribute__ ((__nothrow__ , __leaf__));
extern float modff (float __x, float *__iptr) __attribute__ ((__nothrow__ , __leaf__)); extern float __modff (float __x, float *__iptr) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2)));
 extern float exp10f (float __x) __attribute__ ((__nothrow__ , __leaf__)); extern float __exp10f (float __x) __attribute__ ((__nothrow__ , __leaf__));
 extern float expm1f (float __x) __attribute__ ((__nothrow__ , __leaf__)); extern float __expm1f (float __x) __attribute__ ((__nothrow__ , __leaf__));
 extern float log1pf (float __x) __attribute__ ((__nothrow__ , __leaf__)); extern float __log1pf (float __x) __attribute__ ((__nothrow__ , __leaf__));
extern float logbf (float __x) __attribute__ ((__nothrow__ , __leaf__)); extern float __logbf (float __x) __attribute__ ((__nothrow__ , __leaf__));
 extern float exp2f (float __x) __attribute__ ((__nothrow__ , __leaf__)); extern float __exp2f (float __x) __attribute__ ((__nothrow__ , __leaf__));
 extern float log2f (float __x) __attribute__ ((__nothrow__ , __leaf__)); extern float __log2f (float __x) __attribute__ ((__nothrow__ , __leaf__));
 extern float powf (float __x, float __y) __attribute__ ((__nothrow__ , __leaf__)); extern float __powf (float __x, float __y) __attribute__ ((__nothrow__ , __leaf__));
extern float sqrtf (float __x) __attribute__ ((__nothrow__ , __leaf__)); extern float __sqrtf (float __x) __attribute__ ((__nothrow__ , __leaf__));
 extern float hypotf (float __x, float __y) __attribute__ ((__nothrow__ , __leaf__)); extern float __hypotf (float __x, float __y) __attribute__ ((__nothrow__ , __leaf__));
 extern float cbrtf (float __x) __attribute__ ((__nothrow__ , __leaf__)); extern float __cbrtf (float __x) __attribute__ ((__nothrow__ , __leaf__));
extern float ceilf (float __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern float __ceilf (float __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern float fabsf (float __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern float __fabsf (float __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern float floorf (float __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern float __floorf (float __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern float fmodf (float __x, float __y) __attribute__ ((__nothrow__ , __leaf__)); extern float __fmodf (float __x, float __y) __attribute__ ((__nothrow__ , __leaf__));
extern int isinff (float __value) __attribute__ ((__nothrow__ , __leaf__))
  __attribute__ ((__const__));
extern int finitef (float __value) __attribute__ ((__nothrow__ , __leaf__))
  __attribute__ ((__const__));
extern float dremf (float __x, float __y) __attribute__ ((__nothrow__ , __leaf__)); extern float __dremf (float __x, float __y) __attribute__ ((__nothrow__ , __leaf__));
extern float significandf (float __x) __attribute__ ((__nothrow__ , __leaf__)); extern float __significandf (float __x) __attribute__ ((__nothrow__ , __leaf__));
extern float copysignf (float __x, float __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern float __copysignf (float __x, float __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern float nanf (const char *__tagb) __attribute__ ((__nothrow__ , __leaf__)); extern float __nanf (const char *__tagb) __attribute__ ((__nothrow__ , __leaf__));
extern int isnanf (float __value) __attribute__ ((__nothrow__ , __leaf__))
  __attribute__ ((__const__));
extern float j0f (float) __attribute__ ((__nothrow__ , __leaf__)); extern float __j0f (float) __attribute__ ((__nothrow__ , __leaf__));
extern float j1f (float) __attribute__ ((__nothrow__ , __leaf__)); extern float __j1f (float) __attribute__ ((__nothrow__ , __leaf__));
extern float jnf (int, float) __attribute__ ((__nothrow__ , __leaf__)); extern float __jnf (int, float) __attribute__ ((__nothrow__ , __leaf__));
extern float y0f (float) __attribute__ ((__nothrow__ , __leaf__)); extern float __y0f (float) __attribute__ ((__nothrow__ , __leaf__));
extern float y1f (float) __attribute__ ((__nothrow__ , __leaf__)); extern float __y1f (float) __attribute__ ((__nothrow__ , __leaf__));
extern float ynf (int, float) __attribute__ ((__nothrow__ , __leaf__)); extern float __ynf (int, float) __attribute__ ((__nothrow__ , __leaf__));
 extern float erff (float) __attribute__ ((__nothrow__ , __leaf__)); extern float __erff (float) __attribute__ ((__nothrow__ , __leaf__));
 extern float erfcf (float) __attribute__ ((__nothrow__ , __leaf__)); extern float __erfcf (float) __attribute__ ((__nothrow__ , __leaf__));
extern float lgammaf (float) __attribute__ ((__nothrow__ , __leaf__)); extern float __lgammaf (float) __attribute__ ((__nothrow__ , __leaf__));
extern float tgammaf (float) __attribute__ ((__nothrow__ , __leaf__)); extern float __tgammaf (float) __attribute__ ((__nothrow__ , __leaf__));
extern float gammaf (float) __attribute__ ((__nothrow__ , __leaf__)); extern float __gammaf (float) __attribute__ ((__nothrow__ , __leaf__));
extern float lgammaf_r (float, int *__signgamp) __attribute__ ((__nothrow__ , __leaf__)); extern float __lgammaf_r (float, int *__signgamp) __attribute__ ((__nothrow__ , __leaf__));
extern float rintf (float __x) __attribute__ ((__nothrow__ , __leaf__)); extern float __rintf (float __x) __attribute__ ((__nothrow__ , __leaf__));
extern float nextafterf (float __x, float __y) __attribute__ ((__nothrow__ , __leaf__)); extern float __nextafterf (float __x, float __y) __attribute__ ((__nothrow__ , __leaf__));
extern float nexttowardf (float __x, long double __y) __attribute__ ((__nothrow__ , __leaf__)); extern float __nexttowardf (float __x, long double __y) __attribute__ ((__nothrow__ , __leaf__));
extern float nextdownf (float __x) __attribute__ ((__nothrow__ , __leaf__)); extern float __nextdownf (float __x) __attribute__ ((__nothrow__ , __leaf__));
extern float nextupf (float __x) __attribute__ ((__nothrow__ , __leaf__)); extern float __nextupf (float __x) __attribute__ ((__nothrow__ , __leaf__));
extern float remainderf (float __x, float __y) __attribute__ ((__nothrow__ , __leaf__)); extern float __remainderf (float __x, float __y) __attribute__ ((__nothrow__ , __leaf__));
extern float scalbnf (float __x, int __n) __attribute__ ((__nothrow__ , __leaf__)); extern float __scalbnf (float __x, int __n) __attribute__ ((__nothrow__ , __leaf__));
extern int ilogbf (float __x) __attribute__ ((__nothrow__ , __leaf__)); extern int __ilogbf (float __x) __attribute__ ((__nothrow__ , __leaf__));
extern long int llogbf (float __x) __attribute__ ((__nothrow__ , __leaf__)); extern long int __llogbf (float __x) __attribute__ ((__nothrow__ , __leaf__));
extern float scalblnf (float __x, long int __n) __attribute__ ((__nothrow__ , __leaf__)); extern float __scalblnf (float __x, long int __n) __attribute__ ((__nothrow__ , __leaf__));
extern float nearbyintf (float __x) __attribute__ ((__nothrow__ , __leaf__)); extern float __nearbyintf (float __x) __attribute__ ((__nothrow__ , __leaf__));
extern float roundf (float __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern float __roundf (float __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern float truncf (float __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern float __truncf (float __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern float remquof (float __x, float __y, int *__quo) __attribute__ ((__nothrow__ , __leaf__)); extern float __remquof (float __x, float __y, int *__quo) __attribute__ ((__nothrow__ , __leaf__));
extern long int lrintf (float __x) __attribute__ ((__nothrow__ , __leaf__)); extern long int __lrintf (float __x) __attribute__ ((__nothrow__ , __leaf__));
__extension__
extern long long int llrintf (float __x) __attribute__ ((__nothrow__ , __leaf__)); extern long long int __llrintf (float __x) __attribute__ ((__nothrow__ , __leaf__));
extern long int lroundf (float __x) __attribute__ ((__nothrow__ , __leaf__)); extern long int __lroundf (float __x) __attribute__ ((__nothrow__ , __leaf__));
__extension__
extern long long int llroundf (float __x) __attribute__ ((__nothrow__ , __leaf__)); extern long long int __llroundf (float __x) __attribute__ ((__nothrow__ , __leaf__));
extern float fdimf (float __x, float __y) __attribute__ ((__nothrow__ , __leaf__)); extern float __fdimf (float __x, float __y) __attribute__ ((__nothrow__ , __leaf__));
extern float fmaxf (float __x, float __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern float __fmaxf (float __x, float __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern float fminf (float __x, float __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern float __fminf (float __x, float __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern float fmaf (float __x, float __y, float __z) __attribute__ ((__nothrow__ , __leaf__)); extern float __fmaf (float __x, float __y, float __z) __attribute__ ((__nothrow__ , __leaf__));
extern float roundevenf (float __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern float __roundevenf (float __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern __intmax_t fromfpf (float __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__)); extern __intmax_t __fromfpf (float __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__));
extern __uintmax_t ufromfpf (float __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__)); extern __uintmax_t __ufromfpf (float __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__));
extern __intmax_t fromfpxf (float __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__)); extern __intmax_t __fromfpxf (float __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__));
extern __uintmax_t ufromfpxf (float __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__)); extern __uintmax_t __ufromfpxf (float __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__));
extern int canonicalizef (float *__cx, const float *__x) __attribute__ ((__nothrow__ , __leaf__));
extern float fmaxmagf (float __x, float __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern float __fmaxmagf (float __x, float __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern float fminmagf (float __x, float __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern float __fminmagf (float __x, float __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern float fmaximumf (float __x, float __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern float __fmaximumf (float __x, float __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern float fminimumf (float __x, float __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern float __fminimumf (float __x, float __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern float fmaximum_numf (float __x, float __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern float __fmaximum_numf (float __x, float __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern float fminimum_numf (float __x, float __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern float __fminimum_numf (float __x, float __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern float fmaximum_magf (float __x, float __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern float __fmaximum_magf (float __x, float __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern float fminimum_magf (float __x, float __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern float __fminimum_magf (float __x, float __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern float fmaximum_mag_numf (float __x, float __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern float __fmaximum_mag_numf (float __x, float __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern float fminimum_mag_numf (float __x, float __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern float __fminimum_mag_numf (float __x, float __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern int totalorderf (const float *__x, const float *__y) __attribute__ ((__nothrow__ , __leaf__))
     __attribute__ ((__pure__));
extern int totalordermagf (const float *__x, const float *__y) __attribute__ ((__nothrow__ , __leaf__))
     __attribute__ ((__pure__));
extern float getpayloadf (const float *__x) __attribute__ ((__nothrow__ , __leaf__)); extern float __getpayloadf (const float *__x) __attribute__ ((__nothrow__ , __leaf__));
extern int setpayloadf (float *__x, float __payload) __attribute__ ((__nothrow__ , __leaf__));
extern int setpayloadsigf (float *__x, float __payload) __attribute__ ((__nothrow__ , __leaf__));
extern float scalbf (float __x, float __n) __attribute__ ((__nothrow__ , __leaf__)); extern float __scalbf (float __x, float __n) __attribute__ ((__nothrow__ , __leaf__));
extern int __fpclassifyl (long double __value) __attribute__ ((__nothrow__ , __leaf__))
     __attribute__ ((__const__));
extern int __signbitl (long double __value) __attribute__ ((__nothrow__ , __leaf__))
     __attribute__ ((__const__));
extern int __isinfl (long double __value) __attribute__ ((__nothrow__ , __leaf__))
  __attribute__ ((__const__));
extern int __finitel (long double __value) __attribute__ ((__nothrow__ , __leaf__))
  __attribute__ ((__const__));
extern int __isnanl (long double __value) __attribute__ ((__nothrow__ , __leaf__))
  __attribute__ ((__const__));
extern int __iseqsigl (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__));
extern int __issignalingl (long double __value) __attribute__ ((__nothrow__ , __leaf__))
     __attribute__ ((__const__));
 extern long double acosl (long double __x) __attribute__ ((__nothrow__ , __leaf__)); extern long double __acosl (long double __x) __attribute__ ((__nothrow__ , __leaf__));
 extern long double asinl (long double __x) __attribute__ ((__nothrow__ , __leaf__)); extern long double __asinl (long double __x) __attribute__ ((__nothrow__ , __leaf__));
 extern long double atanl (long double __x) __attribute__ ((__nothrow__ , __leaf__)); extern long double __atanl (long double __x) __attribute__ ((__nothrow__ , __leaf__));
 extern long double atan2l (long double __y, long double __x) __attribute__ ((__nothrow__ , __leaf__)); extern long double __atan2l (long double __y, long double __x) __attribute__ ((__nothrow__ , __leaf__));
 extern long double cosl (long double __x) __attribute__ ((__nothrow__ , __leaf__)); extern long double __cosl (long double __x) __attribute__ ((__nothrow__ , __leaf__));
 extern long double sinl (long double __x) __attribute__ ((__nothrow__ , __leaf__)); extern long double __sinl (long double __x) __attribute__ ((__nothrow__ , __leaf__));
 extern long double tanl (long double __x) __attribute__ ((__nothrow__ , __leaf__)); extern long double __tanl (long double __x) __attribute__ ((__nothrow__ , __leaf__));
 extern long double coshl (long double __x) __attribute__ ((__nothrow__ , __leaf__)); extern long double __coshl (long double __x) __attribute__ ((__nothrow__ , __leaf__));
 extern long double sinhl (long double __x) __attribute__ ((__nothrow__ , __leaf__)); extern long double __sinhl (long double __x) __attribute__ ((__nothrow__ , __leaf__));
 extern long double tanhl (long double __x) __attribute__ ((__nothrow__ , __leaf__)); extern long double __tanhl (long double __x) __attribute__ ((__nothrow__ , __leaf__));
 extern void sincosl (long double __x, long double *__sinx, long double *__cosx) __attribute__ ((__nothrow__ , __leaf__)); extern void __sincosl (long double __x, long double *__sinx, long double *__cosx) __attribute__ ((__nothrow__ , __leaf__));
 extern long double acoshl (long double __x) __attribute__ ((__nothrow__ , __leaf__)); extern long double __acoshl (long double __x) __attribute__ ((__nothrow__ , __leaf__));
 extern long double asinhl (long double __x) __attribute__ ((__nothrow__ , __leaf__)); extern long double __asinhl (long double __x) __attribute__ ((__nothrow__ , __leaf__));
 extern long double atanhl (long double __x) __attribute__ ((__nothrow__ , __leaf__)); extern long double __atanhl (long double __x) __attribute__ ((__nothrow__ , __leaf__));
 extern long double expl (long double __x) __attribute__ ((__nothrow__ , __leaf__)); extern long double __expl (long double __x) __attribute__ ((__nothrow__ , __leaf__));
extern long double frexpl (long double __x, int *__exponent) __attribute__ ((__nothrow__ , __leaf__)); extern long double __frexpl (long double __x, int *__exponent) __attribute__ ((__nothrow__ , __leaf__));
extern long double ldexpl (long double __x, int __exponent) __attribute__ ((__nothrow__ , __leaf__)); extern long double __ldexpl (long double __x, int __exponent) __attribute__ ((__nothrow__ , __leaf__));
 extern long double logl (long double __x) __attribute__ ((__nothrow__ , __leaf__)); extern long double __logl (long double __x) __attribute__ ((__nothrow__ , __leaf__));
 extern long double log10l (long double __x) __attribute__ ((__nothrow__ , __leaf__)); extern long double __log10l (long double __x) __attribute__ ((__nothrow__ , __leaf__));
extern long double modfl (long double __x, long double *__iptr) __attribute__ ((__nothrow__ , __leaf__)); extern long double __modfl (long double __x, long double *__iptr) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2)));
 extern long double exp10l (long double __x) __attribute__ ((__nothrow__ , __leaf__)); extern long double __exp10l (long double __x) __attribute__ ((__nothrow__ , __leaf__));
 extern long double expm1l (long double __x) __attribute__ ((__nothrow__ , __leaf__)); extern long double __expm1l (long double __x) __attribute__ ((__nothrow__ , __leaf__));
 extern long double log1pl (long double __x) __attribute__ ((__nothrow__ , __leaf__)); extern long double __log1pl (long double __x) __attribute__ ((__nothrow__ , __leaf__));
extern long double logbl (long double __x) __attribute__ ((__nothrow__ , __leaf__)); extern long double __logbl (long double __x) __attribute__ ((__nothrow__ , __leaf__));
 extern long double exp2l (long double __x) __attribute__ ((__nothrow__ , __leaf__)); extern long double __exp2l (long double __x) __attribute__ ((__nothrow__ , __leaf__));
 extern long double log2l (long double __x) __attribute__ ((__nothrow__ , __leaf__)); extern long double __log2l (long double __x) __attribute__ ((__nothrow__ , __leaf__));
 extern long double powl (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__)); extern long double __powl (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__));
extern long double sqrtl (long double __x) __attribute__ ((__nothrow__ , __leaf__)); extern long double __sqrtl (long double __x) __attribute__ ((__nothrow__ , __leaf__));
 extern long double hypotl (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__)); extern long double __hypotl (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__));
 extern long double cbrtl (long double __x) __attribute__ ((__nothrow__ , __leaf__)); extern long double __cbrtl (long double __x) __attribute__ ((__nothrow__ , __leaf__));
extern long double ceill (long double __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern long double __ceill (long double __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern long double fabsl (long double __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern long double __fabsl (long double __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern long double floorl (long double __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern long double __floorl (long double __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern long double fmodl (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__)); extern long double __fmodl (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__));
extern int isinfl (long double __value) __attribute__ ((__nothrow__ , __leaf__))
  __attribute__ ((__const__));
extern int finitel (long double __value) __attribute__ ((__nothrow__ , __leaf__))
  __attribute__ ((__const__));
extern long double dreml (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__)); extern long double __dreml (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__));
extern long double significandl (long double __x) __attribute__ ((__nothrow__ , __leaf__)); extern long double __significandl (long double __x) __attribute__ ((__nothrow__ , __leaf__));
extern long double copysignl (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern long double __copysignl (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern long double nanl (const char *__tagb) __attribute__ ((__nothrow__ , __leaf__)); extern long double __nanl (const char *__tagb) __attribute__ ((__nothrow__ , __leaf__));
extern int isnanl (long double __value) __attribute__ ((__nothrow__ , __leaf__))
  __attribute__ ((__const__));
extern long double j0l (long double) __attribute__ ((__nothrow__ , __leaf__)); extern long double __j0l (long double) __attribute__ ((__nothrow__ , __leaf__));
extern long double j1l (long double) __attribute__ ((__nothrow__ , __leaf__)); extern long double __j1l (long double) __attribute__ ((__nothrow__ , __leaf__));
extern long double jnl (int, long double) __attribute__ ((__nothrow__ , __leaf__)); extern long double __jnl (int, long double) __attribute__ ((__nothrow__ , __leaf__));
extern long double y0l (long double) __attribute__ ((__nothrow__ , __leaf__)); extern long double __y0l (long double) __attribute__ ((__nothrow__ , __leaf__));
extern long double y1l (long double) __attribute__ ((__nothrow__ , __leaf__)); extern long double __y1l (long double) __attribute__ ((__nothrow__ , __leaf__));
extern long double ynl (int, long double) __attribute__ ((__nothrow__ , __leaf__)); extern long double __ynl (int, long double) __attribute__ ((__nothrow__ , __leaf__));
 extern long double erfl (long double) __attribute__ ((__nothrow__ , __leaf__)); extern long double __erfl (long double) __attribute__ ((__nothrow__ , __leaf__));
 extern long double erfcl (long double) __attribute__ ((__nothrow__ , __leaf__)); extern long double __erfcl (long double) __attribute__ ((__nothrow__ , __leaf__));
extern long double lgammal (long double) __attribute__ ((__nothrow__ , __leaf__)); extern long double __lgammal (long double) __attribute__ ((__nothrow__ , __leaf__));
extern long double tgammal (long double) __attribute__ ((__nothrow__ , __leaf__)); extern long double __tgammal (long double) __attribute__ ((__nothrow__ , __leaf__));
extern long double gammal (long double) __attribute__ ((__nothrow__ , __leaf__)); extern long double __gammal (long double) __attribute__ ((__nothrow__ , __leaf__));
extern long double lgammal_r (long double, int *__signgamp) __attribute__ ((__nothrow__ , __leaf__)); extern long double __lgammal_r (long double, int *__signgamp) __attribute__ ((__nothrow__ , __leaf__));
extern long double rintl (long double __x) __attribute__ ((__nothrow__ , __leaf__)); extern long double __rintl (long double __x) __attribute__ ((__nothrow__ , __leaf__));
extern long double nextafterl (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__)); extern long double __nextafterl (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__));
extern long double nexttowardl (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__)); extern long double __nexttowardl (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__));
extern long double nextdownl (long double __x) __attribute__ ((__nothrow__ , __leaf__)); extern long double __nextdownl (long double __x) __attribute__ ((__nothrow__ , __leaf__));
extern long double nextupl (long double __x) __attribute__ ((__nothrow__ , __leaf__)); extern long double __nextupl (long double __x) __attribute__ ((__nothrow__ , __leaf__));
extern long double remainderl (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__)); extern long double __remainderl (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__));
extern long double scalbnl (long double __x, int __n) __attribute__ ((__nothrow__ , __leaf__)); extern long double __scalbnl (long double __x, int __n) __attribute__ ((__nothrow__ , __leaf__));
extern int ilogbl (long double __x) __attribute__ ((__nothrow__ , __leaf__)); extern int __ilogbl (long double __x) __attribute__ ((__nothrow__ , __leaf__));
extern long int llogbl (long double __x) __attribute__ ((__nothrow__ , __leaf__)); extern long int __llogbl (long double __x) __attribute__ ((__nothrow__ , __leaf__));
extern long double scalblnl (long double __x, long int __n) __attribute__ ((__nothrow__ , __leaf__)); extern long double __scalblnl (long double __x, long int __n) __attribute__ ((__nothrow__ , __leaf__));
extern long double nearbyintl (long double __x) __attribute__ ((__nothrow__ , __leaf__)); extern long double __nearbyintl (long double __x) __attribute__ ((__nothrow__ , __leaf__));
extern long double roundl (long double __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern long double __roundl (long double __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern long double truncl (long double __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern long double __truncl (long double __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern long double remquol (long double __x, long double __y, int *__quo) __attribute__ ((__nothrow__ , __leaf__)); extern long double __remquol (long double __x, long double __y, int *__quo) __attribute__ ((__nothrow__ , __leaf__));
extern long int lrintl (long double __x) __attribute__ ((__nothrow__ , __leaf__)); extern long int __lrintl (long double __x) __attribute__ ((__nothrow__ , __leaf__));
__extension__
extern long long int llrintl (long double __x) __attribute__ ((__nothrow__ , __leaf__)); extern long long int __llrintl (long double __x) __attribute__ ((__nothrow__ , __leaf__));
extern long int lroundl (long double __x) __attribute__ ((__nothrow__ , __leaf__)); extern long int __lroundl (long double __x) __attribute__ ((__nothrow__ , __leaf__));
__extension__
extern long long int llroundl (long double __x) __attribute__ ((__nothrow__ , __leaf__)); extern long long int __llroundl (long double __x) __attribute__ ((__nothrow__ , __leaf__));
extern long double fdiml (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__)); extern long double __fdiml (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__));
extern long double fmaxl (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern long double __fmaxl (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern long double fminl (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern long double __fminl (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern long double fmal (long double __x, long double __y, long double __z) __attribute__ ((__nothrow__ , __leaf__)); extern long double __fmal (long double __x, long double __y, long double __z) __attribute__ ((__nothrow__ , __leaf__));
extern long double roundevenl (long double __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern long double __roundevenl (long double __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern __intmax_t fromfpl (long double __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__)); extern __intmax_t __fromfpl (long double __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__));
extern __uintmax_t ufromfpl (long double __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__)); extern __uintmax_t __ufromfpl (long double __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__));
extern __intmax_t fromfpxl (long double __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__)); extern __intmax_t __fromfpxl (long double __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__));
extern __uintmax_t ufromfpxl (long double __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__)); extern __uintmax_t __ufromfpxl (long double __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__));
extern int canonicalizel (long double *__cx, const long double *__x) __attribute__ ((__nothrow__ , __leaf__));
extern long double fmaxmagl (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern long double __fmaxmagl (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern long double fminmagl (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern long double __fminmagl (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern long double fmaximuml (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern long double __fmaximuml (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern long double fminimuml (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern long double __fminimuml (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern long double fmaximum_numl (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern long double __fmaximum_numl (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern long double fminimum_numl (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern long double __fminimum_numl (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern long double fmaximum_magl (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern long double __fmaximum_magl (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern long double fminimum_magl (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern long double __fminimum_magl (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern long double fmaximum_mag_numl (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern long double __fmaximum_mag_numl (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern long double fminimum_mag_numl (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern long double __fminimum_mag_numl (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern int totalorderl (const long double *__x, const long double *__y) __attribute__ ((__nothrow__ , __leaf__))
     __attribute__ ((__pure__));
extern int totalordermagl (const long double *__x, const long double *__y) __attribute__ ((__nothrow__ , __leaf__))
     __attribute__ ((__pure__));
extern long double getpayloadl (const long double *__x) __attribute__ ((__nothrow__ , __leaf__)); extern long double __getpayloadl (const long double *__x) __attribute__ ((__nothrow__ , __leaf__));
extern int setpayloadl (long double *__x, long double __payload) __attribute__ ((__nothrow__ , __leaf__));
extern int setpayloadsigl (long double *__x, long double __payload) __attribute__ ((__nothrow__ , __leaf__));
extern long double scalbl (long double __x, long double __n) __attribute__ ((__nothrow__ , __leaf__)); extern long double __scalbl (long double __x, long double __n) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32 acosf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __acosf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32 asinf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __asinf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32 atanf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __atanf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32 atan2f32 (_Float32 __y, _Float32 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __atan2f32 (_Float32 __y, _Float32 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32 cosf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __cosf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32 sinf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __sinf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32 tanf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __tanf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32 coshf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __coshf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32 sinhf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __sinhf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32 tanhf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __tanhf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern void sincosf32 (_Float32 __x, _Float32 *__sinx, _Float32 *__cosx) __attribute__ ((__nothrow__ , __leaf__)); extern void __sincosf32 (_Float32 __x, _Float32 *__sinx, _Float32 *__cosx) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32 acoshf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __acoshf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32 asinhf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __asinhf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32 atanhf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __atanhf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32 expf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __expf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 frexpf32 (_Float32 __x, int *__exponent) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __frexpf32 (_Float32 __x, int *__exponent) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 ldexpf32 (_Float32 __x, int __exponent) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __ldexpf32 (_Float32 __x, int __exponent) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32 logf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __logf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32 log10f32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __log10f32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 modff32 (_Float32 __x, _Float32 *__iptr) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __modff32 (_Float32 __x, _Float32 *__iptr) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2)));
 extern _Float32 exp10f32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __exp10f32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32 expm1f32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __expm1f32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32 log1pf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __log1pf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 logbf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __logbf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32 exp2f32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __exp2f32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32 log2f32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __log2f32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32 powf32 (_Float32 __x, _Float32 __y) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __powf32 (_Float32 __x, _Float32 __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 sqrtf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __sqrtf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32 hypotf32 (_Float32 __x, _Float32 __y) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __hypotf32 (_Float32 __x, _Float32 __y) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32 cbrtf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __cbrtf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 ceilf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float32 __ceilf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float32 fabsf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float32 __fabsf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float32 floorf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float32 __floorf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float32 fmodf32 (_Float32 __x, _Float32 __y) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __fmodf32 (_Float32 __x, _Float32 __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 copysignf32 (_Float32 __x, _Float32 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float32 __copysignf32 (_Float32 __x, _Float32 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float32 nanf32 (const char *__tagb) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __nanf32 (const char *__tagb) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 j0f32 (_Float32) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __j0f32 (_Float32) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 j1f32 (_Float32) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __j1f32 (_Float32) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 jnf32 (int, _Float32) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __jnf32 (int, _Float32) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 y0f32 (_Float32) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __y0f32 (_Float32) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 y1f32 (_Float32) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __y1f32 (_Float32) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 ynf32 (int, _Float32) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __ynf32 (int, _Float32) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32 erff32 (_Float32) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __erff32 (_Float32) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32 erfcf32 (_Float32) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __erfcf32 (_Float32) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 lgammaf32 (_Float32) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __lgammaf32 (_Float32) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 tgammaf32 (_Float32) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __tgammaf32 (_Float32) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 lgammaf32_r (_Float32, int *__signgamp) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __lgammaf32_r (_Float32, int *__signgamp) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 rintf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __rintf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 nextafterf32 (_Float32 __x, _Float32 __y) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __nextafterf32 (_Float32 __x, _Float32 __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 nextdownf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __nextdownf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 nextupf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __nextupf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 remainderf32 (_Float32 __x, _Float32 __y) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __remainderf32 (_Float32 __x, _Float32 __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 scalbnf32 (_Float32 __x, int __n) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __scalbnf32 (_Float32 __x, int __n) __attribute__ ((__nothrow__ , __leaf__));
extern int ilogbf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)); extern int __ilogbf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__));
extern long int llogbf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)); extern long int __llogbf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 scalblnf32 (_Float32 __x, long int __n) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __scalblnf32 (_Float32 __x, long int __n) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 nearbyintf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __nearbyintf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 roundf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float32 __roundf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float32 truncf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float32 __truncf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float32 remquof32 (_Float32 __x, _Float32 __y, int *__quo) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __remquof32 (_Float32 __x, _Float32 __y, int *__quo) __attribute__ ((__nothrow__ , __leaf__));
extern long int lrintf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)); extern long int __lrintf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__));
__extension__
extern long long int llrintf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)); extern long long int __llrintf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__));
extern long int lroundf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)); extern long int __lroundf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__));
__extension__
extern long long int llroundf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)); extern long long int __llroundf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 fdimf32 (_Float32 __x, _Float32 __y) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __fdimf32 (_Float32 __x, _Float32 __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 fmaxf32 (_Float32 __x, _Float32 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float32 __fmaxf32 (_Float32 __x, _Float32 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float32 fminf32 (_Float32 __x, _Float32 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float32 __fminf32 (_Float32 __x, _Float32 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float32 fmaf32 (_Float32 __x, _Float32 __y, _Float32 __z) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __fmaf32 (_Float32 __x, _Float32 __y, _Float32 __z) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 roundevenf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float32 __roundevenf32 (_Float32 __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern __intmax_t fromfpf32 (_Float32 __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__)); extern __intmax_t __fromfpf32 (_Float32 __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__));
extern __uintmax_t ufromfpf32 (_Float32 __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__)); extern __uintmax_t __ufromfpf32 (_Float32 __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__));
extern __intmax_t fromfpxf32 (_Float32 __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__)); extern __intmax_t __fromfpxf32 (_Float32 __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__));
extern __uintmax_t ufromfpxf32 (_Float32 __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__)); extern __uintmax_t __ufromfpxf32 (_Float32 __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__));
extern int canonicalizef32 (_Float32 *__cx, const _Float32 *__x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 fmaxmagf32 (_Float32 __x, _Float32 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float32 __fmaxmagf32 (_Float32 __x, _Float32 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float32 fminmagf32 (_Float32 __x, _Float32 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float32 __fminmagf32 (_Float32 __x, _Float32 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float32 fmaximumf32 (_Float32 __x, _Float32 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float32 __fmaximumf32 (_Float32 __x, _Float32 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float32 fminimumf32 (_Float32 __x, _Float32 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float32 __fminimumf32 (_Float32 __x, _Float32 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float32 fmaximum_numf32 (_Float32 __x, _Float32 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float32 __fmaximum_numf32 (_Float32 __x, _Float32 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float32 fminimum_numf32 (_Float32 __x, _Float32 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float32 __fminimum_numf32 (_Float32 __x, _Float32 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float32 fmaximum_magf32 (_Float32 __x, _Float32 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float32 __fmaximum_magf32 (_Float32 __x, _Float32 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float32 fminimum_magf32 (_Float32 __x, _Float32 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float32 __fminimum_magf32 (_Float32 __x, _Float32 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float32 fmaximum_mag_numf32 (_Float32 __x, _Float32 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float32 __fmaximum_mag_numf32 (_Float32 __x, _Float32 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float32 fminimum_mag_numf32 (_Float32 __x, _Float32 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float32 __fminimum_mag_numf32 (_Float32 __x, _Float32 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern int totalorderf32 (const _Float32 *__x, const _Float32 *__y) __attribute__ ((__nothrow__ , __leaf__))
     __attribute__ ((__pure__));
extern int totalordermagf32 (const _Float32 *__x, const _Float32 *__y) __attribute__ ((__nothrow__ , __leaf__))
     __attribute__ ((__pure__));
extern _Float32 getpayloadf32 (const _Float32 *__x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32 __getpayloadf32 (const _Float32 *__x) __attribute__ ((__nothrow__ , __leaf__));
extern int setpayloadf32 (_Float32 *__x, _Float32 __payload) __attribute__ ((__nothrow__ , __leaf__));
extern int setpayloadsigf32 (_Float32 *__x, _Float32 __payload) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64 acosf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __acosf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64 asinf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __asinf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64 atanf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __atanf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64 atan2f64 (_Float64 __y, _Float64 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __atan2f64 (_Float64 __y, _Float64 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64 cosf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __cosf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64 sinf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __sinf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64 tanf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __tanf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64 coshf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __coshf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64 sinhf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __sinhf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64 tanhf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __tanhf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern void sincosf64 (_Float64 __x, _Float64 *__sinx, _Float64 *__cosx) __attribute__ ((__nothrow__ , __leaf__)); extern void __sincosf64 (_Float64 __x, _Float64 *__sinx, _Float64 *__cosx) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64 acoshf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __acoshf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64 asinhf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __asinhf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64 atanhf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __atanhf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64 expf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __expf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64 frexpf64 (_Float64 __x, int *__exponent) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __frexpf64 (_Float64 __x, int *__exponent) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64 ldexpf64 (_Float64 __x, int __exponent) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __ldexpf64 (_Float64 __x, int __exponent) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64 logf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __logf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64 log10f64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __log10f64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64 modff64 (_Float64 __x, _Float64 *__iptr) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __modff64 (_Float64 __x, _Float64 *__iptr) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2)));
 extern _Float64 exp10f64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __exp10f64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64 expm1f64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __expm1f64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64 log1pf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __log1pf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64 logbf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __logbf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64 exp2f64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __exp2f64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64 log2f64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __log2f64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64 powf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __powf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64 sqrtf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __sqrtf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64 hypotf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __hypotf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64 cbrtf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __cbrtf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64 ceilf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float64 __ceilf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float64 fabsf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float64 __fabsf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float64 floorf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float64 __floorf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float64 fmodf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __fmodf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64 copysignf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float64 __copysignf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float64 nanf64 (const char *__tagb) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __nanf64 (const char *__tagb) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64 j0f64 (_Float64) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __j0f64 (_Float64) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64 j1f64 (_Float64) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __j1f64 (_Float64) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64 jnf64 (int, _Float64) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __jnf64 (int, _Float64) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64 y0f64 (_Float64) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __y0f64 (_Float64) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64 y1f64 (_Float64) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __y1f64 (_Float64) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64 ynf64 (int, _Float64) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __ynf64 (int, _Float64) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64 erff64 (_Float64) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __erff64 (_Float64) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64 erfcf64 (_Float64) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __erfcf64 (_Float64) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64 lgammaf64 (_Float64) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __lgammaf64 (_Float64) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64 tgammaf64 (_Float64) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __tgammaf64 (_Float64) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64 lgammaf64_r (_Float64, int *__signgamp) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __lgammaf64_r (_Float64, int *__signgamp) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64 rintf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __rintf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64 nextafterf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __nextafterf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64 nextdownf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __nextdownf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64 nextupf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __nextupf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64 remainderf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __remainderf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64 scalbnf64 (_Float64 __x, int __n) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __scalbnf64 (_Float64 __x, int __n) __attribute__ ((__nothrow__ , __leaf__));
extern int ilogbf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)); extern int __ilogbf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__));
extern long int llogbf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)); extern long int __llogbf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64 scalblnf64 (_Float64 __x, long int __n) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __scalblnf64 (_Float64 __x, long int __n) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64 nearbyintf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __nearbyintf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64 roundf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float64 __roundf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float64 truncf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float64 __truncf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float64 remquof64 (_Float64 __x, _Float64 __y, int *__quo) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __remquof64 (_Float64 __x, _Float64 __y, int *__quo) __attribute__ ((__nothrow__ , __leaf__));
extern long int lrintf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)); extern long int __lrintf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__));
__extension__
extern long long int llrintf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)); extern long long int __llrintf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__));
extern long int lroundf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)); extern long int __lroundf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__));
__extension__
extern long long int llroundf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)); extern long long int __llroundf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64 fdimf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __fdimf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64 fmaxf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float64 __fmaxf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float64 fminf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float64 __fminf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float64 fmaf64 (_Float64 __x, _Float64 __y, _Float64 __z) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __fmaf64 (_Float64 __x, _Float64 __y, _Float64 __z) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64 roundevenf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float64 __roundevenf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern __intmax_t fromfpf64 (_Float64 __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__)); extern __intmax_t __fromfpf64 (_Float64 __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__));
extern __uintmax_t ufromfpf64 (_Float64 __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__)); extern __uintmax_t __ufromfpf64 (_Float64 __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__));
extern __intmax_t fromfpxf64 (_Float64 __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__)); extern __intmax_t __fromfpxf64 (_Float64 __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__));
extern __uintmax_t ufromfpxf64 (_Float64 __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__)); extern __uintmax_t __ufromfpxf64 (_Float64 __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__));
extern int canonicalizef64 (_Float64 *__cx, const _Float64 *__x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64 fmaxmagf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float64 __fmaxmagf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float64 fminmagf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float64 __fminmagf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float64 fmaximumf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float64 __fmaximumf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float64 fminimumf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float64 __fminimumf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float64 fmaximum_numf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float64 __fmaximum_numf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float64 fminimum_numf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float64 __fminimum_numf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float64 fmaximum_magf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float64 __fmaximum_magf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float64 fminimum_magf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float64 __fminimum_magf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float64 fmaximum_mag_numf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float64 __fmaximum_mag_numf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float64 fminimum_mag_numf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float64 __fminimum_mag_numf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern int totalorderf64 (const _Float64 *__x, const _Float64 *__y) __attribute__ ((__nothrow__ , __leaf__))
     __attribute__ ((__pure__));
extern int totalordermagf64 (const _Float64 *__x, const _Float64 *__y) __attribute__ ((__nothrow__ , __leaf__))
     __attribute__ ((__pure__));
extern _Float64 getpayloadf64 (const _Float64 *__x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64 __getpayloadf64 (const _Float64 *__x) __attribute__ ((__nothrow__ , __leaf__));
extern int setpayloadf64 (_Float64 *__x, _Float64 __payload) __attribute__ ((__nothrow__ , __leaf__));
extern int setpayloadsigf64 (_Float64 *__x, _Float64 __payload) __attribute__ ((__nothrow__ , __leaf__));
extern int __fpclassifyf128 (_Float128 __value) __attribute__ ((__nothrow__ , __leaf__))
     __attribute__ ((__const__));
extern int __signbitf128 (_Float128 __value) __attribute__ ((__nothrow__ , __leaf__))
     __attribute__ ((__const__));
extern int __isinff128 (_Float128 __value) __attribute__ ((__nothrow__ , __leaf__))
  __attribute__ ((__const__));
extern int __finitef128 (_Float128 __value) __attribute__ ((__nothrow__ , __leaf__))
  __attribute__ ((__const__));
extern int __isnanf128 (_Float128 __value) __attribute__ ((__nothrow__ , __leaf__))
  __attribute__ ((__const__));
extern int __iseqsigf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__));
extern int __issignalingf128 (_Float128 __value) __attribute__ ((__nothrow__ , __leaf__))
     __attribute__ ((__const__));
 extern _Float128 acosf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __acosf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float128 asinf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __asinf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float128 atanf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __atanf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float128 atan2f128 (_Float128 __y, _Float128 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __atan2f128 (_Float128 __y, _Float128 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float128 cosf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __cosf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float128 sinf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __sinf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float128 tanf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __tanf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float128 coshf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __coshf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float128 sinhf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __sinhf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float128 tanhf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __tanhf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern void sincosf128 (_Float128 __x, _Float128 *__sinx, _Float128 *__cosx) __attribute__ ((__nothrow__ , __leaf__)); extern void __sincosf128 (_Float128 __x, _Float128 *__sinx, _Float128 *__cosx) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float128 acoshf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __acoshf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float128 asinhf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __asinhf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float128 atanhf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __atanhf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float128 expf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __expf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float128 frexpf128 (_Float128 __x, int *__exponent) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __frexpf128 (_Float128 __x, int *__exponent) __attribute__ ((__nothrow__ , __leaf__));
extern _Float128 ldexpf128 (_Float128 __x, int __exponent) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __ldexpf128 (_Float128 __x, int __exponent) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float128 logf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __logf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float128 log10f128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __log10f128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float128 modff128 (_Float128 __x, _Float128 *__iptr) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __modff128 (_Float128 __x, _Float128 *__iptr) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2)));
 extern _Float128 exp10f128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __exp10f128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float128 expm1f128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __expm1f128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float128 log1pf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __log1pf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float128 logbf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __logbf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float128 exp2f128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __exp2f128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float128 log2f128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __log2f128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float128 powf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __powf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float128 sqrtf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __sqrtf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float128 hypotf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __hypotf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float128 cbrtf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __cbrtf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float128 ceilf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float128 __ceilf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float128 fabsf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float128 __fabsf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float128 floorf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float128 __floorf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float128 fmodf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __fmodf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float128 copysignf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float128 __copysignf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float128 nanf128 (const char *__tagb) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __nanf128 (const char *__tagb) __attribute__ ((__nothrow__ , __leaf__));
extern _Float128 j0f128 (_Float128) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __j0f128 (_Float128) __attribute__ ((__nothrow__ , __leaf__));
extern _Float128 j1f128 (_Float128) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __j1f128 (_Float128) __attribute__ ((__nothrow__ , __leaf__));
extern _Float128 jnf128 (int, _Float128) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __jnf128 (int, _Float128) __attribute__ ((__nothrow__ , __leaf__));
extern _Float128 y0f128 (_Float128) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __y0f128 (_Float128) __attribute__ ((__nothrow__ , __leaf__));
extern _Float128 y1f128 (_Float128) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __y1f128 (_Float128) __attribute__ ((__nothrow__ , __leaf__));
extern _Float128 ynf128 (int, _Float128) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __ynf128 (int, _Float128) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float128 erff128 (_Float128) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __erff128 (_Float128) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float128 erfcf128 (_Float128) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __erfcf128 (_Float128) __attribute__ ((__nothrow__ , __leaf__));
extern _Float128 lgammaf128 (_Float128) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __lgammaf128 (_Float128) __attribute__ ((__nothrow__ , __leaf__));
extern _Float128 tgammaf128 (_Float128) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __tgammaf128 (_Float128) __attribute__ ((__nothrow__ , __leaf__));
extern _Float128 lgammaf128_r (_Float128, int *__signgamp) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __lgammaf128_r (_Float128, int *__signgamp) __attribute__ ((__nothrow__ , __leaf__));
extern _Float128 rintf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __rintf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float128 nextafterf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __nextafterf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float128 nextdownf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __nextdownf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float128 nextupf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __nextupf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float128 remainderf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __remainderf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float128 scalbnf128 (_Float128 __x, int __n) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __scalbnf128 (_Float128 __x, int __n) __attribute__ ((__nothrow__ , __leaf__));
extern int ilogbf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)); extern int __ilogbf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__));
extern long int llogbf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)); extern long int __llogbf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float128 scalblnf128 (_Float128 __x, long int __n) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __scalblnf128 (_Float128 __x, long int __n) __attribute__ ((__nothrow__ , __leaf__));
extern _Float128 nearbyintf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __nearbyintf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float128 roundf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float128 __roundf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float128 truncf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float128 __truncf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float128 remquof128 (_Float128 __x, _Float128 __y, int *__quo) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __remquof128 (_Float128 __x, _Float128 __y, int *__quo) __attribute__ ((__nothrow__ , __leaf__));
extern long int lrintf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)); extern long int __lrintf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__));
__extension__
extern long long int llrintf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)); extern long long int __llrintf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__));
extern long int lroundf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)); extern long int __lroundf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__));
__extension__
extern long long int llroundf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)); extern long long int __llroundf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float128 fdimf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __fdimf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float128 fmaxf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float128 __fmaxf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float128 fminf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float128 __fminf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float128 fmaf128 (_Float128 __x, _Float128 __y, _Float128 __z) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __fmaf128 (_Float128 __x, _Float128 __y, _Float128 __z) __attribute__ ((__nothrow__ , __leaf__));
extern _Float128 roundevenf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float128 __roundevenf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern __intmax_t fromfpf128 (_Float128 __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__)); extern __intmax_t __fromfpf128 (_Float128 __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__));
extern __uintmax_t ufromfpf128 (_Float128 __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__)); extern __uintmax_t __ufromfpf128 (_Float128 __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__));
extern __intmax_t fromfpxf128 (_Float128 __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__)); extern __intmax_t __fromfpxf128 (_Float128 __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__));
extern __uintmax_t ufromfpxf128 (_Float128 __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__)); extern __uintmax_t __ufromfpxf128 (_Float128 __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__));
extern int canonicalizef128 (_Float128 *__cx, const _Float128 *__x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float128 fmaxmagf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float128 __fmaxmagf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float128 fminmagf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float128 __fminmagf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float128 fmaximumf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float128 __fmaximumf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float128 fminimumf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float128 __fminimumf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float128 fmaximum_numf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float128 __fmaximum_numf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float128 fminimum_numf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float128 __fminimum_numf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float128 fmaximum_magf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float128 __fmaximum_magf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float128 fminimum_magf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float128 __fminimum_magf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float128 fmaximum_mag_numf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float128 __fmaximum_mag_numf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float128 fminimum_mag_numf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float128 __fminimum_mag_numf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern int totalorderf128 (const _Float128 *__x, const _Float128 *__y) __attribute__ ((__nothrow__ , __leaf__))
     __attribute__ ((__pure__));
extern int totalordermagf128 (const _Float128 *__x, const _Float128 *__y) __attribute__ ((__nothrow__ , __leaf__))
     __attribute__ ((__pure__));
extern _Float128 getpayloadf128 (const _Float128 *__x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float128 __getpayloadf128 (const _Float128 *__x) __attribute__ ((__nothrow__ , __leaf__));
extern int setpayloadf128 (_Float128 *__x, _Float128 __payload) __attribute__ ((__nothrow__ , __leaf__));
extern int setpayloadsigf128 (_Float128 *__x, _Float128 __payload) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32x acosf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __acosf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32x asinf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __asinf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32x atanf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __atanf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32x atan2f32x (_Float32x __y, _Float32x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __atan2f32x (_Float32x __y, _Float32x __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32x cosf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __cosf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32x sinf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __sinf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32x tanf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __tanf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32x coshf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __coshf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32x sinhf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __sinhf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32x tanhf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __tanhf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__));
 extern void sincosf32x (_Float32x __x, _Float32x *__sinx, _Float32x *__cosx) __attribute__ ((__nothrow__ , __leaf__)); extern void __sincosf32x (_Float32x __x, _Float32x *__sinx, _Float32x *__cosx) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32x acoshf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __acoshf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32x asinhf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __asinhf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32x atanhf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __atanhf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32x expf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __expf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x frexpf32x (_Float32x __x, int *__exponent) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __frexpf32x (_Float32x __x, int *__exponent) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x ldexpf32x (_Float32x __x, int __exponent) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __ldexpf32x (_Float32x __x, int __exponent) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32x logf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __logf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32x log10f32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __log10f32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x modff32x (_Float32x __x, _Float32x *__iptr) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __modff32x (_Float32x __x, _Float32x *__iptr) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2)));
 extern _Float32x exp10f32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __exp10f32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32x expm1f32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __expm1f32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32x log1pf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __log1pf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x logbf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __logbf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32x exp2f32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __exp2f32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32x log2f32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __log2f32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32x powf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __powf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x sqrtf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __sqrtf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32x hypotf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __hypotf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32x cbrtf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __cbrtf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x ceilf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float32x __ceilf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float32x fabsf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float32x __fabsf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float32x floorf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float32x __floorf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float32x fmodf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __fmodf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x copysignf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float32x __copysignf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float32x nanf32x (const char *__tagb) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __nanf32x (const char *__tagb) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x j0f32x (_Float32x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __j0f32x (_Float32x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x j1f32x (_Float32x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __j1f32x (_Float32x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x jnf32x (int, _Float32x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __jnf32x (int, _Float32x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x y0f32x (_Float32x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __y0f32x (_Float32x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x y1f32x (_Float32x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __y1f32x (_Float32x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x ynf32x (int, _Float32x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __ynf32x (int, _Float32x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32x erff32x (_Float32x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __erff32x (_Float32x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float32x erfcf32x (_Float32x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __erfcf32x (_Float32x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x lgammaf32x (_Float32x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __lgammaf32x (_Float32x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x tgammaf32x (_Float32x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __tgammaf32x (_Float32x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x lgammaf32x_r (_Float32x, int *__signgamp) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __lgammaf32x_r (_Float32x, int *__signgamp) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x rintf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __rintf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x nextafterf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __nextafterf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x nextdownf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __nextdownf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x nextupf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __nextupf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x remainderf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __remainderf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x scalbnf32x (_Float32x __x, int __n) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __scalbnf32x (_Float32x __x, int __n) __attribute__ ((__nothrow__ , __leaf__));
extern int ilogbf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)); extern int __ilogbf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__));
extern long int llogbf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)); extern long int __llogbf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x scalblnf32x (_Float32x __x, long int __n) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __scalblnf32x (_Float32x __x, long int __n) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x nearbyintf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __nearbyintf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x roundf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float32x __roundf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float32x truncf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float32x __truncf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float32x remquof32x (_Float32x __x, _Float32x __y, int *__quo) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __remquof32x (_Float32x __x, _Float32x __y, int *__quo) __attribute__ ((__nothrow__ , __leaf__));
extern long int lrintf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)); extern long int __lrintf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__));
__extension__
extern long long int llrintf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)); extern long long int __llrintf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__));
extern long int lroundf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)); extern long int __lroundf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__));
__extension__
extern long long int llroundf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)); extern long long int __llroundf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x fdimf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __fdimf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x fmaxf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float32x __fmaxf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float32x fminf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float32x __fminf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float32x fmaf32x (_Float32x __x, _Float32x __y, _Float32x __z) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __fmaf32x (_Float32x __x, _Float32x __y, _Float32x __z) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x roundevenf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float32x __roundevenf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern __intmax_t fromfpf32x (_Float32x __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__)); extern __intmax_t __fromfpf32x (_Float32x __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__));
extern __uintmax_t ufromfpf32x (_Float32x __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__)); extern __uintmax_t __ufromfpf32x (_Float32x __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__));
extern __intmax_t fromfpxf32x (_Float32x __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__)); extern __intmax_t __fromfpxf32x (_Float32x __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__));
extern __uintmax_t ufromfpxf32x (_Float32x __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__)); extern __uintmax_t __ufromfpxf32x (_Float32x __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__));
extern int canonicalizef32x (_Float32x *__cx, const _Float32x *__x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x fmaxmagf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float32x __fmaxmagf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float32x fminmagf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float32x __fminmagf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float32x fmaximumf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float32x __fmaximumf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float32x fminimumf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float32x __fminimumf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float32x fmaximum_numf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float32x __fmaximum_numf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float32x fminimum_numf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float32x __fminimum_numf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float32x fmaximum_magf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float32x __fmaximum_magf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float32x fminimum_magf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float32x __fminimum_magf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float32x fmaximum_mag_numf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float32x __fmaximum_mag_numf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float32x fminimum_mag_numf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float32x __fminimum_mag_numf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern int totalorderf32x (const _Float32x *__x, const _Float32x *__y) __attribute__ ((__nothrow__ , __leaf__))
     __attribute__ ((__pure__));
extern int totalordermagf32x (const _Float32x *__x, const _Float32x *__y) __attribute__ ((__nothrow__ , __leaf__))
     __attribute__ ((__pure__));
extern _Float32x getpayloadf32x (const _Float32x *__x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float32x __getpayloadf32x (const _Float32x *__x) __attribute__ ((__nothrow__ , __leaf__));
extern int setpayloadf32x (_Float32x *__x, _Float32x __payload) __attribute__ ((__nothrow__ , __leaf__));
extern int setpayloadsigf32x (_Float32x *__x, _Float32x __payload) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64x acosf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __acosf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64x asinf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __asinf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64x atanf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __atanf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64x atan2f64x (_Float64x __y, _Float64x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __atan2f64x (_Float64x __y, _Float64x __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64x cosf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __cosf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64x sinf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __sinf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64x tanf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __tanf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64x coshf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __coshf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64x sinhf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __sinhf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64x tanhf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __tanhf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__));
 extern void sincosf64x (_Float64x __x, _Float64x *__sinx, _Float64x *__cosx) __attribute__ ((__nothrow__ , __leaf__)); extern void __sincosf64x (_Float64x __x, _Float64x *__sinx, _Float64x *__cosx) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64x acoshf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __acoshf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64x asinhf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __asinhf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64x atanhf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __atanhf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64x expf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __expf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64x frexpf64x (_Float64x __x, int *__exponent) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __frexpf64x (_Float64x __x, int *__exponent) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64x ldexpf64x (_Float64x __x, int __exponent) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __ldexpf64x (_Float64x __x, int __exponent) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64x logf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __logf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64x log10f64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __log10f64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64x modff64x (_Float64x __x, _Float64x *__iptr) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __modff64x (_Float64x __x, _Float64x *__iptr) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2)));
 extern _Float64x exp10f64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __exp10f64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64x expm1f64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __expm1f64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64x log1pf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __log1pf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64x logbf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __logbf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64x exp2f64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __exp2f64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64x log2f64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __log2f64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64x powf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __powf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64x sqrtf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __sqrtf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64x hypotf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __hypotf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64x cbrtf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __cbrtf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64x ceilf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float64x __ceilf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float64x fabsf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float64x __fabsf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float64x floorf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float64x __floorf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float64x fmodf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __fmodf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64x copysignf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float64x __copysignf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float64x nanf64x (const char *__tagb) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __nanf64x (const char *__tagb) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64x j0f64x (_Float64x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __j0f64x (_Float64x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64x j1f64x (_Float64x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __j1f64x (_Float64x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64x jnf64x (int, _Float64x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __jnf64x (int, _Float64x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64x y0f64x (_Float64x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __y0f64x (_Float64x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64x y1f64x (_Float64x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __y1f64x (_Float64x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64x ynf64x (int, _Float64x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __ynf64x (int, _Float64x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64x erff64x (_Float64x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __erff64x (_Float64x) __attribute__ ((__nothrow__ , __leaf__));
 extern _Float64x erfcf64x (_Float64x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __erfcf64x (_Float64x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64x lgammaf64x (_Float64x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __lgammaf64x (_Float64x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64x tgammaf64x (_Float64x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __tgammaf64x (_Float64x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64x lgammaf64x_r (_Float64x, int *__signgamp) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __lgammaf64x_r (_Float64x, int *__signgamp) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64x rintf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __rintf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64x nextafterf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __nextafterf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64x nextdownf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __nextdownf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64x nextupf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __nextupf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64x remainderf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __remainderf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64x scalbnf64x (_Float64x __x, int __n) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __scalbnf64x (_Float64x __x, int __n) __attribute__ ((__nothrow__ , __leaf__));
extern int ilogbf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)); extern int __ilogbf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__));
extern long int llogbf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)); extern long int __llogbf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64x scalblnf64x (_Float64x __x, long int __n) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __scalblnf64x (_Float64x __x, long int __n) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64x nearbyintf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __nearbyintf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64x roundf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float64x __roundf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float64x truncf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float64x __truncf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float64x remquof64x (_Float64x __x, _Float64x __y, int *__quo) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __remquof64x (_Float64x __x, _Float64x __y, int *__quo) __attribute__ ((__nothrow__ , __leaf__));
extern long int lrintf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)); extern long int __lrintf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__));
__extension__
extern long long int llrintf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)); extern long long int __llrintf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__));
extern long int lroundf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)); extern long int __lroundf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__));
__extension__
extern long long int llroundf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)); extern long long int __llroundf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64x fdimf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __fdimf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64x fmaxf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float64x __fmaxf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float64x fminf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float64x __fminf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float64x fmaf64x (_Float64x __x, _Float64x __y, _Float64x __z) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __fmaf64x (_Float64x __x, _Float64x __y, _Float64x __z) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64x roundevenf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float64x __roundevenf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern __intmax_t fromfpf64x (_Float64x __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__)); extern __intmax_t __fromfpf64x (_Float64x __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__));
extern __uintmax_t ufromfpf64x (_Float64x __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__)); extern __uintmax_t __ufromfpf64x (_Float64x __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__));
extern __intmax_t fromfpxf64x (_Float64x __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__)); extern __intmax_t __fromfpxf64x (_Float64x __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__));
extern __uintmax_t ufromfpxf64x (_Float64x __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__)); extern __uintmax_t __ufromfpxf64x (_Float64x __x, int __round, unsigned int __width) __attribute__ ((__nothrow__ , __leaf__));
extern int canonicalizef64x (_Float64x *__cx, const _Float64x *__x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64x fmaxmagf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float64x __fmaxmagf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float64x fminmagf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float64x __fminmagf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float64x fmaximumf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float64x __fmaximumf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float64x fminimumf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float64x __fminimumf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float64x fmaximum_numf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float64x __fmaximum_numf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float64x fminimum_numf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float64x __fminimum_numf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float64x fmaximum_magf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float64x __fmaximum_magf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float64x fminimum_magf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float64x __fminimum_magf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float64x fmaximum_mag_numf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float64x __fmaximum_mag_numf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern _Float64x fminimum_mag_numf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)); extern _Float64x __fminimum_mag_numf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern int totalorderf64x (const _Float64x *__x, const _Float64x *__y) __attribute__ ((__nothrow__ , __leaf__))
     __attribute__ ((__pure__));
extern int totalordermagf64x (const _Float64x *__x, const _Float64x *__y) __attribute__ ((__nothrow__ , __leaf__))
     __attribute__ ((__pure__));
extern _Float64x getpayloadf64x (const _Float64x *__x) __attribute__ ((__nothrow__ , __leaf__)); extern _Float64x __getpayloadf64x (const _Float64x *__x) __attribute__ ((__nothrow__ , __leaf__));
extern int setpayloadf64x (_Float64x *__x, _Float64x __payload) __attribute__ ((__nothrow__ , __leaf__));
extern int setpayloadsigf64x (_Float64x *__x, _Float64x __payload) __attribute__ ((__nothrow__ , __leaf__));
extern float fadd (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__));
extern float fdiv (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__));
extern float ffma (double __x, double __y, double __z) __attribute__ ((__nothrow__ , __leaf__));
extern float fmul (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__));
extern float fsqrt (double __x) __attribute__ ((__nothrow__ , __leaf__));
extern float fsub (double __x, double __y) __attribute__ ((__nothrow__ , __leaf__));
extern float faddl (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__));
extern float fdivl (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__));
extern float ffmal (long double __x, long double __y, long double __z) __attribute__ ((__nothrow__ , __leaf__));
extern float fmull (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__));
extern float fsqrtl (long double __x) __attribute__ ((__nothrow__ , __leaf__));
extern float fsubl (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__));
extern double daddl (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__));
extern double ddivl (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__));
extern double dfmal (long double __x, long double __y, long double __z) __attribute__ ((__nothrow__ , __leaf__));
extern double dmull (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__));
extern double dsqrtl (long double __x) __attribute__ ((__nothrow__ , __leaf__));
extern double dsubl (long double __x, long double __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 f32addf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 f32divf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 f32fmaf32x (_Float32x __x, _Float32x __y, _Float32x __z) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 f32mulf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 f32sqrtf32x (_Float32x __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 f32subf32x (_Float32x __x, _Float32x __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 f32addf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 f32divf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 f32fmaf64 (_Float64 __x, _Float64 __y, _Float64 __z) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 f32mulf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 f32sqrtf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 f32subf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 f32addf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 f32divf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 f32fmaf64x (_Float64x __x, _Float64x __y, _Float64x __z) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 f32mulf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 f32sqrtf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 f32subf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 f32addf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 f32divf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 f32fmaf128 (_Float128 __x, _Float128 __y, _Float128 __z) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 f32mulf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 f32sqrtf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32 f32subf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x f32xaddf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x f32xdivf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x f32xfmaf64 (_Float64 __x, _Float64 __y, _Float64 __z) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x f32xmulf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x f32xsqrtf64 (_Float64 __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x f32xsubf64 (_Float64 __x, _Float64 __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x f32xaddf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x f32xdivf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x f32xfmaf64x (_Float64x __x, _Float64x __y, _Float64x __z) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x f32xmulf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x f32xsqrtf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x f32xsubf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x f32xaddf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x f32xdivf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x f32xfmaf128 (_Float128 __x, _Float128 __y, _Float128 __z) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x f32xmulf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x f32xsqrtf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float32x f32xsubf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64 f64addf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64 f64divf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64 f64fmaf64x (_Float64x __x, _Float64x __y, _Float64x __z) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64 f64mulf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64 f64sqrtf64x (_Float64x __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64 f64subf64x (_Float64x __x, _Float64x __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64 f64addf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64 f64divf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64 f64fmaf128 (_Float128 __x, _Float128 __y, _Float128 __z) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64 f64mulf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64 f64sqrtf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64 f64subf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64x f64xaddf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64x f64xdivf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64x f64xfmaf128 (_Float128 __x, _Float128 __y, _Float128 __z) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64x f64xmulf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64x f64xsqrtf128 (_Float128 __x) __attribute__ ((__nothrow__ , __leaf__));
extern _Float64x f64xsubf128 (_Float128 __x, _Float128 __y) __attribute__ ((__nothrow__ , __leaf__));
extern int signgam;
enum
  {
    FP_NAN =
      0,
    FP_INFINITE =
      1,
    FP_ZERO =
      2,
    FP_SUBNORMAL =
      3,
    FP_NORMAL =
      4
  };
extern int __iscanonicall (long double __x)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));

typedef long unsigned int size_t;

extern void _dl_mcount_wrapper_check (void *__selfpc) __attribute__ ((__nothrow__ , __leaf__));

typedef long int Lmid_t;

extern void *dlopen (const char *__file, int __mode) __attribute__ ((__nothrow__));
extern int dlclose (void *__handle) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
extern void *dlsym (void *__restrict __handle,
      const char *__restrict __name) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2)));
extern void *dlmopen (Lmid_t __nsid, const char *__file, int __mode) __attribute__ ((__nothrow__));
extern void *dlvsym (void *__restrict __handle,
       const char *__restrict __name,
       const char *__restrict __version)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2, 3)));
extern char *dlerror (void) __attribute__ ((__nothrow__ , __leaf__));
typedef struct
{
  const char *dli_fname;
  void *dli_fbase;
  const char *dli_sname;
  void *dli_saddr;
} Dl_info;
extern int dladdr (const void *__address, Dl_info *__info)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2)));
extern int dladdr1 (const void *__address, Dl_info *__info,
      void **__extra_info, int __flags) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2)));
enum
  {
    RTLD_DL_SYMENT = 1,
    RTLD_DL_LINKMAP = 2
  };
extern int dlinfo (void *__restrict __handle,
     int __request, void *__restrict __arg)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 3)));
enum
  {
    RTLD_DI_LMID = 1,
    RTLD_DI_LINKMAP = 2,
    RTLD_DI_CONFIGADDR = 3,
    RTLD_DI_SERINFO = 4,
    RTLD_DI_SERINFOSIZE = 5,
    RTLD_DI_ORIGIN = 6,
    RTLD_DI_PROFILENAME = 7,
    RTLD_DI_PROFILEOUT = 8,
    RTLD_DI_TLS_MODID = 9,
    RTLD_DI_TLS_DATA = 10,
    RTLD_DI_MAX = 10
  };
typedef struct
{
  char *dls_name;
  unsigned int dls_flags;
} Dl_serpath;
typedef struct
{
  size_t dls_size;
  unsigned int dls_cnt;
  __extension__ union
  {
    Dl_serpath dls_serpath[0];
    Dl_serpath __dls_serpath_pad[1];
  };
} Dl_serinfo;
struct dl_find_object
{
  __extension__ unsigned long long int dlfo_flags;
  void *dlfo_map_start;
  void *dlfo_map_end;
  struct link_map *dlfo_link_map;
  void *dlfo_eh_frame;
  __extension__ unsigned long long int __dflo_reserved[7];
};
int _dl_find_object (void *__address, struct dl_find_object *__result) __attribute__ ((__nothrow__ , __leaf__));

typedef __builtin_va_list __gnuc_va_list;
typedef __gnuc_va_list va_list;

typedef struct
{
  int __count;
  union
  {
    unsigned int __wch;
    char __wchb[4];
  } __value;
} __mbstate_t;
typedef struct _G_fpos_t
{
  __off_t __pos;
  __mbstate_t __state;
} __fpos_t;
typedef struct _G_fpos64_t
{
  __off64_t __pos;
  __mbstate_t __state;
} __fpos64_t;
struct _IO_FILE;
typedef struct _IO_FILE __FILE;
struct _IO_FILE;
typedef struct _IO_FILE FILE;
struct _IO_FILE;
struct _IO_marker;
struct _IO_codecvt;
struct _IO_wide_data;
typedef void _IO_lock_t;
struct _IO_FILE
{
  int _flags;
  char *_IO_read_ptr;
  char *_IO_read_end;
  char *_IO_read_base;
  char *_IO_write_base;
  char *_IO_write_ptr;
  char *_IO_write_end;
  char *_IO_buf_base;
  char *_IO_buf_end;
  char *_IO_save_base;
  char *_IO_backup_base;
  char *_IO_save_end;
  struct _IO_marker *_markers;
  struct _IO_FILE *_chain;
  int _fileno;
  int _flags2;
  __off_t _old_offset;
  unsigned short _cur_column;
  signed char _vtable_offset;
  char _shortbuf[1];
  _IO_lock_t *_lock;
  __off64_t _offset;
  struct _IO_codecvt *_codecvt;
  struct _IO_wide_data *_wide_data;
  struct _IO_FILE *_freeres_list;
  void *_freeres_buf;
  size_t __pad5;
  int _mode;
  char _unused2[15 * sizeof (int) - 4 * sizeof (void *) - sizeof (size_t)];
};
typedef __ssize_t cookie_read_function_t (void *__cookie, char *__buf,
                                          size_t __nbytes);
typedef __ssize_t cookie_write_function_t (void *__cookie, const char *__buf,
                                           size_t __nbytes);
typedef int cookie_seek_function_t (void *__cookie, __off64_t *__pos, int __w);
typedef int cookie_close_function_t (void *__cookie);
typedef struct _IO_cookie_io_functions_t
{
  cookie_read_function_t *read;
  cookie_write_function_t *write;
  cookie_seek_function_t *seek;
  cookie_close_function_t *close;
} cookie_io_functions_t;
typedef __off_t off_t;
typedef __off64_t off64_t;
typedef __ssize_t ssize_t;
typedef __fpos_t fpos_t;
typedef __fpos64_t fpos64_t;
extern FILE *stdin;
extern FILE *stdout;
extern FILE *stderr;
extern int remove (const char *__filename) __attribute__ ((__nothrow__ , __leaf__));
extern int rename (const char *__old, const char *__new) __attribute__ ((__nothrow__ , __leaf__));
extern int renameat (int __oldfd, const char *__old, int __newfd,
       const char *__new) __attribute__ ((__nothrow__ , __leaf__));
extern int renameat2 (int __oldfd, const char *__old, int __newfd,
        const char *__new, unsigned int __flags) __attribute__ ((__nothrow__ , __leaf__));
extern int fclose (FILE *__stream);
extern FILE *tmpfile (void)
  __attribute__ ((__malloc__)) __attribute__ ((__malloc__ (fclose, 1))) ;
extern FILE *tmpfile64 (void)
   __attribute__ ((__malloc__)) __attribute__ ((__malloc__ (fclose, 1))) ;
extern char *tmpnam (char[20]) __attribute__ ((__nothrow__ , __leaf__)) ;
extern char *tmpnam_r (char __s[20]) __attribute__ ((__nothrow__ , __leaf__)) ;
extern char *tempnam (const char *__dir, const char *__pfx)
   __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__malloc__)) __attribute__ ((__malloc__ (__builtin_free, 1)));
extern int fflush (FILE *__stream);
extern int fflush_unlocked (FILE *__stream);
extern int fcloseall (void);
extern FILE *fopen (const char *__restrict __filename,
      const char *__restrict __modes)
  __attribute__ ((__malloc__)) __attribute__ ((__malloc__ (fclose, 1))) ;
extern FILE *freopen (const char *__restrict __filename,
        const char *__restrict __modes,
        FILE *__restrict __stream) ;
extern FILE *fopen64 (const char *__restrict __filename,
        const char *__restrict __modes)
  __attribute__ ((__malloc__)) __attribute__ ((__malloc__ (fclose, 1))) ;
extern FILE *freopen64 (const char *__restrict __filename,
   const char *__restrict __modes,
   FILE *__restrict __stream) ;
extern FILE *fdopen (int __fd, const char *__modes) __attribute__ ((__nothrow__ , __leaf__))
  __attribute__ ((__malloc__)) __attribute__ ((__malloc__ (fclose, 1))) ;
extern FILE *fopencookie (void *__restrict __magic_cookie,
     const char *__restrict __modes,
     cookie_io_functions_t __io_funcs) __attribute__ ((__nothrow__ , __leaf__))
  __attribute__ ((__malloc__)) __attribute__ ((__malloc__ (fclose, 1))) ;
extern FILE *fmemopen (void *__s, size_t __len, const char *__modes)
  __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__malloc__)) __attribute__ ((__malloc__ (fclose, 1))) ;
extern FILE *open_memstream (char **__bufloc, size_t *__sizeloc) __attribute__ ((__nothrow__ , __leaf__))
  __attribute__ ((__malloc__)) __attribute__ ((__malloc__ (fclose, 1))) ;
extern void setbuf (FILE *__restrict __stream, char *__restrict __buf) __attribute__ ((__nothrow__ , __leaf__));
extern int setvbuf (FILE *__restrict __stream, char *__restrict __buf,
      int __modes, size_t __n) __attribute__ ((__nothrow__ , __leaf__));
extern void setbuffer (FILE *__restrict __stream, char *__restrict __buf,
         size_t __size) __attribute__ ((__nothrow__ , __leaf__));
extern void setlinebuf (FILE *__stream) __attribute__ ((__nothrow__ , __leaf__));
extern int fprintf (FILE *__restrict __stream,
      const char *__restrict __format, ...);
extern int printf (const char *__restrict __format, ...);
extern int sprintf (char *__restrict __s,
      const char *__restrict __format, ...) __attribute__ ((__nothrow__));
extern int vfprintf (FILE *__restrict __s, const char *__restrict __format,
       __gnuc_va_list __arg);
extern int vprintf (const char *__restrict __format, __gnuc_va_list __arg);
extern int vsprintf (char *__restrict __s, const char *__restrict __format,
       __gnuc_va_list __arg) __attribute__ ((__nothrow__));
extern int snprintf (char *__restrict __s, size_t __maxlen,
       const char *__restrict __format, ...)
     __attribute__ ((__nothrow__)) __attribute__ ((__format__ (__printf__, 3, 4)));
extern int vsnprintf (char *__restrict __s, size_t __maxlen,
        const char *__restrict __format, __gnuc_va_list __arg)
     __attribute__ ((__nothrow__)) __attribute__ ((__format__ (__printf__, 3, 0)));
extern int vasprintf (char **__restrict __ptr, const char *__restrict __f,
        __gnuc_va_list __arg)
     __attribute__ ((__nothrow__)) __attribute__ ((__format__ (__printf__, 2, 0))) ;
extern int __asprintf (char **__restrict __ptr,
         const char *__restrict __fmt, ...)
     __attribute__ ((__nothrow__)) __attribute__ ((__format__ (__printf__, 2, 3))) ;
extern int asprintf (char **__restrict __ptr,
       const char *__restrict __fmt, ...)
     __attribute__ ((__nothrow__)) __attribute__ ((__format__ (__printf__, 2, 3))) ;
extern int vdprintf (int __fd, const char *__restrict __fmt,
       __gnuc_va_list __arg)
     __attribute__ ((__format__ (__printf__, 2, 0)));
extern int dprintf (int __fd, const char *__restrict __fmt, ...)
     __attribute__ ((__format__ (__printf__, 2, 3)));
extern int fscanf (FILE *__restrict __stream,
     const char *__restrict __format, ...) ;
extern int scanf (const char *__restrict __format, ...) ;
extern int sscanf (const char *__restrict __s,
     const char *__restrict __format, ...) __attribute__ ((__nothrow__ , __leaf__));
extern int fscanf (FILE *__restrict __stream, const char *__restrict __format, ...) __asm__ ("" "__isoc99_fscanf") ;
extern int scanf (const char *__restrict __format, ...) __asm__ ("" "__isoc99_scanf") ;
extern int sscanf (const char *__restrict __s, const char *__restrict __format, ...) __asm__ ("" "__isoc99_sscanf") __attribute__ ((__nothrow__ , __leaf__));
extern int vfscanf (FILE *__restrict __s, const char *__restrict __format,
      __gnuc_va_list __arg)
     __attribute__ ((__format__ (__scanf__, 2, 0))) ;
extern int vscanf (const char *__restrict __format, __gnuc_va_list __arg)
     __attribute__ ((__format__ (__scanf__, 1, 0))) ;
extern int vsscanf (const char *__restrict __s,
      const char *__restrict __format, __gnuc_va_list __arg)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__format__ (__scanf__, 2, 0)));
extern int vfscanf (FILE *__restrict __s, const char *__restrict __format, __gnuc_va_list __arg) __asm__ ("" "__isoc99_vfscanf")
     __attribute__ ((__format__ (__scanf__, 2, 0))) ;
extern int vscanf (const char *__restrict __format, __gnuc_va_list __arg) __asm__ ("" "__isoc99_vscanf")
     __attribute__ ((__format__ (__scanf__, 1, 0))) ;
extern int vsscanf (const char *__restrict __s, const char *__restrict __format, __gnuc_va_list __arg) __asm__ ("" "__isoc99_vsscanf") __attribute__ ((__nothrow__ , __leaf__))
     __attribute__ ((__format__ (__scanf__, 2, 0)));
extern int fgetc (FILE *__stream);
extern int getc (FILE *__stream);
extern int getchar (void);
extern int getc_unlocked (FILE *__stream);
extern int getchar_unlocked (void);
extern int fgetc_unlocked (FILE *__stream);
extern int fputc (int __c, FILE *__stream);
extern int putc (int __c, FILE *__stream);
extern int putchar (int __c);
extern int fputc_unlocked (int __c, FILE *__stream);
extern int putc_unlocked (int __c, FILE *__stream);
extern int putchar_unlocked (int __c);
extern int getw (FILE *__stream);
extern int putw (int __w, FILE *__stream);
extern char *fgets (char *__restrict __s, int __n, FILE *__restrict __stream)
     __attribute__ ((__access__ (__write_only__, 1, 2)));
extern char *fgets_unlocked (char *__restrict __s, int __n,
        FILE *__restrict __stream)
    __attribute__ ((__access__ (__write_only__, 1, 2)));
extern __ssize_t __getdelim (char **__restrict __lineptr,
                             size_t *__restrict __n, int __delimiter,
                             FILE *__restrict __stream) ;
extern __ssize_t getdelim (char **__restrict __lineptr,
                           size_t *__restrict __n, int __delimiter,
                           FILE *__restrict __stream) ;
extern __ssize_t getline (char **__restrict __lineptr,
                          size_t *__restrict __n,
                          FILE *__restrict __stream) ;
extern int fputs (const char *__restrict __s, FILE *__restrict __stream);
extern int puts (const char *__s);
extern int ungetc (int __c, FILE *__stream);
extern size_t fread (void *__restrict __ptr, size_t __size,
       size_t __n, FILE *__restrict __stream) ;
extern size_t fwrite (const void *__restrict __ptr, size_t __size,
        size_t __n, FILE *__restrict __s);
extern int fputs_unlocked (const char *__restrict __s,
      FILE *__restrict __stream);
extern size_t fread_unlocked (void *__restrict __ptr, size_t __size,
         size_t __n, FILE *__restrict __stream) ;
extern size_t fwrite_unlocked (const void *__restrict __ptr, size_t __size,
          size_t __n, FILE *__restrict __stream);
extern int fseek (FILE *__stream, long int __off, int __whence);
extern long int ftell (FILE *__stream) ;
extern void rewind (FILE *__stream);
extern int fseeko (FILE *__stream, __off_t __off, int __whence);
extern __off_t ftello (FILE *__stream) ;
extern int fgetpos (FILE *__restrict __stream, fpos_t *__restrict __pos);
extern int fsetpos (FILE *__stream, const fpos_t *__pos);
extern int fseeko64 (FILE *__stream, __off64_t __off, int __whence);
extern __off64_t ftello64 (FILE *__stream) ;
extern int fgetpos64 (FILE *__restrict __stream, fpos64_t *__restrict __pos);
extern int fsetpos64 (FILE *__stream, const fpos64_t *__pos);
extern void clearerr (FILE *__stream) __attribute__ ((__nothrow__ , __leaf__));
extern int feof (FILE *__stream) __attribute__ ((__nothrow__ , __leaf__)) ;
extern int ferror (FILE *__stream) __attribute__ ((__nothrow__ , __leaf__)) ;
extern void clearerr_unlocked (FILE *__stream) __attribute__ ((__nothrow__ , __leaf__));
extern int feof_unlocked (FILE *__stream) __attribute__ ((__nothrow__ , __leaf__)) ;
extern int ferror_unlocked (FILE *__stream) __attribute__ ((__nothrow__ , __leaf__)) ;
extern void perror (const char *__s);
extern int fileno (FILE *__stream) __attribute__ ((__nothrow__ , __leaf__)) ;
extern int fileno_unlocked (FILE *__stream) __attribute__ ((__nothrow__ , __leaf__)) ;
extern int pclose (FILE *__stream);
extern FILE *popen (const char *__command, const char *__modes)
  __attribute__ ((__malloc__)) __attribute__ ((__malloc__ (pclose, 1))) ;
extern char *ctermid (char *__s) __attribute__ ((__nothrow__ , __leaf__))
  __attribute__ ((__access__ (__write_only__, 1)));
extern char *cuserid (char *__s)
  __attribute__ ((__access__ (__write_only__, 1)));
struct obstack;
extern int obstack_printf (struct obstack *__restrict __obstack,
      const char *__restrict __format, ...)
     __attribute__ ((__nothrow__)) __attribute__ ((__format__ (__printf__, 2, 3)));
extern int obstack_vprintf (struct obstack *__restrict __obstack,
       const char *__restrict __format,
       __gnuc_va_list __args)
     __attribute__ ((__nothrow__)) __attribute__ ((__format__ (__printf__, 2, 0)));
extern void flockfile (FILE *__stream) __attribute__ ((__nothrow__ , __leaf__));
extern int ftrylockfile (FILE *__stream) __attribute__ ((__nothrow__ , __leaf__)) ;
extern void funlockfile (FILE *__stream) __attribute__ ((__nothrow__ , __leaf__));
extern int __uflow (FILE *);
extern int __overflow (FILE *, int);


typedef __u_char u_char;
typedef __u_short u_short;
typedef __u_int u_int;
typedef __u_long u_long;
typedef __quad_t quad_t;
typedef __u_quad_t u_quad_t;
typedef __fsid_t fsid_t;
typedef __loff_t loff_t;
typedef __ino_t ino_t;
typedef __ino64_t ino64_t;
typedef __dev_t dev_t;
typedef __gid_t gid_t;
typedef __mode_t mode_t;
typedef __nlink_t nlink_t;
typedef __uid_t uid_t;
typedef __pid_t pid_t;
typedef __id_t id_t;
typedef __daddr_t daddr_t;
typedef __caddr_t caddr_t;
typedef __key_t key_t;
typedef __clock_t clock_t;
typedef __clockid_t clockid_t;
typedef __time_t time_t;
typedef __timer_t timer_t;
typedef __useconds_t useconds_t;
typedef __suseconds_t suseconds_t;
typedef unsigned long int ulong;
typedef unsigned short int ushort;
typedef unsigned int uint;
typedef __int8_t int8_t;
typedef __int16_t int16_t;
typedef __int32_t int32_t;
typedef __int64_t int64_t;
typedef __uint8_t u_int8_t;
typedef __uint16_t u_int16_t;
typedef __uint32_t u_int32_t;
typedef __uint64_t u_int64_t;
typedef int register_t __attribute__ ((__mode__ (__word__)));
static __inline __uint16_t
__bswap_16 (__uint16_t __bsx)
{
  return __builtin_bswap16 (__bsx);
}
static __inline __uint32_t
__bswap_32 (__uint32_t __bsx)
{
  return __builtin_bswap32 (__bsx);
}
__extension__ static __inline __uint64_t
__bswap_64 (__uint64_t __bsx)
{
  return __builtin_bswap64 (__bsx);
}
static __inline __uint16_t
__uint16_identity (__uint16_t __x)
{
  return __x;
}
static __inline __uint32_t
__uint32_identity (__uint32_t __x)
{
  return __x;
}
static __inline __uint64_t
__uint64_identity (__uint64_t __x)
{
  return __x;
}
typedef struct
{
  unsigned long int __val[(1024 / (8 * sizeof (unsigned long int)))];
} __sigset_t;
typedef __sigset_t sigset_t;
struct timeval
{
  __time_t tv_sec;
  __suseconds_t tv_usec;
};
struct timespec
{
  __time_t tv_sec;
  __syscall_slong_t tv_nsec;
};
typedef long int __fd_mask;
typedef struct
  {
    __fd_mask fds_bits[1024 / (8 * (int) sizeof (__fd_mask))];
  } fd_set;
typedef __fd_mask fd_mask;

extern int select (int __nfds, fd_set *__restrict __readfds,
     fd_set *__restrict __writefds,
     fd_set *__restrict __exceptfds,
     struct timeval *__restrict __timeout);
extern int pselect (int __nfds, fd_set *__restrict __readfds,
      fd_set *__restrict __writefds,
      fd_set *__restrict __exceptfds,
      const struct timespec *__restrict __timeout,
      const __sigset_t *__restrict __sigmask);

typedef __blksize_t blksize_t;
typedef __blkcnt_t blkcnt_t;
typedef __fsblkcnt_t fsblkcnt_t;
typedef __fsfilcnt_t fsfilcnt_t;
typedef __blkcnt64_t blkcnt64_t;
typedef __fsblkcnt64_t fsblkcnt64_t;
typedef __fsfilcnt64_t fsfilcnt64_t;
typedef union
{
  __extension__ unsigned long long int __value64;
  struct
  {
    unsigned int __low;
    unsigned int __high;
  } __value32;
} __atomic_wide_counter;
typedef struct __pthread_internal_list
{
  struct __pthread_internal_list *__prev;
  struct __pthread_internal_list *__next;
} __pthread_list_t;
typedef struct __pthread_internal_slist
{
  struct __pthread_internal_slist *__next;
} __pthread_slist_t;
struct __pthread_mutex_s
{
  int __lock;
  unsigned int __count;
  int __owner;
  unsigned int __nusers;
  int __kind;
  short __spins;
  short __elision;
  __pthread_list_t __list;
};
struct __pthread_rwlock_arch_t
{
  unsigned int __readers;
  unsigned int __writers;
  unsigned int __wrphase_futex;
  unsigned int __writers_futex;
  unsigned int __pad3;
  unsigned int __pad4;
  int __cur_writer;
  int __shared;
  signed char __rwelision;
  unsigned char __pad1[7];
  unsigned long int __pad2;
  unsigned int __flags;
};
struct __pthread_cond_s
{
  __atomic_wide_counter __wseq;
  __atomic_wide_counter __g1_start;
  unsigned int __g_refs[2] ;
  unsigned int __g_size[2];
  unsigned int __g1_orig_size;
  unsigned int __wrefs;
  unsigned int __g_signals[2];
};
typedef unsigned int __tss_t;
typedef unsigned long int __thrd_t;
typedef struct
{
  int __data ;
} __once_flag;
typedef unsigned long int pthread_t;
typedef union
{
  char __size[4];
  int __align;
} pthread_mutexattr_t;
typedef union
{
  char __size[4];
  int __align;
} pthread_condattr_t;
typedef unsigned int pthread_key_t;
typedef int pthread_once_t;
union pthread_attr_t
{
  char __size[56];
  long int __align;
};
typedef union pthread_attr_t pthread_attr_t;
typedef union
{
  struct __pthread_mutex_s __data;
  char __size[40];
  long int __align;
} pthread_mutex_t;
typedef union
{
  struct __pthread_cond_s __data;
  char __size[48];
  __extension__ long long int __align;
} pthread_cond_t;
typedef union
{
  struct __pthread_rwlock_arch_t __data;
  char __size[56];
  long int __align;
} pthread_rwlock_t;
typedef union
{
  char __size[8];
  long int __align;
} pthread_rwlockattr_t;
typedef volatile int pthread_spinlock_t;
typedef union
{
  char __size[32];
  long int __align;
} pthread_barrier_t;
typedef union
{
  char __size[4];
  int __align;
} pthread_barrierattr_t;


struct stat
  {
    __dev_t st_dev;
    __ino_t st_ino;
    __nlink_t st_nlink;
    __mode_t st_mode;
    __uid_t st_uid;
    __gid_t st_gid;
    int __pad0;
    __dev_t st_rdev;
    __off_t st_size;
    __blksize_t st_blksize;
    __blkcnt_t st_blocks;
    struct timespec st_atim;
    struct timespec st_mtim;
    struct timespec st_ctim;
    __syscall_slong_t __glibc_reserved[3];
  };
struct stat64
  {
    __dev_t st_dev;
    __ino64_t st_ino;
    __nlink_t st_nlink;
    __mode_t st_mode;
    __uid_t st_uid;
    __gid_t st_gid;
    int __pad0;
    __dev_t st_rdev;
    __off_t st_size;
    __blksize_t st_blksize;
    __blkcnt64_t st_blocks;
    struct timespec st_atim;
    struct timespec st_mtim;
    struct timespec st_ctim;
    __syscall_slong_t __glibc_reserved[3];
  };
extern int stat (const char *__restrict __file,
   struct stat *__restrict __buf) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int fstat (int __fd, struct stat *__buf) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2)));
extern int stat64 (const char *__restrict __file,
     struct stat64 *__restrict __buf) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int fstat64 (int __fd, struct stat64 *__buf) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2)));
extern int fstatat (int __fd, const char *__restrict __file,
      struct stat *__restrict __buf, int __flag)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2, 3)));
extern int fstatat64 (int __fd, const char *__restrict __file,
        struct stat64 *__restrict __buf, int __flag)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2, 3)));
extern int lstat (const char *__restrict __file,
    struct stat *__restrict __buf) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int lstat64 (const char *__restrict __file,
      struct stat64 *__restrict __buf)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int chmod (const char *__file, __mode_t __mode)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int lchmod (const char *__file, __mode_t __mode)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int fchmod (int __fd, __mode_t __mode) __attribute__ ((__nothrow__ , __leaf__));
extern int fchmodat (int __fd, const char *__file, __mode_t __mode,
       int __flag)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2))) ;
extern __mode_t umask (__mode_t __mask) __attribute__ ((__nothrow__ , __leaf__));
extern __mode_t getumask (void) __attribute__ ((__nothrow__ , __leaf__));
extern int mkdir (const char *__path, __mode_t __mode)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int mkdirat (int __fd, const char *__path, __mode_t __mode)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2)));
extern int mknod (const char *__path, __mode_t __mode, __dev_t __dev)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int mknodat (int __fd, const char *__path, __mode_t __mode,
      __dev_t __dev) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2)));
extern int mkfifo (const char *__path, __mode_t __mode)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int mkfifoat (int __fd, const char *__path, __mode_t __mode)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2)));
extern int utimensat (int __fd, const char *__path,
        const struct timespec __times[2],
        int __flags)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2)));
extern int futimens (int __fd, const struct timespec __times[2]) __attribute__ ((__nothrow__ , __leaf__));
typedef __signed__ char __s8;
typedef unsigned char __u8;
typedef __signed__ short __s16;
typedef unsigned short __u16;
typedef __signed__ int __s32;
typedef unsigned int __u32;
__extension__ typedef __signed__ long long __s64;
__extension__ typedef unsigned long long __u64;
typedef struct {
 unsigned long fds_bits[1024 / (8 * sizeof(long))];
} __kernel_fd_set;
typedef void (*__kernel_sighandler_t)(int);
typedef int __kernel_key_t;
typedef int __kernel_mqd_t;
typedef unsigned short __kernel_old_uid_t;
typedef unsigned short __kernel_old_gid_t;
typedef unsigned long __kernel_old_dev_t;
typedef long __kernel_long_t;
typedef unsigned long __kernel_ulong_t;
typedef __kernel_ulong_t __kernel_ino_t;
typedef unsigned int __kernel_mode_t;
typedef int __kernel_pid_t;
typedef int __kernel_ipc_pid_t;
typedef unsigned int __kernel_uid_t;
typedef unsigned int __kernel_gid_t;
typedef __kernel_long_t __kernel_suseconds_t;
typedef int __kernel_daddr_t;
typedef unsigned int __kernel_uid32_t;
typedef unsigned int __kernel_gid32_t;
typedef __kernel_ulong_t __kernel_size_t;
typedef __kernel_long_t __kernel_ssize_t;
typedef __kernel_long_t __kernel_ptrdiff_t;
typedef struct {
 int val[2];
} __kernel_fsid_t;
typedef __kernel_long_t __kernel_off_t;
typedef long long __kernel_loff_t;
typedef __kernel_long_t __kernel_old_time_t;
typedef __kernel_long_t __kernel_time_t;
typedef long long __kernel_time64_t;
typedef __kernel_long_t __kernel_clock_t;
typedef int __kernel_timer_t;
typedef int __kernel_clockid_t;
typedef char * __kernel_caddr_t;
typedef unsigned short __kernel_uid16_t;
typedef unsigned short __kernel_gid16_t;
typedef __u16 __le16;
typedef __u16 __be16;
typedef __u32 __le32;
typedef __u32 __be32;
typedef __u64 __le64;
typedef __u64 __be64;
typedef __u16 __sum16;
typedef __u32 __wsum;
typedef unsigned __poll_t;
struct statx_timestamp {
 __s64 tv_sec;
 __u32 tv_nsec;
 __s32 __reserved;
};
struct statx {
 __u32 stx_mask;
 __u32 stx_blksize;
 __u64 stx_attributes;
 __u32 stx_nlink;
 __u32 stx_uid;
 __u32 stx_gid;
 __u16 stx_mode;
 __u16 __spare0[1];
 __u64 stx_ino;
 __u64 stx_size;
 __u64 stx_blocks;
 __u64 stx_attributes_mask;
 struct statx_timestamp stx_atime;
 struct statx_timestamp stx_btime;
 struct statx_timestamp stx_ctime;
 struct statx_timestamp stx_mtime;
 __u32 stx_rdev_major;
 __u32 stx_rdev_minor;
 __u32 stx_dev_major;
 __u32 stx_dev_minor;
 __u64 stx_mnt_id;
 __u64 __spare2;
 __u64 __spare3[12];
};

int statx (int __dirfd, const char *__restrict __path, int __flags,
           unsigned int __mask, struct statx *__restrict __buf)
  __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2, 5)));


typedef int wchar_t;

typedef struct
  {
    int quot;
    int rem;
  } div_t;
typedef struct
  {
    long int quot;
    long int rem;
  } ldiv_t;
__extension__ typedef struct
  {
    long long int quot;
    long long int rem;
  } lldiv_t;
extern size_t __ctype_get_mb_cur_max (void) __attribute__ ((__nothrow__ , __leaf__)) ;
extern double atof (const char *__nptr)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1))) ;
extern int atoi (const char *__nptr)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1))) ;
extern long int atol (const char *__nptr)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1))) ;
__extension__ extern long long int atoll (const char *__nptr)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1))) ;
extern double strtod (const char *__restrict __nptr,
        char **__restrict __endptr)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern float strtof (const char *__restrict __nptr,
       char **__restrict __endptr) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern long double strtold (const char *__restrict __nptr,
       char **__restrict __endptr)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern _Float32 strtof32 (const char *__restrict __nptr,
     char **__restrict __endptr)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern _Float64 strtof64 (const char *__restrict __nptr,
     char **__restrict __endptr)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern _Float128 strtof128 (const char *__restrict __nptr,
       char **__restrict __endptr)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern _Float32x strtof32x (const char *__restrict __nptr,
       char **__restrict __endptr)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern _Float64x strtof64x (const char *__restrict __nptr,
       char **__restrict __endptr)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern long int strtol (const char *__restrict __nptr,
   char **__restrict __endptr, int __base)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern unsigned long int strtoul (const char *__restrict __nptr,
      char **__restrict __endptr, int __base)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
__extension__
extern long long int strtoq (const char *__restrict __nptr,
        char **__restrict __endptr, int __base)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
__extension__
extern unsigned long long int strtouq (const char *__restrict __nptr,
           char **__restrict __endptr, int __base)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
__extension__
extern long long int strtoll (const char *__restrict __nptr,
         char **__restrict __endptr, int __base)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
__extension__
extern unsigned long long int strtoull (const char *__restrict __nptr,
     char **__restrict __endptr, int __base)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int strfromd (char *__dest, size_t __size, const char *__format,
       double __f)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (3)));
extern int strfromf (char *__dest, size_t __size, const char *__format,
       float __f)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (3)));
extern int strfroml (char *__dest, size_t __size, const char *__format,
       long double __f)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (3)));
extern int strfromf32 (char *__dest, size_t __size, const char * __format,
         _Float32 __f)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (3)));
extern int strfromf64 (char *__dest, size_t __size, const char * __format,
         _Float64 __f)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (3)));
extern int strfromf128 (char *__dest, size_t __size, const char * __format,
   _Float128 __f)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (3)));
extern int strfromf32x (char *__dest, size_t __size, const char * __format,
   _Float32x __f)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (3)));
extern int strfromf64x (char *__dest, size_t __size, const char * __format,
   _Float64x __f)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (3)));
struct __locale_struct
{
  struct __locale_data *__locales[13];
  const unsigned short int *__ctype_b;
  const int *__ctype_tolower;
  const int *__ctype_toupper;
  const char *__names[13];
};
typedef struct __locale_struct *__locale_t;
typedef __locale_t locale_t;
extern long int strtol_l (const char *__restrict __nptr,
     char **__restrict __endptr, int __base,
     locale_t __loc) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 4)));
extern unsigned long int strtoul_l (const char *__restrict __nptr,
        char **__restrict __endptr,
        int __base, locale_t __loc)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 4)));
__extension__
extern long long int strtoll_l (const char *__restrict __nptr,
    char **__restrict __endptr, int __base,
    locale_t __loc)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 4)));
__extension__
extern unsigned long long int strtoull_l (const char *__restrict __nptr,
       char **__restrict __endptr,
       int __base, locale_t __loc)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 4)));
extern double strtod_l (const char *__restrict __nptr,
   char **__restrict __endptr, locale_t __loc)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 3)));
extern float strtof_l (const char *__restrict __nptr,
         char **__restrict __endptr, locale_t __loc)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 3)));
extern long double strtold_l (const char *__restrict __nptr,
         char **__restrict __endptr,
         locale_t __loc)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 3)));
extern _Float32 strtof32_l (const char *__restrict __nptr,
       char **__restrict __endptr,
       locale_t __loc)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 3)));
extern _Float64 strtof64_l (const char *__restrict __nptr,
       char **__restrict __endptr,
       locale_t __loc)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 3)));
extern _Float128 strtof128_l (const char *__restrict __nptr,
         char **__restrict __endptr,
         locale_t __loc)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 3)));
extern _Float32x strtof32x_l (const char *__restrict __nptr,
         char **__restrict __endptr,
         locale_t __loc)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 3)));
extern _Float64x strtof64x_l (const char *__restrict __nptr,
         char **__restrict __endptr,
         locale_t __loc)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 3)));
extern char *l64a (long int __n) __attribute__ ((__nothrow__ , __leaf__)) ;
extern long int a64l (const char *__s)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1))) ;
extern long int random (void) __attribute__ ((__nothrow__ , __leaf__));
extern void srandom (unsigned int __seed) __attribute__ ((__nothrow__ , __leaf__));
extern char *initstate (unsigned int __seed, char *__statebuf,
   size_t __statelen) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2)));
extern char *setstate (char *__statebuf) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
struct random_data
  {
    int32_t *fptr;
    int32_t *rptr;
    int32_t *state;
    int rand_type;
    int rand_deg;
    int rand_sep;
    int32_t *end_ptr;
  };
extern int random_r (struct random_data *__restrict __buf,
       int32_t *__restrict __result) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int srandom_r (unsigned int __seed, struct random_data *__buf)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2)));
extern int initstate_r (unsigned int __seed, char *__restrict __statebuf,
   size_t __statelen,
   struct random_data *__restrict __buf)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2, 4)));
extern int setstate_r (char *__restrict __statebuf,
         struct random_data *__restrict __buf)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int rand (void) __attribute__ ((__nothrow__ , __leaf__));
extern void srand (unsigned int __seed) __attribute__ ((__nothrow__ , __leaf__));
extern int rand_r (unsigned int *__seed) __attribute__ ((__nothrow__ , __leaf__));
extern double drand48 (void) __attribute__ ((__nothrow__ , __leaf__));
extern double erand48 (unsigned short int __xsubi[3]) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern long int lrand48 (void) __attribute__ ((__nothrow__ , __leaf__));
extern long int nrand48 (unsigned short int __xsubi[3])
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern long int mrand48 (void) __attribute__ ((__nothrow__ , __leaf__));
extern long int jrand48 (unsigned short int __xsubi[3])
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern void srand48 (long int __seedval) __attribute__ ((__nothrow__ , __leaf__));
extern unsigned short int *seed48 (unsigned short int __seed16v[3])
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern void lcong48 (unsigned short int __param[7]) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
struct drand48_data
  {
    unsigned short int __x[3];
    unsigned short int __old_x[3];
    unsigned short int __c;
    unsigned short int __init;
    __extension__ unsigned long long int __a;
  };
extern int drand48_r (struct drand48_data *__restrict __buffer,
        double *__restrict __result) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int erand48_r (unsigned short int __xsubi[3],
        struct drand48_data *__restrict __buffer,
        double *__restrict __result) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int lrand48_r (struct drand48_data *__restrict __buffer,
        long int *__restrict __result)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int nrand48_r (unsigned short int __xsubi[3],
        struct drand48_data *__restrict __buffer,
        long int *__restrict __result)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int mrand48_r (struct drand48_data *__restrict __buffer,
        long int *__restrict __result)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int jrand48_r (unsigned short int __xsubi[3],
        struct drand48_data *__restrict __buffer,
        long int *__restrict __result)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int srand48_r (long int __seedval, struct drand48_data *__buffer)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2)));
extern int seed48_r (unsigned short int __seed16v[3],
       struct drand48_data *__buffer) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int lcong48_r (unsigned short int __param[7],
        struct drand48_data *__buffer)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern void *malloc (size_t __size) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__malloc__))
     __attribute__ ((__alloc_size__ (1))) ;
extern void *calloc (size_t __nmemb, size_t __size)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__malloc__)) __attribute__ ((__alloc_size__ (1, 2))) ;
extern void *realloc (void *__ptr, size_t __size)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__warn_unused_result__)) __attribute__ ((__alloc_size__ (2)));
extern void free (void *__ptr) __attribute__ ((__nothrow__ , __leaf__));
extern void *reallocarray (void *__ptr, size_t __nmemb, size_t __size)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__warn_unused_result__))
     __attribute__ ((__alloc_size__ (2, 3)))
    __attribute__ ((__malloc__ (__builtin_free, 1)));
extern void *reallocarray (void *__ptr, size_t __nmemb, size_t __size)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__malloc__ (reallocarray, 1)));

extern void *alloca (size_t __size) __attribute__ ((__nothrow__ , __leaf__));

extern void *valloc (size_t __size) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__malloc__))
     __attribute__ ((__alloc_size__ (1))) ;
extern int posix_memalign (void **__memptr, size_t __alignment, size_t __size)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1))) ;
extern void *aligned_alloc (size_t __alignment, size_t __size)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__malloc__)) __attribute__ ((__alloc_align__ (1)))
     __attribute__ ((__alloc_size__ (2))) ;
extern void abort (void) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__noreturn__));
extern int atexit (void (*__func) (void)) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int at_quick_exit (void (*__func) (void)) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int on_exit (void (*__func) (int __status, void *__arg), void *__arg)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern void exit (int __status) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__noreturn__));
extern void quick_exit (int __status) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__noreturn__));
extern void _Exit (int __status) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__noreturn__));
extern char *getenv (const char *__name) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1))) ;
extern char *secure_getenv (const char *__name)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1))) ;
extern int putenv (char *__string) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int setenv (const char *__name, const char *__value, int __replace)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2)));
extern int unsetenv (const char *__name) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int clearenv (void) __attribute__ ((__nothrow__ , __leaf__));
extern char *mktemp (char *__template) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int mkstemp (char *__template) __attribute__ ((__nonnull__ (1))) ;
extern int mkstemp64 (char *__template) __attribute__ ((__nonnull__ (1))) ;
extern int mkstemps (char *__template, int __suffixlen) __attribute__ ((__nonnull__ (1))) ;
extern int mkstemps64 (char *__template, int __suffixlen)
     __attribute__ ((__nonnull__ (1))) ;
extern char *mkdtemp (char *__template) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1))) ;
extern int mkostemp (char *__template, int __flags) __attribute__ ((__nonnull__ (1))) ;
extern int mkostemp64 (char *__template, int __flags) __attribute__ ((__nonnull__ (1))) ;
extern int mkostemps (char *__template, int __suffixlen, int __flags)
     __attribute__ ((__nonnull__ (1))) ;
extern int mkostemps64 (char *__template, int __suffixlen, int __flags)
     __attribute__ ((__nonnull__ (1))) ;
extern int system (const char *__command) ;
extern char *canonicalize_file_name (const char *__name)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1))) __attribute__ ((__malloc__))
     __attribute__ ((__malloc__ (__builtin_free, 1))) ;
extern char *realpath (const char *__restrict __name,
         char *__restrict __resolved) __attribute__ ((__nothrow__ , __leaf__)) ;
typedef int (*__compar_fn_t) (const void *, const void *);
typedef __compar_fn_t comparison_fn_t;
typedef int (*__compar_d_fn_t) (const void *, const void *, void *);
extern void *bsearch (const void *__key, const void *__base,
        size_t __nmemb, size_t __size, __compar_fn_t __compar)
     __attribute__ ((__nonnull__ (1, 2, 5))) ;
extern void qsort (void *__base, size_t __nmemb, size_t __size,
     __compar_fn_t __compar) __attribute__ ((__nonnull__ (1, 4)));
extern void qsort_r (void *__base, size_t __nmemb, size_t __size,
       __compar_d_fn_t __compar, void *__arg)
  __attribute__ ((__nonnull__ (1, 4)));
extern int abs (int __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)) ;
extern long int labs (long int __x) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)) ;
__extension__ extern long long int llabs (long long int __x)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)) ;
extern div_t div (int __numer, int __denom)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)) ;
extern ldiv_t ldiv (long int __numer, long int __denom)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)) ;
__extension__ extern lldiv_t lldiv (long long int __numer,
        long long int __denom)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__)) ;
extern char *ecvt (double __value, int __ndigit, int *__restrict __decpt,
     int *__restrict __sign) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (3, 4))) ;
extern char *fcvt (double __value, int __ndigit, int *__restrict __decpt,
     int *__restrict __sign) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (3, 4))) ;
extern char *gcvt (double __value, int __ndigit, char *__buf)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (3))) ;
extern char *qecvt (long double __value, int __ndigit,
      int *__restrict __decpt, int *__restrict __sign)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (3, 4))) ;
extern char *qfcvt (long double __value, int __ndigit,
      int *__restrict __decpt, int *__restrict __sign)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (3, 4))) ;
extern char *qgcvt (long double __value, int __ndigit, char *__buf)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (3))) ;
extern int ecvt_r (double __value, int __ndigit, int *__restrict __decpt,
     int *__restrict __sign, char *__restrict __buf,
     size_t __len) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (3, 4, 5)));
extern int fcvt_r (double __value, int __ndigit, int *__restrict __decpt,
     int *__restrict __sign, char *__restrict __buf,
     size_t __len) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (3, 4, 5)));
extern int qecvt_r (long double __value, int __ndigit,
      int *__restrict __decpt, int *__restrict __sign,
      char *__restrict __buf, size_t __len)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (3, 4, 5)));
extern int qfcvt_r (long double __value, int __ndigit,
      int *__restrict __decpt, int *__restrict __sign,
      char *__restrict __buf, size_t __len)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (3, 4, 5)));
extern int mblen (const char *__s, size_t __n) __attribute__ ((__nothrow__ , __leaf__));
extern int mbtowc (wchar_t *__restrict __pwc,
     const char *__restrict __s, size_t __n) __attribute__ ((__nothrow__ , __leaf__));
extern int wctomb (char *__s, wchar_t __wchar) __attribute__ ((__nothrow__ , __leaf__));
extern size_t mbstowcs (wchar_t *__restrict __pwcs,
   const char *__restrict __s, size_t __n) __attribute__ ((__nothrow__ , __leaf__))
    __attribute__ ((__access__ (__read_only__, 2)));
extern size_t wcstombs (char *__restrict __s,
   const wchar_t *__restrict __pwcs, size_t __n)
     __attribute__ ((__nothrow__ , __leaf__))
  __attribute__ ((__access__ (__write_only__, 1, 3)))
  __attribute__ ((__access__ (__read_only__, 2)));
extern int rpmatch (const char *__response) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1))) ;
extern int getsubopt (char **__restrict __optionp,
        char *const *__restrict __tokens,
        char **__restrict __valuep)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2, 3))) ;
extern int posix_openpt (int __oflag) ;
extern int grantpt (int __fd) __attribute__ ((__nothrow__ , __leaf__));
extern int unlockpt (int __fd) __attribute__ ((__nothrow__ , __leaf__));
extern char *ptsname (int __fd) __attribute__ ((__nothrow__ , __leaf__)) ;
extern int ptsname_r (int __fd, char *__buf, size_t __buflen)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2))) __attribute__ ((__access__ (__write_only__, 2, 3)));
extern int getpt (void);
extern int getloadavg (double __loadavg[], int __nelem)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));

typedef long int ptrdiff_t;
typedef struct {
  long long __max_align_ll __attribute__((__aligned__(__alignof__(long long))));
  long double __max_align_ld __attribute__((__aligned__(__alignof__(long double))));
} max_align_t;

extern void *memcpy (void *__restrict __dest, const void *__restrict __src,
       size_t __n) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern void *memmove (void *__dest, const void *__src, size_t __n)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern void *memccpy (void *__restrict __dest, const void *__restrict __src,
        int __c, size_t __n)
    __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2))) __attribute__ ((__access__ (__write_only__, 1, 4)));
extern void *memset (void *__s, int __c, size_t __n) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int memcmp (const void *__s1, const void *__s2, size_t __n)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2)));
extern int __memcmpeq (const void *__s1, const void *__s2, size_t __n)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2)));
extern void *memchr (const void *__s, int __c, size_t __n)
      __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1)));
extern void *rawmemchr (const void *__s, int __c)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1)));
extern void *memrchr (const void *__s, int __c, size_t __n)
      __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1)))
      __attribute__ ((__access__ (__read_only__, 1, 3)));
extern char *strcpy (char *__restrict __dest, const char *__restrict __src)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern char *strncpy (char *__restrict __dest,
        const char *__restrict __src, size_t __n)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern char *strcat (char *__restrict __dest, const char *__restrict __src)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern char *strncat (char *__restrict __dest, const char *__restrict __src,
        size_t __n) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int strcmp (const char *__s1, const char *__s2)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2)));
extern int strncmp (const char *__s1, const char *__s2, size_t __n)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2)));
extern int strcoll (const char *__s1, const char *__s2)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2)));
extern size_t strxfrm (char *__restrict __dest,
         const char *__restrict __src, size_t __n)
    __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2))) __attribute__ ((__access__ (__write_only__, 1, 3)));
extern int strcoll_l (const char *__s1, const char *__s2, locale_t __l)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2, 3)));
extern size_t strxfrm_l (char *__dest, const char *__src, size_t __n,
    locale_t __l) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2, 4)))
     __attribute__ ((__access__ (__write_only__, 1, 3)));
extern char *strdup (const char *__s)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__malloc__)) __attribute__ ((__nonnull__ (1)));
extern char *strndup (const char *__string, size_t __n)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__malloc__)) __attribute__ ((__nonnull__ (1)));
extern char *strchr (const char *__s, int __c)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1)));
extern char *strrchr (const char *__s, int __c)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1)));
extern char *strchrnul (const char *__s, int __c)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1)));
extern size_t strcspn (const char *__s, const char *__reject)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2)));
extern size_t strspn (const char *__s, const char *__accept)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2)));
extern char *strpbrk (const char *__s, const char *__accept)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2)));
extern char *strstr (const char *__haystack, const char *__needle)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2)));
extern char *strtok (char *__restrict __s, const char *__restrict __delim)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2)));
extern char *__strtok_r (char *__restrict __s,
    const char *__restrict __delim,
    char **__restrict __save_ptr)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2, 3)));
extern char *strtok_r (char *__restrict __s, const char *__restrict __delim,
         char **__restrict __save_ptr)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2, 3)));
extern char *strcasestr (const char *__haystack, const char *__needle)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2)));
extern void *memmem (const void *__haystack, size_t __haystacklen,
       const void *__needle, size_t __needlelen)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 3)))
    __attribute__ ((__access__ (__read_only__, 1, 2)))
    __attribute__ ((__access__ (__read_only__, 3, 4)));
extern void *__mempcpy (void *__restrict __dest,
   const void *__restrict __src, size_t __n)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern void *mempcpy (void *__restrict __dest,
        const void *__restrict __src, size_t __n)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern size_t strlen (const char *__s)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1)));
extern size_t strnlen (const char *__string, size_t __maxlen)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1)));
extern char *strerror (int __errnum) __attribute__ ((__nothrow__ , __leaf__));
extern char *strerror_r (int __errnum, char *__buf, size_t __buflen)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2))) __attribute__ ((__access__ (__write_only__, 2, 3)));
extern const char *strerrordesc_np (int __err) __attribute__ ((__nothrow__ , __leaf__));
extern const char *strerrorname_np (int __err) __attribute__ ((__nothrow__ , __leaf__));
extern char *strerror_l (int __errnum, locale_t __l) __attribute__ ((__nothrow__ , __leaf__));

extern int bcmp (const void *__s1, const void *__s2, size_t __n)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2)));
extern void bcopy (const void *__src, void *__dest, size_t __n)
  __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern void bzero (void *__s, size_t __n) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern char *index (const char *__s, int __c)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1)));
extern char *rindex (const char *__s, int __c)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1)));
extern int ffs (int __i) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern int ffsl (long int __l) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
__extension__ extern int ffsll (long long int __ll)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern int strcasecmp (const char *__s1, const char *__s2)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2)));
extern int strncasecmp (const char *__s1, const char *__s2, size_t __n)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2)));
extern int strcasecmp_l (const char *__s1, const char *__s2, locale_t __loc)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2, 3)));
extern int strncasecmp_l (const char *__s1, const char *__s2,
     size_t __n, locale_t __loc)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2, 4)));

extern void explicit_bzero (void *__s, size_t __n) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)))
    __attribute__ ((__access__ (__write_only__, 1, 2)));
extern char *strsep (char **__restrict __stringp,
       const char *__restrict __delim)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern char *strsignal (int __sig) __attribute__ ((__nothrow__ , __leaf__));
extern const char *sigabbrev_np (int __sig) __attribute__ ((__nothrow__ , __leaf__));
extern const char *sigdescr_np (int __sig) __attribute__ ((__nothrow__ , __leaf__));
extern char *__stpcpy (char *__restrict __dest, const char *__restrict __src)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern char *stpcpy (char *__restrict __dest, const char *__restrict __src)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern char *__stpncpy (char *__restrict __dest,
   const char *__restrict __src, size_t __n)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern char *stpncpy (char *__restrict __dest,
        const char *__restrict __src, size_t __n)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int strverscmp (const char *__s1, const char *__s2)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__pure__)) __attribute__ ((__nonnull__ (1, 2)));
extern char *strfry (char *__string) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern void *memfrob (void *__s, size_t __n) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)))
    __attribute__ ((__access__ (__read_write__, 1, 2)));
extern char *basename (const char *__filename) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));

typedef __uint8_t uint8_t;
typedef __uint16_t uint16_t;
typedef __uint32_t uint32_t;
typedef __uint64_t uint64_t;
typedef __int_least8_t int_least8_t;
typedef __int_least16_t int_least16_t;
typedef __int_least32_t int_least32_t;
typedef __int_least64_t int_least64_t;
typedef __uint_least8_t uint_least8_t;
typedef __uint_least16_t uint_least16_t;
typedef __uint_least32_t uint_least32_t;
typedef __uint_least64_t uint_least64_t;
typedef signed char int_fast8_t;
typedef long int int_fast16_t;
typedef long int int_fast32_t;
typedef long int int_fast64_t;
typedef unsigned char uint_fast8_t;
typedef unsigned long int uint_fast16_t;
typedef unsigned long int uint_fast32_t;
typedef unsigned long int uint_fast64_t;
typedef long int intptr_t;
typedef unsigned long int uintptr_t;
typedef __intmax_t intmax_t;
typedef __uintmax_t uintmax_t;
typedef int __gwchar_t;

typedef struct
  {
    long int quot;
    long int rem;
  } imaxdiv_t;
extern intmax_t imaxabs (intmax_t __n) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern imaxdiv_t imaxdiv (intmax_t __numer, intmax_t __denom)
      __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern intmax_t strtoimax (const char *__restrict __nptr,
      char **__restrict __endptr, int __base) __attribute__ ((__nothrow__ , __leaf__));
extern uintmax_t strtoumax (const char *__restrict __nptr,
       char ** __restrict __endptr, int __base) __attribute__ ((__nothrow__ , __leaf__));
extern intmax_t wcstoimax (const __gwchar_t *__restrict __nptr,
      __gwchar_t **__restrict __endptr, int __base)
     __attribute__ ((__nothrow__ , __leaf__));
extern uintmax_t wcstoumax (const __gwchar_t *__restrict __nptr,
       __gwchar_t ** __restrict __endptr, int __base)
     __attribute__ ((__nothrow__ , __leaf__));


typedef __socklen_t socklen_t;
extern int access (const char *__name, int __type) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int euidaccess (const char *__name, int __type)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int eaccess (const char *__name, int __type)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int execveat (int __fd, const char *__path, char *const __argv[],
                     char *const __envp[], int __flags)
    __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2, 3)));
extern int faccessat (int __fd, const char *__file, int __type, int __flag)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2))) ;
extern __off_t lseek (int __fd, __off_t __offset, int __whence) __attribute__ ((__nothrow__ , __leaf__));
extern __off64_t lseek64 (int __fd, __off64_t __offset, int __whence)
     __attribute__ ((__nothrow__ , __leaf__));
extern int close (int __fd);
extern void closefrom (int __lowfd) __attribute__ ((__nothrow__ , __leaf__));
extern ssize_t read (int __fd, void *__buf, size_t __nbytes)
    __attribute__ ((__access__ (__write_only__, 2, 3)));
extern ssize_t write (int __fd, const void *__buf, size_t __n)
    __attribute__ ((__access__ (__read_only__, 2, 3)));
extern ssize_t pread (int __fd, void *__buf, size_t __nbytes,
        __off_t __offset)
    __attribute__ ((__access__ (__write_only__, 2, 3)));
extern ssize_t pwrite (int __fd, const void *__buf, size_t __n,
         __off_t __offset)
    __attribute__ ((__access__ (__read_only__, 2, 3)));
extern ssize_t pread64 (int __fd, void *__buf, size_t __nbytes,
   __off64_t __offset)
    __attribute__ ((__access__ (__write_only__, 2, 3)));
extern ssize_t pwrite64 (int __fd, const void *__buf, size_t __n,
    __off64_t __offset)
    __attribute__ ((__access__ (__read_only__, 2, 3)));
extern int pipe (int __pipedes[2]) __attribute__ ((__nothrow__ , __leaf__)) ;
extern int pipe2 (int __pipedes[2], int __flags) __attribute__ ((__nothrow__ , __leaf__)) ;
extern unsigned int alarm (unsigned int __seconds) __attribute__ ((__nothrow__ , __leaf__));
extern unsigned int sleep (unsigned int __seconds);
extern __useconds_t ualarm (__useconds_t __value, __useconds_t __interval)
     __attribute__ ((__nothrow__ , __leaf__));
extern int usleep (__useconds_t __useconds);
extern int pause (void);
extern int chown (const char *__file, __uid_t __owner, __gid_t __group)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1))) ;
extern int fchown (int __fd, __uid_t __owner, __gid_t __group) __attribute__ ((__nothrow__ , __leaf__)) ;
extern int lchown (const char *__file, __uid_t __owner, __gid_t __group)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1))) ;
extern int fchownat (int __fd, const char *__file, __uid_t __owner,
       __gid_t __group, int __flag)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2))) ;
extern int chdir (const char *__path) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1))) ;
extern int fchdir (int __fd) __attribute__ ((__nothrow__ , __leaf__)) ;
extern char *getcwd (char *__buf, size_t __size) __attribute__ ((__nothrow__ , __leaf__)) ;
extern char *get_current_dir_name (void) __attribute__ ((__nothrow__ , __leaf__));
extern char *getwd (char *__buf)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1))) __attribute__ ((__deprecated__))
    __attribute__ ((__access__ (__write_only__, 1)));
extern int dup (int __fd) __attribute__ ((__nothrow__ , __leaf__)) ;
extern int dup2 (int __fd, int __fd2) __attribute__ ((__nothrow__ , __leaf__));
extern int dup3 (int __fd, int __fd2, int __flags) __attribute__ ((__nothrow__ , __leaf__));
extern char **__environ;
extern char **environ;
extern int execve (const char *__path, char *const __argv[],
     char *const __envp[]) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int fexecve (int __fd, char *const __argv[], char *const __envp[])
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2)));
extern int execv (const char *__path, char *const __argv[])
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int execle (const char *__path, const char *__arg, ...)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int execl (const char *__path, const char *__arg, ...)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int execvp (const char *__file, char *const __argv[])
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int execlp (const char *__file, const char *__arg, ...)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int execvpe (const char *__file, char *const __argv[],
      char *const __envp[])
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int nice (int __inc) __attribute__ ((__nothrow__ , __leaf__)) ;
extern void _exit (int __status) __attribute__ ((__noreturn__));
enum
  {
    _PC_LINK_MAX,
    _PC_MAX_CANON,
    _PC_MAX_INPUT,
    _PC_NAME_MAX,
    _PC_PATH_MAX,
    _PC_PIPE_BUF,
    _PC_CHOWN_RESTRICTED,
    _PC_NO_TRUNC,
    _PC_VDISABLE,
    _PC_SYNC_IO,
    _PC_ASYNC_IO,
    _PC_PRIO_IO,
    _PC_SOCK_MAXBUF,
    _PC_FILESIZEBITS,
    _PC_REC_INCR_XFER_SIZE,
    _PC_REC_MAX_XFER_SIZE,
    _PC_REC_MIN_XFER_SIZE,
    _PC_REC_XFER_ALIGN,
    _PC_ALLOC_SIZE_MIN,
    _PC_SYMLINK_MAX,
    _PC_2_SYMLINKS
  };
enum
  {
    _SC_ARG_MAX,
    _SC_CHILD_MAX,
    _SC_CLK_TCK,
    _SC_NGROUPS_MAX,
    _SC_OPEN_MAX,
    _SC_STREAM_MAX,
    _SC_TZNAME_MAX,
    _SC_JOB_CONTROL,
    _SC_SAVED_IDS,
    _SC_REALTIME_SIGNALS,
    _SC_PRIORITY_SCHEDULING,
    _SC_TIMERS,
    _SC_ASYNCHRONOUS_IO,
    _SC_PRIORITIZED_IO,
    _SC_SYNCHRONIZED_IO,
    _SC_FSYNC,
    _SC_MAPPED_FILES,
    _SC_MEMLOCK,
    _SC_MEMLOCK_RANGE,
    _SC_MEMORY_PROTECTION,
    _SC_MESSAGE_PASSING,
    _SC_SEMAPHORES,
    _SC_SHARED_MEMORY_OBJECTS,
    _SC_AIO_LISTIO_MAX,
    _SC_AIO_MAX,
    _SC_AIO_PRIO_DELTA_MAX,
    _SC_DELAYTIMER_MAX,
    _SC_MQ_OPEN_MAX,
    _SC_MQ_PRIO_MAX,
    _SC_VERSION,
    _SC_PAGESIZE,
    _SC_RTSIG_MAX,
    _SC_SEM_NSEMS_MAX,
    _SC_SEM_VALUE_MAX,
    _SC_SIGQUEUE_MAX,
    _SC_TIMER_MAX,
    _SC_BC_BASE_MAX,
    _SC_BC_DIM_MAX,
    _SC_BC_SCALE_MAX,
    _SC_BC_STRING_MAX,
    _SC_COLL_WEIGHTS_MAX,
    _SC_EQUIV_CLASS_MAX,
    _SC_EXPR_NEST_MAX,
    _SC_LINE_MAX,
    _SC_RE_DUP_MAX,
    _SC_CHARCLASS_NAME_MAX,
    _SC_2_VERSION,
    _SC_2_C_BIND,
    _SC_2_C_DEV,
    _SC_2_FORT_DEV,
    _SC_2_FORT_RUN,
    _SC_2_SW_DEV,
    _SC_2_LOCALEDEF,
    _SC_PII,
    _SC_PII_XTI,
    _SC_PII_SOCKET,
    _SC_PII_INTERNET,
    _SC_PII_OSI,
    _SC_POLL,
    _SC_SELECT,
    _SC_UIO_MAXIOV,
    _SC_IOV_MAX = _SC_UIO_MAXIOV,
    _SC_PII_INTERNET_STREAM,
    _SC_PII_INTERNET_DGRAM,
    _SC_PII_OSI_COTS,
    _SC_PII_OSI_CLTS,
    _SC_PII_OSI_M,
    _SC_T_IOV_MAX,
    _SC_THREADS,
    _SC_THREAD_SAFE_FUNCTIONS,
    _SC_GETGR_R_SIZE_MAX,
    _SC_GETPW_R_SIZE_MAX,
    _SC_LOGIN_NAME_MAX,
    _SC_TTY_NAME_MAX,
    _SC_THREAD_DESTRUCTOR_ITERATIONS,
    _SC_THREAD_KEYS_MAX,
    _SC_THREAD_STACK_MIN,
    _SC_THREAD_THREADS_MAX,
    _SC_THREAD_ATTR_STACKADDR,
    _SC_THREAD_ATTR_STACKSIZE,
    _SC_THREAD_PRIORITY_SCHEDULING,
    _SC_THREAD_PRIO_INHERIT,
    _SC_THREAD_PRIO_PROTECT,
    _SC_THREAD_PROCESS_SHARED,
    _SC_NPROCESSORS_CONF,
    _SC_NPROCESSORS_ONLN,
    _SC_PHYS_PAGES,
    _SC_AVPHYS_PAGES,
    _SC_ATEXIT_MAX,
    _SC_PASS_MAX,
    _SC_XOPEN_VERSION,
    _SC_XOPEN_XCU_VERSION,
    _SC_XOPEN_UNIX,
    _SC_XOPEN_CRYPT,
    _SC_XOPEN_ENH_I18N,
    _SC_XOPEN_SHM,
    _SC_2_CHAR_TERM,
    _SC_2_C_VERSION,
    _SC_2_UPE,
    _SC_XOPEN_XPG2,
    _SC_XOPEN_XPG3,
    _SC_XOPEN_XPG4,
    _SC_CHAR_BIT,
    _SC_CHAR_MAX,
    _SC_CHAR_MIN,
    _SC_INT_MAX,
    _SC_INT_MIN,
    _SC_LONG_BIT,
    _SC_WORD_BIT,
    _SC_MB_LEN_MAX,
    _SC_NZERO,
    _SC_SSIZE_MAX,
    _SC_SCHAR_MAX,
    _SC_SCHAR_MIN,
    _SC_SHRT_MAX,
    _SC_SHRT_MIN,
    _SC_UCHAR_MAX,
    _SC_UINT_MAX,
    _SC_ULONG_MAX,
    _SC_USHRT_MAX,
    _SC_NL_ARGMAX,
    _SC_NL_LANGMAX,
    _SC_NL_MSGMAX,
    _SC_NL_NMAX,
    _SC_NL_SETMAX,
    _SC_NL_TEXTMAX,
    _SC_XBS5_ILP32_OFF32,
    _SC_XBS5_ILP32_OFFBIG,
    _SC_XBS5_LP64_OFF64,
    _SC_XBS5_LPBIG_OFFBIG,
    _SC_XOPEN_LEGACY,
    _SC_XOPEN_REALTIME,
    _SC_XOPEN_REALTIME_THREADS,
    _SC_ADVISORY_INFO,
    _SC_BARRIERS,
    _SC_BASE,
    _SC_C_LANG_SUPPORT,
    _SC_C_LANG_SUPPORT_R,
    _SC_CLOCK_SELECTION,
    _SC_CPUTIME,
    _SC_THREAD_CPUTIME,
    _SC_DEVICE_IO,
    _SC_DEVICE_SPECIFIC,
    _SC_DEVICE_SPECIFIC_R,
    _SC_FD_MGMT,
    _SC_FIFO,
    _SC_PIPE,
    _SC_FILE_ATTRIBUTES,
    _SC_FILE_LOCKING,
    _SC_FILE_SYSTEM,
    _SC_MONOTONIC_CLOCK,
    _SC_MULTI_PROCESS,
    _SC_SINGLE_PROCESS,
    _SC_NETWORKING,
    _SC_READER_WRITER_LOCKS,
    _SC_SPIN_LOCKS,
    _SC_REGEXP,
    _SC_REGEX_VERSION,
    _SC_SHELL,
    _SC_SIGNALS,
    _SC_SPAWN,
    _SC_SPORADIC_SERVER,
    _SC_THREAD_SPORADIC_SERVER,
    _SC_SYSTEM_DATABASE,
    _SC_SYSTEM_DATABASE_R,
    _SC_TIMEOUTS,
    _SC_TYPED_MEMORY_OBJECTS,
    _SC_USER_GROUPS,
    _SC_USER_GROUPS_R,
    _SC_2_PBS,
    _SC_2_PBS_ACCOUNTING,
    _SC_2_PBS_LOCATE,
    _SC_2_PBS_MESSAGE,
    _SC_2_PBS_TRACK,
    _SC_SYMLOOP_MAX,
    _SC_STREAMS,
    _SC_2_PBS_CHECKPOINT,
    _SC_V6_ILP32_OFF32,
    _SC_V6_ILP32_OFFBIG,
    _SC_V6_LP64_OFF64,
    _SC_V6_LPBIG_OFFBIG,
    _SC_HOST_NAME_MAX,
    _SC_TRACE,
    _SC_TRACE_EVENT_FILTER,
    _SC_TRACE_INHERIT,
    _SC_TRACE_LOG,
    _SC_LEVEL1_ICACHE_SIZE,
    _SC_LEVEL1_ICACHE_ASSOC,
    _SC_LEVEL1_ICACHE_LINESIZE,
    _SC_LEVEL1_DCACHE_SIZE,
    _SC_LEVEL1_DCACHE_ASSOC,
    _SC_LEVEL1_DCACHE_LINESIZE,
    _SC_LEVEL2_CACHE_SIZE,
    _SC_LEVEL2_CACHE_ASSOC,
    _SC_LEVEL2_CACHE_LINESIZE,
    _SC_LEVEL3_CACHE_SIZE,
    _SC_LEVEL3_CACHE_ASSOC,
    _SC_LEVEL3_CACHE_LINESIZE,
    _SC_LEVEL4_CACHE_SIZE,
    _SC_LEVEL4_CACHE_ASSOC,
    _SC_LEVEL4_CACHE_LINESIZE,
    _SC_IPV6 = _SC_LEVEL1_ICACHE_SIZE + 50,
    _SC_RAW_SOCKETS,
    _SC_V7_ILP32_OFF32,
    _SC_V7_ILP32_OFFBIG,
    _SC_V7_LP64_OFF64,
    _SC_V7_LPBIG_OFFBIG,
    _SC_SS_REPL_MAX,
    _SC_TRACE_EVENT_NAME_MAX,
    _SC_TRACE_NAME_MAX,
    _SC_TRACE_SYS_MAX,
    _SC_TRACE_USER_EVENT_MAX,
    _SC_XOPEN_STREAMS,
    _SC_THREAD_ROBUST_PRIO_INHERIT,
    _SC_THREAD_ROBUST_PRIO_PROTECT,
    _SC_MINSIGSTKSZ,
    _SC_SIGSTKSZ
  };
enum
  {
    _CS_PATH,
    _CS_V6_WIDTH_RESTRICTED_ENVS,
    _CS_GNU_LIBC_VERSION,
    _CS_GNU_LIBPTHREAD_VERSION,
    _CS_V5_WIDTH_RESTRICTED_ENVS,
    _CS_V7_WIDTH_RESTRICTED_ENVS,
    _CS_LFS_CFLAGS = 1000,
    _CS_LFS_LDFLAGS,
    _CS_LFS_LIBS,
    _CS_LFS_LINTFLAGS,
    _CS_LFS64_CFLAGS,
    _CS_LFS64_LDFLAGS,
    _CS_LFS64_LIBS,
    _CS_LFS64_LINTFLAGS,
    _CS_XBS5_ILP32_OFF32_CFLAGS = 1100,
    _CS_XBS5_ILP32_OFF32_LDFLAGS,
    _CS_XBS5_ILP32_OFF32_LIBS,
    _CS_XBS5_ILP32_OFF32_LINTFLAGS,
    _CS_XBS5_ILP32_OFFBIG_CFLAGS,
    _CS_XBS5_ILP32_OFFBIG_LDFLAGS,
    _CS_XBS5_ILP32_OFFBIG_LIBS,
    _CS_XBS5_ILP32_OFFBIG_LINTFLAGS,
    _CS_XBS5_LP64_OFF64_CFLAGS,
    _CS_XBS5_LP64_OFF64_LDFLAGS,
    _CS_XBS5_LP64_OFF64_LIBS,
    _CS_XBS5_LP64_OFF64_LINTFLAGS,
    _CS_XBS5_LPBIG_OFFBIG_CFLAGS,
    _CS_XBS5_LPBIG_OFFBIG_LDFLAGS,
    _CS_XBS5_LPBIG_OFFBIG_LIBS,
    _CS_XBS5_LPBIG_OFFBIG_LINTFLAGS,
    _CS_POSIX_V6_ILP32_OFF32_CFLAGS,
    _CS_POSIX_V6_ILP32_OFF32_LDFLAGS,
    _CS_POSIX_V6_ILP32_OFF32_LIBS,
    _CS_POSIX_V6_ILP32_OFF32_LINTFLAGS,
    _CS_POSIX_V6_ILP32_OFFBIG_CFLAGS,
    _CS_POSIX_V6_ILP32_OFFBIG_LDFLAGS,
    _CS_POSIX_V6_ILP32_OFFBIG_LIBS,
    _CS_POSIX_V6_ILP32_OFFBIG_LINTFLAGS,
    _CS_POSIX_V6_LP64_OFF64_CFLAGS,
    _CS_POSIX_V6_LP64_OFF64_LDFLAGS,
    _CS_POSIX_V6_LP64_OFF64_LIBS,
    _CS_POSIX_V6_LP64_OFF64_LINTFLAGS,
    _CS_POSIX_V6_LPBIG_OFFBIG_CFLAGS,
    _CS_POSIX_V6_LPBIG_OFFBIG_LDFLAGS,
    _CS_POSIX_V6_LPBIG_OFFBIG_LIBS,
    _CS_POSIX_V6_LPBIG_OFFBIG_LINTFLAGS,
    _CS_POSIX_V7_ILP32_OFF32_CFLAGS,
    _CS_POSIX_V7_ILP32_OFF32_LDFLAGS,
    _CS_POSIX_V7_ILP32_OFF32_LIBS,
    _CS_POSIX_V7_ILP32_OFF32_LINTFLAGS,
    _CS_POSIX_V7_ILP32_OFFBIG_CFLAGS,
    _CS_POSIX_V7_ILP32_OFFBIG_LDFLAGS,
    _CS_POSIX_V7_ILP32_OFFBIG_LIBS,
    _CS_POSIX_V7_ILP32_OFFBIG_LINTFLAGS,
    _CS_POSIX_V7_LP64_OFF64_CFLAGS,
    _CS_POSIX_V7_LP64_OFF64_LDFLAGS,
    _CS_POSIX_V7_LP64_OFF64_LIBS,
    _CS_POSIX_V7_LP64_OFF64_LINTFLAGS,
    _CS_POSIX_V7_LPBIG_OFFBIG_CFLAGS,
    _CS_POSIX_V7_LPBIG_OFFBIG_LDFLAGS,
    _CS_POSIX_V7_LPBIG_OFFBIG_LIBS,
    _CS_POSIX_V7_LPBIG_OFFBIG_LINTFLAGS,
    _CS_V6_ENV,
    _CS_V7_ENV
  };
extern long int pathconf (const char *__path, int __name)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern long int fpathconf (int __fd, int __name) __attribute__ ((__nothrow__ , __leaf__));
extern long int sysconf (int __name) __attribute__ ((__nothrow__ , __leaf__));
extern size_t confstr (int __name, char *__buf, size_t __len) __attribute__ ((__nothrow__ , __leaf__))
    __attribute__ ((__access__ (__write_only__, 2, 3)));
extern __pid_t getpid (void) __attribute__ ((__nothrow__ , __leaf__));
extern __pid_t getppid (void) __attribute__ ((__nothrow__ , __leaf__));
extern __pid_t getpgrp (void) __attribute__ ((__nothrow__ , __leaf__));
extern __pid_t __getpgid (__pid_t __pid) __attribute__ ((__nothrow__ , __leaf__));
extern __pid_t getpgid (__pid_t __pid) __attribute__ ((__nothrow__ , __leaf__));
extern int setpgid (__pid_t __pid, __pid_t __pgid) __attribute__ ((__nothrow__ , __leaf__));
extern int setpgrp (void) __attribute__ ((__nothrow__ , __leaf__));
extern __pid_t setsid (void) __attribute__ ((__nothrow__ , __leaf__));
extern __pid_t getsid (__pid_t __pid) __attribute__ ((__nothrow__ , __leaf__));
extern __uid_t getuid (void) __attribute__ ((__nothrow__ , __leaf__));
extern __uid_t geteuid (void) __attribute__ ((__nothrow__ , __leaf__));
extern __gid_t getgid (void) __attribute__ ((__nothrow__ , __leaf__));
extern __gid_t getegid (void) __attribute__ ((__nothrow__ , __leaf__));
extern int getgroups (int __size, __gid_t __list[]) __attribute__ ((__nothrow__ , __leaf__))
    __attribute__ ((__access__ (__write_only__, 2, 1)));
extern int group_member (__gid_t __gid) __attribute__ ((__nothrow__ , __leaf__));
extern int setuid (__uid_t __uid) __attribute__ ((__nothrow__ , __leaf__)) ;
extern int setreuid (__uid_t __ruid, __uid_t __euid) __attribute__ ((__nothrow__ , __leaf__)) ;
extern int seteuid (__uid_t __uid) __attribute__ ((__nothrow__ , __leaf__)) ;
extern int setgid (__gid_t __gid) __attribute__ ((__nothrow__ , __leaf__)) ;
extern int setregid (__gid_t __rgid, __gid_t __egid) __attribute__ ((__nothrow__ , __leaf__)) ;
extern int setegid (__gid_t __gid) __attribute__ ((__nothrow__ , __leaf__)) ;
extern int getresuid (__uid_t *__ruid, __uid_t *__euid, __uid_t *__suid)
     __attribute__ ((__nothrow__ , __leaf__));
extern int getresgid (__gid_t *__rgid, __gid_t *__egid, __gid_t *__sgid)
     __attribute__ ((__nothrow__ , __leaf__));
extern int setresuid (__uid_t __ruid, __uid_t __euid, __uid_t __suid)
     __attribute__ ((__nothrow__ , __leaf__)) ;
extern int setresgid (__gid_t __rgid, __gid_t __egid, __gid_t __sgid)
     __attribute__ ((__nothrow__ , __leaf__)) ;
extern __pid_t fork (void) __attribute__ ((__nothrow__));
extern __pid_t vfork (void) __attribute__ ((__nothrow__ , __leaf__));
extern __pid_t _Fork (void) __attribute__ ((__nothrow__ , __leaf__));
extern char *ttyname (int __fd) __attribute__ ((__nothrow__ , __leaf__));
extern int ttyname_r (int __fd, char *__buf, size_t __buflen)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2)))
     __attribute__ ((__access__ (__write_only__, 2, 3)));
extern int isatty (int __fd) __attribute__ ((__nothrow__ , __leaf__));
extern int ttyslot (void) __attribute__ ((__nothrow__ , __leaf__));
extern int link (const char *__from, const char *__to)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2))) ;
extern int linkat (int __fromfd, const char *__from, int __tofd,
     const char *__to, int __flags)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2, 4))) ;
extern int symlink (const char *__from, const char *__to)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2))) ;
extern ssize_t readlink (const char *__restrict __path,
    char *__restrict __buf, size_t __len)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)))
     __attribute__ ((__access__ (__write_only__, 2, 3)));
extern int symlinkat (const char *__from, int __tofd,
        const char *__to) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 3))) ;
extern ssize_t readlinkat (int __fd, const char *__restrict __path,
      char *__restrict __buf, size_t __len)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2, 3)))
     __attribute__ ((__access__ (__write_only__, 3, 4)));
extern int unlink (const char *__name) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int unlinkat (int __fd, const char *__name, int __flag)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2)));
extern int rmdir (const char *__path) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern __pid_t tcgetpgrp (int __fd) __attribute__ ((__nothrow__ , __leaf__));
extern int tcsetpgrp (int __fd, __pid_t __pgrp_id) __attribute__ ((__nothrow__ , __leaf__));
extern char *getlogin (void);
extern int getlogin_r (char *__name, size_t __name_len) __attribute__ ((__nonnull__ (1)))
    __attribute__ ((__access__ (__write_only__, 1, 2)));
extern int setlogin (const char *__name) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));

extern char *optarg;
extern int optind;
extern int opterr;
extern int optopt;
extern int getopt (int ___argc, char *const *___argv, const char *__shortopts)
       __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2, 3)));



extern int gethostname (char *__name, size_t __len) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)))
    __attribute__ ((__access__ (__write_only__, 1, 2)));
extern int sethostname (const char *__name, size_t __len)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1))) __attribute__ ((__access__ (__read_only__, 1, 2)));
extern int sethostid (long int __id) __attribute__ ((__nothrow__ , __leaf__)) ;
extern int getdomainname (char *__name, size_t __len)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)))
     __attribute__ ((__access__ (__write_only__, 1, 2)));
extern int setdomainname (const char *__name, size_t __len)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1))) __attribute__ ((__access__ (__read_only__, 1, 2)));
extern int vhangup (void) __attribute__ ((__nothrow__ , __leaf__));
extern int revoke (const char *__file) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1))) ;
extern int profil (unsigned short int *__sample_buffer, size_t __size,
     size_t __offset, unsigned int __scale)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int acct (const char *__name) __attribute__ ((__nothrow__ , __leaf__));
extern char *getusershell (void) __attribute__ ((__nothrow__ , __leaf__));
extern void endusershell (void) __attribute__ ((__nothrow__ , __leaf__));
extern void setusershell (void) __attribute__ ((__nothrow__ , __leaf__));
extern int daemon (int __nochdir, int __noclose) __attribute__ ((__nothrow__ , __leaf__)) ;
extern int chroot (const char *__path) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1))) ;
extern char *getpass (const char *__prompt) __attribute__ ((__nonnull__ (1)));
extern int fsync (int __fd);
extern int syncfs (int __fd) __attribute__ ((__nothrow__ , __leaf__));
extern long int gethostid (void);
extern void sync (void) __attribute__ ((__nothrow__ , __leaf__));
extern int getpagesize (void) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern int getdtablesize (void) __attribute__ ((__nothrow__ , __leaf__));
extern int truncate (const char *__file, __off_t __length)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1))) ;
extern int truncate64 (const char *__file, __off64_t __length)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1))) ;
extern int ftruncate (int __fd, __off_t __length) __attribute__ ((__nothrow__ , __leaf__)) ;
extern int ftruncate64 (int __fd, __off64_t __length) __attribute__ ((__nothrow__ , __leaf__)) ;
extern int brk (void *__addr) __attribute__ ((__nothrow__ , __leaf__)) ;
extern void *sbrk (intptr_t __delta) __attribute__ ((__nothrow__ , __leaf__));
extern long int syscall (long int __sysno, ...) __attribute__ ((__nothrow__ , __leaf__));
extern int lockf (int __fd, int __cmd, __off_t __len) ;
extern int lockf64 (int __fd, int __cmd, __off64_t __len) ;
ssize_t copy_file_range (int __infd, __off64_t *__pinoff,
    int __outfd, __off64_t *__poutoff,
    size_t __length, unsigned int __flags);
extern int fdatasync (int __fildes);
extern char *crypt (const char *__key, const char *__salt)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern void swab (const void *__restrict __from, void *__restrict __to,
    ssize_t __n) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)))
    __attribute__ ((__access__ (__read_only__, 1, 3)))
    __attribute__ ((__access__ (__write_only__, 2, 3)));
int getentropy (void *__buffer, size_t __length)
    __attribute__ ((__access__ (__write_only__, 1, 2)));
extern int close_range (unsigned int __fd, unsigned int __max_fd,
   int __flags) __attribute__ ((__nothrow__ , __leaf__));
extern __pid_t gettid (void) __attribute__ ((__nothrow__ , __leaf__));


#pragma GCC visibility push(default)

[[nodiscard]]
__attribute__((__malloc__))
__attribute__((__returns_nonnull__))
__attribute__((__alloc_size__ (1)))
void *ruby_xmalloc(size_t size)

;
[[nodiscard]]
__attribute__((__malloc__))
__attribute__((__returns_nonnull__))
__attribute__((__alloc_size__ (1,2)))
void *ruby_xmalloc2(size_t nelems, size_t elemsiz)

;
[[nodiscard]]
__attribute__((__malloc__))
__attribute__((__returns_nonnull__))
__attribute__((__alloc_size__ (1,2)))
void *ruby_xcalloc(size_t nelems, size_t elemsiz)

;
[[nodiscard]]
__attribute__((__returns_nonnull__))
__attribute__((__alloc_size__ (2)))
void *ruby_xrealloc(void *ptr, size_t newsiz)

;
[[nodiscard]]
__attribute__((__returns_nonnull__))
__attribute__((__alloc_size__ (2,3)))
void *ruby_xrealloc2(void *ptr, size_t newelems, size_t newsiz)

;
void ruby_xfree(void *ptr)

;

#pragma GCC visibility pop


#pragma GCC visibility push(default)

__attribute__((__noreturn__))
__attribute__((__cold__))
void rb_assert_failure(const char *file, int line, const char *name, const char *expr);
__attribute__((__noreturn__))
__attribute__((__cold__))
__attribute__((__format__(__printf__, 5, 6)))
void rb_assert_failure_detail(const char *file, int line, const char *name, const char *expr, const char *fmt, ...);

#pragma GCC visibility pop

struct timex
{
  unsigned int modes;
  __syscall_slong_t offset;
  __syscall_slong_t freq;
  __syscall_slong_t maxerror;
  __syscall_slong_t esterror;
  int status;
  __syscall_slong_t constant;
  __syscall_slong_t precision;
  __syscall_slong_t tolerance;
  struct timeval time;
  __syscall_slong_t tick;
  __syscall_slong_t ppsfreq;
  __syscall_slong_t jitter;
  int shift;
  __syscall_slong_t stabil;
  __syscall_slong_t jitcnt;
  __syscall_slong_t calcnt;
  __syscall_slong_t errcnt;
  __syscall_slong_t stbcnt;
  int tai;
  int :32; int :32; int :32; int :32;
  int :32; int :32; int :32; int :32;
  int :32; int :32; int :32;
};

extern int clock_adjtime (__clockid_t __clock_id, struct timex *__utx) __attribute__ ((__nothrow__ , __leaf__));

struct tm
{
  int tm_sec;
  int tm_min;
  int tm_hour;
  int tm_mday;
  int tm_mon;
  int tm_year;
  int tm_wday;
  int tm_yday;
  int tm_isdst;
  long int tm_gmtoff;
  const char *tm_zone;
};
struct itimerspec
  {
    struct timespec it_interval;
    struct timespec it_value;
  };
struct sigevent;

extern clock_t clock (void) __attribute__ ((__nothrow__ , __leaf__));
extern time_t time (time_t *__timer) __attribute__ ((__nothrow__ , __leaf__));
extern double difftime (time_t __time1, time_t __time0)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern time_t mktime (struct tm *__tp) __attribute__ ((__nothrow__ , __leaf__));
extern size_t strftime (char *__restrict __s, size_t __maxsize,
   const char *__restrict __format,
   const struct tm *__restrict __tp) __attribute__ ((__nothrow__ , __leaf__));
extern char *strptime (const char *__restrict __s,
         const char *__restrict __fmt, struct tm *__tp)
     __attribute__ ((__nothrow__ , __leaf__));
extern size_t strftime_l (char *__restrict __s, size_t __maxsize,
     const char *__restrict __format,
     const struct tm *__restrict __tp,
     locale_t __loc) __attribute__ ((__nothrow__ , __leaf__));
extern char *strptime_l (const char *__restrict __s,
    const char *__restrict __fmt, struct tm *__tp,
    locale_t __loc) __attribute__ ((__nothrow__ , __leaf__));
extern struct tm *gmtime (const time_t *__timer) __attribute__ ((__nothrow__ , __leaf__));
extern struct tm *localtime (const time_t *__timer) __attribute__ ((__nothrow__ , __leaf__));
extern struct tm *gmtime_r (const time_t *__restrict __timer,
       struct tm *__restrict __tp) __attribute__ ((__nothrow__ , __leaf__));
extern struct tm *localtime_r (const time_t *__restrict __timer,
          struct tm *__restrict __tp) __attribute__ ((__nothrow__ , __leaf__));
extern char *asctime (const struct tm *__tp) __attribute__ ((__nothrow__ , __leaf__));
extern char *ctime (const time_t *__timer) __attribute__ ((__nothrow__ , __leaf__));
extern char *asctime_r (const struct tm *__restrict __tp,
   char *__restrict __buf) __attribute__ ((__nothrow__ , __leaf__));
extern char *ctime_r (const time_t *__restrict __timer,
        char *__restrict __buf) __attribute__ ((__nothrow__ , __leaf__));
extern char *__tzname[2];
extern int __daylight;
extern long int __timezone;
extern char *tzname[2];
extern void tzset (void) __attribute__ ((__nothrow__ , __leaf__));
extern int daylight;
extern long int timezone;
extern time_t timegm (struct tm *__tp) __attribute__ ((__nothrow__ , __leaf__));
extern time_t timelocal (struct tm *__tp) __attribute__ ((__nothrow__ , __leaf__));
extern int dysize (int __year) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern int nanosleep (const struct timespec *__requested_time,
        struct timespec *__remaining);
extern int clock_getres (clockid_t __clock_id, struct timespec *__res) __attribute__ ((__nothrow__ , __leaf__));
extern int clock_gettime (clockid_t __clock_id, struct timespec *__tp) __attribute__ ((__nothrow__ , __leaf__));
extern int clock_settime (clockid_t __clock_id, const struct timespec *__tp)
     __attribute__ ((__nothrow__ , __leaf__));
extern int clock_nanosleep (clockid_t __clock_id, int __flags,
       const struct timespec *__req,
       struct timespec *__rem);
extern int clock_getcpuclockid (pid_t __pid, clockid_t *__clock_id) __attribute__ ((__nothrow__ , __leaf__));
extern int timer_create (clockid_t __clock_id,
    struct sigevent *__restrict __evp,
    timer_t *__restrict __timerid) __attribute__ ((__nothrow__ , __leaf__));
extern int timer_delete (timer_t __timerid) __attribute__ ((__nothrow__ , __leaf__));
extern int timer_settime (timer_t __timerid, int __flags,
     const struct itimerspec *__restrict __value,
     struct itimerspec *__restrict __ovalue) __attribute__ ((__nothrow__ , __leaf__));
extern int timer_gettime (timer_t __timerid, struct itimerspec *__value)
     __attribute__ ((__nothrow__ , __leaf__));
extern int timer_getoverrun (timer_t __timerid) __attribute__ ((__nothrow__ , __leaf__));
extern int timespec_get (struct timespec *__ts, int __base)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int timespec_getres (struct timespec *__ts, int __base)
     __attribute__ ((__nothrow__ , __leaf__));
extern int getdate_err;
extern struct tm *getdate (const char *__string);
extern int getdate_r (const char *__restrict __string,
        struct tm *__restrict __resbufp);


struct timezone
  {
    int tz_minuteswest;
    int tz_dsttime;
  };
extern int gettimeofday (struct timeval *__restrict __tv,
    void *__restrict __tz) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int settimeofday (const struct timeval *__tv,
    const struct timezone *__tz)
     __attribute__ ((__nothrow__ , __leaf__));
extern int adjtime (const struct timeval *__delta,
      struct timeval *__olddelta) __attribute__ ((__nothrow__ , __leaf__));
enum __itimer_which
  {
    ITIMER_REAL = 0,
    ITIMER_VIRTUAL = 1,
    ITIMER_PROF = 2
  };
struct itimerval
  {
    struct timeval it_interval;
    struct timeval it_value;
  };
typedef enum __itimer_which __itimer_which_t;
extern int getitimer (__itimer_which_t __which,
        struct itimerval *__value) __attribute__ ((__nothrow__ , __leaf__));
extern int setitimer (__itimer_which_t __which,
        const struct itimerval *__restrict __new,
        struct itimerval *__restrict __old) __attribute__ ((__nothrow__ , __leaf__));
extern int utimes (const char *__file, const struct timeval __tvp[2])
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int lutimes (const char *__file, const struct timeval __tvp[2])
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int futimes (int __fd, const struct timeval __tvp[2]) __attribute__ ((__nothrow__ , __leaf__));
extern int futimesat (int __fd, const char *__file,
        const struct timeval __tvp[2]) __attribute__ ((__nothrow__ , __leaf__));


#pragma GCC visibility push(default)

extern size_t strlcpy(char *, const char*, size_t);
extern size_t strlcat(char *, const char*, size_t);
__attribute__((__format__(__printf__, 1, 2)))
extern void setproctitle(const char *fmt, ...);

#pragma GCC visibility pop

__attribute__ ((__visibility__("default"))) extern unsigned long long __attribute__((weak))
ruby_abi_version(void)
{
    return 1;
}

extern long int __sysconf (int __name) __attribute__ ((__nothrow__ , __leaf__));

typedef unsigned long VALUE;
typedef unsigned long ID;
__extension__ _Static_assert(4 == sizeof(int), "sizeof_int" ": " "SIZEOF_INT == sizeof(int)");
__extension__ _Static_assert(8 == sizeof(long), "sizeof_long" ": " "SIZEOF_LONG == sizeof(long)");
__extension__ _Static_assert(8 == sizeof(long long), "sizeof_long_long" ": " "SIZEOF_LONG_LONG == sizeof(LONG_LONG)");
__extension__ _Static_assert(8 == sizeof(void *), "sizeof_voidp" ": " "SIZEOF_VOIDP == sizeof(void *)");

#pragma GCC visibility push(default)

VALUE rb_class_new(VALUE super);
VALUE rb_mod_init_copy(VALUE clone, VALUE orig);
void rb_check_inheritable(VALUE super);
VALUE rb_define_class_id(ID id, VALUE super);
VALUE rb_define_class_id_under(VALUE outer, ID id, VALUE super);
VALUE rb_module_new(void);
VALUE rb_refinement_new(void);
VALUE rb_define_module_id(ID id);
VALUE rb_define_module_id_under(VALUE outer, ID id);
VALUE rb_mod_included_modules(VALUE mod);
VALUE rb_mod_include_p(VALUE child, VALUE parent);
VALUE rb_mod_ancestors(VALUE mod);
VALUE rb_class_descendants(VALUE klass);
VALUE rb_class_subclasses(VALUE klass);
VALUE rb_class_attached_object(VALUE klass);
VALUE rb_class_instance_methods(int argc, const VALUE *argv, VALUE mod);
VALUE rb_class_public_instance_methods(int argc, const VALUE *argv, VALUE mod);
VALUE rb_class_protected_instance_methods(int argc, const VALUE *argv, VALUE mod);
VALUE rb_class_private_instance_methods(int argc, const VALUE *argv, VALUE mod);
VALUE rb_obj_singleton_methods(int argc, const VALUE *argv, VALUE obj);
void rb_define_method_id(VALUE klass, ID mid, VALUE (*func)(), int arity);
void rb_undef(VALUE mod, ID mid);
__attribute__((__nonnull__ ()))
void rb_define_protected_method(VALUE klass, const char *mid, VALUE (*func)(), int arity);
__attribute__((__nonnull__ ()))
void rb_define_private_method(VALUE klass, const char *mid, VALUE (*func)(), int arity);
__attribute__((__nonnull__ ()))
void rb_define_singleton_method(VALUE obj, const char *mid, VALUE(*func)(), int arity);
VALUE rb_singleton_class(VALUE obj);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

int rb_sourceline(void);
const char *rb_sourcefile(void);
int rb_frame_method_id_and_class(ID *idp, VALUE *klassp);
VALUE rb_check_funcall(VALUE recv, ID mid, int argc, const VALUE *argv);
VALUE rb_check_funcall_kw(VALUE recv, ID mid, int argc, const VALUE *argv, int kw_splat);
VALUE rb_eval_cmd_kw(VALUE cmd, VALUE arg, int kw_splat);
VALUE rb_apply(VALUE recv, ID mid, VALUE args);
VALUE rb_obj_instance_eval(int argc, const VALUE *argv, VALUE recv);
VALUE rb_obj_instance_exec(int argc, const VALUE *argv, VALUE recv);
VALUE rb_mod_module_eval(int argc, const VALUE *argv, VALUE mod);
VALUE rb_mod_module_exec(int argc, const VALUE *argv, VALUE mod);
typedef VALUE (*rb_alloc_func_t)(VALUE klass);
void rb_define_alloc_func(VALUE klass, rb_alloc_func_t func);
void rb_undef_alloc_func(VALUE klass);
rb_alloc_func_t rb_get_alloc_func(VALUE klass);
void rb_clear_constant_cache_for_id(ID id);
void rb_alias(VALUE klass, ID dst, ID src);
void rb_attr(VALUE klass, ID name, int need_reader, int need_writer, int honour_visibility);
__attribute__((__nonnull__ ()))
void rb_remove_method(VALUE klass, const char *name);
void rb_remove_method_id(VALUE klass, ID mid);
int rb_method_boundp(VALUE klass, ID id, int ex);
int rb_method_basic_definition_p(VALUE klass, ID mid);
int rb_obj_respond_to(VALUE obj, ID mid, int private_p);
int rb_respond_to(VALUE obj, ID mid);
__attribute__((__noreturn__))
VALUE rb_f_notimplement(int argc, const VALUE *argv, VALUE obj, VALUE marker);
void rb_backtrace(void);
VALUE rb_make_backtrace(void);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

__attribute__((__nonnull__ ()))
void rb_define_method(VALUE klass, const char *mid, VALUE (*func)(), int arity);
__attribute__((__nonnull__ ()))
void rb_define_module_function(VALUE klass, const char *mid, VALUE (*func)(), int arity);
__attribute__((__nonnull__ ()))
void rb_define_global_function(const char *mid, VALUE (*func)(), int arity);
__attribute__((__nonnull__ ()))
void rb_undef_method(VALUE klass, const char *name);
__attribute__((__nonnull__ ()))
void rb_define_alias(VALUE klass, const char *dst, const char *src);
__attribute__((__nonnull__ ()))
void rb_define_attr(VALUE klass, const char *name, int read, int write);

#pragma GCC visibility pop

[[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_singleton_method"))) static void rb_define_singleton_method_notimpl(VALUE, const char *, VALUE(*)(int, const VALUE *, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_singleton_method"))) static void rb_define_singleton_method_m3(VALUE, const char *, VALUE(*)(), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_singleton_method"))) static void rb_define_singleton_method_m2(VALUE, const char *, VALUE(*)(VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_singleton_method"))) static void rb_define_singleton_method_m1(VALUE, const char *, VALUE(*)(int, union { VALUE *x; const VALUE *y; } __attribute__((__transparent_union__)), VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_singleton_method"))) static void rb_define_singleton_method_00(VALUE, const char *, VALUE(*)(VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_singleton_method"))) static void rb_define_singleton_method_01(VALUE, const char *, VALUE(*)(VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_singleton_method"))) static void rb_define_singleton_method_02(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_singleton_method"))) static void rb_define_singleton_method_03(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_singleton_method"))) static void rb_define_singleton_method_04(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_singleton_method"))) static void rb_define_singleton_method_05(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_singleton_method"))) static void rb_define_singleton_method_06(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_singleton_method"))) static void rb_define_singleton_method_07(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_singleton_method"))) static void rb_define_singleton_method_08(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_singleton_method"))) static void rb_define_singleton_method_09(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_singleton_method"))) static void rb_define_singleton_method_10(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_singleton_method"))) static void rb_define_singleton_method_11(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_singleton_method"))) static void rb_define_singleton_method_12(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_singleton_method"))) static void rb_define_singleton_method_13(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_singleton_method"))) static void rb_define_singleton_method_14(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_singleton_method"))) static void rb_define_singleton_method_15(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int);
[[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_protected_method"))) static void rb_define_protected_method_notimpl(VALUE, const char *, VALUE(*)(int, const VALUE *, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_protected_method"))) static void rb_define_protected_method_m3(VALUE, const char *, VALUE(*)(), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_protected_method"))) static void rb_define_protected_method_m2(VALUE, const char *, VALUE(*)(VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_protected_method"))) static void rb_define_protected_method_m1(VALUE, const char *, VALUE(*)(int, union { VALUE *x; const VALUE *y; } __attribute__((__transparent_union__)), VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_protected_method"))) static void rb_define_protected_method_00(VALUE, const char *, VALUE(*)(VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_protected_method"))) static void rb_define_protected_method_01(VALUE, const char *, VALUE(*)(VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_protected_method"))) static void rb_define_protected_method_02(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_protected_method"))) static void rb_define_protected_method_03(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_protected_method"))) static void rb_define_protected_method_04(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_protected_method"))) static void rb_define_protected_method_05(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_protected_method"))) static void rb_define_protected_method_06(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_protected_method"))) static void rb_define_protected_method_07(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_protected_method"))) static void rb_define_protected_method_08(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_protected_method"))) static void rb_define_protected_method_09(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_protected_method"))) static void rb_define_protected_method_10(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_protected_method"))) static void rb_define_protected_method_11(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_protected_method"))) static void rb_define_protected_method_12(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_protected_method"))) static void rb_define_protected_method_13(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_protected_method"))) static void rb_define_protected_method_14(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_protected_method"))) static void rb_define_protected_method_15(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int);
[[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_private_method"))) static void rb_define_private_method_notimpl(VALUE, const char *, VALUE(*)(int, const VALUE *, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_private_method"))) static void rb_define_private_method_m3(VALUE, const char *, VALUE(*)(), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_private_method"))) static void rb_define_private_method_m2(VALUE, const char *, VALUE(*)(VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_private_method"))) static void rb_define_private_method_m1(VALUE, const char *, VALUE(*)(int, union { VALUE *x; const VALUE *y; } __attribute__((__transparent_union__)), VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_private_method"))) static void rb_define_private_method_00(VALUE, const char *, VALUE(*)(VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_private_method"))) static void rb_define_private_method_01(VALUE, const char *, VALUE(*)(VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_private_method"))) static void rb_define_private_method_02(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_private_method"))) static void rb_define_private_method_03(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_private_method"))) static void rb_define_private_method_04(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_private_method"))) static void rb_define_private_method_05(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_private_method"))) static void rb_define_private_method_06(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_private_method"))) static void rb_define_private_method_07(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_private_method"))) static void rb_define_private_method_08(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_private_method"))) static void rb_define_private_method_09(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_private_method"))) static void rb_define_private_method_10(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_private_method"))) static void rb_define_private_method_11(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_private_method"))) static void rb_define_private_method_12(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_private_method"))) static void rb_define_private_method_13(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_private_method"))) static void rb_define_private_method_14(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_private_method"))) static void rb_define_private_method_15(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int);
[[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_module_function"))) static void rb_define_module_function_notimpl(VALUE, const char *, VALUE(*)(int, const VALUE *, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_module_function"))) static void rb_define_module_function_m3(VALUE, const char *, VALUE(*)(), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_module_function"))) static void rb_define_module_function_m2(VALUE, const char *, VALUE(*)(VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_module_function"))) static void rb_define_module_function_m1(VALUE, const char *, VALUE(*)(int, union { VALUE *x; const VALUE *y; } __attribute__((__transparent_union__)), VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_module_function"))) static void rb_define_module_function_00(VALUE, const char *, VALUE(*)(VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_module_function"))) static void rb_define_module_function_01(VALUE, const char *, VALUE(*)(VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_module_function"))) static void rb_define_module_function_02(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_module_function"))) static void rb_define_module_function_03(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_module_function"))) static void rb_define_module_function_04(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_module_function"))) static void rb_define_module_function_05(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_module_function"))) static void rb_define_module_function_06(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_module_function"))) static void rb_define_module_function_07(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_module_function"))) static void rb_define_module_function_08(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_module_function"))) static void rb_define_module_function_09(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_module_function"))) static void rb_define_module_function_10(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_module_function"))) static void rb_define_module_function_11(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_module_function"))) static void rb_define_module_function_12(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_module_function"))) static void rb_define_module_function_13(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_module_function"))) static void rb_define_module_function_14(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_module_function"))) static void rb_define_module_function_15(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int);
[[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_global_function"))) static void rb_define_global_function_notimpl(const char *, VALUE(*)(int, const VALUE *, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_global_function"))) static void rb_define_global_function_m3(const char *, VALUE(*)(), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_global_function"))) static void rb_define_global_function_m2(const char *, VALUE(*)(VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_global_function"))) static void rb_define_global_function_m1(const char *, VALUE(*)(int, union { VALUE *x; const VALUE *y; } __attribute__((__transparent_union__)), VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_global_function"))) static void rb_define_global_function_00(const char *, VALUE(*)(VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_global_function"))) static void rb_define_global_function_01(const char *, VALUE(*)(VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_global_function"))) static void rb_define_global_function_02(const char *, VALUE(*)(VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_global_function"))) static void rb_define_global_function_03(const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_global_function"))) static void rb_define_global_function_04(const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_global_function"))) static void rb_define_global_function_05(const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_global_function"))) static void rb_define_global_function_06(const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_global_function"))) static void rb_define_global_function_07(const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_global_function"))) static void rb_define_global_function_08(const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_global_function"))) static void rb_define_global_function_09(const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_global_function"))) static void rb_define_global_function_10(const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_global_function"))) static void rb_define_global_function_11(const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_global_function"))) static void rb_define_global_function_12(const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_global_function"))) static void rb_define_global_function_13(const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_global_function"))) static void rb_define_global_function_14(const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_global_function"))) static void rb_define_global_function_15(const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int);
[[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_method_id"))) static void rb_define_method_id_notimpl(VALUE, ID, VALUE(*)(int, const VALUE *, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_method_id"))) static void rb_define_method_id_m3(VALUE, ID, VALUE(*)(), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_method_id"))) static void rb_define_method_id_m2(VALUE, ID, VALUE(*)(VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_method_id"))) static void rb_define_method_id_m1(VALUE, ID, VALUE(*)(int, union { VALUE *x; const VALUE *y; } __attribute__((__transparent_union__)), VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_method_id"))) static void rb_define_method_id_00(VALUE, ID, VALUE(*)(VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_method_id"))) static void rb_define_method_id_01(VALUE, ID, VALUE(*)(VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_method_id"))) static void rb_define_method_id_02(VALUE, ID, VALUE(*)(VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_method_id"))) static void rb_define_method_id_03(VALUE, ID, VALUE(*)(VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_method_id"))) static void rb_define_method_id_04(VALUE, ID, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_method_id"))) static void rb_define_method_id_05(VALUE, ID, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_method_id"))) static void rb_define_method_id_06(VALUE, ID, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_method_id"))) static void rb_define_method_id_07(VALUE, ID, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_method_id"))) static void rb_define_method_id_08(VALUE, ID, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_method_id"))) static void rb_define_method_id_09(VALUE, ID, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_method_id"))) static void rb_define_method_id_10(VALUE, ID, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_method_id"))) static void rb_define_method_id_11(VALUE, ID, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_method_id"))) static void rb_define_method_id_12(VALUE, ID, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_method_id"))) static void rb_define_method_id_13(VALUE, ID, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_method_id"))) static void rb_define_method_id_14(VALUE, ID, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_method_id"))) static void rb_define_method_id_15(VALUE, ID, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int);
[[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_method"))) static void rb_define_method_notimpl(VALUE, const char *, VALUE(*)(int, const VALUE *, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_method"))) static void rb_define_method_m3(VALUE, const char *, VALUE(*)(), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_method"))) static void rb_define_method_m2(VALUE, const char *, VALUE(*)(VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_method"))) static void rb_define_method_m1(VALUE, const char *, VALUE(*)(int, union { VALUE *x; const VALUE *y; } __attribute__((__transparent_union__)), VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_method"))) static void rb_define_method_00(VALUE, const char *, VALUE(*)(VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_method"))) static void rb_define_method_01(VALUE, const char *, VALUE(*)(VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_method"))) static void rb_define_method_02(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_method"))) static void rb_define_method_03(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_method"))) static void rb_define_method_04(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_method"))) static void rb_define_method_05(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_method"))) static void rb_define_method_06(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_method"))) static void rb_define_method_07(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_method"))) static void rb_define_method_08(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_method"))) static void rb_define_method_09(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_method"))) static void rb_define_method_10(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_method"))) static void rb_define_method_11(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_method"))) static void rb_define_method_12(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_method"))) static void rb_define_method_13(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_method"))) static void rb_define_method_14(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int); [[maybe_unused]] __attribute__((__nonnull__ ())) __attribute__((__weakref__("rb_define_method"))) static void rb_define_method_15(VALUE, const char *, VALUE(*)(VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE), int);

#pragma GCC visibility push(default)

VALUE rb_int2big(intptr_t i);
VALUE rb_int2inum(intptr_t i);
VALUE rb_uint2big(uintptr_t i);
VALUE rb_uint2inum(uintptr_t i);

#pragma GCC visibility pop

enum

ruby_special_consts {
    RUBY_Qfalse = 0x00,
    RUBY_Qnil = 0x04,
    RUBY_Qtrue = 0x14,
    RUBY_Qundef = 0x24,
    RUBY_IMMEDIATE_MASK = 0x07,
    RUBY_FIXNUM_FLAG = 0x01,
    RUBY_FLONUM_MASK = 0x03,
    RUBY_FLONUM_FLAG = 0x02,
    RUBY_SYMBOL_FLAG = 0x0c,
    RUBY_SPECIAL_SHIFT = 8
};
__attribute__((__const__))

__attribute__((__artificial__))
static inline _Bool
RB_TEST(VALUE obj)
{
    return obj & ((VALUE)~RUBY_Qnil);
}
__attribute__((__const__))

__attribute__((__artificial__))
static inline _Bool
RB_NIL_P(VALUE obj)
{
    return obj == RUBY_Qnil;
}
__attribute__((__const__))

__attribute__((__artificial__))
static inline _Bool
RB_UNDEF_P(VALUE obj)
{
    return obj == RUBY_Qundef;
}
__attribute__((__const__))

__attribute__((__artificial__))
static inline _Bool
RB_NIL_OR_UNDEF_P(VALUE obj)
{
    const VALUE mask = ((VALUE)~(RUBY_Qundef ^ RUBY_Qnil));
    const VALUE common_bits = RUBY_Qundef & RUBY_Qnil;
    return (obj & mask) == common_bits;
}
__attribute__((__const__))

__attribute__((__artificial__))
static inline _Bool
RB_FIXNUM_P(VALUE obj)
{
    return obj & RUBY_FIXNUM_FLAG;
}
__attribute__((__const__))

__attribute__((__artificial__))
static inline _Bool
RB_STATIC_SYM_P(VALUE obj)
{
   
    const VALUE mask = ~((0x7fffffffffffffffL * 2UL + 1UL) << RUBY_SPECIAL_SHIFT);
    return (obj & mask) == RUBY_SYMBOL_FLAG;
}
__attribute__((__const__))

__attribute__((__artificial__))
static inline _Bool
RB_FLONUM_P(VALUE obj)
{
    return (obj & RUBY_FLONUM_MASK) == RUBY_FLONUM_FLAG;
}
__attribute__((__const__))

__attribute__((__artificial__))
static inline _Bool
RB_IMMEDIATE_P(VALUE obj)
{
    return obj & RUBY_IMMEDIATE_MASK;
}
__attribute__((__const__))

__attribute__((__artificial__))
static inline _Bool
RB_SPECIAL_CONST_P(VALUE obj)
{
    return (obj == RUBY_Qfalse) || RB_IMMEDIATE_P(obj);
}
__attribute__((__const__))

static inline VALUE
rb_special_const_p(VALUE obj)
{
    return (unsigned int)RB_SPECIAL_CONST_P(obj) * RUBY_Qtrue;
}

#pragma GCC visibility push(default)

__attribute__((__noreturn__))
__attribute__((__cold__))
void rb_out_of_int(long num);
long rb_num2long(VALUE num);
unsigned long rb_num2ulong(VALUE num);

#pragma GCC visibility pop

__attribute__((__const__))

__attribute__((__artificial__))
static inline VALUE
RB_INT2FIX(long i)
{
    ((void)0);
    const unsigned long j = ((unsigned long)i);
    const unsigned long k = (j << 1) + RUBY_FIXNUM_FLAG;
    const long l = ((long)k);
    const long m = l;
    const VALUE n = ((VALUE)m);
    ((void)0);
    return n;
}
static inline int
rb_long2int_inline(long n)
{
    int i = ((int)n);
    if (sizeof(long) <= sizeof(int)) {
        ((__builtin_expect(!!(!!(i == n)), 1)) ? ((void)0) : __builtin_unreachable());
    }
    if (i != n)
        rb_out_of_int(n);
    return i;
}
__attribute__((__const__))

static inline long
rbimpl_fix2long_by_idiv(VALUE x)
{
    ((void)0);
    const long y = ((long)(x - RUBY_FIXNUM_FLAG));
    const long z = y / 2;
    const long w = ((long)z);
    ((void)0);
    return w;
}
__attribute__((__const__))

static inline long
rbimpl_fix2long_by_shift(VALUE x)
{
    ((void)0);
    const long y = ((long)x);
    const long z = y >> 1;
    const long w = ((long)z);
    ((void)0);
    return w;
}
__attribute__((__const__))

static inline _Bool
rbimpl_right_shift_is_arithmetic_p(void)
{
    return (-1 >> 1) == -1;
}
__attribute__((__const__))

static inline long
rb_fix2long(VALUE x)
{
    if (rbimpl_right_shift_is_arithmetic_p()) {
        return rbimpl_fix2long_by_shift(x);
    }
    else {
        return rbimpl_fix2long_by_idiv(x);
    }
}
__attribute__((__const__))

static inline unsigned long
rb_fix2ulong(VALUE x)
{
    ((void)0);
    return ((unsigned long)rb_fix2long(x));
}
static inline long
rb_num2long_inline(VALUE x)
{
    if (RB_FIXNUM_P(x))
        return rb_fix2long(x);
    else
        return rb_num2long(x);
}
static inline unsigned long
rb_num2ulong_inline(VALUE x)
{
    if (RB_FIXNUM_P(x))
        return rb_fix2ulong(x);
    else
        return rb_num2ulong(x);
}
static inline VALUE
rb_long2num_inline(long v)
{
    if ((((v) < (0x7fffffffffffffffL / 2) + 1) && ((v) >= ((-0x7fffffffffffffffL - 1L) / 2))))
        return RB_INT2FIX(v);
    else
        return rb_int2big(v);
}
static inline VALUE
rb_ulong2num_inline(unsigned long v)
{
    if (((v) < (0x7fffffffffffffffL / 2) + 1))
        return RB_INT2FIX(((long)v));
    else
        return rb_uint2big(v);
}

#pragma GCC visibility push(default)

long rb_num2int(VALUE num);
long rb_fix2int(VALUE num);
unsigned long rb_num2uint(VALUE num);
unsigned long rb_fix2uint(VALUE num);

#pragma GCC visibility pop

__attribute__((__artificial__))
static inline int
RB_FIX2INT(VALUE x)
{
    long ret;
    if (sizeof(int) < sizeof(long)) {
        ret = rb_fix2int(x);
    }
    else {
        ret = rb_fix2long(x);
    }
    return ((int)ret);
}
static inline int
rb_num2int_inline(VALUE x)
{
    long ret;
    if (sizeof(int) == sizeof(long)) {
        ret = rb_num2long_inline(x);
    }
    else if (RB_FIXNUM_P(x)) {
        ret = rb_fix2int(x);
    }
    else {
        ret = rb_num2int(x);
    }
    return ((int)ret);
}
__attribute__((__artificial__))
static inline unsigned int
RB_NUM2UINT(VALUE x)
{
    unsigned long ret;
    if (sizeof(int) < sizeof(long)) {
        ret = rb_num2uint(x);
    }
    else {
        ret = rb_num2ulong_inline(x);
    }
    return ((unsigned int)ret);
}
__attribute__((__artificial__))
static inline unsigned int
RB_FIX2UINT(VALUE x)
{
    unsigned long ret;
    if (sizeof(int) < sizeof(long)) {
        ret = rb_fix2uint(x);
    }
    else {
        ret = rb_fix2ulong(x);
    }
    return ((unsigned int)ret);
}

#pragma GCC diagnostic push


#pragma GCC diagnostic ignored "-Wtype-limits"

static inline VALUE
rb_int2num_inline(int v)
{
    if ((((v) < (0x7fffffffffffffffL / 2) + 1) && ((v) >= ((-0x7fffffffffffffffL - 1L) / 2))))
        return RB_INT2FIX(v);
    else
        return rb_int2big(v);
}
static inline VALUE
rb_uint2num_inline(unsigned int v)
{
    if (((v) < (0x7fffffffffffffffL / 2) + 1))
        return RB_INT2FIX(((long)v));
    else
        return rb_uint2big(v);
}

#pragma GCC diagnostic pop

enum ruby_rvalue_flags {
    RVALUE_EMBED_LEN_MAX = 3
};
struct
__attribute__((__aligned__(8)))
RBasic {
    VALUE flags;
    const VALUE klass;
};

#pragma GCC visibility push(default)

VALUE rb_obj_hide(VALUE obj);
VALUE rb_obj_reveal(VALUE obj, VALUE klass);

#pragma GCC visibility pop

__attribute__((__pure__))
__attribute__((__artificial__))
static inline VALUE
RBASIC_CLASS(VALUE obj)
{
    ((void)0);
    return ((struct RBasic *)(obj))->klass;
}
typedef enum {
    RB_WARN_CATEGORY_NONE,
    RB_WARN_CATEGORY_DEPRECATED,
    RB_WARN_CATEGORY_EXPERIMENTAL,
    RB_WARN_CATEGORY_PERFORMANCE,
    RB_WARN_CATEGORY_STRICT_UNUSED_BLOCK,
    RB_WARN_CATEGORY_DEFAULT_BITS = (
        (1U << RB_WARN_CATEGORY_DEPRECATED) |
        (1U << RB_WARN_CATEGORY_EXPERIMENTAL) |
        0),
    RB_WARN_CATEGORY_ALL_BITS = (
        (1U << RB_WARN_CATEGORY_DEPRECATED) |
        (1U << RB_WARN_CATEGORY_EXPERIMENTAL) |
        (1U << RB_WARN_CATEGORY_PERFORMANCE) |
        (1U << RB_WARN_CATEGORY_STRICT_UNUSED_BLOCK) |
        0)
} rb_warning_category_t;
enum rb_io_wait_readwrite {RB_IO_WAIT_READABLE, RB_IO_WAIT_WRITABLE};

#pragma GCC visibility push(default)

VALUE rb_errinfo(void);
void rb_set_errinfo(VALUE err);
__attribute__((__noreturn__))
__attribute__((__nonnull__ (2)))
__attribute__((__format__(__printf__, 2, 3)))
void rb_raise(VALUE exc, const char *fmt, ...);
__attribute__((__noreturn__))
__attribute__((__nonnull__ (1)))
__attribute__((__format__(__printf__, 1, 2)))
void rb_fatal(const char *fmt, ...);
__attribute__((__cold__))
__attribute__((__noreturn__))
__attribute__((__nonnull__ (1)))
__attribute__((__format__(__printf__, 1, 2)))
void rb_bug(const char *fmt, ...);
__attribute__((__noreturn__))
__attribute__((__nonnull__ ()))
void rb_bug_errno(const char *msg, int err);
__attribute__((__noreturn__))
void rb_sys_fail(const char *msg);
__attribute__((__noreturn__))
void rb_sys_fail_str(VALUE msg);
__attribute__((__noreturn__))
__attribute__((__nonnull__ (2)))
void rb_mod_sys_fail(VALUE mod, const char *msg);
__attribute__((__noreturn__))
void rb_mod_sys_fail_str(VALUE mod, VALUE msg);
__attribute__((__noreturn__))
void rb_readwrite_sys_fail(enum rb_io_wait_readwrite waiting, const char *msg);
__attribute__((__noreturn__))
void rb_iter_break(void);
__attribute__((__noreturn__))
void rb_iter_break_value(VALUE val);
__attribute__((__noreturn__))
void rb_exit(int status);
__attribute__((__noreturn__))
void rb_notimplement(void);
VALUE rb_syserr_new(int err, const char * msg);
VALUE rb_syserr_new_str(int n, VALUE arg);
__attribute__((__noreturn__))
void rb_syserr_fail(int err, const char *msg);
__attribute__((__noreturn__))
void rb_syserr_fail_str(int err, VALUE msg);
__attribute__((__noreturn__))
__attribute__((__nonnull__ ()))
void rb_mod_syserr_fail(VALUE mod, int err, const char *msg);
__attribute__((__noreturn__))
void rb_mod_syserr_fail_str(VALUE mod, int err, VALUE msg);
__attribute__((__noreturn__))
void rb_readwrite_syserr_fail(enum rb_io_wait_readwrite waiting, int err, const char *msg);
__attribute__((__cold__))
__attribute__((__noreturn__))
void rb_unexpected_type(VALUE self, int t);
VALUE *rb_ruby_verbose_ptr(void);
VALUE *rb_ruby_debug_ptr(void);
__attribute__((__nonnull__ (1)))
__attribute__((__format__(__printf__, 1, 2)))
void rb_warning(const char *fmt, ...);
__attribute__((__nonnull__ (2)))
__attribute__((__format__(__printf__, 2, 3)))
void rb_category_warning(rb_warning_category_t cat, const char *fmt, ...);
__attribute__((__nonnull__ (1, 3)))
__attribute__((__format__(__printf__, 3, 4)))
void rb_compile_warning(const char *file, int line, const char *fmt, ...);
__attribute__((__nonnull__ (1)))
__attribute__((__format__(__printf__, 1, 2)))
void rb_sys_warning(const char *fmt, ...);
__attribute__((__cold__))
__attribute__((__nonnull__ (1)))
__attribute__((__format__(__printf__, 1, 2)))
void rb_warn(const char *fmt, ...);
__attribute__((__cold__))
__attribute__((__nonnull__ (2)))
__attribute__((__format__(__printf__, 2, 3)))
void rb_category_warn(rb_warning_category_t cat, const char *fmt, ...);
__attribute__((__nonnull__ (1, 3)))
__attribute__((__format__(__printf__, 3, 4)))
void rb_compile_warn(const char *file, int line, const char *fmt, ...);
__attribute__((__nonnull__ (2, 4)))
__attribute__((__format__(__printf__, 4, 5)))
void rb_category_compile_warn(rb_warning_category_t cat, const char *file, int line, const char *fmt, ...);

#pragma GCC visibility pop

enum

ruby_value_type {
    RUBY_T_NONE = 0x00,
    RUBY_T_OBJECT = 0x01,
    RUBY_T_CLASS = 0x02,
    RUBY_T_MODULE = 0x03,
    RUBY_T_FLOAT = 0x04,
    RUBY_T_STRING = 0x05,
    RUBY_T_REGEXP = 0x06,
    RUBY_T_ARRAY = 0x07,
    RUBY_T_HASH = 0x08,
    RUBY_T_STRUCT = 0x09,
    RUBY_T_BIGNUM = 0x0a,
    RUBY_T_FILE = 0x0b,
    RUBY_T_DATA = 0x0c,
    RUBY_T_MATCH = 0x0d,
    RUBY_T_COMPLEX = 0x0e,
    RUBY_T_RATIONAL = 0x0f,
    RUBY_T_NIL = 0x11,
    RUBY_T_TRUE = 0x12,
    RUBY_T_FALSE = 0x13,
    RUBY_T_SYMBOL = 0x14,
    RUBY_T_FIXNUM = 0x15,
    RUBY_T_UNDEF = 0x16,
    RUBY_T_IMEMO = 0x1a,
    RUBY_T_NODE = 0x1b,
    RUBY_T_ICLASS = 0x1c,
    RUBY_T_ZOMBIE = 0x1d,
    RUBY_T_MOVED = 0x1e,
    RUBY_T_MASK = 0x1f
};

#pragma GCC visibility push(default)

__attribute__((__cold__))
void rb_check_type(VALUE obj, int t);

#pragma GCC visibility pop

__attribute__((__pure__))
__attribute__((__artificial__))
static inline enum ruby_value_type
RB_BUILTIN_TYPE(VALUE obj)
{
    ((void)0);
    VALUE ret = ((struct RBasic *)(obj))->flags & RUBY_T_MASK;
    return ((enum ruby_value_type)ret);
}
__attribute__((__pure__))
static inline _Bool
rb_integer_type_p(VALUE obj)
{
    if (RB_FIXNUM_P(obj)) {
        return 1;
    }
    else if (RB_SPECIAL_CONST_P(obj)) {
        return 0;
    }
    else {
        return RB_BUILTIN_TYPE(obj) == RUBY_T_BIGNUM;
    }
}
__attribute__((__pure__))
static inline enum ruby_value_type
rb_type(VALUE obj)
{
    if (! RB_SPECIAL_CONST_P(obj)) {
        return RB_BUILTIN_TYPE(obj);
    }
    else if (obj == ((VALUE)RUBY_Qfalse)) {
        return RUBY_T_FALSE;
    }
    else if (obj == ((VALUE)RUBY_Qnil)) {
        return RUBY_T_NIL;
    }
    else if (obj == ((VALUE)RUBY_Qtrue)) {
        return RUBY_T_TRUE;
    }
    else if (obj == ((VALUE)RUBY_Qundef)) {
        return RUBY_T_UNDEF;
    }
    else if (RB_FIXNUM_P(obj)) {
        return RUBY_T_FIXNUM;
    }
    else if (RB_STATIC_SYM_P(obj)) {
        return RUBY_T_SYMBOL;
    }
    else {
        ((__builtin_expect(!!(!!(RB_FLONUM_P(obj))), 1)) ? ((void)0) : __builtin_unreachable());
        return RUBY_T_FLOAT;
    }
}
__attribute__((__pure__))
__attribute__((__artificial__))
static inline _Bool
RB_FLOAT_TYPE_P(VALUE obj)
{
    if (RB_FLONUM_P(obj)) {
        return 1;
    }
    else if (RB_SPECIAL_CONST_P(obj)) {
        return 0;
    }
    else {
        return RB_BUILTIN_TYPE(obj) == RUBY_T_FLOAT;
    }
}
__attribute__((__pure__))
__attribute__((__artificial__))
static inline _Bool
RB_DYNAMIC_SYM_P(VALUE obj)
{
    if (RB_SPECIAL_CONST_P(obj)) {
        return 0;
    }
    else {
        return RB_BUILTIN_TYPE(obj) == RUBY_T_SYMBOL;
    }
}
__attribute__((__pure__))
__attribute__((__artificial__))
static inline _Bool
RB_SYMBOL_P(VALUE obj)
{
    return RB_STATIC_SYM_P(obj) || RB_DYNAMIC_SYM_P(obj);
}
__attribute__((__pure__))
__attribute__((__artificial__))
__attribute__((__always_inline__)) inline
static _Bool
rbimpl_RB_TYPE_P_fastpath(VALUE obj, enum ruby_value_type t)
{
    if (t == RUBY_T_TRUE) {
        return obj == ((VALUE)RUBY_Qtrue);
    }
    else if (t == RUBY_T_FALSE) {
        return obj == ((VALUE)RUBY_Qfalse);
    }
    else if (t == RUBY_T_NIL) {
        return obj == ((VALUE)RUBY_Qnil);
    }
    else if (t == RUBY_T_UNDEF) {
        return obj == ((VALUE)RUBY_Qundef);
    }
    else if (t == RUBY_T_FIXNUM) {
        return RB_FIXNUM_P(obj);
    }
    else if (t == RUBY_T_SYMBOL) {
        return RB_SYMBOL_P(obj);
    }
    else if (t == RUBY_T_FLOAT) {
        return RB_FLOAT_TYPE_P(obj);
    }
    else if (RB_SPECIAL_CONST_P(obj)) {
        return 0;
    }
    else if (t == RB_BUILTIN_TYPE(obj)) {
        return 1;
    }
    else {
        return 0;
    }
}
__attribute__((__pure__))
__attribute__((__artificial__))
static inline _Bool
RB_TYPE_P(VALUE obj, enum ruby_value_type t)
{
    if (__builtin_constant_p(t)) {
        return rbimpl_RB_TYPE_P_fastpath(obj, t);
    }
    else {
        return t == rb_type(obj);
    }
}
__attribute__((__pure__))
__attribute__((__artificial__))
static inline _Bool rbimpl_rtypeddata_p(VALUE obj);
__attribute__((__artificial__))
static inline void
Check_Type(VALUE v, enum ruby_value_type t)
{
    if ((__builtin_expect(!!(! RB_TYPE_P(v, t)), 0))) {
        goto unexpected_type;
    }
    else if (t == RUBY_T_DATA && rbimpl_rtypeddata_p(v)) {
        goto unexpected_type;
    }
    else {
        return;
    }
  unexpected_type:
    rb_unexpected_type(v, ((int)t));
}
enum ruby_fl_ushift {
    RUBY_FL_USHIFT = 12
};
__extension__
enum

ruby_fl_type {
    RUBY_FL_WB_PROTECTED = (1<<5),
    RUBY_FL_PROMOTED = (1<<5),
    RUBY_FL_UNUSED6 = (1<<6),
    RUBY_FL_FINALIZE = (1<<7),
    RUBY_FL_TAINT
    __attribute__((__deprecated__ ("taintedness turned out to be a wrong idea.")))
                         = 0,
    RUBY_FL_SHAREABLE = (1<<8),
    RUBY_FL_UNTRUSTED
    __attribute__((__deprecated__ ("trustedness turned out to be a wrong idea.")))
                         = 0,
    RUBY_FL_SEEN_OBJ_ID = (1<<9),
    RUBY_FL_EXIVAR = (1<<10),
    RUBY_FL_FREEZE = (1<<11),
    RUBY_FL_USER0 = (1<<(RUBY_FL_USHIFT+0)),
    RUBY_FL_USER1 = (1<<(RUBY_FL_USHIFT+1)),
    RUBY_FL_USER2 = (1<<(RUBY_FL_USHIFT+2)),
    RUBY_FL_USER3 = (1<<(RUBY_FL_USHIFT+3)),
    RUBY_FL_USER4 = (1<<(RUBY_FL_USHIFT+4)),
    RUBY_FL_USER5 = (1<<(RUBY_FL_USHIFT+5)),
    RUBY_FL_USER6 = (1<<(RUBY_FL_USHIFT+6)),
    RUBY_FL_USER7 = (1<<(RUBY_FL_USHIFT+7)),
    RUBY_FL_USER8 = (1<<(RUBY_FL_USHIFT+8)),
    RUBY_FL_USER9 = (1<<(RUBY_FL_USHIFT+9)),
    RUBY_FL_USER10 = (1<<(RUBY_FL_USHIFT+10)),
    RUBY_FL_USER11 = (1<<(RUBY_FL_USHIFT+11)),
    RUBY_FL_USER12 = (1<<(RUBY_FL_USHIFT+12)),
    RUBY_FL_USER13 = (1<<(RUBY_FL_USHIFT+13)),
    RUBY_FL_USER14 = (1<<(RUBY_FL_USHIFT+14)),
    RUBY_FL_USER15 = (1<<(RUBY_FL_USHIFT+15)),
    RUBY_FL_USER16 = (1<<(RUBY_FL_USHIFT+16)),
    RUBY_FL_USER17 = (1<<(RUBY_FL_USHIFT+17)),
    RUBY_FL_USER18 = (1<<(RUBY_FL_USHIFT+18)),
    RUBY_FL_USER19 = (1<<(RUBY_FL_USHIFT+19)),
    RUBY_ELTS_SHARED = RUBY_FL_USER0,
    RUBY_FL_SINGLETON = RUBY_FL_USER1,
};
enum {
    RUBY_FL_DUPPED
    __attribute__((__deprecated__ ("It seems there is no actual usage of this enum.")))
    = (int)RUBY_T_MASK | (int)RUBY_FL_EXIVAR
};

#pragma GCC visibility push(default)

void rb_freeze_singleton_class(VALUE klass);

#pragma GCC visibility pop

__attribute__((__pure__))
__attribute__((__artificial__))
__attribute__((__always_inline__)) inline
static _Bool
RB_FL_ABLE(VALUE obj)
{
    if (RB_SPECIAL_CONST_P(obj)) {
        return 0;
    }
    else if (RB_TYPE_P(obj, RUBY_T_NODE)) {
        return 0;
    }
    else {
        return 1;
    }
}
__attribute__((__pure__))
__attribute__((__artificial__))
static inline VALUE
RB_FL_TEST_RAW(VALUE obj, VALUE flags)
{
    ((void)0);
    return ((struct RBasic *)(obj))->flags & flags;
}
__attribute__((__pure__))
__attribute__((__artificial__))
static inline VALUE
RB_FL_TEST(VALUE obj, VALUE flags)
{
    if (RB_FL_ABLE(obj)) {
        return RB_FL_TEST_RAW(obj, flags);
    }
    else {
        return 0UL;
    }
}
__attribute__((__pure__))
__attribute__((__artificial__))
static inline _Bool
RB_FL_ANY_RAW(VALUE obj, VALUE flags)
{
    return RB_FL_TEST_RAW(obj, flags);
}
__attribute__((__pure__))
__attribute__((__artificial__))
static inline _Bool
RB_FL_ANY(VALUE obj, VALUE flags)
{
    return RB_FL_TEST(obj, flags);
}
__attribute__((__pure__))
__attribute__((__artificial__))
static inline _Bool
RB_FL_ALL_RAW(VALUE obj, VALUE flags)
{
    return RB_FL_TEST_RAW(obj, flags) == flags;
}
__attribute__((__pure__))
__attribute__((__artificial__))
static inline _Bool
RB_FL_ALL(VALUE obj, VALUE flags)
{
    return RB_FL_TEST(obj, flags) == flags;
}

__attribute__((__artificial__))
static inline void
rbimpl_fl_set_raw_raw(struct RBasic *obj, VALUE flags)
{
    obj->flags |= flags;
}
__attribute__((__artificial__))
static inline void
RB_FL_SET_RAW(VALUE obj, VALUE flags)
{
    ((void)0);
    rbimpl_fl_set_raw_raw(((struct RBasic *)(obj)), flags);
}
__attribute__((__artificial__))
static inline void
RB_FL_SET(VALUE obj, VALUE flags)
{
    if (RB_FL_ABLE(obj)) {
        RB_FL_SET_RAW(obj, flags);
    }
}

__attribute__((__artificial__))
static inline void
rbimpl_fl_unset_raw_raw(struct RBasic *obj, VALUE flags)
{
    obj->flags &= ~flags;
}
__attribute__((__artificial__))
static inline void
RB_FL_UNSET_RAW(VALUE obj, VALUE flags)
{
    ((void)0);
    rbimpl_fl_unset_raw_raw(((struct RBasic *)(obj)), flags);
}
__attribute__((__artificial__))
static inline void
RB_FL_UNSET(VALUE obj, VALUE flags)
{
    if (RB_FL_ABLE(obj)) {
        RB_FL_UNSET_RAW(obj, flags);
    }
}

__attribute__((__artificial__))
static inline void
rbimpl_fl_reverse_raw_raw(struct RBasic *obj, VALUE flags)
{
    obj->flags ^= flags;
}
__attribute__((__artificial__))
static inline void
RB_FL_REVERSE_RAW(VALUE obj, VALUE flags)
{
    ((void)0);
    rbimpl_fl_reverse_raw_raw(((struct RBasic *)(obj)), flags);
}
__attribute__((__artificial__))
static inline void
RB_FL_REVERSE(VALUE obj, VALUE flags)
{
    if (RB_FL_ABLE(obj)) {
        RB_FL_REVERSE_RAW(obj, flags);
    }
}
__attribute__((__pure__))
__attribute__((__artificial__))
__attribute__((__deprecated__ ("taintedness turned out to be a wrong idea.")))
static inline _Bool
RB_OBJ_TAINTABLE(VALUE obj)
{
    (void)obj;
    return 0;
}
__attribute__((__pure__))
__attribute__((__artificial__))
__attribute__((__deprecated__ ("taintedness turned out to be a wrong idea.")))
static inline VALUE
RB_OBJ_TAINTED_RAW(VALUE obj)
{
    (void)obj;
    return 0;
}
__attribute__((__pure__))
__attribute__((__artificial__))
__attribute__((__deprecated__ ("taintedness turned out to be a wrong idea.")))
static inline _Bool
RB_OBJ_TAINTED(VALUE obj)
{
    (void)obj;
    return 0;
}
__attribute__((__artificial__))
__attribute__((__deprecated__ ("taintedness turned out to be a wrong idea.")))
static inline void
RB_OBJ_TAINT_RAW(VALUE obj)
{
    (void)obj;
    return;
}
__attribute__((__artificial__))
__attribute__((__deprecated__ ("taintedness turned out to be a wrong idea.")))
static inline void
RB_OBJ_TAINT(VALUE obj)
{
    (void)obj;
    return;
}
__attribute__((__artificial__))
__attribute__((__deprecated__ ("taintedness turned out to be a wrong idea.")))
static inline void
RB_OBJ_INFECT_RAW(VALUE dst, VALUE src)
{
    (void)dst;
    (void)src;
    return;
}
__attribute__((__artificial__))
__attribute__((__deprecated__ ("taintedness turned out to be a wrong idea.")))
static inline void
RB_OBJ_INFECT(VALUE dst, VALUE src)
{
    (void)dst;
    (void)src;
    return;
}
__attribute__((__pure__))
__attribute__((__artificial__))
static inline VALUE
RB_OBJ_FROZEN_RAW(VALUE obj)
{
    return RB_FL_TEST_RAW(obj, RUBY_FL_FREEZE);
}
__attribute__((__pure__))
__attribute__((__artificial__))
static inline _Bool
RB_OBJ_FROZEN(VALUE obj)
{
    if (! RB_FL_ABLE(obj)) {
        return 1;
    }
    else {
        return RB_OBJ_FROZEN_RAW(obj);
    }
}

#pragma GCC visibility push(default)

void rb_obj_freeze_inline(VALUE obj);

#pragma GCC visibility pop

__attribute__((__artificial__))
static inline void
RB_OBJ_FREEZE_RAW(VALUE obj)
{
    rb_obj_freeze_inline(obj);
}
enum ruby_rstring_flags {
    RSTRING_NOEMBED = RUBY_FL_USER1,
    RSTRING_FSTR = RUBY_FL_USER17
};
struct RString {
    struct RBasic basic;
    long len;
    union {
        struct {
            char *ptr;
            union {
                long capa;
                VALUE shared;
            } aux;
        } heap;
        struct {
            char ary[1];
        } embed;
    } as;
};

#pragma GCC visibility push(default)

VALUE rb_str_to_str(VALUE obj);
VALUE rb_string_value(volatile VALUE *ptr);
char *rb_string_value_ptr(volatile VALUE *ptr);
char *rb_string_value_cstr(volatile VALUE *ptr);
VALUE rb_str_export(VALUE obj);
VALUE rb_str_export_locale(VALUE obj);
__attribute__((__error__ ("rb_check_safe_str() and Check_SafeStr() are obsolete; use StringValue() instead")))
void rb_check_safe_str(VALUE);
void rb_debug_rstring_null_ptr(const char *func);

#pragma GCC visibility pop

__attribute__((__pure__))
__attribute__((__artificial__))
static inline long
RSTRING_LEN(VALUE str)
{
    return ((struct RString *)(str))->len;
}

#pragma GCC diagnostic push

__attribute__((__pure__))
__attribute__((__artificial__))
static inline struct RString
rbimpl_rstring_getmem(VALUE str)
{
    ((void)0);
    if (RB_FL_ANY_RAW(str, RSTRING_NOEMBED)) {
        return *((struct RString *)(str));
    }
    else {
        struct RString retval;
        retval.len = RSTRING_LEN(str);
        retval.as.heap.ptr = ((struct RString *)(str))->as.embed.ary;
        return retval;
    }
}

#pragma GCC diagnostic pop

__attribute__((__artificial__))
static inline char *
RSTRING_PTR(VALUE str)
{
    char *ptr = rbimpl_rstring_getmem(str).as.heap.ptr;
    if (0 && (__builtin_expect(!!(! ptr), 0))) {
        rb_debug_rstring_null_ptr("RSTRING_PTR");
    }
    return ptr;
}
__attribute__((__artificial__))
static inline char *
RSTRING_END(VALUE str)
{
    struct RString buf = rbimpl_rstring_getmem(str);
    if (0 && (__builtin_expect(!!(! buf.as.heap.ptr), 0))) {
        rb_debug_rstring_null_ptr("RSTRING_END");
    }
    return &buf.as.heap.ptr[buf.len];
}
__attribute__((__artificial__))
static inline int
RSTRING_LENINT(VALUE str)
{
    return rb_long2int_inline(RSTRING_LEN(str));
}
__attribute__((__const__))

__attribute__((__artificial__))
static inline VALUE
RB_CHR2FIX(unsigned char c)
{
    return RB_INT2FIX(c);
}
static inline char
rb_num2char_inline(VALUE x)
{
    if (RB_TYPE_P(x, RUBY_T_STRING) && (RSTRING_LEN(x)>=1))
        return RSTRING_PTR(x)[0];
    else
        return ((char)rb_num2int_inline(x));
}

#pragma GCC visibility push(default)

double rb_num2dbl(VALUE num);
__attribute__((__pure__))
double rb_float_value(VALUE num);
VALUE rb_float_new(double d);
VALUE rb_float_new_in_heap(double d);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

VALUE rb_ll2inum(long long num);
VALUE rb_ull2inum(unsigned long long num);
long long rb_num2ll(VALUE num);
unsigned long long rb_num2ull(VALUE num);

#pragma GCC visibility pop

static inline VALUE
rb_ll2num_inline(long long n)
{
    if ((((n) < (0x7fffffffffffffffL / 2) + 1) && ((n) >= ((-0x7fffffffffffffffL - 1L) / 2)))) return RB_INT2FIX((long)n);
    return rb_ll2inum(n);
}
static inline VALUE
rb_ull2num_inline(unsigned long long n)
{
    if (((n) < (0x7fffffffffffffffL / 2) + 1)) return RB_INT2FIX((long)n);
    return rb_ull2inum(n);
}
static inline long long
rb_num2ll_inline(VALUE x)
{
    if (RB_FIXNUM_P(x))
        return rb_fix2long(x);
    else
        return rb_num2ll(x);
}
static inline unsigned long long
rb_num2ull_inline(VALUE x)
{
    if (RB_FIXNUM_P(x))
        return ((unsigned long long)rb_fix2long(x));
    else
        return rb_num2ull(x);
}

#pragma GCC visibility push(default)

short rb_num2short(VALUE num);
unsigned short rb_num2ushort(VALUE num);
short rb_fix2short(VALUE num);
unsigned short rb_fix2ushort(VALUE num);

#pragma GCC visibility pop

static inline short
rb_num2short_inline(VALUE x)
{
    if (RB_FIXNUM_P(x))
        return rb_fix2short(x);
    else
        return rb_num2short(x);
}

#pragma GCC visibility push(default)

typedef unsigned long st_data_t;
typedef struct st_table st_table;
typedef st_data_t st_index_t;
typedef int st_compare_func(st_data_t, st_data_t);
typedef st_index_t st_hash_func(st_data_t);
typedef char st_check_for_sizeof_st_index_t[8 == (int)sizeof(st_index_t) ? 1 : -1];
struct st_hash_type {
    int (*compare)(st_data_t, st_data_t);
    st_index_t (*hash)(st_data_t);
};
typedef struct st_table_entry st_table_entry;
struct st_table_entry;
struct st_table {
    unsigned char entry_power, bin_power, size_ind;
    unsigned int rebuilds_num;
    const struct st_hash_type *type;
    st_index_t num_entries;
    st_index_t *bins;
    st_index_t entries_start, entries_bound;
    st_table_entry *entries;
};
enum st_retval {ST_CONTINUE, ST_STOP, ST_DELETE, ST_CHECK, ST_REPLACE};
size_t rb_st_table_size(const struct st_table *tbl);
st_table *rb_st_init_table(const struct st_hash_type *);
st_table *rb_st_init_table_with_size(const struct st_hash_type *, st_index_t);
st_table *rb_st_init_numtable(void);
st_table *rb_st_init_numtable_with_size(st_index_t);
st_table *rb_st_init_strtable(void);
st_table *rb_st_init_strtable_with_size(st_index_t);
st_table *rb_st_init_strcasetable(void);
st_table *rb_st_init_strcasetable_with_size(st_index_t);
int rb_st_delete(st_table *, st_data_t *, st_data_t *);
int rb_st_delete_safe(st_table *, st_data_t *, st_data_t *, st_data_t);
int rb_st_shift(st_table *, st_data_t *, st_data_t *);
int rb_st_insert(st_table *, st_data_t, st_data_t);
int rb_st_insert2(st_table *, st_data_t, st_data_t, st_data_t (*)(st_data_t));
int rb_st_lookup(st_table *, st_data_t, st_data_t *);
int rb_st_get_key(st_table *, st_data_t, st_data_t *);
typedef int st_update_callback_func(st_data_t *key, st_data_t *value, st_data_t arg, int existing);
int rb_st_update(st_table *table, st_data_t key, st_update_callback_func *func, st_data_t arg);
typedef int st_foreach_callback_func(st_data_t, st_data_t, st_data_t);
typedef int st_foreach_check_callback_func(st_data_t, st_data_t, st_data_t, int);
int rb_st_foreach_with_replace(st_table *tab, st_foreach_check_callback_func *func, st_update_callback_func *replace, st_data_t arg);
int rb_st_foreach(st_table *, st_foreach_callback_func *, st_data_t);
int rb_st_foreach_check(st_table *, st_foreach_check_callback_func *, st_data_t, st_data_t);
st_index_t rb_st_keys(st_table *table, st_data_t *keys, st_index_t size);
st_index_t rb_st_keys_check(st_table *table, st_data_t *keys, st_index_t size, st_data_t never);
st_index_t rb_st_values(st_table *table, st_data_t *values, st_index_t size);
st_index_t rb_st_values_check(st_table *table, st_data_t *values, st_index_t size, st_data_t never);
void rb_st_add_direct(st_table *, st_data_t, st_data_t);
void rb_st_free_table(st_table *);
void rb_st_cleanup_safe(st_table *, st_data_t);
void rb_st_clear(st_table *);
st_table *rb_st_copy(st_table *);
__attribute__((__const__)) int rb_st_numcmp(st_data_t, st_data_t);
__attribute__((__const__)) st_index_t rb_st_numhash(st_data_t);
__attribute__((__pure__)) int rb_st_locale_insensitive_strcasecmp(const char *s1, const char *s2);
__attribute__((__pure__)) int rb_st_locale_insensitive_strncasecmp(const char *s1, const char *s2, size_t n);
__attribute__((__pure__)) size_t rb_st_memsize(const st_table *);
__attribute__((__pure__)) st_index_t rb_st_hash(const void *ptr, size_t len, st_index_t h);
__attribute__((__const__)) st_index_t rb_st_hash_uint32(st_index_t h, uint32_t i);
__attribute__((__const__)) st_index_t rb_st_hash_uint(st_index_t h, st_index_t i);
__attribute__((__const__)) st_index_t rb_st_hash_end(st_index_t h);
__attribute__((__const__)) st_index_t rb_st_hash_start(st_index_t h);
void rb_hash_bulk_insert_into_st_table(long, const VALUE *, VALUE);

#pragma GCC visibility pop

__attribute__((__const__))

__attribute__((__artificial__))
static inline VALUE
RB_ST2FIX(st_data_t i)
{
    long x = ((long)i);
    if (x >= 0) {
        x &= (0x7fffffffffffffffL / 2);
    }
    else {
        x |= ((-0x7fffffffffffffffL - 1L) / 2);
    }
    ((void)0);
    unsigned long y = ((unsigned long)x);
    return RB_INT2FIX(((long)y));
}

#pragma GCC visibility push(default)

__attribute__((__cold__))
__attribute__((__noreturn__))
void rb_memerror(void);
__attribute__((__pure__))
int rb_during_gc(void);
__attribute__((__nonnull__ (1)))
void rb_gc_mark_locations(const VALUE *start, const VALUE *end);
void rb_mark_tbl(struct st_table *tbl);
void rb_mark_tbl_no_pin(struct st_table *tbl);
void rb_mark_set(struct st_table *tbl);
void rb_mark_hash(struct st_table *tbl);
void rb_gc_update_tbl_refs(st_table *ptr);
void rb_gc_mark_maybe(VALUE obj);
void rb_gc_mark(VALUE obj);
void rb_gc_mark_movable(VALUE obj);
VALUE rb_gc_location(VALUE obj);
void rb_gc(void);
void rb_gc_copy_finalizer(VALUE dst, VALUE src);
VALUE rb_gc_enable(void);
VALUE rb_gc_disable(void);
VALUE rb_gc_start(void);
VALUE rb_define_finalizer(VALUE obj, VALUE block);
VALUE rb_undefine_finalizer(VALUE obj);
size_t rb_gc_count(void);
size_t rb_gc_stat(VALUE key_or_buf);
VALUE rb_gc_latest_gc_info(VALUE key_or_buf);
void rb_gc_adjust_memory_usage(ssize_t diff);
void rb_gc_register_address(VALUE *valptr);
void rb_global_variable(VALUE *);
void rb_gc_unregister_address(VALUE *valptr);
void rb_gc_register_mark_object(VALUE object);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

void rb_gc_writebarrier(VALUE old, VALUE young);
void rb_gc_writebarrier_unprotect(VALUE obj);

#pragma GCC visibility pop

__attribute__((__pure__))
__attribute__((__artificial__))
static inline _Bool
RB_OBJ_PROMOTED_RAW(VALUE obj)
{
    ((void)0);
    return RB_FL_ANY_RAW(obj, RUBY_FL_PROMOTED);
}
__attribute__((__pure__))
__attribute__((__artificial__))
static inline _Bool
RB_OBJ_PROMOTED(VALUE obj)
{
    if (! RB_FL_ABLE(obj)) {
        return 0;
    }
    else {
        return RB_OBJ_PROMOTED_RAW(obj);
    }
}
static inline VALUE
rb_obj_wb_unprotect(
    VALUE x,
    [[maybe_unused]]
    const char *filename,
    [[maybe_unused]]
    int line)
{
    rb_gc_writebarrier_unprotect(x);
    return x;
}
static inline VALUE
rb_obj_written(
    VALUE a,
    [[maybe_unused]]
    VALUE oldv,
    VALUE b,
    [[maybe_unused]]
    const char *filename,
    [[maybe_unused]]
    int line)
{
    if (!RB_SPECIAL_CONST_P(b)) {
        rb_gc_writebarrier(a, b);
    }
    return a;
}
static inline VALUE
rb_obj_write(
    VALUE a, VALUE *slot, VALUE b,
    [[maybe_unused]]
    const char *filename,
    [[maybe_unused]]
    int line)
{
    *slot = b;
    rb_obj_written(a, ((VALUE)RUBY_Qundef) , b, filename, line);
    return a;
}
__attribute__((__deprecated__ ("Will be removed soon")))
static inline void rb_gc_force_recycle(VALUE obj){}
enum ruby_rarray_flags {
    RARRAY_EMBED_FLAG = RUBY_FL_USER1,
    RARRAY_EMBED_LEN_MASK = RUBY_FL_USER9 | RUBY_FL_USER8 | RUBY_FL_USER7 | RUBY_FL_USER6 |
                                 RUBY_FL_USER5 | RUBY_FL_USER4 | RUBY_FL_USER3
};
enum ruby_rarray_consts {
    RARRAY_EMBED_LEN_SHIFT = RUBY_FL_USHIFT + 3
};
struct RArray {
    struct RBasic basic;
    union {
        struct {
            long len;
            union {
                long capa;
                const
                VALUE shared_root;
            } aux;
            const VALUE *ptr;
        } heap;
        const VALUE ary[1];
    } as;
};

#pragma GCC visibility push(default)

VALUE *rb_ary_ptr_use_start(VALUE ary);
void rb_ary_ptr_use_end(VALUE a);

#pragma GCC visibility pop

__attribute__((__pure__))
__attribute__((__artificial__))
static inline long
RARRAY_EMBED_LEN(VALUE ary)
{
    ((void)0);
    ((void)0);
    VALUE f = ((struct RBasic *)(ary))->flags;
    f &= RARRAY_EMBED_LEN_MASK;
    f >>= RARRAY_EMBED_LEN_SHIFT;
    return ((long)f);
}
__attribute__((__pure__))
static inline long
rb_array_len(VALUE a)
{
    ((void)0);
    if (RB_FL_ANY_RAW(a, RARRAY_EMBED_FLAG)) {
        return RARRAY_EMBED_LEN(a);
    }
    else {
        return ((struct RArray *)(a))->as.heap.len;
    }
}
__attribute__((__artificial__))
static inline int
RARRAY_LENINT(VALUE ary)
{
    return rb_long2int_inline(rb_array_len(ary));
}
__attribute__((__pure__))
static inline const VALUE *
rb_array_const_ptr(VALUE a)
{
    ((void)0);
    if (RB_FL_ANY_RAW(a, RARRAY_EMBED_FLAG)) {
        return (((struct RArray *)(a))->as.ary);
    }
    else {
        return (((struct RArray *)(a))->as.heap.ptr);
    }
}
static inline VALUE *
RARRAY_PTR(VALUE ary)
{
    ((void)0);
    VALUE tmp = (1 ? rb_obj_wb_unprotect(ary, "./include/ruby/internal/core/rarray.h", 370) : ary);
    return ((VALUE *)rb_array_const_ptr(tmp));
}
static inline void
RARRAY_ASET(VALUE ary, long i, VALUE v)
{
    do { ((void)0); const VALUE rbimpl_ary = (ary); VALUE *ptr = rb_ary_ptr_use_start(rbimpl_ary); (rb_obj_write((VALUE)(ary), (VALUE *)(&ptr[i]), (VALUE)(v), "./include/ruby/internal/core/rarray.h", 389)); rb_ary_ptr_use_end(rbimpl_ary); } while (0);
}

#pragma GCC visibility push(default)

int rb_big_sign(VALUE num);

#pragma GCC visibility pop

static inline _Bool
RBIGNUM_POSITIVE_P(VALUE b)
{
    ((void)0);
    return rb_big_sign(b);
}
static inline _Bool
RBIGNUM_NEGATIVE_P(VALUE b)
{
    ((void)0);
    return ! RBIGNUM_POSITIVE_P(b);
}
enum ruby_rmodule_flags {
    RMODULE_IS_REFINEMENT = RUBY_FL_USER3
};
struct RClass;

#pragma GCC visibility push(default)

VALUE rb_class_get_superclass(VALUE klass);

#pragma GCC visibility pop

typedef void (*RUBY_DATA_FUNC)(void*);
struct RData {
    struct RBasic basic;
    RUBY_DATA_FUNC dmark;
    RUBY_DATA_FUNC dfree;
    void *data;
};

#pragma GCC visibility push(default)

VALUE rb_data_object_wrap(VALUE klass, void *datap, RUBY_DATA_FUNC dmark, RUBY_DATA_FUNC dfree);
VALUE rb_data_object_zalloc(VALUE klass, size_t size, RUBY_DATA_FUNC dmark, RUBY_DATA_FUNC dfree);
extern VALUE rb_cObject;

#pragma GCC visibility pop

__attribute__((__warning__ ("untyped Data is unsafe; use TypedData instead"))) __attribute__((__deprecated__ ("by TypedData")))
static inline VALUE
rb_data_object_wrap_warning(VALUE klass, void *ptr, RUBY_DATA_FUNC mark, RUBY_DATA_FUNC free)
{
    return rb_data_object_wrap(klass, ptr, mark, free);
}
static inline void *
rb_data_object_get(VALUE obj)
{
    Check_Type(obj, RUBY_T_DATA);
    return ((struct RData *)(obj))->data;
}
__attribute__((__warning__ ("untyped Data is unsafe; use TypedData instead"))) __attribute__((__deprecated__ ("by TypedData")))
static inline void *
rb_data_object_get_warning(VALUE obj)
{
    return rb_data_object_get(obj);
}
static inline VALUE
rb_data_object_make(VALUE klass, RUBY_DATA_FUNC mark_func, RUBY_DATA_FUNC free_func, void **datap, size_t size)
{
    VALUE result = rb_data_object_zalloc( (klass), (size), ((void (*)(void *))(mark_func)), ((void (*)(void *))(free_func))); (*datap) = ((void *)((struct RData *)(result))->data); ((void)(*datap));
    return result;
}
__attribute__((__deprecated__ ("by: rb_data_object_wrap")))
static inline VALUE
rb_data_object_alloc(VALUE klass, void *data, RUBY_DATA_FUNC dmark, RUBY_DATA_FUNC dfree)
{
    return rb_data_object_wrap(klass, data, dmark, dfree);
}
struct rb_io;
struct RFile {
    struct RBasic basic;
    struct rb_io *fptr;
};

#pragma GCC visibility push(default)

__attribute__((__nonnull__ ()))
void ruby_sysinit(int *argc, char ***argv);
void ruby_init(void);
void* ruby_options(int argc, char** argv);
int ruby_executable_node(void *n, int *status);
int ruby_run_node(void *n);
void ruby_show_version(void);
void ruby_show_copyright(void);
void ruby_init_stack(void *addr);
int ruby_setup(void);
int ruby_cleanup(int ex);
void ruby_finalize(void);
__attribute__((__noreturn__))
void ruby_stop(int);
int ruby_stack_check(void);
size_t ruby_stack_length(VALUE **topnotch);
int ruby_exec_node(void *n);
void ruby_script(const char* name);
void ruby_set_script_name(VALUE name);
void ruby_prog_init(void);
void ruby_set_argv(int argc, char **argv);
void *ruby_process_options(int argc, char **argv);
void ruby_init_loadpath(void);
void ruby_incpush(const char *path);
void ruby_sig_finalize(void);

#pragma GCC visibility pop

__attribute__((__deprecated__ ("only for internal use"))) void rb_clear_constant_cache(void);
struct st_table;

#pragma GCC visibility push(default)

size_t rb_hash_size_num(VALUE hash);
struct st_table *rb_hash_tbl(VALUE hash, const char *file, int line);
VALUE rb_hash_set_ifnone(VALUE hash, VALUE ifnone);

#pragma GCC visibility pop

enum ruby_robject_flags {
    ROBJECT_EMBED = RUBY_FL_USER1
};
struct st_table;
struct RObject {
    struct RBasic basic;
    union {
        struct {
            VALUE *ivptr;
            struct rb_id_table *iv_index_tbl;
        } heap;
        VALUE ary[1];
    } as;
};
__attribute__((__pure__))
__attribute__((__artificial__))
static inline VALUE *
ROBJECT_IVPTR(VALUE obj)
{
    ((void)0);
    struct RObject *const ptr = ((struct RObject *)(obj));
    if (RB_FL_ANY_RAW(obj, ROBJECT_EMBED)) {
        return ptr->as.ary;
    }
    else {
        return ptr->as.heap.ivptr;
    }
}
struct re_patter_buffer;
struct RRegexp {
    struct RBasic basic;
    struct re_pattern_buffer *ptr;
    const VALUE src;
    unsigned long usecnt;
};
__attribute__((__pure__))
__attribute__((__artificial__))
static inline VALUE
RREGEXP_SRC(VALUE rexp)
{
    ((void)0);
    VALUE ret = ((struct RRegexp *)(rexp))->src;
    ((void)0);
    return ret;
}
__attribute__((__pure__))
__attribute__((__artificial__))
static inline char *
RREGEXP_SRC_PTR(VALUE rexp)
{
    return RSTRING_PTR(RREGEXP_SRC(rexp));
}
__attribute__((__pure__))
__attribute__((__artificial__))
static inline long
RREGEXP_SRC_LEN(VALUE rexp)
{
    return RSTRING_LEN(RREGEXP_SRC(rexp));
}
__attribute__((__pure__))
__attribute__((__artificial__))
static inline char *
RREGEXP_SRC_END(VALUE rexp)
{
    return RSTRING_END(RREGEXP_SRC(rexp));
}

#pragma GCC visibility push(default)

VALUE rb_struct_size(VALUE st);
VALUE rb_struct_aref(VALUE st, VALUE k);
VALUE rb_struct_aset(VALUE st, VALUE k, VALUE v);

#pragma GCC visibility pop

__attribute__((__artificial__))
static inline long
RSTRUCT_LEN(VALUE st)
{
    ((void)0);
    return rb_num2long_inline(rb_struct_size(st));
}
__attribute__((__artificial__))
static inline VALUE
RSTRUCT_SET(VALUE st, int k, VALUE v)
{
    ((void)0);
    return rb_struct_aset(st, rb_int2num_inline(k), (v));
}
__attribute__((__artificial__))
static inline VALUE
RSTRUCT_GET(VALUE st, int k)
{
    ((void)0);
    return rb_struct_aref(st, rb_int2num_inline(k));
}
enum

rbimpl_typeddata_flags {
    RUBY_TYPED_FREE_IMMEDIATELY = 1,
    RUBY_TYPED_EMBEDDABLE = 2,
    RUBY_TYPED_FROZEN_SHAREABLE = RUBY_FL_SHAREABLE,
    RUBY_TYPED_WB_PROTECTED = RUBY_FL_WB_PROTECTED,
    RUBY_TYPED_UNUSED = RUBY_FL_UNUSED6,
    RUBY_TYPED_DECL_MARKING = RUBY_FL_USER2
};
typedef struct rb_data_type_struct rb_data_type_t;
struct rb_data_type_struct {
    const char *wrap_struct_name;
    struct {
        RUBY_DATA_FUNC dmark;
        RUBY_DATA_FUNC dfree;
        size_t (*dsize)(const void *);
        RUBY_DATA_FUNC dcompact;
        void *reserved[1];
    } function;
    const rb_data_type_t *parent;
    void *data;
    VALUE flags;
};
struct RTypedData {
    struct RBasic basic;
    const rb_data_type_t *const type;
    const VALUE typed_flag;
    void *data;
};

#pragma GCC visibility push(default)

__attribute__((__nonnull__ (3)))
VALUE rb_data_typed_object_wrap(VALUE klass, void *datap, const rb_data_type_t *type);
VALUE rb_data_typed_object_zalloc(VALUE klass, size_t size, const rb_data_type_t *type);
int rb_typeddata_inherited_p(const rb_data_type_t *child, const rb_data_type_t *parent);
int rb_typeddata_is_kind_of(VALUE obj, const rb_data_type_t *data_type);
void *rb_check_typeddata(VALUE obj, const rb_data_type_t *data_type);

#pragma GCC visibility pop

static inline _Bool
RTYPEDDATA_EMBEDDED_P(VALUE obj)
{
    return ((struct RTypedData *)(obj))->typed_flag & 2;
}
static inline void *
RTYPEDDATA_GET_DATA(VALUE obj)
{
    const size_t embedded_typed_data_size = sizeof(struct RTypedData) - sizeof(void *);
    return RTYPEDDATA_EMBEDDED_P(obj) ? (char *)obj + embedded_typed_data_size : ((struct RTypedData *)(obj))->data;
}
__attribute__((__pure__))
__attribute__((__artificial__))
static inline _Bool
rbimpl_rtypeddata_p(VALUE obj)
{
    VALUE typed_flag = ((struct RTypedData *)(obj))->typed_flag;
    return typed_flag != 0 && typed_flag <= 3;
}
__attribute__((__pure__))
__attribute__((__artificial__))
static inline _Bool
RTYPEDDATA_P(VALUE obj)
{
    return rbimpl_rtypeddata_p(obj);
}
__attribute__((__pure__))
__attribute__((__artificial__))
static inline const struct rb_data_type_struct *
RTYPEDDATA_TYPE(VALUE obj)
{
    return ((struct RTypedData *)(obj))->type;
}
static inline VALUE
rb_data_typed_object_make(VALUE klass, const rb_data_type_t *type, void **datap, size_t size)
{
    VALUE result = rb_data_typed_object_zalloc(klass, size, type); (*datap) = (void *)RTYPEDDATA_GET_DATA(result); ((void)(*datap));
    return result;
}
__attribute__((__deprecated__ ("by: rb_data_typed_object_wrap")))
static inline VALUE
rb_data_typed_object_alloc(VALUE klass, void *datap, const rb_data_type_t *type)
{
    return rb_data_typed_object_wrap(klass, datap, type);
}

enum
{
  _ISupper = ((0) < 8 ? ((1 << (0)) << 8) : ((1 << (0)) >> 8)),
  _ISlower = ((1) < 8 ? ((1 << (1)) << 8) : ((1 << (1)) >> 8)),
  _ISalpha = ((2) < 8 ? ((1 << (2)) << 8) : ((1 << (2)) >> 8)),
  _ISdigit = ((3) < 8 ? ((1 << (3)) << 8) : ((1 << (3)) >> 8)),
  _ISxdigit = ((4) < 8 ? ((1 << (4)) << 8) : ((1 << (4)) >> 8)),
  _ISspace = ((5) < 8 ? ((1 << (5)) << 8) : ((1 << (5)) >> 8)),
  _ISprint = ((6) < 8 ? ((1 << (6)) << 8) : ((1 << (6)) >> 8)),
  _ISgraph = ((7) < 8 ? ((1 << (7)) << 8) : ((1 << (7)) >> 8)),
  _ISblank = ((8) < 8 ? ((1 << (8)) << 8) : ((1 << (8)) >> 8)),
  _IScntrl = ((9) < 8 ? ((1 << (9)) << 8) : ((1 << (9)) >> 8)),
  _ISpunct = ((10) < 8 ? ((1 << (10)) << 8) : ((1 << (10)) >> 8)),
  _ISalnum = ((11) < 8 ? ((1 << (11)) << 8) : ((1 << (11)) >> 8))
};
extern const unsigned short int **__ctype_b_loc (void)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern const __int32_t **__ctype_tolower_loc (void)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern const __int32_t **__ctype_toupper_loc (void)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern int isalnum (int) __attribute__ ((__nothrow__ , __leaf__));
extern int isalpha (int) __attribute__ ((__nothrow__ , __leaf__));
extern int iscntrl (int) __attribute__ ((__nothrow__ , __leaf__));
extern int isdigit (int) __attribute__ ((__nothrow__ , __leaf__));
extern int islower (int) __attribute__ ((__nothrow__ , __leaf__));
extern int isgraph (int) __attribute__ ((__nothrow__ , __leaf__));
extern int isprint (int) __attribute__ ((__nothrow__ , __leaf__));
extern int ispunct (int) __attribute__ ((__nothrow__ , __leaf__));
extern int isspace (int) __attribute__ ((__nothrow__ , __leaf__));
extern int isupper (int) __attribute__ ((__nothrow__ , __leaf__));
extern int isxdigit (int) __attribute__ ((__nothrow__ , __leaf__));
extern int tolower (int __c) __attribute__ ((__nothrow__ , __leaf__));
extern int toupper (int __c) __attribute__ ((__nothrow__ , __leaf__));
extern int isblank (int) __attribute__ ((__nothrow__ , __leaf__));
extern int isctype (int __c, int __mask) __attribute__ ((__nothrow__ , __leaf__));
extern int isascii (int __c) __attribute__ ((__nothrow__ , __leaf__));
extern int toascii (int __c) __attribute__ ((__nothrow__ , __leaf__));
extern int _toupper (int) __attribute__ ((__nothrow__ , __leaf__));
extern int _tolower (int) __attribute__ ((__nothrow__ , __leaf__));
extern int isalnum_l (int, locale_t) __attribute__ ((__nothrow__ , __leaf__));
extern int isalpha_l (int, locale_t) __attribute__ ((__nothrow__ , __leaf__));
extern int iscntrl_l (int, locale_t) __attribute__ ((__nothrow__ , __leaf__));
extern int isdigit_l (int, locale_t) __attribute__ ((__nothrow__ , __leaf__));
extern int islower_l (int, locale_t) __attribute__ ((__nothrow__ , __leaf__));
extern int isgraph_l (int, locale_t) __attribute__ ((__nothrow__ , __leaf__));
extern int isprint_l (int, locale_t) __attribute__ ((__nothrow__ , __leaf__));
extern int ispunct_l (int, locale_t) __attribute__ ((__nothrow__ , __leaf__));
extern int isspace_l (int, locale_t) __attribute__ ((__nothrow__ , __leaf__));
extern int isupper_l (int, locale_t) __attribute__ ((__nothrow__ , __leaf__));
extern int isxdigit_l (int, locale_t) __attribute__ ((__nothrow__ , __leaf__));
extern int isblank_l (int, locale_t) __attribute__ ((__nothrow__ , __leaf__));
extern int __tolower_l (int __c, locale_t __l) __attribute__ ((__nothrow__ , __leaf__));
extern int tolower_l (int __c, locale_t __l) __attribute__ ((__nothrow__ , __leaf__));
extern int __toupper_l (int __c, locale_t __l) __attribute__ ((__nothrow__ , __leaf__));
extern int toupper_l (int __c, locale_t __l) __attribute__ ((__nothrow__ , __leaf__));


#pragma GCC visibility push(default)

__attribute__((__nonnull__ ()))
int rb_st_locale_insensitive_strcasecmp(const char *s1, const char *s2);
__attribute__((__nonnull__ ()))
int rb_st_locale_insensitive_strncasecmp(const char *s1, const char *s2, size_t n);
__attribute__((__nonnull__ (1)))
unsigned long ruby_strtoul(const char *str, char **endptr, int base);

#pragma GCC visibility pop

__attribute__((__const__))

__attribute__((__artificial__))
static inline int
rb_isascii(int c)
{
    return '\0' <= c && c <= '\x7f';
}
__attribute__((__const__))

__attribute__((__artificial__))
static inline int
rb_isupper(int c)
{
    return 'A' <= c && c <= 'Z';
}
__attribute__((__const__))

__attribute__((__artificial__))
static inline int
rb_islower(int c)
{
    return 'a' <= c && c <= 'z';
}
__attribute__((__const__))

__attribute__((__artificial__))
static inline int
rb_isalpha(int c)
{
    return rb_isupper(c) || rb_islower(c);
}
__attribute__((__const__))

__attribute__((__artificial__))
static inline int
rb_isdigit(int c)
{
    return '0' <= c && c <= '9';
}
__attribute__((__const__))

__attribute__((__artificial__))
static inline int
rb_isalnum(int c)
{
    return rb_isalpha(c) || rb_isdigit(c);
}
__attribute__((__const__))

__attribute__((__artificial__))
static inline int
rb_isxdigit(int c)
{
    return rb_isdigit(c) || ('A' <= c && c <= 'F') || ('a' <= c && c <= 'f');
}
__attribute__((__const__))

__attribute__((__artificial__))
static inline int
rb_isblank(int c)
{
    return c == ' ' || c == '\t';
}
__attribute__((__const__))

__attribute__((__artificial__))
static inline int
rb_isspace(int c)
{
    return c == ' ' || ('\t' <= c && c <= '\r');
}
__attribute__((__const__))

__attribute__((__artificial__))
static inline int
rb_iscntrl(int c)
{
    return ('\0' <= c && c < ' ') || c == '\x7f';
}
__attribute__((__const__))

__attribute__((__artificial__))
static inline int
rb_isprint(int c)
{
    return ' ' <= c && c <= '\x7e';
}
__attribute__((__const__))

__attribute__((__artificial__))
static inline int
rb_ispunct(int c)
{
    return !rb_isalnum(c);
}
__attribute__((__const__))

__attribute__((__artificial__))
static inline int
rb_isgraph(int c)
{
    return '!' <= c && c <= '\x7e';
}
__attribute__((__const__))

__attribute__((__artificial__))
static inline int
rb_tolower(int c)
{
    return rb_isupper(c) ? (c|0x20) : c;
}
__attribute__((__const__))

__attribute__((__artificial__))
static inline int
rb_toupper(int c)
{
    return rb_islower(c) ? (c&0x5f) : c;
}

#pragma GCC visibility push(default)

__attribute__((__nonnull__ ()))
VALUE rb_eval_string(const char *str);
__attribute__((__nonnull__ (1)))
VALUE rb_eval_string_protect(const char *str, int *state);
__attribute__((__nonnull__ (1)))
VALUE rb_eval_string_wrap(const char *str, int *state);
VALUE rb_funcall(VALUE recv, ID mid, int n, ...);
VALUE rb_funcallv(VALUE recv, ID mid, int argc, const VALUE *argv);
VALUE rb_funcallv_kw(VALUE recv, ID mid, int argc, const VALUE *argv, int kw_splat);
VALUE rb_funcallv_public(VALUE recv, ID mid, int argc, const VALUE *argv);
VALUE rb_funcallv_public_kw(VALUE recv, ID mid, int argc, const VALUE *argv, int kw_splat);
VALUE rb_funcall_passing_block(VALUE recv, ID mid, int argc, const VALUE *argv);
VALUE rb_funcall_passing_block_kw(VALUE recv, ID mid, int argc, const VALUE *argv, int kw_splat);
VALUE rb_funcall_with_block(VALUE recv, ID mid, int argc, const VALUE *argv, VALUE procval);
VALUE rb_funcall_with_block_kw(VALUE recv, ID mid, int argc, const VALUE *argv, VALUE procval, int kw_splat);
VALUE rb_call_super(int argc, const VALUE *argv);
VALUE rb_call_super_kw(int argc, const VALUE *argv, int kw_splat);
VALUE rb_current_receiver(void);
__attribute__((__nonnull__ (2)))
int rb_get_kwargs(VALUE keyword_hash, const ID *table, int required, int optional, VALUE *values);
__attribute__((__nonnull__ ()))
VALUE rb_extract_keywords(VALUE *orighash);

#pragma GCC visibility pop

typedef uint32_t rb_event_flag_t;
typedef void (*rb_event_hook_func_t)(rb_event_flag_t evflag, VALUE data, VALUE self, ID mid, VALUE klass);

#pragma GCC visibility push(default)

void rb_add_event_hook(rb_event_hook_func_t func, rb_event_flag_t events, VALUE data);
int rb_remove_event_hook(rb_event_hook_func_t func);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

typedef int ruby_glob_func(const char *path, VALUE arg, void *enc);
__attribute__((__nonnull__ ()))
void rb_glob(const char *pattern, void (*func)(const char *path, VALUE arg, void *enc), VALUE arg);
__attribute__((__nonnull__ ()))
int ruby_glob(const char *pattern, int flags, ruby_glob_func *func, VALUE arg);
__attribute__((__nonnull__ ()))
int ruby_brace_glob(const char *pattern, int flags, ruby_glob_func *func, VALUE arg);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

extern VALUE rb_mKernel;
extern VALUE rb_mComparable;
extern VALUE rb_mEnumerable;
extern VALUE rb_mErrno;
extern VALUE rb_mFileTest;
extern VALUE rb_mGC;
extern VALUE rb_mMath;
extern VALUE rb_mProcess;
extern VALUE rb_mWaitReadable;
extern VALUE rb_mWaitWritable;
extern VALUE rb_cBasicObject;
extern VALUE rb_cObject;
extern VALUE rb_cArray;
extern VALUE rb_cBinding;
extern VALUE rb_cClass;
extern VALUE rb_cDir;
extern VALUE rb_cEncoding;
extern VALUE rb_cEnumerator;
extern VALUE rb_cFalseClass;
extern VALUE rb_cFile;
extern VALUE rb_cComplex;
extern VALUE rb_cFloat;
extern VALUE rb_cHash;
extern VALUE rb_cIO;
extern VALUE rb_cInteger;
extern VALUE rb_cMatch;
extern VALUE rb_cMethod;
extern VALUE rb_cModule;
extern VALUE rb_cRefinement;
extern VALUE rb_cNameErrorMesg;
extern VALUE rb_cNilClass;
extern VALUE rb_cNumeric;
extern VALUE rb_cProc;
extern VALUE rb_cRandom;
extern VALUE rb_cRange;
extern VALUE rb_cRational;
extern VALUE rb_cRegexp;
extern VALUE rb_cStat;
extern VALUE rb_cString;
extern VALUE rb_cStruct;
extern VALUE rb_cSymbol;
extern VALUE rb_cThread;
extern VALUE rb_cTime;
extern VALUE rb_cTrueClass;
extern VALUE rb_cUnboundMethod;
extern VALUE rb_eException;
extern VALUE rb_eStandardError;
extern VALUE rb_eSystemExit;
extern VALUE rb_eInterrupt;
extern VALUE rb_eSignal;
extern VALUE rb_eFatal;
extern VALUE rb_eArgError;
extern VALUE rb_eEOFError;
extern VALUE rb_eIndexError;
extern VALUE rb_eStopIteration;
extern VALUE rb_eKeyError;
extern VALUE rb_eRangeError;
extern VALUE rb_eIOError;
extern VALUE rb_eRuntimeError;
extern VALUE rb_eFrozenError;
extern VALUE rb_eSecurityError;
extern VALUE rb_eSystemCallError;
extern VALUE rb_eThreadError;
extern VALUE rb_eTypeError;
extern VALUE rb_eZeroDivError;
extern VALUE rb_eNotImpError;
extern VALUE rb_eNoMemError;
extern VALUE rb_eNoMethodError;
extern VALUE rb_eFloatDomainError;
extern VALUE rb_eLocalJumpError;
extern VALUE rb_eSysStackError;
extern VALUE rb_eRegexpError;
extern VALUE rb_eEncodingError;
extern VALUE rb_eEncCompatError;
extern VALUE rb_eNoMatchingPatternError;
extern VALUE rb_eNoMatchingPatternKeyError;
extern VALUE rb_eScriptError;
extern VALUE rb_eNameError;
extern VALUE rb_eSyntaxError;
extern VALUE rb_eLoadError;
extern VALUE rb_eMathDomainError;
extern VALUE rb_stdin;
extern VALUE rb_stdout;
extern VALUE rb_stderr;
__attribute__((__pure__))
static inline VALUE
rb_class_of(VALUE obj)
{
    if (! RB_SPECIAL_CONST_P(obj)) {
        return RBASIC_CLASS(obj);
    }
    else if (obj == ((VALUE)RUBY_Qfalse)) {
        return rb_cFalseClass;
    }
    else if (obj == ((VALUE)RUBY_Qnil)) {
        return rb_cNilClass;
    }
    else if (obj == ((VALUE)RUBY_Qtrue)) {
        return rb_cTrueClass;
    }
    else if (RB_FIXNUM_P(obj)) {
        return rb_cInteger;
    }
    else if (RB_STATIC_SYM_P(obj)) {
        return rb_cSymbol;
    }
    else if (RB_FLONUM_P(obj)) {
        return rb_cFloat;
    }
    __builtin_unreachable();
}

#pragma GCC visibility pop


#pragma GCC visibility push(default)

typedef VALUE rb_block_call_func(VALUE yielded_arg, VALUE callback_arg, int argc, const VALUE *argv, VALUE blockarg);
typedef rb_block_call_func *rb_block_call_func_t;
VALUE rb_each(VALUE obj);
VALUE rb_yield(VALUE val);
VALUE rb_yield_values(int n, ...);
VALUE rb_yield_values2(int n, const VALUE *argv);
VALUE rb_yield_values_kw(int n, const VALUE *argv, int kw_splat);
VALUE rb_yield_splat(VALUE ary);
VALUE rb_yield_splat_kw(VALUE ary, int kw_splat);
VALUE rb_yield_block(VALUE yielded_arg, VALUE callback_arg, int argc, const VALUE *argv, VALUE blockarg);
int rb_keyword_given_p(void);
int rb_block_given_p(void);
void rb_need_block(void);
__attribute__((__deprecated__ ("by: rb_block_call since 1.9")))
VALUE rb_iterate(VALUE (*func1)(VALUE), VALUE data1, rb_block_call_func_t proc, VALUE data2);
VALUE rb_block_call(VALUE obj, ID mid, int argc, const VALUE *argv, rb_block_call_func_t proc, VALUE data2);
VALUE rb_block_call_kw(VALUE obj, ID mid, int argc, const VALUE *argv, rb_block_call_func_t proc, VALUE data2, int kw_splat);
VALUE rb_rescue(VALUE (*b_proc)(VALUE), VALUE data1, VALUE (*r_proc)(VALUE, VALUE), VALUE data2);
VALUE rb_rescue2(VALUE (*b_proc)(VALUE), VALUE data1, VALUE (*r_proc)(VALUE, VALUE), VALUE data2, ...);
VALUE rb_vrescue2(VALUE (*b_proc)(VALUE), VALUE data1, VALUE (*r_proc)(VALUE, VALUE), VALUE data2, va_list ap);
VALUE rb_ensure(VALUE (*b_proc)(VALUE), VALUE data1, VALUE (*e_proc)(VALUE), VALUE data2);
VALUE rb_catch(const char *tag, rb_block_call_func_t func, VALUE data);
VALUE rb_catch_obj(VALUE tag, rb_block_call_func_t func, VALUE data);
__attribute__((__noreturn__))
void rb_throw(const char *tag, VALUE val);
__attribute__((__noreturn__))
void rb_throw_obj(VALUE tag, VALUE val);

#pragma GCC visibility pop

struct rbimpl_size_mul_overflow_tag {
    _Bool left;
    size_t right;
};

#pragma GCC visibility push(default)

__attribute__((__malloc__))
__attribute__((__returns_nonnull__))
__attribute__((__alloc_size__ (2)))
__attribute__((__nonnull__ ()))
void *rb_alloc_tmp_buffer(volatile VALUE *store, long len);
__attribute__((__malloc__))
__attribute__((__returns_nonnull__))
__attribute__((__alloc_size__ (2,3)))
__attribute__((__nonnull__ ()))
void *rb_alloc_tmp_buffer_with_count(volatile VALUE *store, size_t len,size_t count);
void rb_free_tmp_buffer(volatile VALUE *store);
__attribute__((__noreturn__))
void ruby_malloc_size_overflow(size_t x, size_t y);

#pragma GCC visibility pop

static inline int
rb_mul_size_overflow(size_t a, size_t b, size_t max, size_t *c)
{
    __extension__ unsigned __int128 da, db, c2;
    da = a;
    db = b;
    c2 = da * db;
    if (c2 > max) return 1;
    *c = ((size_t)c2);
    return 0;
}

__attribute__((__const__))
static inline struct rbimpl_size_mul_overflow_tag
rbimpl_size_mul_overflow(size_t x, size_t y)
{
    struct rbimpl_size_mul_overflow_tag ret = { 0, 0, };
    ret.left = ((_Bool)__builtin_mul_overflow((x), (y), (&ret.right)));
    return ret;
}
static inline size_t
rbimpl_size_mul_or_raise(size_t x, size_t y)
{
    struct rbimpl_size_mul_overflow_tag size =
        rbimpl_size_mul_overflow(x, y);
    if ((__builtin_expect(!!(! size.left), 1))) {
        return size.right;
    }
    else {
        ruby_malloc_size_overflow(x, y);
        __builtin_unreachable();
    }
}
static inline void *
rb_alloc_tmp_buffer2(volatile VALUE *store, long count, size_t elsize)
{
    const size_t total_size = rbimpl_size_mul_or_raise(((size_t)count), elsize);
    const size_t cnt = (total_size + sizeof(VALUE) - 1) / sizeof(VALUE);
    return rb_alloc_tmp_buffer_with_count(store, total_size, cnt);
}

#pragma GCC visibility push(default)


__attribute__((__nonnull__ (1)))
__attribute__((__returns_nonnull__))
static inline void *
ruby_nonempty_memcpy(void *dest, const void *src, size_t n)
{
    if (n) {
        return memcpy(dest, src, n);
    }
    else {
        return dest;
    }
}

#pragma GCC visibility pop


#pragma GCC visibility push(default)

__attribute__((__nonnull__ ()))
VALUE rb_define_class(const char *name, VALUE super);
__attribute__((__nonnull__ ()))
VALUE rb_define_module(const char *name);
__attribute__((__nonnull__ ()))
VALUE rb_define_class_under(VALUE outer, const char *name, VALUE super);
__attribute__((__nonnull__ ()))
VALUE rb_define_module_under(VALUE outer, const char *name);
void rb_include_module(VALUE klass, VALUE module);
void rb_extend_object(VALUE obj, VALUE mod);
void rb_prepend_module(VALUE klass, VALUE module);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

VALUE rb_obj_setup(VALUE obj, VALUE klass, VALUE type);
VALUE rb_obj_class(VALUE obj);
VALUE rb_singleton_class_clone(VALUE obj);
void rb_singleton_class_attached(VALUE klass, VALUE obj);
void rb_copy_generic_ivar(VALUE clone, VALUE obj);

#pragma GCC visibility pop

__attribute__((__deprecated__ ("This is no longer how Object#clone works.")))
static inline void
rb_clone_setup(VALUE clone, VALUE obj)
{
    (void)clone;
    (void)obj;
    return;
}
__attribute__((__deprecated__ ("This is no longer how Object#dup works.")))
static inline void
rb_dup_setup(VALUE dup, VALUE obj)
{
    (void)dup;
    (void)obj;
    return;
}

#pragma GCC visibility push(default)

__attribute__((__nonnull__ ()))

void rb_mem_clear(VALUE *buf, long len)
   
    ;
VALUE rb_assoc_new(VALUE car, VALUE cdr);
VALUE rb_check_array_type(VALUE obj);
VALUE rb_ary_new(void);
VALUE rb_ary_new_capa(long capa);
VALUE rb_ary_new_from_args(long n, ...);
VALUE rb_ary_new_from_values(long n, const VALUE *elts);
VALUE rb_ary_hidden_new(long capa);
void rb_ary_free(VALUE ary);
void rb_ary_modify(VALUE ary);
VALUE rb_ary_freeze(VALUE obj);
__attribute__((__pure__))
VALUE rb_ary_shared_with_p(VALUE lhs, VALUE rhs);
VALUE rb_ary_aref(int argc, const VALUE *argv, VALUE ary);
VALUE rb_ary_subseq(VALUE ary, long beg, long len);
void rb_ary_store(VALUE ary, long key, VALUE val);
VALUE rb_ary_dup(VALUE ary);
VALUE rb_ary_resurrect(VALUE ary);
VALUE rb_ary_to_ary(VALUE obj);
VALUE rb_ary_to_s(VALUE ary);
VALUE rb_ary_cat(VALUE ary, const VALUE *train, long len);
VALUE rb_ary_push(VALUE ary, VALUE elem);
VALUE rb_ary_pop(VALUE ary);
VALUE rb_ary_shift(VALUE ary);
VALUE rb_ary_unshift(VALUE ary, VALUE elem);
__attribute__((__pure__))
VALUE rb_ary_entry(VALUE ary, long off);
VALUE rb_ary_each(VALUE ary);
VALUE rb_ary_join(VALUE ary, VALUE sep);
VALUE rb_ary_reverse(VALUE ary);
VALUE rb_ary_rotate(VALUE ary, long rot);
VALUE rb_ary_sort(VALUE ary);
VALUE rb_ary_sort_bang(VALUE ary);
VALUE rb_ary_delete(VALUE ary, VALUE elem);
VALUE rb_ary_delete_at(VALUE ary, long pos);
VALUE rb_ary_clear(VALUE ary);
VALUE rb_ary_plus(VALUE lhs, VALUE rhs);
VALUE rb_ary_concat(VALUE lhs, VALUE rhs);
VALUE rb_ary_assoc(VALUE alist, VALUE key);
VALUE rb_ary_rassoc(VALUE alist, VALUE key);
VALUE rb_ary_includes(VALUE ary, VALUE elem);
VALUE rb_ary_cmp(VALUE lhs, VALUE rhs);
VALUE rb_ary_replace(VALUE copy, VALUE orig);
VALUE rb_get_values_at(VALUE obj, long olen, int argc, const VALUE *argv, VALUE (*func)(VALUE obj, long oidx));
VALUE rb_ary_resize(VALUE ary, long len);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

VALUE rb_exc_new(VALUE etype, const char *ptr, long len);
__attribute__((__nonnull__ ()))
VALUE rb_exc_new_cstr(VALUE etype, const char *str);
VALUE rb_exc_new_str(VALUE etype, VALUE str);
__attribute__((__noreturn__))
__attribute__((__nonnull__ (1)))
__attribute__((__format__(__printf__, 1, 2)))
void rb_loaderror(const char *fmt, ...);
__attribute__((__noreturn__))
__attribute__((__nonnull__ (2)))
__attribute__((__format__(__printf__, 2, 3)))
void rb_loaderror_with_path(VALUE path, const char *fmt, ...);
__attribute__((__noreturn__))
__attribute__((__nonnull__ (2)))
__attribute__((__format__(__printf__, 2, 3)))
void rb_name_error(ID name, const char *fmt, ...);
__attribute__((__noreturn__))
__attribute__((__nonnull__ (2)))
__attribute__((__format__(__printf__, 2, 3)))
void rb_name_error_str(VALUE name, const char *fmt, ...);
__attribute__((__noreturn__))
__attribute__((__nonnull__ (2)))
__attribute__((__format__(__printf__, 2, 3)))
void rb_frozen_error_raise(VALUE recv, const char *fmt, ...);
__attribute__((__noreturn__))
__attribute__((__nonnull__ ()))
void rb_invalid_str(const char *str, const char *type);
__attribute__((__noreturn__))
__attribute__((__nonnull__ ()))
void rb_error_frozen(const char *what);
__attribute__((__noreturn__))
void rb_error_frozen_object(VALUE what);
void rb_check_frozen(VALUE obj);
void rb_check_copyable(VALUE obj, VALUE orig);
__attribute__((__noreturn__))
void rb_error_arity(int argc, int min, int max);
void rb_str_modify(VALUE str);

#pragma GCC visibility pop

static inline void
rb_check_frozen_inline(VALUE obj)
{
    if ((__builtin_expect(!!(RB_OBJ_FROZEN(obj)), 0))) {
        rb_error_frozen_object(obj);
    }
    if ((__builtin_expect(!!(RB_TYPE_P(obj, RUBY_T_STRING) && RB_FL_TEST_RAW(obj, RUBY_FL_USER2 | RUBY_FL_USER3)), 0))) {
        rb_str_modify(obj);
    }
}
static inline int
rb_check_arity(int argc, int min, int max)
{
    if ((argc < min) || (max != (-1) && argc > max))
        rb_error_arity(argc, min, max);
    return argc;
}

#pragma GCC visibility push(default)

__attribute__((__nonnull__ ()))
void rb_st_foreach_safe(struct st_table *st, st_foreach_callback_func *func, st_data_t arg);
VALUE rb_check_hash_type(VALUE obj);
__attribute__((__nonnull__ ()))
void rb_hash_foreach(VALUE hash, int (*func)(VALUE key, VALUE val, VALUE arg), VALUE arg);
VALUE rb_hash(VALUE obj);
VALUE rb_hash_new(void);
VALUE rb_hash_new_capa(long capa);
VALUE rb_hash_dup(VALUE hash);
VALUE rb_hash_freeze(VALUE obj);
VALUE rb_hash_aref(VALUE hash, VALUE key);
VALUE rb_hash_lookup(VALUE hash, VALUE key);
VALUE rb_hash_lookup2(VALUE hash, VALUE key, VALUE def);
VALUE rb_hash_fetch(VALUE hash, VALUE key);
VALUE rb_hash_aset(VALUE hash, VALUE key, VALUE val);
VALUE rb_hash_clear(VALUE hash);
VALUE rb_hash_delete_if(VALUE hash);
VALUE rb_hash_delete(VALUE hash, VALUE key);
void rb_hash_bulk_insert(long argc, const VALUE *argv, VALUE hash);
typedef VALUE rb_hash_update_func(VALUE newkey, VALUE oldkey, VALUE value);
VALUE rb_hash_update_by(VALUE hash1, VALUE hash2, rb_hash_update_func *func);
int rb_path_check(const char *path);
VALUE rb_env_clear(void);
VALUE rb_hash_size(VALUE hash);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

VALUE rb_block_proc(void);
VALUE rb_block_lambda(void);
VALUE rb_proc_new(rb_block_call_func_t func, VALUE callback_arg);
VALUE rb_obj_is_proc(VALUE recv);
VALUE rb_proc_call(VALUE recv, VALUE args);
VALUE rb_proc_call_kw(VALUE recv, VALUE args, int kw_splat);
VALUE rb_proc_call_with_block(VALUE recv, int argc, const VALUE *argv, VALUE proc);
VALUE rb_proc_call_with_block_kw(VALUE recv, int argc, const VALUE *argv, VALUE proc, int kw_splat);
int rb_proc_arity(VALUE recv);
VALUE rb_proc_lambda_p(VALUE recv);
VALUE rb_binding_new(void);
VALUE rb_obj_method(VALUE recv, VALUE mid);
VALUE rb_obj_is_method(VALUE recv);
VALUE rb_method_call(int argc, const VALUE *argv, VALUE recv);
VALUE rb_method_call_kw(int argc, const VALUE *argv, VALUE recv, int kw_splat);
VALUE rb_method_call_with_block(int argc, const VALUE *argv, VALUE recv, VALUE proc);
VALUE rb_method_call_with_block_kw(int argc, const VALUE *argv, VALUE recv, VALUE proc, int kw_splat);
int rb_mod_method_arity(VALUE mod, ID mid);
int rb_obj_method_arity(VALUE obj, ID mid);
__attribute__((__nonnull__ (1)))
VALUE rb_protect(VALUE (*func)(VALUE args), VALUE args, int *state);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

__attribute__((__nonnull__ (2, 3)))
int rb_scan_args(int argc, const VALUE *argv, const char *fmt, ...);
__attribute__((__nonnull__ (3, 4)))
int rb_scan_args_kw(int kw_splat, int argc, const VALUE *argv, const char *fmt, ...);
__attribute__((__error__ ("bad scan arg format")))
void rb_scan_args_bad_format(const char*);
__attribute__((__error__ ("variable argument length doesn't match")))
void rb_scan_args_length_mismatch(const char*,int);

#pragma GCC visibility pop

static inline _Bool
rb_scan_args_keyword_p(int kw_flag, VALUE last)
{
    switch (kw_flag) {
      case 0:
        return !! rb_keyword_given_p();
      case 1:
        return 1;
      case 3:
        return RB_TYPE_P(last, RUBY_T_HASH);
      default:
        return 0;
    }
}
__attribute__((__always_inline__)) inline
static _Bool
rb_scan_args_lead_p(const char *fmt)
{
    return (((unsigned char)((fmt[0])-'0'))<10);
}
__attribute__((__always_inline__)) inline
static int
rb_scan_args_n_lead(const char *fmt)
{
    return (rb_scan_args_lead_p(fmt) ? fmt[0]-'0' : 0);
}
__attribute__((__always_inline__)) inline
static _Bool
rb_scan_args_opt_p(const char *fmt)
{
    return (rb_scan_args_lead_p(fmt) && (((unsigned char)((fmt[1])-'0'))<10));
}
__attribute__((__always_inline__)) inline
static int
rb_scan_args_n_opt(const char *fmt)
{
    return (rb_scan_args_opt_p(fmt) ? fmt[1]-'0' : 0);
}
__attribute__((__always_inline__)) inline
static int
rb_scan_args_var_idx(const char *fmt)
{
    return (!rb_scan_args_lead_p(fmt) ? 0 : !(((unsigned char)((fmt[1])-'0'))<10) ? 1 : 2);
}
__attribute__((__always_inline__)) inline
static _Bool
rb_scan_args_f_var(const char *fmt)
{
    return (fmt[rb_scan_args_var_idx(fmt)]=='*');
}
__attribute__((__always_inline__)) inline
static int
rb_scan_args_trail_idx(const char *fmt)
{
    const int idx = rb_scan_args_var_idx(fmt);
    return idx+(fmt[idx]=='*');
}
__attribute__((__always_inline__)) inline
static int
rb_scan_args_n_trail(const char *fmt)
{
    const int idx = rb_scan_args_trail_idx(fmt);
    return ((((unsigned char)((fmt[idx])-'0'))<10) ? fmt[idx]-'0' : 0);
}
__attribute__((__always_inline__)) inline
static int
rb_scan_args_hash_idx(const char *fmt)
{
    const int idx = rb_scan_args_trail_idx(fmt);
    return idx+(((unsigned char)((fmt[idx])-'0'))<10);
}
__attribute__((__always_inline__)) inline
static _Bool
rb_scan_args_f_hash(const char *fmt)
{
    return (fmt[rb_scan_args_hash_idx(fmt)]==':');
}
__attribute__((__always_inline__)) inline
static int
rb_scan_args_block_idx(const char *fmt)
{
    const int idx = rb_scan_args_hash_idx(fmt);
    return idx+(fmt[idx]==':');
}
__attribute__((__always_inline__)) inline
static _Bool
rb_scan_args_f_block(const char *fmt)
{
    return (fmt[rb_scan_args_block_idx(fmt)]=='&');
}
__attribute__((__always_inline__)) inline
static int
rb_scan_args_set(int kw_flag, int argc, const VALUE *argv,
                 int n_lead, int n_opt, int n_trail,
                 _Bool f_var, _Bool f_hash, _Bool f_block,
                 VALUE *vars[], const char *fmt [[maybe_unused]], int varc [[maybe_unused]])
   
   
{
    int i, argi = 0, vari = 0;
    VALUE *var, hash = ((VALUE)RUBY_Qnil);
    const int n_mand = n_lead + n_trail;
    if (f_hash && argc > 0) {
        VALUE last = argv[argc - 1];
        if (rb_scan_args_keyword_p(kw_flag, last)) {
            hash = rb_hash_dup(last);
            argc--;
        }
    }
    if (argc < n_mand) {
        goto argc_error;
    }
    for (i = 0; i < n_lead; i++) {
        var = vars[vari++];
        if (var) *var = argv[argi];
        argi++;
    }
    for (i = 0; i < n_opt; i++) {
        var = vars[vari++];
        if (argi < argc - n_trail) {
            if (var) *var = argv[argi];
            argi++;
        }
        else {
            if (var) *var = ((VALUE)RUBY_Qnil);
        }
    }
    if (f_var) {
        int n_var = argc - argi - n_trail;
        var = vars[vari++];
        if (0 < n_var) {
            if (var) *var = rb_ary_new_from_values(n_var, &argv[argi]);
            argi += n_var;
        }
        else {
            if (var) *var = rb_ary_new();
        }
    }
    for (i = 0; i < n_trail; i++) {
        var = vars[vari++];
        if (var) *var = argv[argi];
        argi++;
    }
    if (f_hash) {
        var = vars[vari++];
        if (var) *var = hash;
    }
    if (f_block) {
        var = vars[vari++];
        if (rb_block_given_p()) {
            *var = rb_block_proc();
        }
        else {
            *var = ((VALUE)RUBY_Qnil);
        }
    }
    if (argi == argc) {
        return argc;
    }
  argc_error:
    rb_error_arity(argc, n_mand, f_var ? (-1) : n_mand + n_opt);
    __builtin_unreachable();
}

#pragma GCC visibility push(default)

ID rb_sym2id(VALUE obj);
VALUE rb_id2sym(ID id);
__attribute__((__nonnull__ ()))
ID rb_intern(const char *name);
ID rb_intern2(const char *name, long len);
ID rb_intern_str(VALUE str);
const char *rb_id2name(ID id);
__attribute__((__nonnull__ ()))
ID rb_check_id(volatile VALUE *namep);
ID rb_to_id(VALUE str);
VALUE rb_id2str(ID id);
VALUE rb_sym2str(VALUE symbol);
VALUE rb_to_symbol(VALUE name);
__attribute__((__nonnull__ ()))
VALUE rb_check_symbol(volatile VALUE *namep);

#pragma GCC visibility pop

__attribute__((__pure__))
__attribute__((__nonnull__ ()))
static inline ID
rb_intern_const(const char *str)
{
    size_t len = strlen(str);
    return rb_intern2(str, ((long)len));
}

__attribute__((__nonnull__ ()))
static inline ID
rbimpl_intern_const(ID *ptr, const char *str)
{
    while (! *ptr) {
        *ptr = rb_intern_const(str);
    }
    return *ptr;
}

#pragma GCC visibility push(default)

typedef VALUE rb_gvar_getter_t(ID id, VALUE *data);
typedef void rb_gvar_setter_t(VALUE val, ID id, VALUE *data);
typedef void rb_gvar_marker_t(VALUE *var);
rb_gvar_getter_t rb_gvar_undef_getter;
rb_gvar_setter_t rb_gvar_undef_setter;
rb_gvar_marker_t rb_gvar_undef_marker;
rb_gvar_getter_t rb_gvar_val_getter;
rb_gvar_setter_t rb_gvar_val_setter;
rb_gvar_marker_t rb_gvar_val_marker;
rb_gvar_getter_t rb_gvar_var_getter;
rb_gvar_setter_t rb_gvar_var_setter;
rb_gvar_marker_t rb_gvar_var_marker;
__attribute__((__noreturn__))
rb_gvar_setter_t rb_gvar_readonly_setter;
__attribute__((__nonnull__ ()))
void rb_define_variable(const char *name, VALUE *var);
__attribute__((__nonnull__ (1)))
void rb_define_virtual_variable(const char *name, rb_gvar_getter_t *getter, rb_gvar_setter_t *setter);
__attribute__((__nonnull__ (1)))
void rb_define_hooked_variable(const char *name, VALUE *var, rb_gvar_getter_t *getter, rb_gvar_setter_t *setter);
__attribute__((__nonnull__ ()))
void rb_define_readonly_variable(const char *name, const VALUE *var);
__attribute__((__nonnull__ ()))
void rb_define_const(VALUE klass, const char *name, VALUE val);
__attribute__((__nonnull__ ()))
void rb_define_global_const(const char *name, VALUE val);
__attribute__((__nonnull__ ()))
void rb_deprecate_constant(VALUE mod, const char *name);
__attribute__((__nonnull__ ()))
VALUE rb_gv_set(const char *name, VALUE val);
__attribute__((__nonnull__ ()))
VALUE rb_gv_get(const char *name);
__attribute__((__nonnull__ ()))
VALUE rb_iv_get(VALUE obj, const char *name);
__attribute__((__nonnull__ ()))
VALUE rb_iv_set(VALUE obj, const char *name, VALUE val);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

VALUE rb_get_path(VALUE obj);
VALUE rb_get_path_no_checksafe(VALUE);
__attribute__((__error__ (" argument length doesn't match"))) int rb_varargs_bad_length(int,int);
const char *rb_class2name(VALUE klass);
const char *rb_obj_classname(VALUE obj);
void rb_p(VALUE obj);
VALUE rb_equal(VALUE lhs, VALUE rhs);
VALUE rb_require(const char *feature);

#pragma GCC visibility push(default)

VALUE rb_big_new(size_t len, int sign);
int rb_bigzero_p(VALUE x);
VALUE rb_big_clone(VALUE num);
void rb_big_2comp(VALUE num);
VALUE rb_big_norm(VALUE x);
void rb_big_resize(VALUE big, size_t len);
__attribute__((__nonnull__ ()))
VALUE rb_cstr_to_inum(const char *str, int base, int badcheck);
VALUE rb_str_to_inum(VALUE str, int base, int badcheck);
__attribute__((__nonnull__ ()))
VALUE rb_cstr2inum(const char *str, int base);
VALUE rb_str2inum(VALUE str, int base);
VALUE rb_big2str(VALUE x, int base);
long rb_big2long(VALUE x);
unsigned long rb_big2ulong(VALUE x);
long long rb_big2ll(VALUE);
unsigned long long rb_big2ull(VALUE);
__attribute__((__nonnull__ ()))
void rb_big_pack(VALUE val, unsigned long *buf, long num_longs);
__attribute__((__nonnull__ ()))
VALUE rb_big_unpack(unsigned long *buf, long num_longs);
__attribute__((__nonnull__ ()))
int rb_uv_to_utf8(char buf[6], unsigned long uv);
VALUE rb_dbl2big(double d);
double rb_big2dbl(VALUE x);
VALUE rb_big_cmp(VALUE lhs, VALUE rhs);
VALUE rb_big_eq(VALUE lhs, VALUE rhs);
VALUE rb_big_eql(VALUE lhs, VALUE rhs);
VALUE rb_big_plus(VALUE x, VALUE y);
VALUE rb_big_minus(VALUE x, VALUE y);
VALUE rb_big_mul(VALUE x, VALUE y);
VALUE rb_big_div(VALUE x, VALUE y);
VALUE rb_big_idiv(VALUE x, VALUE y);
VALUE rb_big_modulo(VALUE x, VALUE y);
VALUE rb_big_divmod(VALUE x, VALUE y);
VALUE rb_big_pow(VALUE x, VALUE y);
VALUE rb_big_and(VALUE x, VALUE y);
VALUE rb_big_or(VALUE x, VALUE y);
VALUE rb_big_xor(VALUE x, VALUE y);
VALUE rb_big_lshift(VALUE x, VALUE y);
VALUE rb_big_rshift(VALUE x, VALUE y);
__attribute__((__nonnull__ ()))
int rb_integer_pack(VALUE val, void *words, size_t numwords, size_t wordsize, size_t nails, int flags);
__attribute__((__nonnull__ ()))
VALUE rb_integer_unpack(const void *words, size_t numwords, size_t wordsize, size_t nails, int flags);
size_t rb_absint_size(VALUE val, int *nlz_bits_ret);
size_t rb_absint_numwords(VALUE val, size_t word_numbits, size_t *nlz_bits_ret);
int rb_absint_singlebit_p(VALUE val);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

int rb_cmpint(VALUE val, VALUE a, VALUE b);
__attribute__((__cold__))
__attribute__((__noreturn__))
void rb_cmperr(VALUE a, VALUE b);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

VALUE rb_complex_raw(VALUE real, VALUE imag);
VALUE rb_complex_new(VALUE real, VALUE imag);
VALUE rb_complex_new_polar(VALUE abs, VALUE arg);
__attribute__((__deprecated__ ("by: rb_complex_new_polar")))
VALUE rb_complex_polar(VALUE abs, VALUE arg);
__attribute__((__pure__))
VALUE rb_complex_real(VALUE z);
__attribute__((__pure__))
VALUE rb_complex_imag(VALUE z);
VALUE rb_complex_plus(VALUE x, VALUE y);
VALUE rb_complex_minus(VALUE x, VALUE y);
VALUE rb_complex_mul(VALUE x, VALUE y);
VALUE rb_complex_div(VALUE x, VALUE y);
VALUE rb_complex_uminus(VALUE z);
VALUE rb_complex_conjugate(VALUE z);
VALUE rb_complex_abs(VALUE z);
VALUE rb_complex_arg(VALUE z);
VALUE rb_complex_pow(VALUE base, VALUE exp);
VALUE rb_dbl_complex_new(double real, double imag);
VALUE rb_Complex(VALUE real, VALUE imag);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

VALUE rb_fiber_new(rb_block_call_func_t func, VALUE callback_obj);
VALUE rb_fiber_new_storage(rb_block_call_func_t func, VALUE callback_obj, VALUE storage);
VALUE rb_fiber_current(void);
VALUE rb_fiber_alive_p(VALUE fiber);
VALUE rb_obj_is_fiber(VALUE obj);
VALUE rb_fiber_resume(VALUE fiber, int argc, const VALUE *argv);
VALUE rb_fiber_resume_kw(VALUE fiber, int argc, const VALUE *argv, int kw_splat);
VALUE rb_fiber_yield(int argc, const VALUE *argv);
VALUE rb_fiber_yield_kw(int argc, const VALUE *argv, int kw_splat);
VALUE rb_fiber_transfer(VALUE fiber, int argc, const VALUE *argv);
VALUE rb_fiber_transfer_kw(VALUE fiber, int argc, const VALUE *argv, int kw_splat);
VALUE rb_fiber_raise(VALUE fiber, int argc, const VALUE *argv);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

VALUE rb_dir_getwd(void);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

VALUE rb_enum_values_pack(int argc, const VALUE *argv);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

__attribute__((__noreturn__))
void rb_exc_raise(VALUE exc);
__attribute__((__noreturn__))
void rb_exc_fatal(VALUE exc);
__attribute__((__noreturn__))
VALUE rb_f_exit(int argc, const VALUE *argv);
__attribute__((__noreturn__))
VALUE rb_f_abort(int argc, const VALUE *argv);
__attribute__((__noreturn__))
void rb_interrupt(void);
ID rb_frame_this_func(void);
__attribute__((__noreturn__))
void rb_jump_tag(int state);
void rb_obj_call_init(VALUE obj, int argc, const VALUE *argv);
void rb_obj_call_init_kw(VALUE, int, const VALUE*, int);
ID rb_frame_callee(void);
VALUE rb_make_exception(int argc, const VALUE *argv);
void rb_set_end_proc(void (*func)(VALUE arg), VALUE arg);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

typedef VALUE rb_enumerator_size_func(VALUE recv, VALUE argv, VALUE eobj);
typedef struct {
    VALUE begin;
    VALUE end;
    VALUE step;
    int exclude_end;
} rb_arithmetic_sequence_components_t;
VALUE rb_enumeratorize(VALUE recv, VALUE meth, int argc, const VALUE *argv);
VALUE rb_enumeratorize_with_size(VALUE recv, VALUE meth, int argc, const VALUE *argv, rb_enumerator_size_func *func);
VALUE rb_enumeratorize_with_size_kw(VALUE recv, VALUE meth, int argc, const VALUE *argv, rb_enumerator_size_func *func, int kw_splat);
__attribute__((__nonnull__ ()))
int rb_arithmetic_sequence_extract(VALUE as, rb_arithmetic_sequence_components_t *buf);
__attribute__((__nonnull__ ()))
VALUE rb_arithmetic_sequence_beg_len_step(VALUE as, long *begp, long *lenp, long *stepp, long len, int err);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

__attribute__((__nonnull__ ()))
VALUE rb_file_s_expand_path(int argc, const VALUE *argv);
VALUE rb_file_expand_path(VALUE fname, VALUE dname);
__attribute__((__nonnull__ ()))
VALUE rb_file_s_absolute_path(int argc, const VALUE *argv);
VALUE rb_file_absolute_path(VALUE fname, VALUE dname);
VALUE rb_file_dirname(VALUE fname);
__attribute__((__nonnull__ ()))
int rb_find_file_ext(VALUE *feature, const char *const *exts);
VALUE rb_find_file(VALUE path);
VALUE rb_file_directory_p(VALUE _, VALUE path);
VALUE rb_str_encode_ospath(VALUE path);
__attribute__((__nonnull__ ()))
__attribute__((__pure__))
int rb_is_absolute_path(const char *path);
off_t rb_file_size(VALUE file);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

extern VALUE rb_fs;
extern VALUE rb_output_fs;
extern VALUE rb_rs;
extern VALUE rb_default_rs;
extern VALUE rb_output_rs;
VALUE rb_io_write(VALUE io, VALUE str);
VALUE rb_io_gets(VALUE io);
VALUE rb_io_getbyte(VALUE io);
VALUE rb_io_ungetc(VALUE io, VALUE c);
VALUE rb_io_ungetbyte(VALUE io, VALUE b);
VALUE rb_io_close(VALUE io);
VALUE rb_io_flush(VALUE io);
VALUE rb_io_eof(VALUE io);
VALUE rb_io_binmode(VALUE io);
VALUE rb_io_ascii8bit_binmode(VALUE io);
VALUE rb_io_addstr(VALUE io, VALUE str);
VALUE rb_io_printf(int argc, const VALUE *argv, VALUE io);
VALUE rb_io_print(int argc, const VALUE *argv, VALUE io);
VALUE rb_io_puts(int argc, const VALUE *argv, VALUE io);
VALUE rb_io_fdopen(int fd, int flags, const char *path);
__attribute__((__nonnull__ ()))
VALUE rb_file_open(const char *fname, const char *fmode);
__attribute__((__nonnull__ ()))
VALUE rb_file_open_str(VALUE fname, const char *fmode);
VALUE rb_gets(void);
__attribute__((__nonnull__ ()))
void rb_write_error(const char *str);
void rb_write_error2(const char *str, long len);
void rb_close_before_exec(int lowfd, int maxhint, VALUE noclose_fds);
__attribute__((__nonnull__ ()))
int rb_pipe(int *pipes);
int rb_reserved_fd_p(int fd);
int rb_cloexec_open(const char *pathname, int flags, mode_t mode);
int rb_cloexec_dup(int oldfd);
int rb_cloexec_dup2(int oldfd, int newfd);
__attribute__((__nonnull__ ()))
int rb_cloexec_pipe(int fildes[2]);
int rb_cloexec_fcntl_dupfd(int fd, int minfd);
void rb_update_max_fd(int fd);
void rb_fd_fix_cloexec(int fd);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

void rb_load(VALUE path, int wrap);
void rb_load_protect(VALUE path, int wrap, int *state);
__attribute__((__nonnull__ ()))
int rb_provided(const char *feature);
__attribute__((__nonnull__ (1)))
int rb_feature_provided(const char *feature, const char **loading);
__attribute__((__nonnull__ ()))
void rb_provide(const char *feature);
VALUE rb_f_require(VALUE self, VALUE feature);
VALUE rb_require_string(VALUE feature);
void *rb_ext_resolve_symbol(const char *feature, const char *symbol);
void rb_ext_ractor_safe(_Bool flag);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

VALUE rb_marshal_dump(VALUE obj, VALUE port);
VALUE rb_marshal_load(VALUE port);
void rb_marshal_define_compat(VALUE newclass, VALUE oldclass, VALUE (*dumper)(VALUE), VALUE (*loader)(VALUE, VALUE));

#pragma GCC visibility pop


#pragma GCC visibility push(default)

__attribute__((__noreturn__))
__attribute__((__cold__))
void rb_num_zerodiv(void);
VALUE rb_num_coerce_bin(VALUE lhs, VALUE rhs, ID op);
VALUE rb_num_coerce_cmp(VALUE lhs, VALUE rhs, ID op);
VALUE rb_num_coerce_relop(VALUE lhs, VALUE rhs, ID op);
VALUE rb_num_coerce_bit(VALUE lhs, VALUE rhs, ID op);
VALUE rb_num2fix(VALUE val);
VALUE rb_fix2str(VALUE val, int base);
__attribute__((__const__))
VALUE rb_dbl_cmp(double lhs, double rhs);
extern VALUE rb_int_positive_pow(long x, unsigned long y);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

VALUE rb_class_new_instance_pass_kw(int argc, const VALUE *argv, VALUE klass);
VALUE rb_class_new_instance(int argc, const VALUE *argv, VALUE klass);
VALUE rb_class_new_instance_kw(int argc, const VALUE *argv, VALUE klass, int kw_splat);
int rb_eql(VALUE lhs, VALUE rhs);
VALUE rb_any_to_s(VALUE obj);
VALUE rb_inspect(VALUE obj);
VALUE rb_obj_is_instance_of(VALUE obj, VALUE klass);
VALUE rb_obj_is_kind_of(VALUE obj, VALUE klass);
VALUE rb_obj_alloc(VALUE klass);
VALUE rb_obj_clone(VALUE obj);
VALUE rb_obj_dup(VALUE obj);
VALUE rb_obj_init_copy(VALUE src, VALUE dst);
VALUE rb_obj_freeze(VALUE obj);
__attribute__((__pure__))
VALUE rb_obj_frozen_p(VALUE obj);
VALUE rb_obj_id(VALUE obj);
__attribute__((__const__))
VALUE rb_memory_id(VALUE obj);
__attribute__((__pure__))
VALUE rb_class_real(VALUE klass);
__attribute__((__pure__))
VALUE rb_class_inherited_p(VALUE scion, VALUE ascendant);
__attribute__((__pure__))
VALUE rb_class_superclass(VALUE klass);
__attribute__((__nonnull__ ()))
VALUE rb_convert_type(VALUE val, int type, const char *name, const char *mid);
__attribute__((__nonnull__ ()))
VALUE rb_check_convert_type(VALUE val, int type, const char *name, const char *mid);
__attribute__((__nonnull__ ()))
VALUE rb_check_to_integer(VALUE val, const char *mid);
VALUE rb_check_to_float(VALUE val);
VALUE rb_to_int(VALUE val);
VALUE rb_check_to_int(VALUE val);
VALUE rb_Integer(VALUE val);
VALUE rb_to_float(VALUE val);
VALUE rb_Float(VALUE val);
VALUE rb_String(VALUE val);
VALUE rb_Array(VALUE val);
VALUE rb_Hash(VALUE val);
__attribute__((__nonnull__ ()))
double rb_cstr_to_dbl(const char *str, int mode);
double rb_str_to_dbl(VALUE str, int mode);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

ID rb_id_attrset(ID id);
__attribute__((__const__))
int rb_is_const_id(ID id);
__attribute__((__const__))
int rb_is_global_id(ID id);
__attribute__((__const__))
int rb_is_instance_id(ID id);
__attribute__((__const__))
int rb_is_attrset_id(ID id);
__attribute__((__const__))
int rb_is_class_id(ID id);
__attribute__((__const__))
int rb_is_local_id(ID id);
__attribute__((__const__))
int rb_is_junk_id(ID);
__attribute__((__nonnull__ ()))
int rb_symname_p(const char *str);
VALUE rb_backref_get(void);
void rb_backref_set(VALUE md);
VALUE rb_lastline_get(void);
void rb_lastline_set(VALUE str);
VALUE rb_sym_all_symbols(void);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

VALUE rb_process_status_wait(pid_t pid, int flags);
void rb_last_status_set(int status, pid_t pid);
VALUE rb_last_status_get(void);
__attribute__((__nonnull__ ()))
int rb_proc_exec(const char *cmd);
__attribute__((__noreturn__))
VALUE rb_f_exec(int argc, const VALUE *argv);
pid_t rb_waitpid(pid_t pid, int *status, int flags);
void rb_syswait(pid_t pid);
pid_t rb_spawn(int argc, const VALUE *argv);
pid_t rb_spawn_err(int argc, const VALUE *argv, char *errbuf, size_t buflen);
VALUE rb_proc_times(VALUE _);
VALUE rb_detach_process(pid_t pid);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

unsigned int rb_genrand_int32(void);
double rb_genrand_real(void);
void rb_reset_random_seed(void);
VALUE rb_random_bytes(VALUE rnd, long n);
unsigned int rb_random_int32(VALUE rnd);
double rb_random_real(VALUE rnd);
unsigned long rb_random_ulong_limited(VALUE rnd, unsigned long limit);
unsigned long rb_genrand_ulong_limited(unsigned long i);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

VALUE rb_range_new(VALUE beg, VALUE end, int excl);
__attribute__((__nonnull__ ()))
VALUE rb_range_beg_len(VALUE range, long *begp, long *lenp, long len, int err);
__attribute__((__nonnull__ ()))
int rb_range_values(VALUE range, VALUE *begp, VALUE *endp, int *exclp);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

VALUE rb_rational_raw(VALUE num, VALUE den);
VALUE rb_rational_new(VALUE num, VALUE den);
VALUE rb_Rational(VALUE num, VALUE den);
__attribute__((__pure__))
VALUE rb_rational_num(VALUE rat);
__attribute__((__pure__))
VALUE rb_rational_den(VALUE rat);
VALUE rb_flt_rationalize_with_prec(VALUE flt, VALUE prec);
VALUE rb_flt_rationalize(VALUE flt);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

int rb_memcicmp(const void *s1,const void *s2, long n);
void rb_match_busy(VALUE md);
VALUE rb_reg_nth_defined(int n, VALUE md);
VALUE rb_reg_nth_match(int n, VALUE md);
int rb_reg_backref_number(VALUE match, VALUE backref);
VALUE rb_reg_last_match(VALUE md);
VALUE rb_reg_match_pre(VALUE md);
VALUE rb_reg_match_post(VALUE md);
VALUE rb_reg_match_last(VALUE md);
VALUE rb_reg_new_str(VALUE src, int opts);
__attribute__((__nonnull__ ()))
VALUE rb_reg_new(const char *src, long len, int opts);
VALUE rb_reg_alloc(void);
VALUE rb_reg_init_str(VALUE re, VALUE s, int options);
VALUE rb_reg_match(VALUE re, VALUE str);
VALUE rb_reg_match2(VALUE re);
int rb_reg_options(VALUE re);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

extern VALUE rb_argv0;
VALUE rb_get_argv(void);
__attribute__((__nonnull__ ()))
void *rb_load_file(const char *file);
void *rb_load_file_str(VALUE file);

#pragma GCC visibility pop

struct timeval;
typedef struct {
    int maxfd;
    fd_set *fdset;
} rb_fdset_t;

#pragma GCC visibility push(default)

__attribute__((__nonnull__ ()))
void rb_fd_init(rb_fdset_t *f);
__attribute__((__nonnull__ ()))
void rb_fd_term(rb_fdset_t *f);
__attribute__((__nonnull__ ()))
void rb_fd_zero(rb_fdset_t *f);
__attribute__((__nonnull__ ()))
void rb_fd_set(int fd, rb_fdset_t *f);
__attribute__((__nonnull__ ()))
void rb_fd_clr(int fd, rb_fdset_t *f);
__attribute__((__nonnull__ ()))
__attribute__((__pure__))
int rb_fd_isset(int fd, const rb_fdset_t *f);
void rb_fd_copy(rb_fdset_t *dst, const fd_set *src, int max);
void rb_fd_dup(rb_fdset_t *dst, const rb_fdset_t *src);
int rb_fd_select(int nfds, rb_fdset_t *rfds, rb_fdset_t *wfds, rb_fdset_t *efds, struct timeval *timeout);

#pragma GCC visibility pop

__attribute__((__nonnull__ ()))
__attribute__((__pure__))
static inline fd_set *
rb_fd_ptr(const rb_fdset_t *f)
{
    return f->fdset;
}
__attribute__((__nonnull__ ()))
__attribute__((__pure__))
static inline int
rb_fd_max(const rb_fdset_t *f)
{
    return f->maxfd;
}

#pragma GCC visibility push(default)

struct timeval;
int rb_thread_fd_select(int nfds, rb_fdset_t *rfds, rb_fdset_t *wfds, rb_fdset_t *efds, struct timeval *timeout);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

__attribute__((__nonnull__ ()))
VALUE rb_f_kill(int argc, const VALUE *argv);
__attribute__((__pure__))
const char *ruby_signal_name(int signo);
void ruby_default_signal(int sig);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

VALUE rb_f_sprintf(int argc, const VALUE *argv);
__attribute__((__nonnull__ (1)))
__attribute__((__format__(__printf__, 1, 2)))
VALUE rb_sprintf(const char *fmt, ...);
__attribute__((__nonnull__ (1)))
__attribute__((__format__(__printf__, 1, 0)))
VALUE rb_vsprintf(const char *fmt, va_list ap);
__attribute__((__nonnull__ (2)))
__attribute__((__format__(__printf__, 2, 3)))
VALUE rb_str_catf(VALUE dst, const char *fmt, ...);
__attribute__((__nonnull__ (2)))
__attribute__((__format__(__printf__, 2, 0)))
VALUE rb_str_vcatf(VALUE dst, const char *fmt, va_list ap);
VALUE rb_str_format(int argc, const VALUE *argv, VALUE fmt);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

VALUE rb_str_new(const char *ptr, long len);
VALUE rb_str_new_cstr(const char *ptr);
VALUE rb_str_new_shared(VALUE str);
VALUE rb_str_new_frozen(VALUE str);
VALUE rb_str_new_with_class(VALUE obj, const char *ptr, long len);
VALUE rb_external_str_new(const char *ptr, long len);
__attribute__((__nonnull__ ()))
VALUE rb_external_str_new_cstr(const char *ptr);
VALUE rb_locale_str_new(const char *ptr, long len);
__attribute__((__nonnull__ ()))
VALUE rb_locale_str_new_cstr(const char *ptr);
VALUE rb_filesystem_str_new(const char *ptr, long len);
__attribute__((__nonnull__ ()))
VALUE rb_filesystem_str_new_cstr(const char *ptr);
VALUE rb_str_buf_new(long capa);
__attribute__((__nonnull__ ()))
VALUE rb_str_buf_new_cstr(const char *ptr);
VALUE rb_str_tmp_new(long len);
VALUE rb_usascii_str_new(const char *ptr, long len);
VALUE rb_usascii_str_new_cstr(const char *ptr);
VALUE rb_utf8_str_new(const char *ptr, long len);
VALUE rb_utf8_str_new_cstr(const char *ptr);
VALUE rb_str_new_static(const char *ptr, long len);
VALUE rb_usascii_str_new_static(const char *ptr, long len);
VALUE rb_utf8_str_new_static(const char *ptr, long len);
VALUE rb_str_to_interned_str(VALUE str);
VALUE rb_interned_str(const char *ptr, long len);
__attribute__((__nonnull__ ()))
VALUE rb_interned_str_cstr(const char *ptr);
void rb_str_free(VALUE str);
void rb_str_shared_replace(VALUE dst, VALUE src);
VALUE rb_str_buf_append(VALUE dst, VALUE src);
VALUE rb_str_buf_cat(VALUE, const char*, long);
VALUE rb_str_buf_cat2(VALUE, const char*);
__attribute__((__nonnull__ ()))
VALUE rb_str_buf_cat_ascii(VALUE dst, const char *src);
VALUE rb_obj_as_string(VALUE obj);
VALUE rb_check_string_type(VALUE obj);
void rb_must_asciicompat(VALUE obj);
VALUE rb_str_dup(VALUE str);
VALUE rb_str_resurrect(VALUE str);
VALUE rb_str_locktmp(VALUE str);
VALUE rb_str_unlocktmp(VALUE str);
VALUE rb_str_dup_frozen(VALUE);
VALUE rb_str_plus(VALUE lhs, VALUE rhs);
VALUE rb_str_times(VALUE str, VALUE num);
long rb_str_sublen(VALUE str, long pos);
VALUE rb_str_substr(VALUE str, long beg, long len);
VALUE rb_str_subseq(VALUE str, long beg, long len);
char *rb_str_subpos(VALUE str, long beg, long *len);
void rb_str_modify(VALUE str);
void rb_str_modify_expand(VALUE str, long capa);
VALUE rb_str_freeze(VALUE str);
void rb_str_set_len(VALUE str, long len);
VALUE rb_str_resize(VALUE str, long len);
VALUE rb_str_cat(VALUE dst, const char *src, long srclen);
VALUE rb_str_cat_cstr(VALUE dst, const char *src);
VALUE rb_str_cat2(VALUE, const char*);
VALUE rb_str_append(VALUE dst, VALUE src);
VALUE rb_str_concat(VALUE dst, VALUE src);
st_index_t rb_memhash(const void *ptr, long len);
st_index_t rb_hash_start(st_index_t i);
st_index_t rb_str_hash(VALUE str);
int rb_str_hash_cmp(VALUE str1, VALUE str2);
int rb_str_comparable(VALUE str1, VALUE str2);
int rb_str_cmp(VALUE lhs, VALUE rhs);
VALUE rb_str_equal(VALUE str1, VALUE str2);
VALUE rb_str_drop_bytes(VALUE str, long len);
void rb_str_update(VALUE dst, long beg, long len, VALUE src);
VALUE rb_str_replace(VALUE dst, VALUE src);
VALUE rb_str_inspect(VALUE str);
VALUE rb_str_dump(VALUE str);
VALUE rb_str_split(VALUE str, const char *delim);
rb_gvar_setter_t rb_str_setter;
VALUE rb_str_intern(VALUE str);
VALUE rb_sym_to_s(VALUE sym);
long rb_str_strlen(VALUE str);
VALUE rb_str_length(VALUE);
long rb_str_offset(VALUE str, long pos);
__attribute__((__pure__))
size_t rb_str_capacity(VALUE str);
VALUE rb_str_ellipsize(VALUE str, long len);
VALUE rb_str_scrub(VALUE str, VALUE repl);
VALUE rb_str_succ(VALUE orig);
__attribute__((__nonnull__ ()))
static inline long
rbimpl_strlen(const char *str)
{
    return ((long)strlen(str));
}
__attribute__((__nonnull__ ()))
static inline VALUE
rbimpl_str_new_cstr(const char *str)
{
    long len = rbimpl_strlen(str);
    return rb_str_new_static(str, len);
}
__attribute__((__nonnull__ ()))
static inline VALUE
rbimpl_usascii_str_new_cstr(const char *str)
{
    long len = rbimpl_strlen(str);
    return rb_usascii_str_new_static(str, len);
}
__attribute__((__nonnull__ ()))
static inline VALUE
rbimpl_utf8_str_new_cstr(const char *str)
{
    long len = rbimpl_strlen(str);
    return rb_utf8_str_new_static(str, len);
}
__attribute__((__nonnull__ ()))
static inline VALUE
rbimpl_external_str_new_cstr(const char *str)
{
    long len = rbimpl_strlen(str);
    return rb_external_str_new(str, len);
}
__attribute__((__nonnull__ ()))
static inline VALUE
rbimpl_locale_str_new_cstr(const char *str)
{
    long len = rbimpl_strlen(str);
    return rb_locale_str_new(str, len);
}
__attribute__((__nonnull__ ()))
static inline VALUE
rbimpl_str_buf_new_cstr(const char *str)
{
    long len = rbimpl_strlen(str);
    VALUE buf = rb_str_buf_new(len);
    return rb_str_buf_cat(buf, str, len);
}
__attribute__((__nonnull__ ()))
static inline VALUE
rbimpl_str_cat_cstr(VALUE buf, const char *str)
{
    long len = rbimpl_strlen(str);
    return rb_str_cat(buf, str, len);
}
__attribute__((__nonnull__ ()))
static inline VALUE
rbimpl_exc_new_cstr(VALUE exc, const char *str)
{
    long len = rbimpl_strlen(str);
    return rb_exc_new(exc, str, len);
}

#pragma GCC visibility pop


#pragma GCC visibility push(default)

VALUE rb_struct_new(VALUE klass, ...);
VALUE rb_struct_define(const char *name, ...);
__attribute__((__nonnull__ (2)))
VALUE rb_struct_define_under(VALUE space, const char *name, ...);
VALUE rb_struct_alloc(VALUE klass, VALUE values);
VALUE rb_struct_initialize(VALUE self, VALUE values);
VALUE rb_struct_getmember(VALUE self, ID key);
VALUE rb_struct_s_members(VALUE klass);
VALUE rb_struct_members(VALUE self);
VALUE rb_struct_alloc_noinit(VALUE klass);
VALUE rb_struct_define_without_accessor(const char *name, VALUE super, rb_alloc_func_t func, ...);
__attribute__((__nonnull__ (2)))
VALUE rb_struct_define_without_accessor_under(VALUE outer, const char *class_name, VALUE super, rb_alloc_func_t alloc, ...);
VALUE rb_data_define(VALUE super, ...);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

struct timeval;
void rb_thread_schedule(void);
int rb_thread_wait_fd(int fd);
int rb_thread_fd_writable(int fd);
void rb_thread_fd_close(int fd);
int rb_thread_alone(void);
void rb_thread_sleep(int sec);
void rb_thread_sleep_forever(void);
void rb_thread_sleep_deadly(void);
VALUE rb_thread_stop(void);
VALUE rb_thread_wakeup(VALUE thread);
VALUE rb_thread_wakeup_alive(VALUE thread);
VALUE rb_thread_run(VALUE thread);
VALUE rb_thread_kill(VALUE thread);
__attribute__((__nonnull__ (1)))
VALUE rb_thread_create(VALUE (*f)(void *g), void *g);
void rb_thread_wait_for(struct timeval time);
VALUE rb_thread_current(void);
VALUE rb_thread_main(void);
VALUE rb_thread_local_aref(VALUE thread, ID key);
VALUE rb_thread_local_aset(VALUE thread, ID key, VALUE val);
void rb_thread_atfork(void);
void rb_thread_atfork_before_exec(void);
VALUE rb_exec_recursive(VALUE (*f)(VALUE g, VALUE h, int r), VALUE g, VALUE h);
VALUE rb_exec_recursive_paired(VALUE (*f)(VALUE g, VALUE h, int r), VALUE g, VALUE p, VALUE h);
VALUE rb_exec_recursive_outer(VALUE (*f)(VALUE g, VALUE h, int r), VALUE g, VALUE h);
VALUE rb_exec_recursive_paired_outer(VALUE (*f)(VALUE g, VALUE h, int r), VALUE g, VALUE p, VALUE h);
typedef void rb_unblock_function_t(void *);
typedef VALUE rb_blocking_function_t(void *);
void rb_thread_check_ints(void);
int rb_thread_interrupted(VALUE thval);
VALUE rb_mutex_new(void);
VALUE rb_mutex_locked_p(VALUE mutex);
VALUE rb_mutex_trylock(VALUE mutex);
VALUE rb_mutex_lock(VALUE mutex);
VALUE rb_mutex_unlock(VALUE mutex);
VALUE rb_mutex_sleep(VALUE self, VALUE timeout);
VALUE rb_mutex_synchronize(VALUE mutex, VALUE (*func)(VALUE arg), VALUE arg);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

struct timespec;
struct timeval;
__attribute__((__nonnull__ ()))
void rb_timespec_now(struct timespec *ts);
VALUE rb_time_new(time_t sec, long usec);
VALUE rb_time_nano_new(time_t sec, long nsec);
__attribute__((__nonnull__ ()))
VALUE rb_time_timespec_new(const struct timespec *ts, int offset);
VALUE rb_time_num_new(VALUE timev, VALUE off);
struct timeval rb_time_interval(VALUE num);
struct timeval rb_time_timeval(VALUE time);
struct timespec rb_time_timespec(VALUE time);
struct timespec rb_time_timespec_interval(VALUE num);
VALUE rb_time_utc_offset(VALUE time);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

VALUE rb_mod_name(VALUE mod);
VALUE rb_class_path(VALUE mod);
VALUE rb_class_path_cached(VALUE mod);
__attribute__((__nonnull__ ()))
void rb_set_class_path(VALUE klass, VALUE space, const char *name);
void rb_set_class_path_string(VALUE klass, VALUE space, VALUE name);
VALUE rb_path_to_class(VALUE path);
__attribute__((__nonnull__ ()))
VALUE rb_path2class(const char *path);
VALUE rb_class_name(VALUE obj);
VALUE rb_autoload_load(VALUE space, ID name);
VALUE rb_autoload_p(VALUE space, ID name);
VALUE rb_f_trace_var(int argc, const VALUE *argv);
VALUE rb_f_untrace_var(int argc, const VALUE *argv);
VALUE rb_f_global_variables(void);
void rb_alias_variable(ID dst, ID src);
void rb_free_generic_ivar(VALUE obj);
VALUE rb_ivar_get(VALUE obj, ID name);
VALUE rb_ivar_set(VALUE obj, ID name, VALUE val);
VALUE rb_ivar_defined(VALUE obj, ID name);
void rb_ivar_foreach(VALUE obj, int (*func)(ID name, VALUE val, st_data_t arg), st_data_t arg);
st_index_t rb_ivar_count(VALUE obj);
VALUE rb_attr_get(VALUE obj, ID name);
VALUE rb_obj_instance_variables(VALUE obj);
VALUE rb_obj_remove_instance_variable(VALUE obj, VALUE name);
void *rb_mod_const_at(VALUE, void*);
void *rb_mod_const_of(VALUE, void*);
VALUE rb_const_list(void*);
VALUE rb_mod_constants(int argc, const VALUE *argv, VALUE recv);
VALUE rb_mod_remove_const(VALUE space, VALUE name);
int rb_const_defined(VALUE space, ID name);
int rb_const_defined_at(VALUE space, ID name);
int rb_const_defined_from(VALUE space, ID name);
VALUE rb_const_get(VALUE space, ID name);
VALUE rb_const_get_at(VALUE space, ID name);
VALUE rb_const_get_from(VALUE space, ID name);
void rb_const_set(VALUE space, ID name, VALUE val);
VALUE rb_const_remove(VALUE space, ID name);
VALUE rb_cvar_defined(VALUE klass, ID name);
void rb_cvar_set(VALUE klass, ID name, VALUE val);
VALUE rb_cvar_get(VALUE klass, ID name);
__attribute__((__nonnull__ ()))
VALUE rb_cvar_find(VALUE klass, ID name, VALUE *front);
__attribute__((__nonnull__ ()))
void rb_cv_set(VALUE klass, const char *name, VALUE val);
__attribute__((__nonnull__ ()))
VALUE rb_cv_get(VALUE klass, const char *name);
__attribute__((__nonnull__ ()))
void rb_define_class_variable(VALUE, const char*, VALUE);
VALUE rb_mod_class_variables(int argc, const VALUE *argv, VALUE recv);
VALUE rb_mod_remove_cvar(VALUE mod, VALUE name);

#pragma GCC visibility pop

int ruby_native_thread_p(void);
__attribute__((__nonnull__ (3)))
__attribute__((__format__(__printf__, 3, 4)))
int ruby_snprintf(char *str, size_t n, char const *fmt, ...);
__attribute__((__nonnull__ (3)))
__attribute__((__format__(__printf__, 3, 0)))
int ruby_vsnprintf(char *str, size_t n, char const *fmt, va_list ap);

extern int *__errno_location (void) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern char *program_invocation_name;
extern char *program_invocation_short_name;
typedef int error_t;

int rb_errno(void);
void rb_errno_set(int err);
int *rb_errno_ptr(void);
static inline int *
rb_orig_errno_ptr(void)
{
    return &(*__errno_location ());
}

#pragma GCC visibility pop


#pragma GCC visibility push(default)

enum ruby_coderange_type {
    RUBY_ENC_CODERANGE_UNKNOWN = 0,
    RUBY_ENC_CODERANGE_7BIT = ((int)RUBY_FL_USER8),
    RUBY_ENC_CODERANGE_VALID = ((int)RUBY_FL_USER9),
    RUBY_ENC_CODERANGE_BROKEN = ((int)(RUBY_FL_USER8|RUBY_FL_USER9)),
    RUBY_ENC_CODERANGE_MASK = (RUBY_ENC_CODERANGE_7BIT|
                                   RUBY_ENC_CODERANGE_VALID|
                                   RUBY_ENC_CODERANGE_BROKEN)
};
__attribute__((__const__))
static inline int
rb_enc_coderange_clean_p(int cr)
{
    return (cr ^ (cr >> 1)) & RUBY_ENC_CODERANGE_7BIT;
}
__attribute__((__const__))
static inline _Bool
RB_ENC_CODERANGE_CLEAN_P(enum ruby_coderange_type cr)
{
    return rb_enc_coderange_clean_p(cr);
}
__attribute__((__pure__))
static inline enum ruby_coderange_type
RB_ENC_CODERANGE(VALUE obj)
{
    VALUE ret = RB_FL_TEST_RAW(obj, RUBY_ENC_CODERANGE_MASK);
    return ((enum ruby_coderange_type)ret);
}
__attribute__((__pure__))
static inline _Bool
RB_ENC_CODERANGE_ASCIIONLY(VALUE obj)
{
    return RB_ENC_CODERANGE(obj) == RUBY_ENC_CODERANGE_7BIT;
}
static inline void
RB_ENC_CODERANGE_SET(VALUE obj, enum ruby_coderange_type cr)
{
    RB_FL_UNSET_RAW(obj, RUBY_ENC_CODERANGE_MASK);
    RB_FL_SET_RAW(obj, cr);
}
static inline void
RB_ENC_CODERANGE_CLEAR(VALUE obj)
{
    RB_FL_UNSET_RAW(obj, RUBY_ENC_CODERANGE_MASK);
}
__attribute__((__const__))
static inline enum ruby_coderange_type
RB_ENC_CODERANGE_AND(enum ruby_coderange_type a, enum ruby_coderange_type b)
{
    if (a == RUBY_ENC_CODERANGE_7BIT) {
        return b;
    }
    else if (a != RUBY_ENC_CODERANGE_VALID) {
        return RUBY_ENC_CODERANGE_UNKNOWN;
    }
    else if (b == RUBY_ENC_CODERANGE_7BIT) {
        return RUBY_ENC_CODERANGE_VALID;
    }
    else {
        return b;
    }
}

#pragma GCC visibility pop


#pragma GCC visibility push(default)

typedef unsigned char OnigUChar;
typedef unsigned int OnigCodePoint;
typedef unsigned int OnigCtype;
typedef size_t OnigDistance;
typedef ptrdiff_t OnigPosition;
typedef unsigned int OnigCaseFoldType;
extern OnigCaseFoldType OnigDefaultCaseFoldFlag;
typedef struct {
  int byte_len;
  int code_len;
  OnigCodePoint code[3];
} OnigCaseFoldCodeItem;
typedef struct {
  OnigCodePoint esc;
  OnigCodePoint anychar;
  OnigCodePoint anytime;
  OnigCodePoint zero_or_one_time;
  OnigCodePoint one_or_more_time;
  OnigCodePoint anychar_anytime;
} OnigMetaCharTableType;
typedef int (*OnigApplyAllCaseFoldFunc)(OnigCodePoint from, OnigCodePoint* to, int to_len, void* arg);
typedef struct OnigEncodingTypeST {
  int (*precise_mbc_enc_len)(const OnigUChar* p,const OnigUChar* e, const struct OnigEncodingTypeST* enc);
  const char* name;
  int max_enc_len;
  int min_enc_len;
  int (*is_mbc_newline)(const OnigUChar* p, const OnigUChar* end, const struct OnigEncodingTypeST* enc);
  OnigCodePoint (*mbc_to_code)(const OnigUChar* p, const OnigUChar* end, const struct OnigEncodingTypeST* enc);
  int (*code_to_mbclen)(OnigCodePoint code, const struct OnigEncodingTypeST* enc);
  int (*code_to_mbc)(OnigCodePoint code, OnigUChar *buf, const struct OnigEncodingTypeST* enc);
  int (*mbc_case_fold)(OnigCaseFoldType flag, const OnigUChar** pp, const OnigUChar* end, OnigUChar* to, const struct OnigEncodingTypeST* enc);
  int (*apply_all_case_fold)(OnigCaseFoldType flag, OnigApplyAllCaseFoldFunc f, void* arg, const struct OnigEncodingTypeST* enc);
  int (*get_case_fold_codes_by_str)(OnigCaseFoldType flag, const OnigUChar* p, const OnigUChar* end, OnigCaseFoldCodeItem acs[], const struct OnigEncodingTypeST* enc);
  int (*property_name_to_ctype)(const struct OnigEncodingTypeST* enc, const OnigUChar* p, const OnigUChar* end);
  int (*is_code_ctype)(OnigCodePoint code, OnigCtype ctype, const struct OnigEncodingTypeST* enc);
  int (*get_ctype_code_range)(OnigCtype ctype, OnigCodePoint* sb_out, const OnigCodePoint* ranges[], const struct OnigEncodingTypeST* enc);
  OnigUChar* (*left_adjust_char_head)(const OnigUChar* start, const OnigUChar* p, const OnigUChar* end, const struct OnigEncodingTypeST* enc);
  int (*is_allowed_reverse_match)(const OnigUChar* p, const OnigUChar* end, const struct OnigEncodingTypeST* enc);
  int (*case_map)(OnigCaseFoldType* flagP, const OnigUChar** pp, const OnigUChar* end, OnigUChar* to, OnigUChar* to_end, const struct OnigEncodingTypeST* enc);
  int ruby_encoding_index;
  unsigned int flags;
} OnigEncodingType;
typedef const OnigEncodingType* OnigEncoding;
extern const OnigEncodingType OnigEncodingASCII;
extern
int onigenc_ascii_only_case_map(OnigCaseFoldType* flagP, const OnigUChar** pp, const OnigUChar* end, OnigUChar* to, OnigUChar* to_end, const struct OnigEncodingTypeST* enc);
extern
int onigenc_mbclen(const OnigUChar* p,const OnigUChar* e, const struct OnigEncodingTypeST* enc);
extern
OnigUChar* onigenc_step_back(OnigEncoding enc, const OnigUChar* start, const OnigUChar* s, const OnigUChar* end, int n);
extern
int onigenc_init(void);
extern
int onigenc_set_default_encoding(OnigEncoding enc);
extern
OnigEncoding onigenc_get_default_encoding(void);
extern
OnigUChar* onigenc_get_right_adjust_char_head_with_prev(OnigEncoding enc, const OnigUChar* start, const OnigUChar* s, const OnigUChar* end, const OnigUChar** prev);
extern
OnigUChar* onigenc_get_prev_char_head(OnigEncoding enc, const OnigUChar* start, const OnigUChar* s, const OnigUChar* end);
extern
OnigUChar* onigenc_get_left_adjust_char_head(OnigEncoding enc, const OnigUChar* start, const OnigUChar* s, const OnigUChar* end);
extern
OnigUChar* onigenc_get_right_adjust_char_head(OnigEncoding enc, const OnigUChar* start, const OnigUChar* s, const OnigUChar* end);
extern
int onigenc_strlen(OnigEncoding enc, const OnigUChar* p, const OnigUChar* end);
extern
int onigenc_strlen_null(OnigEncoding enc, const OnigUChar* p);
extern
int onigenc_str_bytelen_null(OnigEncoding enc, const OnigUChar* p);
typedef unsigned int OnigOptionType;
typedef struct {
  unsigned int op;
  unsigned int op2;
  unsigned int behavior;
  OnigOptionType options;
  OnigMetaCharTableType meta_char_table;
} OnigSyntaxType;
extern const OnigSyntaxType OnigSyntaxASIS;
extern const OnigSyntaxType OnigSyntaxPosixBasic;
extern const OnigSyntaxType OnigSyntaxPosixExtended;
extern const OnigSyntaxType OnigSyntaxEmacs;
extern const OnigSyntaxType OnigSyntaxGrep;
extern const OnigSyntaxType OnigSyntaxGnuRegex;
extern const OnigSyntaxType OnigSyntaxJava;
extern const OnigSyntaxType OnigSyntaxPerl58;
extern const OnigSyntaxType OnigSyntaxPerl58_NG;
extern const OnigSyntaxType OnigSyntaxPerl;
extern const OnigSyntaxType OnigSyntaxRuby;
extern const OnigSyntaxType OnigSyntaxPython;
extern const OnigSyntaxType* OnigDefaultSyntax;
struct re_registers {
  int allocated;
  int num_regs;
  OnigPosition* beg;
  OnigPosition* end;
};
typedef struct re_registers OnigRegion;
typedef struct {
  OnigEncoding enc;
  OnigUChar* par;
  OnigUChar* par_end;
} OnigErrorInfo;
typedef struct {
  int lower;
  int upper;
} OnigRepeatRange;
typedef void (*OnigWarnFunc)(const char* s);
extern void onig_null_warn(const char* s);
typedef struct re_pattern_buffer {
  unsigned char* p;
  unsigned int used;
  unsigned int alloc;
  int num_mem;
  int num_repeat;
  int num_null_check;
  int num_comb_exp_check;
  int num_call;
  unsigned int capture_history;
  unsigned int bt_mem_start;
  unsigned int bt_mem_end;
  int stack_pop_level;
  int repeat_range_alloc;
  OnigOptionType options;
  OnigRepeatRange* repeat_range;
  OnigEncoding enc;
  const OnigSyntaxType* syntax;
  void* name_table;
  OnigCaseFoldType case_fold_flag;
  int optimize;
  int threshold_len;
  int anchor;
  OnigDistance anchor_dmin;
  OnigDistance anchor_dmax;
  int sub_anchor;
  unsigned char *exact;
  unsigned char *exact_end;
  unsigned char map[256];
  int *int_map;
  int *int_map_backward;
  OnigDistance dmin;
  OnigDistance dmax;
  uint64_t timelimit;
  struct re_pattern_buffer* chain;
} OnigRegexType;
typedef OnigRegexType* OnigRegex;
typedef OnigRegexType regex_t;
typedef struct {
  int num_of_elements;
  OnigEncoding pattern_enc;
  OnigEncoding target_enc;
  const OnigSyntaxType* syntax;
  OnigOptionType option;
  OnigCaseFoldType case_fold_flag;
} OnigCompileInfo;
extern
int onig_initialize(OnigEncoding encodings[], int n);
extern
int onig_init(void);
extern
int onig_error_code_to_str(OnigUChar* s, OnigPosition err_code, ...);
extern
void onig_set_warn_func(OnigWarnFunc f);
extern
void onig_set_verb_warn_func(OnigWarnFunc f);
extern
int onig_new(OnigRegex*, const OnigUChar* pattern, const OnigUChar* pattern_end, OnigOptionType option, OnigEncoding enc, const OnigSyntaxType* syntax, OnigErrorInfo* einfo);
extern
int onig_reg_init(OnigRegex reg, OnigOptionType option, OnigCaseFoldType case_fold_flag, OnigEncoding enc, const OnigSyntaxType* syntax);
extern
int onig_new_without_alloc(OnigRegex, const OnigUChar* pattern, const OnigUChar* pattern_end, OnigOptionType option, OnigEncoding enc, const OnigSyntaxType* syntax, OnigErrorInfo* einfo);
extern
int onig_new_deluxe(OnigRegex* reg, const OnigUChar* pattern, const OnigUChar* pattern_end, OnigCompileInfo* ci, OnigErrorInfo* einfo);
extern
void onig_free(OnigRegex);
extern
void onig_free_body(OnigRegex);
extern
int onig_reg_copy(OnigRegex* reg, OnigRegex orig_reg);
extern
OnigPosition onig_scan(OnigRegex reg, const OnigUChar* str, const OnigUChar* end, OnigRegion* region, OnigOptionType option, int (*scan_callback)(OnigPosition, OnigPosition, OnigRegion*, void*), void* callback_arg);
extern
OnigPosition onig_search(OnigRegex, const OnigUChar* str, const OnigUChar* end, const OnigUChar* start, const OnigUChar* range, OnigRegion* region, OnigOptionType option);
extern
OnigPosition onig_search_gpos(OnigRegex, const OnigUChar* str, const OnigUChar* end, const OnigUChar* global_pos, const OnigUChar* start, const OnigUChar* range, OnigRegion* region, OnigOptionType option);
extern
OnigPosition onig_match(OnigRegex, const OnigUChar* str, const OnigUChar* end, const OnigUChar* at, OnigRegion* region, OnigOptionType option);
extern
int onig_check_linear_time(OnigRegex reg);
extern
OnigRegion* onig_region_new(void);
extern
void onig_region_init(OnigRegion* region);
extern
void onig_region_free(OnigRegion* region, int free_self);
extern
void onig_region_copy(OnigRegion* to, const OnigRegion* from);
extern
void onig_region_clear(OnigRegion* region);
extern
int onig_region_resize(OnigRegion* region, int n);
extern
int onig_region_set(OnigRegion* region, int at, int beg, int end);
extern
int onig_name_to_group_numbers(OnigRegex reg, const OnigUChar* name, const OnigUChar* name_end, int** nums);
extern
int onig_name_to_backref_number(OnigRegex reg, const OnigUChar* name, const OnigUChar* name_end, const OnigRegion *region);
extern
int onig_foreach_name(OnigRegex reg, int (*func)(const OnigUChar*, const OnigUChar*,int,int*,OnigRegex,void*), void* arg);
extern
int onig_number_of_names(const OnigRegexType *reg);
extern
int onig_number_of_captures(const OnigRegexType *reg);
extern
int onig_number_of_capture_histories(const OnigRegexType *reg);
extern
int onig_capture_tree_traverse(OnigRegion* region, int at, int(*callback_func)(int,OnigPosition,OnigPosition,int,int,void*), void* arg);
extern
int onig_noname_group_capture_is_active(const OnigRegexType *reg);
extern
OnigEncoding onig_get_encoding(const OnigRegexType *reg);
extern
OnigOptionType onig_get_options(const OnigRegexType *reg);
extern
OnigCaseFoldType onig_get_case_fold_flag(const OnigRegexType *reg);
extern
const OnigSyntaxType* onig_get_syntax(const OnigRegexType *reg);
extern
int onig_set_default_syntax(const OnigSyntaxType* syntax);
extern
void onig_copy_syntax(OnigSyntaxType* to, const OnigSyntaxType* from);
extern
unsigned int onig_get_syntax_op(const OnigSyntaxType* syntax);
extern
unsigned int onig_get_syntax_op2(const OnigSyntaxType* syntax);
extern
unsigned int onig_get_syntax_behavior(const OnigSyntaxType* syntax);
extern
OnigOptionType onig_get_syntax_options(const OnigSyntaxType* syntax);
extern
void onig_set_syntax_op(OnigSyntaxType* syntax, unsigned int op);
extern
void onig_set_syntax_op2(OnigSyntaxType* syntax, unsigned int op2);
extern
void onig_set_syntax_behavior(OnigSyntaxType* syntax, unsigned int behavior);
extern
void onig_set_syntax_options(OnigSyntaxType* syntax, OnigOptionType options);
extern
int onig_set_meta_char(OnigSyntaxType* syntax, unsigned int what, OnigCodePoint code);
extern
void onig_copy_encoding(OnigEncodingType *to, OnigEncoding from);
extern
OnigCaseFoldType onig_get_default_case_fold_flag(void);
extern
int onig_set_default_case_fold_flag(OnigCaseFoldType case_fold_flag);
extern
unsigned int onig_get_match_stack_limit_size(void);
extern
int onig_set_match_stack_limit_size(unsigned int size);
extern
unsigned int onig_get_parse_depth_limit(void);
extern
int onig_set_parse_depth_limit(unsigned int depth);
extern
int onig_end(void);
extern
const char* onig_version(void);
extern
const char* onig_copyright(void);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

extern VALUE rb_cEncoding;
enum ruby_encoding_consts {
    RUBY_ENCODING_INLINE_MAX = 127,
    RUBY_ENCODING_SHIFT = (RUBY_FL_USHIFT+10),
    RUBY_ENCODING_MASK = (RUBY_ENCODING_INLINE_MAX<<RUBY_ENCODING_SHIFT
                                                              ),
    RUBY_ENCODING_MAXNAMELEN = 42
};
static inline void
RB_ENCODING_SET_INLINED(VALUE obj, int encindex)
{
    VALUE f = ((VALUE)encindex);
    f <<= RUBY_ENCODING_SHIFT;
    RB_FL_UNSET_RAW(obj, RUBY_ENCODING_MASK);
    RB_FL_SET_RAW(obj, f);
}
static inline int
RB_ENCODING_GET_INLINED(VALUE obj)
{
    VALUE ret = RB_FL_TEST_RAW(obj, RUBY_ENCODING_MASK) >> RUBY_ENCODING_SHIFT;
    return ((int)ret);
}
typedef const OnigEncodingType rb_encoding;

int rb_char_to_option_kcode(int c, int *option, int *kcode);
int rb_define_dummy_encoding(const char *name);
__attribute__((__pure__))
int rb_enc_dummy_p(rb_encoding *enc);
__attribute__((__pure__))
int rb_enc_to_index(rb_encoding *enc);
int rb_enc_get_index(VALUE obj);
static inline int
RB_ENCODING_GET(VALUE obj)
{
    int encindex = RB_ENCODING_GET_INLINED(obj);
    if (encindex == RUBY_ENCODING_INLINE_MAX) {
        return rb_enc_get_index(obj);
    }
    else {
        return encindex;
    }
}
void rb_enc_set_index(VALUE obj, int encindex);
static inline void
RB_ENCODING_SET(VALUE obj, int encindex)
{
    rb_enc_set_index(obj, encindex);
}
static inline void
RB_ENCODING_CODERANGE_SET(VALUE obj, int encindex, enum ruby_coderange_type cr)
{
    RB_ENCODING_SET(obj, encindex);
    RB_ENC_CODERANGE_SET(obj, cr);
}
__attribute__((__pure__))
int rb_enc_capable(VALUE obj);
int rb_enc_find_index(const char *name);
int rb_enc_alias(const char *alias, const char *orig);
int rb_to_encoding_index(VALUE obj);
rb_encoding *rb_to_encoding(VALUE obj);
rb_encoding *rb_find_encoding(VALUE obj);
rb_encoding *rb_enc_get(VALUE obj);
rb_encoding *rb_enc_compatible(VALUE str1, VALUE str2);
rb_encoding *rb_enc_check(VALUE str1,VALUE str2);
VALUE rb_enc_associate_index(VALUE obj, int encindex);
VALUE rb_enc_associate(VALUE obj, rb_encoding *enc);
void rb_enc_copy(VALUE dst, VALUE src);
rb_encoding *rb_enc_from_index(int idx);
rb_encoding *rb_enc_find(const char *name);
static inline const char *
rb_enc_name(rb_encoding *enc)
{
    return enc->name;
}
static inline int
rb_enc_mbminlen(rb_encoding *enc)
{
    return enc->min_enc_len;
}
static inline int
rb_enc_mbmaxlen(rb_encoding *enc)
{
    return enc->max_enc_len;
}
int rb_enc_mbclen(const char *p, const char *e, rb_encoding *enc);
int rb_enc_fast_mbclen(const char *p, const char *e, rb_encoding *enc);
int rb_enc_precise_mbclen(const char *p, const char *e, rb_encoding *enc);
int rb_enc_ascget(const char *p, const char *e, int *len, rb_encoding *enc);
unsigned int rb_enc_codepoint_len(const char *p, const char *e, int *len, rb_encoding *enc);
static inline unsigned int
rb_enc_codepoint(const char *p, const char *e, rb_encoding *enc)
{
    return rb_enc_codepoint_len(p, e, 0, enc);
}
static inline OnigCodePoint
rb_enc_mbc_to_codepoint(const char *p, const char *e, rb_encoding *enc)
{
    const OnigUChar *up = ((const OnigUChar *)p);
    const OnigUChar *ue = ((const OnigUChar *)e);
    return (enc)->mbc_to_code((up),(ue),enc);
}
int rb_enc_codelen(int code, rb_encoding *enc);
static inline int
rb_enc_code_to_mbclen(int c, rb_encoding *enc)
{
    OnigCodePoint uc = ((OnigCodePoint)c);
    return (enc)->code_to_mbclen(uc,enc);
}
static inline int
rb_enc_mbcput(unsigned int c, void *buf, rb_encoding *enc)
{
    OnigCodePoint uc = ((OnigCodePoint)c);
    OnigUChar *ubuf = ((OnigUChar *)buf);
    return (enc)->code_to_mbc(uc,ubuf,enc);
}
static inline char *
rb_enc_prev_char(const char *s, const char *p, const char *e, rb_encoding *enc)
{
    const OnigUChar *us = ((const OnigUChar *)s);
    const OnigUChar *up = ((const OnigUChar *)p);
    const OnigUChar *ue = ((const OnigUChar *)e);
    OnigUChar *ur = onigenc_get_prev_char_head(enc, us, up, ue);
    return ((char *)ur);
}
static inline char *
rb_enc_left_char_head(const char *s, const char *p, const char *e, rb_encoding *enc)
{
    const OnigUChar *us = ((const OnigUChar *)s);
    const OnigUChar *up = ((const OnigUChar *)p);
    const OnigUChar *ue = ((const OnigUChar *)e);
    OnigUChar *ur = onigenc_get_left_adjust_char_head(enc, us, up, ue);
    return ((char *)ur);
}
static inline char *
rb_enc_right_char_head(const char *s, const char *p, const char *e, rb_encoding *enc)
{
    const OnigUChar *us = ((const OnigUChar *)s);
    const OnigUChar *up = ((const OnigUChar *)p);
    const OnigUChar *ue = ((const OnigUChar *)e);
    OnigUChar *ur = onigenc_get_right_adjust_char_head(enc, us, up, ue);
    return ((char *)ur);
}
static inline char *
rb_enc_step_back(const char *s, const char *p, const char *e, int n, rb_encoding *enc)
{
    const OnigUChar *us = ((const OnigUChar *)s);
    const OnigUChar *up = ((const OnigUChar *)p);
    const OnigUChar *ue = ((const OnigUChar *)e);
    const OnigUChar *ur = onigenc_step_back(enc, us, up, ue, n);
    return ((char *)ur);
}
static inline int
rb_enc_asciicompat_inline(rb_encoding *enc)
{
    return rb_enc_mbminlen(enc)==1 && !rb_enc_dummy_p(enc);
}
static inline _Bool
rb_enc_asciicompat(rb_encoding *enc)
{
    if (rb_enc_mbminlen(enc) != 1) {
        return 0;
    }
    else if (rb_enc_dummy_p(enc)) {
        return 0;
    }
    else {
        return 1;
    }
}
static inline _Bool
rb_enc_str_asciicompat_p(VALUE str)
{
    rb_encoding *enc = rb_enc_get(str);
    return rb_enc_asciicompat(enc);
}
VALUE rb_enc_from_encoding(rb_encoding *enc);
__attribute__((__pure__))
int rb_enc_unicode_p(rb_encoding *enc);
__attribute__((__returns_nonnull__))
rb_encoding *rb_ascii8bit_encoding(void);
__attribute__((__returns_nonnull__))
rb_encoding *rb_utf8_encoding(void);
__attribute__((__returns_nonnull__))
rb_encoding *rb_usascii_encoding(void);
rb_encoding *rb_locale_encoding(void);
rb_encoding *rb_filesystem_encoding(void);
rb_encoding *rb_default_external_encoding(void);
rb_encoding *rb_default_internal_encoding(void);
__attribute__((__const__))
int rb_ascii8bit_encindex(void);
static inline _Bool
RB_ENCODING_IS_ASCII8BIT(VALUE obj)
{
    return RB_ENCODING_GET_INLINED(obj) == rb_ascii8bit_encindex();
}
__attribute__((__const__))
int rb_utf8_encindex(void);
__attribute__((__const__))
int rb_usascii_encindex(void);
int rb_locale_encindex(void);
int rb_filesystem_encindex(void);
VALUE rb_enc_default_external(void);
VALUE rb_enc_default_internal(void);
void rb_enc_set_default_external(VALUE encoding);
void rb_enc_set_default_internal(VALUE encoding);
VALUE rb_locale_charmap(VALUE klass);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

static inline _Bool
rb_enc_is_newline(const char *p, const char *e, rb_encoding *enc)
{
    OnigUChar *up = ((OnigUChar *)p);
    OnigUChar *ue = ((OnigUChar *)e);
    return (enc)->is_mbc_newline((up),(ue),enc);
}
static inline _Bool
rb_enc_isctype(OnigCodePoint c, OnigCtype t, rb_encoding *enc)
{
    return (enc)->is_code_ctype(c,t,enc);
}
static inline _Bool
rb_enc_isascii(OnigCodePoint c, rb_encoding *enc)
{
    return ((c) < 128);
}
static inline _Bool
rb_enc_isalpha(OnigCodePoint c, rb_encoding *enc)
{
    return (enc)->is_code_ctype(c,1,enc);
}
static inline _Bool
rb_enc_islower(OnigCodePoint c, rb_encoding *enc)
{
    return (enc)->is_code_ctype(c,6,enc);
}
static inline _Bool
rb_enc_isupper(OnigCodePoint c, rb_encoding *enc)
{
    return (enc)->is_code_ctype(c,10,enc);
}
static inline _Bool
rb_enc_iscntrl(OnigCodePoint c, rb_encoding *enc)
{
    return (enc)->is_code_ctype(c,3,enc);
}
static inline _Bool
rb_enc_ispunct(OnigCodePoint c, rb_encoding *enc)
{
    return (enc)->is_code_ctype(c,8,enc);
}
static inline _Bool
rb_enc_isalnum(OnigCodePoint c, rb_encoding *enc)
{
    return (enc)->is_code_ctype(c,13,enc);
}
static inline _Bool
rb_enc_isprint(OnigCodePoint c, rb_encoding *enc)
{
    return (enc)->is_code_ctype(c,7,enc);
}
static inline _Bool
rb_enc_isspace(OnigCodePoint c, rb_encoding *enc)
{
    return (enc)->is_code_ctype(c,9,enc);
}
static inline _Bool
rb_enc_isdigit(OnigCodePoint c, rb_encoding *enc)
{
    return (enc)->is_code_ctype(c,4,enc);
}
__attribute__((__const__))
int rb_enc_toupper(int c, rb_encoding *enc);
__attribute__((__const__))
int rb_enc_tolower(int c, rb_encoding *enc);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

__attribute__((__nonnull__ ()))
char *rb_enc_path_next(const char *path, const char *end, rb_encoding *enc);
__attribute__((__nonnull__ ()))
char *rb_enc_path_skip_prefix(const char *path, const char *end, rb_encoding *enc);
__attribute__((__nonnull__ ()))
char *rb_enc_path_last_separator(const char *path, const char *end, rb_encoding *enc);
__attribute__((__nonnull__ ()))
char *rb_enc_path_end(const char *path, const char *end, rb_encoding *enc);
__attribute__((__nonnull__ (1, 4)))
const char *ruby_enc_find_basename(const char *name, long *baselen, long *alllen, rb_encoding *enc);
__attribute__((__nonnull__ (1, 3)))
const char *ruby_enc_find_extname(const char *name, long *len, rb_encoding *enc);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

VALUE rb_enc_reg_new(const char *ptr, long len, rb_encoding *enc, int opts);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

__attribute__((__nonnull__ (2)))
__attribute__((__format__(__printf__, 2, 3)))
VALUE rb_enc_sprintf(rb_encoding *enc, const char *fmt, ...);
__attribute__((__nonnull__ (2)))
__attribute__((__format__(__printf__, 2, 0)))
VALUE rb_enc_vsprintf(rb_encoding *enc, const char *fmt, va_list ap);
__attribute__((__noreturn__))
__attribute__((__nonnull__ (3)))
__attribute__((__format__(__printf__, 3, 4)))
void rb_enc_raise(rb_encoding *enc, VALUE exc, const char *fmt, ...);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

VALUE rb_enc_str_new(const char *ptr, long len, rb_encoding *enc);
__attribute__((__nonnull__ (1)))
VALUE rb_enc_str_new_cstr(const char *ptr, rb_encoding *enc);
VALUE rb_enc_str_new_static(const char *ptr, long len, rb_encoding *enc);
VALUE rb_enc_interned_str(const char *ptr, long len, rb_encoding *enc);
__attribute__((__nonnull__ (1)))
VALUE rb_enc_interned_str_cstr(const char *ptr, rb_encoding *enc);
long rb_enc_strlen(const char *head, const char *tail, rb_encoding *enc);
char *rb_enc_nth(const char *head, const char *tail, long nth, rb_encoding *enc);
VALUE rb_obj_encoding(VALUE obj);
VALUE rb_enc_str_buf_cat(VALUE str, const char *ptr, long len, rb_encoding *enc);
VALUE rb_enc_uint_chr(unsigned int code, rb_encoding *enc);
VALUE rb_external_str_new_with_enc(const char *ptr, long len, rb_encoding *enc);
VALUE rb_str_export_to_enc(VALUE obj, rb_encoding *enc);
VALUE rb_str_conv_enc(VALUE str, rb_encoding *from, rb_encoding *to);
VALUE rb_str_conv_enc_opts(VALUE str, rb_encoding *from, rb_encoding *to, int ecflags, VALUE ecopts);
int rb_enc_str_coderange(VALUE str);
long rb_str_coderange_scan_restartable(const char *str, const char *end, rb_encoding *enc, int *cr);
int rb_enc_str_asciionly_p(VALUE str);
__attribute__((__nonnull__ ()))
long rb_memsearch(const void *x, long m, const void *y, long n, rb_encoding *enc);
__attribute__((__nonnull__ ()))
static inline VALUE
rbimpl_enc_str_new_cstr(const char *str, rb_encoding *enc)
{
    long len = rbimpl_strlen(str);
    return rb_enc_str_new_static(str, len, enc);
}

#pragma GCC visibility pop


#pragma GCC visibility push(default)

ID rb_intern3(const char *name, long len, rb_encoding *enc);
__attribute__((__nonnull__ ()))
int rb_enc_symname_p(const char *str, rb_encoding *enc);
int rb_enc_symname2_p(const char *name, long len, rb_encoding *enc);
ID rb_check_id_cstr(const char *ptr, long len, rb_encoding *enc);
VALUE rb_check_symbol_cstr(const char *ptr, long len, rb_encoding *enc);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

typedef enum {
    econv_invalid_byte_sequence,
    econv_undefined_conversion,
    econv_destination_buffer_full,
    econv_source_buffer_empty,
    econv_finished,
    econv_after_output,
    econv_incomplete_input
} rb_econv_result_t;
typedef struct rb_econv_t rb_econv_t;
VALUE rb_str_encode(VALUE str, VALUE to, int ecflags, VALUE ecopts);
int rb_econv_has_convpath_p(const char* from_encoding, const char* to_encoding);
int rb_econv_prepare_options(VALUE opthash, VALUE *ecopts, int ecflags);
int rb_econv_prepare_opts(VALUE opthash, VALUE *ecopts);
rb_econv_t *rb_econv_open(const char *source_encoding, const char *destination_encoding, int ecflags);
rb_econv_t *rb_econv_open_opts(const char *source_encoding, const char *destination_encoding, int ecflags, VALUE ecopts);
rb_econv_result_t rb_econv_convert(rb_econv_t *ec,
    const unsigned char **source_buffer_ptr, const unsigned char *source_buffer_end,
    unsigned char **destination_buffer_ptr, unsigned char *destination_buffer_end,
    int flags);
void rb_econv_close(rb_econv_t *ec);
int rb_econv_set_replacement(rb_econv_t *ec, const unsigned char *str, size_t len, const char *encname);
int rb_econv_decorate_at_first(rb_econv_t *ec, const char *decorator_name);
int rb_econv_decorate_at_last(rb_econv_t *ec, const char *decorator_name);
VALUE rb_econv_open_exc(const char *senc, const char *denc, int ecflags);
int rb_econv_insert_output(rb_econv_t *ec,
    const unsigned char *str, size_t len, const char *str_encoding);
const char *rb_econv_encoding_to_insert_output(rb_econv_t *ec);
void rb_econv_check_error(rb_econv_t *ec);
VALUE rb_econv_make_exception(rb_econv_t *ec);
int rb_econv_putbackable(rb_econv_t *ec);
void rb_econv_putback(rb_econv_t *ec, unsigned char *p, int n);
const char *rb_econv_asciicompat_encoding(const char *encname);
VALUE rb_econv_str_convert(rb_econv_t *ec, VALUE src, int flags);
VALUE rb_econv_substr_convert(rb_econv_t *ec, VALUE src, long byteoff, long bytesize, int flags);
VALUE rb_econv_str_append(rb_econv_t *ec, VALUE src, VALUE dst, int flags);
VALUE rb_econv_substr_append(rb_econv_t *ec, VALUE src, long byteoff, long bytesize, VALUE dst, int flags);
VALUE rb_econv_append(rb_econv_t *ec, const char *bytesrc, long bytesize, VALUE dst, int flags);
void rb_econv_binmode(rb_econv_t *ec);
enum ruby_econv_flag_type {
    RUBY_ECONV_ERROR_HANDLER_MASK = 0x000000ff,
    RUBY_ECONV_INVALID_MASK = 0x0000000f,
    RUBY_ECONV_INVALID_REPLACE = 0x00000002,
    RUBY_ECONV_UNDEF_MASK = 0x000000f0,
    RUBY_ECONV_UNDEF_REPLACE = 0x00000020,
    RUBY_ECONV_UNDEF_HEX_CHARREF = 0x00000030,
    RUBY_ECONV_DECORATOR_MASK = 0x0001ff00,
    RUBY_ECONV_NEWLINE_DECORATOR_MASK = 0x00007f00,
    RUBY_ECONV_NEWLINE_DECORATOR_READ_MASK = 0x00000f00,
    RUBY_ECONV_NEWLINE_DECORATOR_WRITE_MASK = 0x00007000,
    RUBY_ECONV_UNIVERSAL_NEWLINE_DECORATOR = 0x00000100,
    RUBY_ECONV_CRLF_NEWLINE_DECORATOR = 0x00001000,
    RUBY_ECONV_CR_NEWLINE_DECORATOR = 0x00002000,
    RUBY_ECONV_LF_NEWLINE_DECORATOR = 0x00004000,
    RUBY_ECONV_XML_TEXT_DECORATOR = 0x00008000,
    RUBY_ECONV_XML_ATTR_CONTENT_DECORATOR = 0x00010000,
    RUBY_ECONV_STATEFUL_DECORATOR_MASK = 0x00f00000,
    RUBY_ECONV_XML_ATTR_QUOTE_DECORATOR = 0x00100000,
    RUBY_ECONV_DEFAULT_NEWLINE_DECORATOR =
        0,
    RUBY_ECONV_PARTIAL_INPUT = 0x00020000,
    RUBY_ECONV_AFTER_OUTPUT = 0x00040000,
    RUBY_ECONV_FLAGS_PLACEHOLDER
};

#pragma GCC visibility pop

enum ruby_preserved_encindex {
    RUBY_ENCINDEX_ASCII_8BIT,
    RUBY_ENCINDEX_UTF_8,
    RUBY_ENCINDEX_US_ASCII,
    RUBY_ENCINDEX_UTF_16BE,
    RUBY_ENCINDEX_UTF_16LE,
    RUBY_ENCINDEX_UTF_32BE,
    RUBY_ENCINDEX_UTF_32LE,
    RUBY_ENCINDEX_UTF_16,
    RUBY_ENCINDEX_UTF_32,
    RUBY_ENCINDEX_UTF8_MAC,
    RUBY_ENCINDEX_EUC_JP,
    RUBY_ENCINDEX_Windows_31J,
    RUBY_ENCINDEX_BUILTIN_MAX
};
int rb_enc_find_index2(const char *name, long len);
struct rb_id_table;
enum rb_id_table_iterator_result {
    ID_TABLE_CONTINUE = ST_CONTINUE,
    ID_TABLE_STOP = ST_STOP,
    ID_TABLE_DELETE = ST_DELETE,
    ID_TABLE_REPLACE = ST_REPLACE,
    ID_TABLE_ITERATOR_RESULT_END
};
struct rb_id_table *rb_id_table_create(size_t size);
void rb_id_table_free(struct rb_id_table *tbl);
void rb_id_table_clear(struct rb_id_table *tbl);
size_t rb_id_table_memsize(const struct rb_id_table *tbl);
int rb_id_table_insert(struct rb_id_table *tbl, ID id, VALUE val);
int rb_id_table_lookup(struct rb_id_table *tbl, ID id, VALUE *valp);
int rb_id_table_delete(struct rb_id_table *tbl, ID id);
typedef enum rb_id_table_iterator_result rb_id_table_update_value_callback_func_t(VALUE *val, void *data, int existing);
typedef enum rb_id_table_iterator_result rb_id_table_foreach_func_t(ID id, VALUE val, void *data);
typedef enum rb_id_table_iterator_result rb_id_table_foreach_values_func_t(VALUE val, void *data);
void rb_id_table_foreach(struct rb_id_table *tbl, rb_id_table_foreach_func_t *func, void *data);
void rb_id_table_foreach_values(struct rb_id_table *tbl, rb_id_table_foreach_values_func_t *func, void *data);
void rb_id_table_foreach_values_with_replace(struct rb_id_table *tbl, rb_id_table_foreach_values_func_t *func, rb_id_table_update_value_callback_func_t *replace, void *data);

#pragma GCC visibility push(default)

size_t rb_id_table_size(const struct rb_id_table *tbl);

#pragma GCC visibility pop

void rb_obj_info_dump(VALUE obj);
void rb_obj_info_dump_loc(VALUE obj, const char *file, int line, const char *func);

#pragma GCC visibility push(default)

void ruby_debug_breakpoint(void);
__attribute__((__format__(__printf__, (1), (2)))) void ruby_debug_printf(const char*, ...);

#pragma GCC visibility pop

VALUE rb_ary_hash_values(long len, const VALUE *elements);
VALUE rb_ary_last(int, const VALUE *, VALUE);
void rb_ary_set_len(VALUE, long);
void rb_ary_delete_same(VALUE, VALUE);
VALUE rb_ary_hidden_new_fill(long capa);
VALUE rb_ary_at(VALUE, VALUE);
size_t rb_ary_memsize(VALUE);
VALUE rb_to_array_type(VALUE obj);
VALUE rb_to_array(VALUE obj);
void rb_ary_cancel_sharing(VALUE ary);
size_t rb_ary_size_as_embedded(VALUE ary);
void rb_ary_make_embedded(VALUE ary);
_Bool rb_ary_embeddable_p(VALUE ary);
VALUE rb_ary_diff(VALUE ary1, VALUE ary2);
extern VALUE rb_cArray_empty_frozen;
static inline VALUE rb_ary_entry_internal(VALUE ary, long offset);
static inline _Bool ARY_PTR_USING_P(VALUE ary);
VALUE rb_ary_tmp_new_from_values(VALUE, long, const VALUE *);
VALUE rb_check_to_array(VALUE ary);
VALUE rb_ary_behead(VALUE, long);
VALUE rb_ary_aref1(VALUE ary, VALUE i);
struct rb_execution_context_struct;
VALUE rb_ec_ary_new_from_values(struct rb_execution_context_struct *ec, long n, const VALUE *elts);
static inline VALUE
rb_ary_entry_internal(VALUE ary, long offset)
{
    long len = rb_array_len(ary);
    const VALUE *ptr = rb_array_const_ptr(ary);
    if (len == 0) return ((VALUE)RUBY_Qnil);
    if (offset < 0) {
        offset += len;
        if (offset < 0) return ((VALUE)RUBY_Qnil);
    }
    else if (len <= offset) {
        return ((VALUE)RUBY_Qnil);
    }
    return ptr[offset];
}
static inline _Bool
ARY_PTR_USING_P(VALUE ary)
{
    return RB_FL_TEST_RAW(ary, ((VALUE)RUBY_FL_USER14));
}
[[maybe_unused]]
static inline int
ary_should_not_be_shared_and_embedded(VALUE ary)
{
    return !RB_FL_ALL_RAW(ary, RUBY_ELTS_SHARED|RARRAY_EMBED_FLAG);
}
static inline _Bool
ARY_SHARED_P(VALUE ary)
{
    ((void) (0));
    ((void) (0));
    return RB_FL_TEST_RAW(ary, RUBY_ELTS_SHARED);
}
static inline _Bool
ARY_EMBED_P(VALUE ary)
{
    ((void) (0));
    ((void) (0));
    return RB_FL_TEST_RAW(ary, RARRAY_EMBED_FLAG);
}
static inline VALUE
ARY_SHARED_ROOT(VALUE ary)
{
    ((void) (0));
    return ((struct RArray *)(ary))->as.heap.aux.shared_root;
}
static inline _Bool
ARY_SHARED_ROOT_P(VALUE ary)
{
    ((void) (0));
    return RB_FL_TEST_RAW(ary, ((VALUE)RUBY_FL_USER12));
}
static inline long
ARY_SHARED_ROOT_REFCNT(VALUE ary)
{
    ((void) (0));
    return ((struct RArray *)(ary))->as.heap.aux.capa;
}
__attribute__((__pure__))
__attribute__((__artificial__))
static inline VALUE
RARRAY_AREF(VALUE ary, long i)
{
    VALUE val;
    ((void)0);
   
#pragma GCC diagnostic push
   ;
    val = rb_array_const_ptr(ary)[i];
   
#pragma GCC diagnostic pop
   ;
    return val;
}
struct rb_iseq_struct;
int rb_dvar_defined(ID, const struct rb_iseq_struct *);
int rb_local_defined(ID, const struct rb_iseq_struct *);
int rb_insn_len(VALUE insn);
const char *rb_insns_name(int i);
VALUE rb_insns_name_array(void);
int rb_iseq_cdhash_cmp(VALUE val, VALUE lit);
st_index_t rb_iseq_cdhash_hash(VALUE a);
int rb_vm_insn_addr2insn(const void *);
int rb_vm_insn_decode(const VALUE encoded);
extern _Bool ruby_vm_keep_script_lines;
rb_event_flag_t rb_iseq_event_flags(const struct rb_iseq_struct *iseq, size_t pos);
struct RComplex {
    struct RBasic basic;
    VALUE real;
    VALUE imag;
};
VALUE rb_dbl_complex_new_polar_pi(double abs, double ang);
st_index_t rb_complex_hash(VALUE comp);
ID rb_id_encoding(void);
const char * rb_enc_inspect_name(rb_encoding *enc);
rb_encoding *rb_enc_get_from_index(int index);
rb_encoding *rb_enc_check_str(VALUE str1, VALUE str2);
int rb_encdb_replicate(const char *alias, const char *orig);
int rb_encdb_alias(const char *alias, const char *orig);
int rb_enc_autoload(rb_encoding *enc);
int rb_encdb_dummy(const char *name);
void rb_encdb_declare(const char *name);
void rb_enc_set_base(const char *name, const char *orig);
int rb_enc_set_dummy(int index);
void rb_enc_raw_set(VALUE obj, rb_encoding *enc);
__attribute__((__pure__)) int rb_data_is_encoding(VALUE obj);
void rb_free_global_enc_table(void);
enum ruby_rstring_private_flags {
    RSTRING_CHILLED = (((VALUE)RUBY_FL_USER2) | ((VALUE)RUBY_FL_USER3)),
};
VALUE rb_fstring(VALUE);
VALUE rb_fstring_cstr(const char *str);
VALUE rb_fstring_enc_new(const char *ptr, long len, rb_encoding *enc);
int rb_str_buf_cat_escaped_char(VALUE result, unsigned int c, int unicode_p);
int rb_str_symname_p(VALUE);
VALUE rb_str_quote_unprintable(VALUE);
char *rb_str_fill_terminator(VALUE str, const int termlen);
void rb_str_change_terminator_length(VALUE str, const int oldtermlen, const int termlen);
VALUE rb_str_locktmp_ensure(VALUE str, VALUE (*func)(VALUE), VALUE arg);
VALUE rb_str_chomp_string(VALUE str, VALUE chomp);
VALUE rb_external_str_with_enc(VALUE str, rb_encoding *eenc);
VALUE rb_str_cat_conv_enc_opts(VALUE newstr, long ofs, const char *ptr, long len,
                               rb_encoding *from, int ecflags, VALUE ecopts);
VALUE rb_enc_str_scrub(rb_encoding *enc, VALUE str, VALUE repl);
VALUE rb_str_escape(VALUE str);
size_t rb_str_memsize(VALUE);
char *rb_str_to_cstr(VALUE str);
const char *ruby_escaped_char(int c);
void rb_str_make_independent(VALUE str);
int rb_enc_str_coderange_scan(VALUE str, rb_encoding *enc);
int rb_ascii8bit_appendable_encoding_index(rb_encoding *enc, unsigned int code);
VALUE rb_str_include(VALUE str, VALUE arg);
VALUE rb_str_byte_substr(VALUE str, VALUE beg, VALUE len);
VALUE rb_str_substr_two_fixnums(VALUE str, VALUE beg, VALUE len, int empty);
VALUE rb_str_tmp_frozen_no_embed_acquire(VALUE str);
void rb_str_make_embedded(VALUE);
VALUE rb_str_upto_each(VALUE, VALUE, int, int (*each)(VALUE, VALUE), VALUE);
size_t rb_str_size_as_embedded(VALUE);
_Bool rb_str_reembeddable_p(VALUE);
VALUE rb_str_upto_endless_each(VALUE, int (*each)(VALUE, VALUE), VALUE);
VALUE rb_str_with_debug_created_info(VALUE, VALUE, int);
void rb_warn_unchilled_literal(VALUE str);
void rb_warn_unchilled_symbol_to_s(VALUE str);
static inline _Bool STR_EMBED_P(VALUE str);
static inline _Bool STR_SHARED_P(VALUE str);
static inline VALUE QUOTE(VALUE v);
static inline VALUE QUOTE_ID(ID v);
static inline _Bool is_ascii_string(VALUE str);
static inline _Bool is_broken_string(VALUE str);
static inline VALUE rb_str_eql_internal(const VALUE str1, const VALUE str2);

#pragma GCC visibility push(default)

VALUE rb_str_tmp_frozen_acquire(VALUE str);
void rb_str_tmp_frozen_release(VALUE str, VALUE tmp);
VALUE rb_setup_fake_str(struct RString *fake_str, const char *name, long len, rb_encoding *enc);

#pragma GCC visibility pop

VALUE rb_fstring_new(const char *ptr, long len);
VALUE rb_obj_as_string_result(VALUE str, VALUE obj);
VALUE rb_str_opt_plus(VALUE x, VALUE y);
VALUE rb_str_concat_literals(size_t num, const VALUE *strary);
VALUE rb_str_eql(VALUE str1, VALUE str2);
VALUE rb_id_quote_unprintable(ID);
VALUE rb_sym_proc_call(ID mid, int argc, const VALUE *argv, int kw_splat, VALUE passed_proc);
VALUE rb_enc_literal_str(const char *ptr, long len, rb_encoding *enc);
struct rb_execution_context_struct;
VALUE rb_ec_str_resurrect(struct rb_execution_context_struct *ec, VALUE str, _Bool chilled);
static inline VALUE
QUOTE(VALUE v)
{
    return rb_str_quote_unprintable(v);
}
static inline VALUE
QUOTE_ID(ID i)
{
    return rb_id_quote_unprintable(i);
}
static inline _Bool
STR_EMBED_P(VALUE str)
{
    return ! RB_FL_TEST_RAW(str, ((VALUE)RUBY_FL_USER1));
}
static inline _Bool
STR_SHARED_P(VALUE str)
{
    return RB_FL_ALL_RAW(str, ((VALUE)RUBY_FL_USER1) | ((VALUE)RUBY_FL_USER0));
}
static inline _Bool
CHILLED_STRING_P(VALUE obj)
{
    return RB_TYPE_P(obj, RUBY_T_STRING) && RB_FL_TEST_RAW(obj, (((VALUE)RUBY_FL_USER2) | ((VALUE)RUBY_FL_USER3)));
}
static inline void
CHILLED_STRING_MUTATED(VALUE str)
{
    VALUE chilled_reason = RB_FL_TEST_RAW(str, (((VALUE)RUBY_FL_USER2) | ((VALUE)RUBY_FL_USER3)));
    RB_FL_UNSET_RAW(str, (((VALUE)RUBY_FL_USER2) | ((VALUE)RUBY_FL_USER3)));
    switch (chilled_reason) {
      case ((VALUE)RUBY_FL_USER3):
        rb_warn_unchilled_symbol_to_s(str);
        break;
      case ((VALUE)RUBY_FL_USER2):
        rb_warn_unchilled_literal(str);
        break;
      default:
        rb_bug("RString was chilled for multiple reasons");
    }
}
static inline _Bool
is_ascii_string(VALUE str)
{
    return rb_enc_str_coderange(str) == RUBY_ENC_CODERANGE_7BIT;
}
static inline _Bool
is_broken_string(VALUE str)
{
    return rb_enc_str_coderange(str) == RUBY_ENC_CODERANGE_BROKEN;
}
static inline _Bool
at_char_boundary(const char *s, const char *p, const char *e, rb_encoding *enc)
{
    return rb_enc_left_char_head(s, p, e, enc) == p;
}
static inline _Bool
at_char_right_boundary(const char *s, const char *p, const char *e, rb_encoding *enc)
{
    ((void)0);
    ((void)0);
    return rb_enc_right_char_head(s, p, e, enc) == p;
}
static inline VALUE
rb_str_eql_internal(const VALUE str1, const VALUE str2)
{
    const long len = RSTRING_LEN(str1);
    const char *ptr1, *ptr2;
    if (len != RSTRING_LEN(str2)) return ((VALUE)RUBY_Qfalse);
    if (!rb_str_comparable(str1, str2)) return ((VALUE)RUBY_Qfalse);
    if ((ptr1 = RSTRING_PTR(str1)) == (ptr2 = RSTRING_PTR(str2)))
        return ((VALUE)RUBY_Qtrue);
    if (memcmp(ptr1, ptr2, len) == 0)
        return ((VALUE)RUBY_Qtrue);
    return ((VALUE)RUBY_Qfalse);
}
extern long rb_backtrace_length_limit;
extern VALUE rb_eEAGAIN;
extern VALUE rb_eEWOULDBLOCK;
extern VALUE rb_eEINPROGRESS;
__attribute__((__format__(__printf__, 3, 0)))
void rb_report_bug_valist(VALUE file, int line, const char *fmt, va_list args);
__attribute__((__noreturn__)) void rb_async_bug_errno(const char *,int);
const char *rb_builtin_type_name(int t);
const char *rb_builtin_class_name(VALUE x);
__attribute__((__format__(__printf__, (1), (3)))) void rb_warn_deprecated(const char *fmt, const char *suggest, ...);
__attribute__((__format__(__printf__, (2), (4)))) void rb_warn_deprecated_to_remove(const char *removal, const char *fmt, const char *suggest, ...);
__attribute__((__format__(__printf__, 6, 0)))
VALUE rb_syntax_error_append(VALUE, VALUE, int, int, rb_encoding*, const char*, va_list);
__attribute__((__format__(__printf__, (2), (3)))) void rb_enc_warn(rb_encoding *enc, const char *fmt, ...);
__attribute__((__format__(__printf__, (2), (3)))) void rb_sys_enc_warning(rb_encoding *enc, const char *fmt, ...);
__attribute__((__format__(__printf__, (3), (4)))) void rb_syserr_enc_warning(int err, rb_encoding *enc, const char *fmt, ...);
__attribute__((__format__(__printf__, (4), (5)))) void rb_enc_compile_warning(rb_encoding *enc, const char *file, int line, const char *fmt, ...);
__attribute__((__format__(__printf__, (4), (5)))) void rb_enc_compile_warn(rb_encoding *enc, const char *file, int line, const char *fmt, ...);
rb_warning_category_t rb_warning_category_from_name(VALUE category);
_Bool rb_warning_category_enabled_p(rb_warning_category_t category);
VALUE rb_name_err_new(VALUE mesg, VALUE recv, VALUE method);
VALUE rb_nomethod_err_new(VALUE mesg, VALUE recv, VALUE method, VALUE args, int priv);
VALUE rb_key_err_new(VALUE mesg, VALUE recv, VALUE name);
__attribute__((__format__(__printf__, (1), (2)))) VALUE rb_warning_string(const char *fmt, ...);
__attribute__((__format__(__printf__, 2, 0)))
__attribute__((__noreturn__)) void rb_vraise(VALUE, const char *, va_list);
__attribute__((__noreturn__)) static inline void rb_raise_cstr(VALUE etype, const char *mesg);
__attribute__((__noreturn__)) static inline void rb_raise_cstr_i(VALUE etype, VALUE mesg);
__attribute__((__noreturn__)) static inline void rb_name_err_raise_str(VALUE mesg, VALUE recv, VALUE name);
__attribute__((__noreturn__)) static inline void rb_name_err_raise(const char *mesg, VALUE recv, VALUE name);
__attribute__((__noreturn__)) static inline void rb_key_err_raise(VALUE mesg, VALUE recv, VALUE name);
static inline void Check_Type(VALUE v, enum ruby_value_type t);
static inline _Bool rb_typeddata_is_instance_of_inline(VALUE obj, const rb_data_type_t *data_type);

#pragma GCC visibility push(default)

int rb_bug_reporter_add(void (*func)(FILE *, void *), void *data);
__attribute__((__noreturn__)) void rb_sys_fail_path_in(const char *func_name, VALUE path);
__attribute__((__noreturn__)) void rb_syserr_fail_path_in(const char *func_name, int err, VALUE path);
VALUE rb_syserr_new_path_in(const char *func_name, int n, VALUE path);

#pragma GCC visibility pop

void rb_free_warning(void);
static inline void
rb_raise_cstr_i(VALUE etype, VALUE mesg)
{
    VALUE exc = rb_exc_new_str(etype, mesg);
    rb_exc_raise(exc);
}
static inline void
rb_raise_cstr(VALUE etype, const char *mesg)
{
    VALUE str = ((__builtin_constant_p(mesg) ? rbimpl_str_new_cstr : rb_str_new_cstr) (mesg));
    rb_raise_cstr_i(etype, str);
}
static inline void
rb_name_err_raise_str(VALUE mesg, VALUE recv, VALUE name)
{
    VALUE exc = rb_name_err_new(mesg, recv, name);
    rb_exc_raise(exc);
}
static inline void
rb_name_err_raise(const char *mesg, VALUE recv, VALUE name)
{
    VALUE str = (__builtin_constant_p(mesg) ? rb_fstring_new((mesg), (long)strlen(mesg)) : (rb_fstring_cstr)(mesg));
    rb_name_err_raise_str(str, recv, name);
}
static inline void
rb_key_err_raise(VALUE mesg, VALUE recv, VALUE name)
{
    VALUE exc = rb_key_err_new(mesg, recv, name);
    rb_exc_raise(exc);
}
static inline _Bool
rb_typeddata_is_instance_of_inline(VALUE obj, const rb_data_type_t *data_type)
{
    return RB_TYPE_P(obj, RUBY_T_DATA) && RTYPEDDATA_P(obj) && (RTYPEDDATA_TYPE(obj) == data_type);
}

typedef __sig_atomic_t sig_atomic_t;
union sigval
{
  int sival_int;
  void *sival_ptr;
};
typedef union sigval __sigval_t;
typedef struct
  {
    int si_signo;
    int si_errno;
    int si_code;
    int __pad0;
    union
      {
 int _pad[((128 / sizeof (int)) - 4)];
 struct
   {
     __pid_t si_pid;
     __uid_t si_uid;
   } _kill;
 struct
   {
     int si_tid;
     int si_overrun;
     __sigval_t si_sigval;
   } _timer;
 struct
   {
     __pid_t si_pid;
     __uid_t si_uid;
     __sigval_t si_sigval;
   } _rt;
 struct
   {
     __pid_t si_pid;
     __uid_t si_uid;
     int si_status;
     __clock_t si_utime;
     __clock_t si_stime;
   } _sigchld;
 struct
   {
     void *si_addr;
    
     short int si_addr_lsb;
     union
       {
  struct
    {
      void *_lower;
      void *_upper;
    } _addr_bnd;
  __uint32_t _pkey;
       } _bounds;
   } _sigfault;
 struct
   {
     long int si_band;
     int si_fd;
   } _sigpoll;
 struct
   {
     void *_call_addr;
     int _syscall;
     unsigned int _arch;
   } _sigsys;
      } _sifields;
  } siginfo_t ;
enum
{
  SI_ASYNCNL = -60,
  SI_DETHREAD = -7,
  SI_TKILL,
  SI_SIGIO,
  SI_ASYNCIO,
  SI_MESGQ,
  SI_TIMER,
  SI_QUEUE,
  SI_USER,
  SI_KERNEL = 0x80
};
enum
{
  ILL_ILLOPC = 1,
  ILL_ILLOPN,
  ILL_ILLADR,
  ILL_ILLTRP,
  ILL_PRVOPC,
  ILL_PRVREG,
  ILL_COPROC,
  ILL_BADSTK,
  ILL_BADIADDR
};
enum
{
  FPE_INTDIV = 1,
  FPE_INTOVF,
  FPE_FLTDIV,
  FPE_FLTOVF,
  FPE_FLTUND,
  FPE_FLTRES,
  FPE_FLTINV,
  FPE_FLTSUB,
  FPE_FLTUNK = 14,
  FPE_CONDTRAP
};
enum
{
  SEGV_MAPERR = 1,
  SEGV_ACCERR,
  SEGV_BNDERR,
  SEGV_PKUERR,
  SEGV_ACCADI,
  SEGV_ADIDERR,
  SEGV_ADIPERR,
  SEGV_MTEAERR,
  SEGV_MTESERR
};
enum
{
  BUS_ADRALN = 1,
  BUS_ADRERR,
  BUS_OBJERR,
  BUS_MCEERR_AR,
  BUS_MCEERR_AO
};
enum
{
  TRAP_BRKPT = 1,
  TRAP_TRACE,
  TRAP_BRANCH,
  TRAP_HWBKPT,
  TRAP_UNK
};
enum
{
  CLD_EXITED = 1,
  CLD_KILLED,
  CLD_DUMPED,
  CLD_TRAPPED,
  CLD_STOPPED,
  CLD_CONTINUED
};
enum
{
  POLL_IN = 1,
  POLL_OUT,
  POLL_MSG,
  POLL_ERR,
  POLL_PRI,
  POLL_HUP
};
typedef __sigval_t sigval_t;
typedef struct sigevent
  {
    __sigval_t sigev_value;
    int sigev_signo;
    int sigev_notify;
    union
      {
 int _pad[((64 / sizeof (int)) - 4)];
 __pid_t _tid;
 struct
   {
     void (*_function) (__sigval_t);
     pthread_attr_t *_attribute;
   } _sigev_thread;
      } _sigev_un;
  } sigevent_t;
enum
{
  SIGEV_SIGNAL = 0,
  SIGEV_NONE,
  SIGEV_THREAD,
  SIGEV_THREAD_ID = 4
};
typedef void (*__sighandler_t) (int);
extern __sighandler_t __sysv_signal (int __sig, __sighandler_t __handler)
     __attribute__ ((__nothrow__ , __leaf__));
extern __sighandler_t sysv_signal (int __sig, __sighandler_t __handler)
     __attribute__ ((__nothrow__ , __leaf__));
extern __sighandler_t signal (int __sig, __sighandler_t __handler)
     __attribute__ ((__nothrow__ , __leaf__));
extern int kill (__pid_t __pid, int __sig) __attribute__ ((__nothrow__ , __leaf__));
extern int killpg (__pid_t __pgrp, int __sig) __attribute__ ((__nothrow__ , __leaf__));
extern int raise (int __sig) __attribute__ ((__nothrow__ , __leaf__));
extern __sighandler_t ssignal (int __sig, __sighandler_t __handler)
     __attribute__ ((__nothrow__ , __leaf__));
extern int gsignal (int __sig) __attribute__ ((__nothrow__ , __leaf__));
extern void psignal (int __sig, const char *__s);
extern void psiginfo (const siginfo_t *__pinfo, const char *__s);
extern int sigpause (int __sig) __asm__ ("__xpg_sigpause")
  __attribute__ ((__deprecated__ ("Use the sigsuspend function instead")));
extern int sigblock (int __mask) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__deprecated__));
extern int sigsetmask (int __mask) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__deprecated__));
extern int siggetmask (void) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__deprecated__));
typedef __sighandler_t sighandler_t;
typedef __sighandler_t sig_t;
extern int sigemptyset (sigset_t *__set) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int sigfillset (sigset_t *__set) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int sigaddset (sigset_t *__set, int __signo) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int sigdelset (sigset_t *__set, int __signo) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int sigismember (const sigset_t *__set, int __signo)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int sigisemptyset (const sigset_t *__set) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int sigandset (sigset_t *__set, const sigset_t *__left,
        const sigset_t *__right) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2, 3)));
extern int sigorset (sigset_t *__set, const sigset_t *__left,
       const sigset_t *__right) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2, 3)));
struct sigaction
  {
    union
      {
 __sighandler_t sa_handler;
 void (*sa_sigaction) (int, siginfo_t *, void *);
      }
    __sigaction_handler;
    __sigset_t sa_mask;
    int sa_flags;
    void (*sa_restorer) (void);
  };
extern int sigprocmask (int __how, const sigset_t *__restrict __set,
   sigset_t *__restrict __oset) __attribute__ ((__nothrow__ , __leaf__));
extern int sigsuspend (const sigset_t *__set) __attribute__ ((__nonnull__ (1)));
extern int sigaction (int __sig, const struct sigaction *__restrict __act,
        struct sigaction *__restrict __oact) __attribute__ ((__nothrow__ , __leaf__));
extern int sigpending (sigset_t *__set) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int sigwait (const sigset_t *__restrict __set, int *__restrict __sig)
     __attribute__ ((__nonnull__ (1, 2)));
extern int sigwaitinfo (const sigset_t *__restrict __set,
   siginfo_t *__restrict __info) __attribute__ ((__nonnull__ (1)));
extern int sigtimedwait (const sigset_t *__restrict __set,
    siginfo_t *__restrict __info,
    const struct timespec *__restrict __timeout)
     __attribute__ ((__nonnull__ (1)));
extern int sigqueue (__pid_t __pid, int __sig, const union sigval __val)
     __attribute__ ((__nothrow__ , __leaf__));
struct _fpx_sw_bytes
{
  __uint32_t magic1;
  __uint32_t extended_size;
  __uint64_t xstate_bv;
  __uint32_t xstate_size;
  __uint32_t __glibc_reserved1[7];
};
struct _fpreg
{
  unsigned short significand[4];
  unsigned short exponent;
};
struct _fpxreg
{
  unsigned short significand[4];
  unsigned short exponent;
  unsigned short __glibc_reserved1[3];
};
struct _xmmreg
{
  __uint32_t element[4];
};
struct _fpstate
{
  __uint16_t cwd;
  __uint16_t swd;
  __uint16_t ftw;
  __uint16_t fop;
  __uint64_t rip;
  __uint64_t rdp;
  __uint32_t mxcsr;
  __uint32_t mxcr_mask;
  struct _fpxreg _st[8];
  struct _xmmreg _xmm[16];
  __uint32_t __glibc_reserved1[24];
};
struct sigcontext
{
  __uint64_t r8;
  __uint64_t r9;
  __uint64_t r10;
  __uint64_t r11;
  __uint64_t r12;
  __uint64_t r13;
  __uint64_t r14;
  __uint64_t r15;
  __uint64_t rdi;
  __uint64_t rsi;
  __uint64_t rbp;
  __uint64_t rbx;
  __uint64_t rdx;
  __uint64_t rax;
  __uint64_t rcx;
  __uint64_t rsp;
  __uint64_t rip;
  __uint64_t eflags;
  unsigned short cs;
  unsigned short gs;
  unsigned short fs;
  unsigned short __pad0;
  __uint64_t err;
  __uint64_t trapno;
  __uint64_t oldmask;
  __uint64_t cr2;
  __extension__ union
    {
      struct _fpstate * fpstate;
      __uint64_t __fpstate_word;
    };
  __uint64_t __reserved1 [8];
};
struct _xsave_hdr
{
  __uint64_t xstate_bv;
  __uint64_t __glibc_reserved1[2];
  __uint64_t __glibc_reserved2[5];
};
struct _ymmh_state
{
  __uint32_t ymmh_space[64];
};
struct _xstate
{
  struct _fpstate fpstate;
  struct _xsave_hdr xstate_hdr;
  struct _ymmh_state ymmh;
};
extern int sigreturn (struct sigcontext *__scp) __attribute__ ((__nothrow__ , __leaf__));
typedef struct
  {
    void *ss_sp;
    int ss_flags;
    size_t ss_size;
  } stack_t;
__extension__ typedef long long int greg_t;
typedef greg_t gregset_t[23];
enum
{
  REG_R8 = 0,
  REG_R9,
  REG_R10,
  REG_R11,
  REG_R12,
  REG_R13,
  REG_R14,
  REG_R15,
  REG_RDI,
  REG_RSI,
  REG_RBP,
  REG_RBX,
  REG_RDX,
  REG_RAX,
  REG_RCX,
  REG_RSP,
  REG_RIP,
  REG_EFL,
  REG_CSGSFS,
  REG_ERR,
  REG_TRAPNO,
  REG_OLDMASK,
  REG_CR2
};
struct _libc_fpxreg
{
  unsigned short int significand[4];
  unsigned short int exponent;
  unsigned short int __glibc_reserved1[3];
};
struct _libc_xmmreg
{
  __uint32_t element[4];
};
struct _libc_fpstate
{
  __uint16_t cwd;
  __uint16_t swd;
  __uint16_t ftw;
  __uint16_t fop;
  __uint64_t rip;
  __uint64_t rdp;
  __uint32_t mxcsr;
  __uint32_t mxcr_mask;
  struct _libc_fpxreg _st[8];
  struct _libc_xmmreg _xmm[16];
  __uint32_t __glibc_reserved1[24];
};
typedef struct _libc_fpstate *fpregset_t;
typedef struct
  {
    gregset_t gregs;
    fpregset_t fpregs;
    __extension__ unsigned long long __reserved1 [8];
} mcontext_t;
typedef struct ucontext_t
  {
    unsigned long int uc_flags;
    struct ucontext_t *uc_link;
    stack_t uc_stack;
    mcontext_t uc_mcontext;
    sigset_t uc_sigmask;
    struct _libc_fpstate __fpregs_mem;
    __extension__ unsigned long long int __ssp[4];
  } ucontext_t;
extern int siginterrupt (int __sig, int __interrupt) __attribute__ ((__nothrow__ , __leaf__))
  __attribute__ ((__deprecated__ ("Use sigaction with SA_RESTART instead")));
enum
{
  SS_ONSTACK = 1,
  SS_DISABLE
};
extern int sigaltstack (const stack_t *__restrict __ss,
   stack_t *__restrict __oss) __attribute__ ((__nothrow__ , __leaf__));
struct sigstack
  {
    void *ss_sp;
    int ss_onstack;
  };
extern int sigstack (struct sigstack *__ss, struct sigstack *__oss)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__deprecated__));
extern int sighold (int __sig) __attribute__ ((__nothrow__ , __leaf__))
  __attribute__ ((__deprecated__ ("Use the sigprocmask function instead")));
extern int sigrelse (int __sig) __attribute__ ((__nothrow__ , __leaf__))
  __attribute__ ((__deprecated__ ("Use the sigprocmask function instead")));
extern int sigignore (int __sig) __attribute__ ((__nothrow__ , __leaf__))
  __attribute__ ((__deprecated__ ("Use the signal function instead")));
extern __sighandler_t sigset (int __sig, __sighandler_t __disp) __attribute__ ((__nothrow__ , __leaf__))
  __attribute__ ((__deprecated__ ("Use the signal and sigprocmask functions instead")));
extern int pthread_sigmask (int __how,
       const __sigset_t *__restrict __newmask,
       __sigset_t *__restrict __oldmask)__attribute__ ((__nothrow__ , __leaf__));
extern int pthread_kill (pthread_t __threadid, int __signo) __attribute__ ((__nothrow__ , __leaf__));
extern int pthread_sigqueue (pthread_t __threadid, int __signo,
        const union sigval __value) __attribute__ ((__nothrow__ , __leaf__));
extern int __libc_current_sigrtmin (void) __attribute__ ((__nothrow__ , __leaf__));
extern int __libc_current_sigrtmax (void) __attribute__ ((__nothrow__ , __leaf__));
extern int tgkill (__pid_t __tgid, __pid_t __tid, int __signal);


typedef long int __jmp_buf[8];
struct __jmp_buf_tag
  {
    __jmp_buf __jmpbuf;
    int __mask_was_saved;
    __sigset_t __saved_mask;
  };
typedef struct __jmp_buf_tag jmp_buf[1];
extern int setjmp (jmp_buf __env) __attribute__ ((__nothrow__));
extern int __sigsetjmp (struct __jmp_buf_tag __env[1], int __savemask) __attribute__ ((__nothrow__));
extern int _setjmp (struct __jmp_buf_tag __env[1]) __attribute__ ((__nothrow__));
extern void longjmp (struct __jmp_buf_tag __env[1], int __val)
     __attribute__ ((__nothrow__)) __attribute__ ((__noreturn__));
extern void _longjmp (struct __jmp_buf_tag __env[1], int __val)
     __attribute__ ((__nothrow__)) __attribute__ ((__noreturn__));
typedef struct __jmp_buf_tag sigjmp_buf[1];
extern void siglongjmp (sigjmp_buf __env, int __val)
     __attribute__ ((__nothrow__)) __attribute__ ((__noreturn__));

static inline char *container_of_or_null_(void *member_ptr, size_t offset)
{
 return member_ptr ? (char *)member_ptr - offset : ((void *)0);
}
struct ccan_list_node
{
 struct ccan_list_node *next, *prev;
};
struct ccan_list_head
{
 struct ccan_list_node n;
};
static inline void ccan_list_head_init(struct ccan_list_head *h)
{
 h->n.next = h->n.prev = &h->n;
}
static inline void ccan_list_node_init(struct ccan_list_node *n)
{
 n->next = n->prev = n;
}
static inline void ccan_list_add_after_(struct ccan_list_head *h,
       struct ccan_list_node *p,
       struct ccan_list_node *n,
       const char *abortstr)
{
 n->next = p->next;
 n->prev = p;
 p->next->prev = n;
 p->next = n;
 (void)((void)abortstr, h);
}
static inline void ccan_list_add_(struct ccan_list_head *h,
        struct ccan_list_node *n,
        const char *abortstr)
{
 ccan_list_add_after_(h, &h->n, n, abortstr);
}
static inline void ccan_list_add_before_(struct ccan_list_head *h,
        struct ccan_list_node *p,
        struct ccan_list_node *n,
        const char *abortstr)
{
 n->next = p;
 n->prev = p->prev;
 p->prev->next = n;
 p->prev = n;
 (void)((void)abortstr, h);
}
static inline void ccan_list_add_tail_(struct ccan_list_head *h,
      struct ccan_list_node *n,
      const char *abortstr)
{
 ccan_list_add_before_(h, &h->n, n, abortstr);
}
static inline int ccan_list_empty_(const struct ccan_list_head *h, const char* abortstr)
{
 (void)((void)abortstr, h);
 return h->n.next == &h->n;
}
static inline _Bool ccan_list_empty_nocheck(const struct ccan_list_head *h)
{
 return h->n.next == &h->n;
}
static inline void ccan_list_del_(struct ccan_list_node *n, const char* abortstr)
{
 (void)((void)abortstr, n);
 n->next->prev = n->prev;
 n->prev->next = n->next;
}
static inline void ccan_list_del_init_(struct ccan_list_node *n, const char *abortstr)
{
 ccan_list_del_(n, abortstr);
 ccan_list_node_init(n);
}
static inline void ccan_list_del_from(struct ccan_list_head *h, struct ccan_list_node *n)
{
 ((void) (0));
 ccan_list_del_(n, "./ccan/list/list.h" ":" "329");
}
static inline void ccan_list_swap_(struct ccan_list_node *o,
         struct ccan_list_node *n,
         const char* abortstr)
{
 (void)((void)abortstr, o);
 *n = *o;
 n->next->prev = n;
 n->prev->next = n;
}
static inline const void *ccan_list_top_(const struct ccan_list_head *h, size_t off)
{
 if (ccan_list_empty_(h, "./ccan/list/list.h" ":" "399"))
  return ((void *)0);
 return (const char *)h->n.next - off;
}
static inline const void *ccan_list_pop_(const struct ccan_list_head *h, size_t off)
{
 struct ccan_list_node *n;
 if (ccan_list_empty_(h, "./ccan/list/list.h" ":" "425"))
  return ((void *)0);
 n = h->n.next;
 ccan_list_del_(n, "./ccan/list/list.h" ":" "428");
 return (const char *)n - off;
}
static inline const void *ccan_list_tail_(const struct ccan_list_head *h, size_t off)
{
 if (ccan_list_empty_(h, "./ccan/list/list.h" ":" "451"))
  return ((void *)0);
 return (const char *)h->n.prev - off;
}
static inline void ccan_list_append_list_(struct ccan_list_head *to,
         struct ccan_list_head *from,
         const char *abortstr)
{
 struct ccan_list_node *from_tail = ((void)abortstr, from)->n.prev;
 struct ccan_list_node *to_tail = ((void)abortstr, to)->n.prev;
 to->n.prev = from_tail;
 from_tail->next = &to->n;
 to_tail->next = &from->n;
 from->n.prev = to_tail;
 ccan_list_del_(&from->n, "./ccan/list/list.h" ":" "600");
 ccan_list_head_init(from);
}
static inline void ccan_list_prepend_list_(struct ccan_list_head *to,
          struct ccan_list_head *from,
          const char *abortstr)
{
 struct ccan_list_node *from_tail = ((void)abortstr, from)->n.prev;
 struct ccan_list_node *to_head = ((void)abortstr, to)->n.next;
 to->n.next = &from->n;
 from->n.prev = &to->n;
 to_head->prev = from_tail;
 from_tail->next = to_head;
 ccan_list_del_(&from->n, "./ccan/list/list.h" ":" "632");
 ccan_list_head_init(from);
}
static inline void *ccan_list_node_to_off_(struct ccan_list_node *node, size_t off)
{
 return (void *)((char *)node - off);
}
static inline struct ccan_list_node *ccan_list_node_from_off_(void *ptr, size_t off)
{
 return (struct ccan_list_node *)((char *)ptr + off);
}
static inline void *ccan_list_entry_or_null(const struct ccan_list_head *h,
           const struct ccan_list_node *n,
           size_t off)
{
 if (n == &h->n)
  return ((void *)0);
 return (char *)n - off;
}
enum ruby_id_types {
    RUBY_ID_STATIC_SYM = 0x01,
    RUBY_ID_LOCAL = 0x00,
    RUBY_ID_INSTANCE = (0x01<<1),
    RUBY_ID_GLOBAL = (0x03<<1),
    RUBY_ID_ATTRSET = (0x04<<1),
    RUBY_ID_CONST = (0x05<<1),
    RUBY_ID_CLASS = (0x06<<1),
    RUBY_ID_JUNK = (0x07<<1),
    RUBY_ID_INTERNAL = RUBY_ID_JUNK,
    RUBY_ID_SCOPE_SHIFT = 4,
    RUBY_ID_SCOPE_MASK = (~(~0U<<(RUBY_ID_SCOPE_SHIFT-1))<<1)
};
enum ruby_method_ids {
    idDot2 = 128,
    idDot3 = 129,
    idUPlus = 132,
    idUMinus = 133,
    idPow = 134,
    idCmp = 135,
    idPLUS = '+',
    idMINUS = '-',
    idMULT = '*',
    idDIV = '/',
    idMOD = '%',
    idLTLT = 136,
    idGTGT = 137,
    idLT = '<',
    idLE = 138,
    idGT = '>',
    idGE = 139,
    idEq = 140,
    idEqq = 141,
    idNeq = 142,
    idNot = '!',
    idAnd = '&',
    idOr = '|',
    idBackquote = '`',
    idEqTilde = 143,
    idNeqTilde = 144,
    idAREF = 145,
    idASET = 146,
    idCOLON2 = 147,
    idANDOP = 148,
    idOROP = 149,
    idANDDOT = 150,
    tPRESERVED_ID_BEGIN = 150,
    idNilP,
    idIncludeP,
    idNULL,
    idEmptyP,
    idEqlP,
    idRespond_to,
    idRespond_to_missing,
    idIFUNC,
    idCFUNC,
    id_core_set_method_alias,
    id_core_set_variable_alias,
    id_core_undef_method,
    id_core_define_method,
    id_core_define_singleton_method,
    id_core_set_postexe,
    id_core_hash_merge_ptr,
    id_core_hash_merge_kwd,
    id_core_raise,
    id_core_sprintf,
    id_debug_created_info,
    tPRESERVED_ID_END,
    tTOKEN_LOCAL_BEGIN = tPRESERVED_ID_END-1,
    tMax,
    tMin,
    tHash,
    tFreeze,
    tInspect,
    tIntern,
    tObject_id,
    t__id__,
    tConst_added,
    tConst_missing,
    tMethodMissing,
    tMethod_added,
    tSingleton_method_added,
    tMethod_removed,
    tSingleton_method_removed,
    tMethod_undefined,
    tSingleton_method_undefined,
    tLength,
    tSize,
    tGets,
    tSucc,
    tEach,
    tProc,
    tLambda,
    tSend,
    t__send__,
    t__recursive_key__,
    tInitialize,
    tInitialize_copy,
    tInitialize_clone,
    tInitialize_dup,
    tTo_int,
    tTo_ary,
    tTo_str,
    tTo_sym,
    tTo_hash,
    tTo_proc,
    tTo_io,
    tTo_a,
    tTo_s,
    tTo_i,
    tTo_f,
    tTo_r,
    tBt,
    tBt_locations,
    tCall,
    tMesg,
    tException,
    tLocals,
    tNOT,
    tAND,
    tOR,
    tDiv,
    tDivmod,
    tFdiv,
    tQuo,
    tName,
    tNil,
    tPath,
    tPack,
    tBuffer,
    tUScore,
    tNUMPARAM_1,
    tNUMPARAM_2,
    tNUMPARAM_3,
    tNUMPARAM_4,
    tNUMPARAM_5,
    tNUMPARAM_6,
    tNUMPARAM_7,
    tNUMPARAM_8,
    tNUMPARAM_9,
    tDefault,
    tTOKEN_LOCAL_END,
    tTOKEN_INSTANCE_BEGIN = tTOKEN_LOCAL_END-1,
    tTOKEN_INSTANCE_END,
    tTOKEN_GLOBAL_BEGIN = tTOKEN_INSTANCE_END-1,
    tLASTLINE,
    tBACKREF,
    tERROR_INFO,
    tTOKEN_GLOBAL_END,
    tTOKEN_CONST_BEGIN = tTOKEN_GLOBAL_END-1,
    tTOKEN_CONST_END,
    tTOKEN_CLASS_BEGIN = tTOKEN_CONST_END-1,
    tTOKEN_CLASS_END,
    tTOKEN_ATTRSET_BEGIN = tTOKEN_CLASS_END-1,
    tTOKEN_ATTRSET_END,
    tNEXT_ID = tTOKEN_ATTRSET_END,
    idMax = ((tMax<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idMin = ((tMin<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idHash = ((tHash<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idFreeze = ((tFreeze<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idInspect = ((tInspect<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idIntern = ((tIntern<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idObject_id = ((tObject_id<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    id__id__ = ((t__id__<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idConst_added = ((tConst_added<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idConst_missing = ((tConst_missing<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idMethodMissing = ((tMethodMissing<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idMethod_added = ((tMethod_added<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idSingleton_method_added = ((tSingleton_method_added<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idMethod_removed = ((tMethod_removed<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idSingleton_method_removed = ((tSingleton_method_removed<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idMethod_undefined = ((tMethod_undefined<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idSingleton_method_undefined = ((tSingleton_method_undefined<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idLength = ((tLength<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idSize = ((tSize<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idGets = ((tGets<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idSucc = ((tSucc<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idEach = ((tEach<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idProc = ((tProc<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idLambda = ((tLambda<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idSend = ((tSend<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    id__send__ = ((t__send__<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    id__recursive_key__ = ((t__recursive_key__<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idInitialize = ((tInitialize<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idInitialize_copy = ((tInitialize_copy<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idInitialize_clone = ((tInitialize_clone<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idInitialize_dup = ((tInitialize_dup<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idTo_int = ((tTo_int<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idTo_ary = ((tTo_ary<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idTo_str = ((tTo_str<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idTo_sym = ((tTo_sym<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idTo_hash = ((tTo_hash<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idTo_proc = ((tTo_proc<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idTo_io = ((tTo_io<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idTo_a = ((tTo_a<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idTo_s = ((tTo_s<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idTo_i = ((tTo_i<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idTo_f = ((tTo_f<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idTo_r = ((tTo_r<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idBt = ((tBt<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idBt_locations = ((tBt_locations<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idCall = ((tCall<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idMesg = ((tMesg<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idException = ((tException<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idLocals = ((tLocals<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idNOT = ((tNOT<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idAND = ((tAND<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idOR = ((tOR<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idDiv = ((tDiv<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idDivmod = ((tDivmod<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idFdiv = ((tFdiv<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idQuo = ((tQuo<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idName = ((tName<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idNil = ((tNil<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idPath = ((tPath<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idPack = ((tPack<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idBuffer = ((tBuffer<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idUScore = ((tUScore<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idNUMPARAM_1 = ((tNUMPARAM_1<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idNUMPARAM_2 = ((tNUMPARAM_2<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idNUMPARAM_3 = ((tNUMPARAM_3<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idNUMPARAM_4 = ((tNUMPARAM_4<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idNUMPARAM_5 = ((tNUMPARAM_5<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idNUMPARAM_6 = ((tNUMPARAM_6<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idNUMPARAM_7 = ((tNUMPARAM_7<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idNUMPARAM_8 = ((tNUMPARAM_8<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idNUMPARAM_9 = ((tNUMPARAM_9<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idDefault = ((tDefault<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_LOCAL|RUBY_ID_STATIC_SYM),
    idLASTLINE = ((tLASTLINE<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_GLOBAL|RUBY_ID_STATIC_SYM),
    idBACKREF = ((tBACKREF<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_GLOBAL|RUBY_ID_STATIC_SYM),
    idERROR_INFO = ((tERROR_INFO<<RUBY_ID_SCOPE_SHIFT)|RUBY_ID_GLOBAL|RUBY_ID_STATIC_SYM),
    tLAST_OP_ID = tPRESERVED_ID_END-1,
    idLAST_OP_ID = tLAST_OP_ID >> RUBY_ID_SCOPE_SHIFT
};
enum ruby_basic_operators {
    BOP_PLUS,
    BOP_MINUS,
    BOP_MULT,
    BOP_DIV,
    BOP_MOD,
    BOP_EQ,
    BOP_EQQ,
    BOP_LT,
    BOP_LE,
    BOP_LTLT,
    BOP_AREF,
    BOP_ASET,
    BOP_LENGTH,
    BOP_SIZE,
    BOP_EMPTY_P,
    BOP_NIL_P,
    BOP_SUCC,
    BOP_GT,
    BOP_GE,
    BOP_NOT,
    BOP_NEQ,
    BOP_MATCH,
    BOP_FREEZE,
    BOP_UMINUS,
    BOP_MAX,
    BOP_MIN,
    BOP_HASH,
    BOP_CALL,
    BOP_AND,
    BOP_OR,
    BOP_CMP,
    BOP_DEFAULT,
    BOP_PACK,
    BOP_INCLUDE_P,
    BOP_LAST_
};
extern short ruby_vm_redefined_flag[BOP_LAST_];
static inline void
asan_poison_memory_region(const volatile void *ptr, size_t size)
{
    ((void)(ptr), (void)(size));
    ;
}
static inline void
asan_poison_object(VALUE obj)
{
    __attribute__ ((__unused__)) struct RVALUE * ptr = (void *)obj;
    asan_poison_memory_region(ptr, 8);
}
static inline void *
asan_poisoned_object_p(VALUE obj)
{
    __attribute__ ((__unused__)) struct RVALUE * ptr = (void *)obj;
    return 0;
}
static inline void
asan_unpoison_memory_region(const volatile void *ptr, size_t size, _Bool malloc_p)
{
    ;
    if (malloc_p) {
        ((void)(ptr), (void)(size));
    }
    else {
        ((void)(ptr), (void)(size));
    }
}
static inline void
asan_unpoison_object(VALUE obj, _Bool newobj_p)
{
    __attribute__ ((__unused__)) struct RVALUE * ptr = (void *)obj;
    asan_unpoison_memory_region(ptr, 8, newobj_p);
}
static inline void *
asan_unpoison_object_temporary(VALUE obj)
{
    void *ptr = asan_poisoned_object_p(obj);
    asan_unpoison_object(obj, 0);
    return ptr;
}
static inline void *
asan_poison_object_restore(VALUE obj, void *ptr)
{
    if (ptr) {
        asan_poison_object(obj);
    }
    return ((void *)0);
}
static inline void *
asan_unpoison_memory_region_temporary(void *ptr, size_t len)
{
    void *poisoned_ptr = 0;
    asan_unpoison_memory_region(ptr, len, 0);
    return poisoned_ptr;
}
static inline void *
asan_poison_memory_region_restore(void *ptr, size_t len, void *poisoned_ptr)
{
    if (poisoned_ptr) {
        asan_poison_memory_region(ptr, len);
    }
    return ((void *)0);
}
static inline void *
asan_get_real_stack_addr(void* slot)
{
    VALUE *addr;
    addr = ((void *)0);
    return addr ? addr : slot;
}
static inline void *
asan_get_thread_fake_stack_handle(void)
{
    return ((void *)0);
}
static inline _Bool
asan_get_fake_stack_extents(void *thread_fake_stack_handle, VALUE slot,
                            void *machine_stack_start, void *machine_stack_end,
                            void **fake_stack_start_out, void **fake_stack_end_out)
{
    *fake_stack_start_out = 0;
    *fake_stack_end_out = 0;
    return 0;
}
typedef unsigned long long rb_serial_t;
struct rb_callable_method_entry_struct;
struct rb_method_definition_struct;
struct rb_execution_context_struct;
struct rb_control_frame_struct;
struct rb_callinfo;
enum method_missing_reason {
    MISSING_NOENTRY = 0x00,
    MISSING_PRIVATE = 0x01,
    MISSING_PROTECTED = 0x02,
    MISSING_FCALL = 0x04,
    MISSING_VCALL = 0x08,
    MISSING_SUPER = 0x10,
    MISSING_MISSING = 0x20,
    MISSING_NONE = 0x40
};
VALUE rb_vm_push_frame_fname(struct rb_execution_context_struct *ec, VALUE fname);
VALUE rb_obj_is_thread(VALUE obj);
void rb_vm_mark(void *ptr);
void rb_vm_register_global_object(VALUE obj);
void rb_vm_each_stack_value(void *ptr, void (*cb)(VALUE, void*), void *ctx);
__attribute__((__pure__)) VALUE rb_vm_top_self(void);
const void **rb_vm_get_insns_address_table(void);
VALUE rb_source_location(int *pline);
const char *rb_source_location_cstr(int *pline);
void rb_vm_pop_cfunc_frame(void);
void rb_vm_check_redefinition_by_prepend(VALUE klass);
int rb_vm_check_optimizable_mid(VALUE mid);
VALUE rb_yield_refine_block(VALUE refinement, VALUE refinements);
VALUE ruby_vm_special_exception_copy(VALUE);
__attribute__((__pure__)) st_table *rb_vm_fstring_table(void);
void rb_lastline_set_up(VALUE val, unsigned int up);
VALUE rb_current_realfilepath(void);
VALUE rb_check_block_call(VALUE, ID, int, const VALUE *, rb_block_call_func_t, VALUE);
typedef void rb_check_funcall_hook(int, VALUE, ID, int, const VALUE *, VALUE);
VALUE rb_check_funcall_with_hook_kw(VALUE recv, ID mid, int argc, const VALUE *argv,
                                 rb_check_funcall_hook *hook, VALUE arg, int kw_splat);
const char *rb_type_str(enum ruby_value_type type);
VALUE rb_check_funcall_default(VALUE, ID, int, const VALUE *, VALUE);
VALUE rb_check_funcall_basic_kw(VALUE, ID, VALUE, int, const VALUE*, int);
VALUE rb_yield_1(VALUE val);
VALUE rb_yield_force_blockarg(VALUE values);
VALUE rb_lambda_call(VALUE obj, ID mid, int argc, const VALUE *argv,
                     rb_block_call_func_t bl_proc, int min_argc, int max_argc,
                     VALUE data2);
void rb_check_stack_overflow(void);
VALUE rb_block_call2(VALUE obj, ID mid, int argc, const VALUE *argv, rb_block_call_func_t bl_proc, VALUE data2, long flags);
struct vm_ifunc *rb_current_ifunc(void);
extern uint64_t rb_vm_insns_count;
extern _Bool rb_free_at_exit;
void rb_free_loaded_builtin_table(void);
VALUE rb_equal_opt(VALUE obj1, VALUE obj2);
VALUE rb_eql_opt(VALUE obj1, VALUE obj2);
struct rb_iseq_struct;
const struct rb_callcache *rb_vm_search_method_slowpath(const struct rb_callinfo *ci, VALUE klass);
int rb_ec_obj_respond_to(struct rb_execution_context_struct *ec, VALUE obj, ID id, int priv);
void rb_clear_constant_cache(void);
void rb_print_backtrace(FILE *);
VALUE rb_vm_thread_backtrace(int argc, const VALUE *argv, VALUE thval);
VALUE rb_vm_thread_backtrace_locations(int argc, const VALUE *argv, VALUE thval);
VALUE rb_vm_backtrace(int argc, const VALUE * argv, struct rb_execution_context_struct * ec);
VALUE rb_vm_backtrace_locations(int argc, const VALUE * argv, struct rb_execution_context_struct * ec);
VALUE rb_make_backtrace(void);
void rb_backtrace_print_as_bugreport(FILE*);
int rb_backtrace_p(VALUE obj);
VALUE rb_backtrace_to_str_ary(VALUE obj);
VALUE rb_backtrace_to_location_ary(VALUE obj);
VALUE rb_location_ary_to_backtrace(VALUE ary);
void rb_backtrace_each(VALUE (*iter)(VALUE recv, VALUE str), VALUE output);
int rb_frame_info_p(VALUE obj);
int rb_get_node_id_from_frame_info(VALUE obj);
const struct rb_iseq_struct *rb_get_iseq_from_frame_info(VALUE obj);
VALUE rb_ec_backtrace_object(const struct rb_execution_context_struct *ec);
void rb_backtrace_use_iseq_first_lineno_for_last_location(VALUE self);
enum imemo_type {
    imemo_env = 0,
    imemo_cref = 1,
    imemo_svar = 2,
    imemo_throw_data = 3,
    imemo_ifunc = 4,
    imemo_memo = 5,
    imemo_ment = 6,
    imemo_iseq = 7,
    imemo_tmpbuf = 8,
    imemo_ast = 9,
    imemo_parser_strterm = 10,
    imemo_callinfo = 11,
    imemo_callcache = 12,
    imemo_constcache = 13,
};
struct vm_svar {
    VALUE flags;
    const VALUE cref_or_me;
    const VALUE lastline;
    const VALUE backref;
    const VALUE others;
};
struct vm_throw_data {
    VALUE flags;
    VALUE reserved;
    const VALUE throw_obj;
    const struct rb_control_frame_struct *catch_frame;
    int throw_state;
};
struct vm_ifunc_argc {
    int min, max;
};
struct vm_ifunc {
    VALUE flags;
    VALUE *svar_lep;
    rb_block_call_func_t func;
    const void *data;
    struct vm_ifunc_argc argc;
};
struct rb_imemo_tmpbuf_struct {
    VALUE flags;
    VALUE reserved;
    VALUE *ptr;
    struct rb_imemo_tmpbuf_struct *next;
    size_t cnt;
};
struct MEMO {
    VALUE flags;
    VALUE reserved;
    const VALUE v1;
    const VALUE v2;
    union {
        long cnt;
        long state;
        const VALUE value;
        void (*func)(void);
    } u3;
};
typedef struct rb_imemo_tmpbuf_struct rb_imemo_tmpbuf_t;
rb_imemo_tmpbuf_t *rb_imemo_tmpbuf_parser_heap(void *buf, rb_imemo_tmpbuf_t *old_heap, size_t cnt);
struct vm_ifunc *rb_vm_ifunc_new(rb_block_call_func_t func, const void *data, int min_argc, int max_argc);
static inline enum imemo_type imemo_type(VALUE imemo);
static inline int imemo_type_p(VALUE imemo, enum imemo_type imemo_type);
static inline _Bool imemo_throw_data_p(VALUE imemo);
static inline struct vm_ifunc *rb_vm_ifunc_proc_new(rb_block_call_func_t func, const void *data);
static inline VALUE rb_imemo_tmpbuf_auto_free_pointer(void);
static inline void *RB_IMEMO_TMPBUF_PTR(VALUE v);
static inline void *rb_imemo_tmpbuf_set_ptr(VALUE v, void *ptr);
static inline VALUE rb_imemo_tmpbuf_auto_free_pointer_new_from_an_RString(VALUE str);
static inline void MEMO_V1_SET(struct MEMO *m, VALUE v);
static inline void MEMO_V2_SET(struct MEMO *m, VALUE v);
size_t rb_imemo_memsize(VALUE obj);
void rb_cc_table_mark(VALUE klass);
void rb_imemo_mark_and_move(VALUE obj, _Bool reference_updating);
void rb_cc_table_free(VALUE klass);
void rb_imemo_free(VALUE obj);

#pragma GCC visibility push(default)

VALUE rb_imemo_new(enum imemo_type type, VALUE v0);
const char *rb_imemo_name(enum imemo_type type);

#pragma GCC visibility pop

static inline struct MEMO *
MEMO_NEW(VALUE a, VALUE b, VALUE c)
{
    struct MEMO *memo = ((struct MEMO *)rb_imemo_new((imemo_memo), (0)));
    *((VALUE *)&memo->v1) = a;
    *((VALUE *)&memo->v2) = b;
    *((VALUE *)&memo->u3.value) = c;
    return memo;
}
static inline enum imemo_type
imemo_type(VALUE imemo)
{
    return (((struct RBasic *)(imemo))->flags >> ((VALUE)RUBY_FL_USHIFT)) & 0x0f;
}
static inline int
imemo_type_p(VALUE imemo, enum imemo_type imemo_type)
{
    if ((__builtin_expect(!!(!RB_SPECIAL_CONST_P(imemo)), 1))) {
        const VALUE mask = (0x0f << ((VALUE)RUBY_FL_USHIFT)) | RUBY_T_MASK;
        const VALUE expected_type = (imemo_type << ((VALUE)RUBY_FL_USHIFT)) | RUBY_T_IMEMO;
        return expected_type == (((struct RBasic *)(imemo))->flags & mask);
    }
    else {
        return 0;
    }
}
static inline _Bool
imemo_throw_data_p(VALUE imemo)
{
    return RB_TYPE_P(imemo, RUBY_T_IMEMO);
}
static inline struct vm_ifunc *
rb_vm_ifunc_proc_new(rb_block_call_func_t func, const void *data)
{
    return rb_vm_ifunc_new(func, data, 0, (-1));
}
static inline VALUE
rb_imemo_tmpbuf_auto_free_pointer(void)
{
    return rb_imemo_new(imemo_tmpbuf, 0);
}
static inline void *
RB_IMEMO_TMPBUF_PTR(VALUE v)
{
    const struct rb_imemo_tmpbuf_struct *p = (const void *)v;
    return p->ptr;
}
static inline void *
rb_imemo_tmpbuf_set_ptr(VALUE v, void *ptr)
{
    return ((rb_imemo_tmpbuf_t *)v)->ptr = ptr;
}
static inline VALUE
rb_imemo_tmpbuf_auto_free_pointer_new_from_an_RString(VALUE str)
{
    const void *src;
    VALUE imemo;
    rb_imemo_tmpbuf_t *tmpbuf;
    void *dst;
    size_t len;
    rb_string_value(&(str));
    imemo = rb_imemo_tmpbuf_auto_free_pointer();
    tmpbuf = (rb_imemo_tmpbuf_t *)imemo;
    len = RSTRING_LEN(str);
    src = RSTRING_PTR(str);
    dst = ruby_xmalloc(len);
    ruby_nonempty_memcpy(dst, src, len);
    tmpbuf->ptr = dst;
    return imemo;
}
static inline void
MEMO_V1_SET(struct MEMO *m, VALUE v)
{
    (rb_obj_write((VALUE)(m), (VALUE *)(&m->v1), (VALUE)(v), "./internal/imemo.h", 257));
}
static inline void
MEMO_V2_SET(struct MEMO *m, VALUE v)
{
    (rb_obj_write((VALUE)(m), (VALUE *)(&m->v2), (VALUE)(v), "./internal/imemo.h", 263));
}
typedef enum {
    METHOD_VISI_UNDEF = 0x00,
    METHOD_VISI_PUBLIC = 0x01,
    METHOD_VISI_PRIVATE = 0x02,
    METHOD_VISI_PROTECTED = 0x03,
    METHOD_VISI_MASK = 0x03
} rb_method_visibility_t;
typedef struct rb_scope_visi_struct {
    rb_method_visibility_t method_visi : 3;
    unsigned int module_func : 1;
} rb_scope_visibility_t;
typedef struct rb_cref_struct {
    VALUE flags;
    VALUE refinements;
    VALUE klass_or_self;
    struct rb_cref_struct * next;
    const rb_scope_visibility_t scope_visi;
} rb_cref_t;
typedef struct rb_method_entry_struct {
    VALUE flags;
    VALUE defined_class;
    struct rb_method_definition_struct * const def;
    ID called_id;
    VALUE owner;
} rb_method_entry_t;
typedef struct rb_callable_method_entry_struct {
    VALUE flags;
    const VALUE defined_class;
    struct rb_method_definition_struct * const def;
    ID called_id;
    const VALUE owner;
} rb_callable_method_entry_t;
static inline void
METHOD_ENTRY_VISI_SET(rb_method_entry_t *me, rb_method_visibility_t visi)
{
    ((void)0);
    me->flags = (me->flags & ~(((VALUE)RUBY_FL_USER4) | ((VALUE)RUBY_FL_USER5))) | (visi << ((((VALUE)RUBY_FL_USHIFT) + 4)+0));
}
static inline void
METHOD_ENTRY_BASIC_SET(rb_method_entry_t *me, unsigned int basic)
{
    ((void)0);
    me->flags = (me->flags & ~(((VALUE)RUBY_FL_USER6) )) | (basic << ((((VALUE)RUBY_FL_USHIFT) + 4)+2));
}
static inline void
METHOD_ENTRY_FLAGS_SET(rb_method_entry_t *me, rb_method_visibility_t visi, unsigned int basic)
{
    ((void)0);
    ((void)0);
    me->flags =
      (me->flags & ~(((VALUE)RUBY_FL_USER4)|((VALUE)RUBY_FL_USER5)|((VALUE)RUBY_FL_USER6))) |
        ((visi << ((((VALUE)RUBY_FL_USHIFT) + 4)+0)) | (basic << ((((VALUE)RUBY_FL_USHIFT) + 4)+2)));
}
static inline void
METHOD_ENTRY_FLAGS_COPY(rb_method_entry_t *dst, const rb_method_entry_t *src)
{
    dst->flags =
      (dst->flags & ~(((VALUE)RUBY_FL_USER4)|((VALUE)RUBY_FL_USER5)|((VALUE)RUBY_FL_USER6)
      |((VALUE)RUBY_FL_USER7))) |
        (src->flags & (((VALUE)RUBY_FL_USER4)|((VALUE)RUBY_FL_USER5)|((VALUE)RUBY_FL_USER6)|((VALUE)RUBY_FL_USER7)));
}
typedef enum {
    VM_METHOD_TYPE_ISEQ,
    VM_METHOD_TYPE_CFUNC,
    VM_METHOD_TYPE_ATTRSET,
    VM_METHOD_TYPE_IVAR,
    VM_METHOD_TYPE_BMETHOD,
    VM_METHOD_TYPE_ZSUPER,
    VM_METHOD_TYPE_ALIAS,
    VM_METHOD_TYPE_UNDEF,
    VM_METHOD_TYPE_NOTIMPLEMENTED,
    VM_METHOD_TYPE_OPTIMIZED,
    VM_METHOD_TYPE_MISSING,
    VM_METHOD_TYPE_REFINED,
   
} rb_method_type_t;
__extension__ _Static_assert(VM_METHOD_TYPE_REFINED <= (1<<4), "VM_METHOD_TYPE_MINIMUM_BITS" ": " "VM_METHOD_TYPE_REFINED <= (1<<VM_METHOD_TYPE_MINIMUM_BITS)");
typedef struct rb_iseq_struct rb_iseq_t;
typedef struct rb_method_iseq_struct {
    const rb_iseq_t * iseqptr;
    rb_cref_t * cref;
} rb_method_iseq_t;
typedef VALUE (*rb_cfunc_t)();
typedef struct rb_method_cfunc_struct {
    rb_cfunc_t func;
    VALUE (*invoker)(VALUE recv, int argc, const VALUE *argv, VALUE (*func)());
    int argc;
} rb_method_cfunc_t;
typedef struct rb_method_attr_struct {
    ID id;
    VALUE location;
} rb_method_attr_t;
typedef struct rb_method_alias_struct {
    struct rb_method_entry_struct * original_me;
} rb_method_alias_t;
typedef struct rb_method_refined_struct {
    struct rb_method_entry_struct * orig_me;
} rb_method_refined_t;
typedef struct rb_method_bmethod_struct {
    VALUE proc;
    struct rb_hook_list_struct *hooks;
    VALUE defined_ractor;
} rb_method_bmethod_t;
enum method_optimized_type {
    OPTIMIZED_METHOD_TYPE_SEND,
    OPTIMIZED_METHOD_TYPE_CALL,
    OPTIMIZED_METHOD_TYPE_BLOCK_CALL,
    OPTIMIZED_METHOD_TYPE_STRUCT_AREF,
    OPTIMIZED_METHOD_TYPE_STRUCT_ASET,
    OPTIMIZED_METHOD_TYPE__MAX
};
typedef struct rb_method_optimized {
    enum method_optimized_type type;
    unsigned int index;
} rb_method_optimized_t;
struct rb_method_definition_struct {
    rb_method_type_t type : 4;
    unsigned int iseq_overload: 1;
    unsigned int no_redef_warning: 1;
    unsigned int aliased : 1;
    int reference_count : 28;
    union {
        rb_method_iseq_t iseq;
        rb_method_cfunc_t cfunc;
        rb_method_attr_t attr;
        rb_method_alias_t alias;
        rb_method_refined_t refined;
        rb_method_bmethod_t bmethod;
        rb_method_optimized_t optimized;
    } body;
    ID original_id;
    uintptr_t method_serial;
};
struct rb_id_table;
typedef struct rb_method_definition_struct rb_method_definition_t;
__extension__ _Static_assert(__builtin_offsetof (rb_method_definition_t, body) <= 8, "sizeof_method_def" ": " "offsetof(rb_method_definition_t, body) <= 8");
void rb_add_method(VALUE klass, ID mid, rb_method_type_t type, void *option, rb_method_visibility_t visi);
void rb_add_method_cfunc(VALUE klass, ID mid, VALUE (*func)(), int argc, rb_method_visibility_t visi);
void rb_add_method_iseq(VALUE klass, ID mid, const rb_iseq_t *iseq, rb_cref_t *cref, rb_method_visibility_t visi);
void rb_add_method_optimized(VALUE klass, ID mid, enum method_optimized_type, unsigned int index, rb_method_visibility_t visi);
void rb_add_refined_method_entry(VALUE refined_class, ID mid);
rb_method_entry_t *rb_method_entry_set(VALUE klass, ID mid, const rb_method_entry_t *, rb_method_visibility_t noex);
rb_method_entry_t *rb_method_entry_create(ID called_id, VALUE klass, rb_method_visibility_t visi, rb_method_definition_t *def);
const rb_method_entry_t *rb_method_entry_at(VALUE obj, ID id);
const rb_method_entry_t *rb_method_entry(VALUE klass, ID id);
const rb_method_entry_t *rb_method_entry_with_refinements(VALUE klass, ID id, VALUE *defined_class);
const rb_method_entry_t *rb_method_entry_without_refinements(VALUE klass, ID id, VALUE *defined_class);
const rb_method_entry_t *rb_resolve_refined_method(VALUE refinements, const rb_method_entry_t *me);

#pragma GCC visibility push(default)

const rb_method_entry_t *rb_resolve_me_location(const rb_method_entry_t *, VALUE[5]);

#pragma GCC visibility pop

const rb_callable_method_entry_t *rb_callable_method_entry(VALUE klass, ID id);
const rb_callable_method_entry_t *rb_callable_method_entry_or_negative(VALUE klass, ID id);
const rb_callable_method_entry_t *rb_callable_method_entry_with_refinements(VALUE klass, ID id, VALUE *defined_class);
const rb_callable_method_entry_t *rb_callable_method_entry_without_refinements(VALUE klass, ID id, VALUE *defined_class);
int rb_method_entry_arity(const rb_method_entry_t *me);
int rb_method_entry_eq(const rb_method_entry_t *m1, const rb_method_entry_t *m2);
st_index_t rb_hash_method_entry(st_index_t hash, const rb_method_entry_t *me);
VALUE rb_method_entry_location(const rb_method_entry_t *me);
void rb_free_method_entry_vm_weak_references(const rb_method_entry_t *me);
void rb_free_method_entry(const rb_method_entry_t *me);
const rb_method_entry_t *rb_method_entry_clone(const rb_method_entry_t *me);
const rb_callable_method_entry_t *rb_method_entry_complement_defined_class(const rb_method_entry_t *src_me, ID called_id, VALUE defined_class);
void rb_method_entry_copy(rb_method_entry_t *dst, const rb_method_entry_t *src);
void rb_method_table_insert(VALUE klass, struct rb_id_table *table, ID method_id, const rb_method_entry_t *me);
void rb_scope_visibility_set(rb_method_visibility_t);
VALUE rb_unnamed_parameters(int arity);
void rb_clear_method_cache(VALUE klass_or_module, ID mid);
void rb_clear_all_refinement_method_cache(void);
enum rb_parser_string_coderange_type {
    RB_PARSER_ENC_CODERANGE_UNKNOWN = 0,
    RB_PARSER_ENC_CODERANGE_7BIT = 1,
    RB_PARSER_ENC_CODERANGE_VALID = 2,
    RB_PARSER_ENC_CODERANGE_BROKEN = 3
};
typedef struct rb_parser_string {
    enum rb_parser_string_coderange_type coderange;
    rb_encoding *enc;
    long len;
    char *ptr;
} rb_parser_string_t;
enum rb_parser_shareability {
    rb_parser_shareable_none,
    rb_parser_shareable_literal,
    rb_parser_shareable_copy,
    rb_parser_shareable_everything,
};
typedef void* rb_parser_input_data;
enum node_type {
    NODE_SCOPE,
    NODE_BLOCK,
    NODE_IF,
    NODE_UNLESS,
    NODE_CASE,
    NODE_CASE2,
    NODE_CASE3,
    NODE_WHEN,
    NODE_IN,
    NODE_WHILE,
    NODE_UNTIL,
    NODE_ITER,
    NODE_FOR,
    NODE_FOR_MASGN,
    NODE_BREAK,
    NODE_NEXT,
    NODE_REDO,
    NODE_RETRY,
    NODE_BEGIN,
    NODE_RESCUE,
    NODE_RESBODY,
    NODE_ENSURE,
    NODE_AND,
    NODE_OR,
    NODE_MASGN,
    NODE_LASGN,
    NODE_DASGN,
    NODE_GASGN,
    NODE_IASGN,
    NODE_CDECL,
    NODE_CVASGN,
    NODE_OP_ASGN1,
    NODE_OP_ASGN2,
    NODE_OP_ASGN_AND,
    NODE_OP_ASGN_OR,
    NODE_OP_CDECL,
    NODE_CALL,
    NODE_OPCALL,
    NODE_FCALL,
    NODE_VCALL,
    NODE_QCALL,
    NODE_SUPER,
    NODE_ZSUPER,
    NODE_LIST,
    NODE_ZLIST,
    NODE_HASH,
    NODE_RETURN,
    NODE_YIELD,
    NODE_LVAR,
    NODE_DVAR,
    NODE_GVAR,
    NODE_IVAR,
    NODE_CONST,
    NODE_CVAR,
    NODE_NTH_REF,
    NODE_BACK_REF,
    NODE_MATCH,
    NODE_MATCH2,
    NODE_MATCH3,
    NODE_INTEGER,
    NODE_FLOAT,
    NODE_RATIONAL,
    NODE_IMAGINARY,
    NODE_STR,
    NODE_DSTR,
    NODE_XSTR,
    NODE_DXSTR,
    NODE_EVSTR,
    NODE_REGX,
    NODE_DREGX,
    NODE_ONCE,
    NODE_ARGS,
    NODE_ARGS_AUX,
    NODE_OPT_ARG,
    NODE_KW_ARG,
    NODE_POSTARG,
    NODE_ARGSCAT,
    NODE_ARGSPUSH,
    NODE_SPLAT,
    NODE_BLOCK_PASS,
    NODE_DEFN,
    NODE_DEFS,
    NODE_ALIAS,
    NODE_VALIAS,
    NODE_UNDEF,
    NODE_CLASS,
    NODE_MODULE,
    NODE_SCLASS,
    NODE_COLON2,
    NODE_COLON3,
    NODE_DOT2,
    NODE_DOT3,
    NODE_FLIP2,
    NODE_FLIP3,
    NODE_SELF,
    NODE_NIL,
    NODE_TRUE,
    NODE_FALSE,
    NODE_ERRINFO,
    NODE_DEFINED,
    NODE_POSTEXE,
    NODE_SYM,
    NODE_DSYM,
    NODE_ATTRASGN,
    NODE_LAMBDA,
    NODE_ARYPTN,
    NODE_HSHPTN,
    NODE_FNDPTN,
    NODE_ERROR,
    NODE_LINE,
    NODE_FILE,
    NODE_ENCODING,
    NODE_LAST
};
typedef struct rb_ast_id_table {
    int size;
    ID ids[];
} rb_ast_id_table_t;
typedef struct rb_code_position_struct {
    int lineno;
    int column;
} rb_code_position_t;
typedef struct rb_code_location_struct {
    rb_code_position_t beg_pos;
    rb_code_position_t end_pos;
} rb_code_location_t;
typedef struct rb_parser_ast_token {
    int id;
    const char *type_name;
    rb_parser_string_t *str;
    rb_code_location_t loc;
} rb_parser_ast_token_t;
typedef void* rb_parser_ary_data;
enum rb_parser_ary_data_type {
    PARSER_ARY_DATA_AST_TOKEN = 1,
    PARSER_ARY_DATA_SCRIPT_LINE,
    PARSER_ARY_DATA_NODE
};
typedef struct rb_parser_ary {
    enum rb_parser_ary_data_type data_type;
    rb_parser_ary_data *data;
    long len;
    long capa;
} rb_parser_ary_t;
typedef struct RNode {
    VALUE flags;
    rb_code_location_t nd_loc;
    int node_id;
} NODE;
typedef struct RNode_SCOPE {
    NODE node;
    rb_ast_id_table_t *nd_tbl;
    struct RNode *nd_body;
    struct RNode_ARGS *nd_args;
} rb_node_scope_t;
typedef struct RNode_BLOCK {
    NODE node;
    struct RNode *nd_head;
    struct RNode *nd_end;
    struct RNode *nd_next;
} rb_node_block_t;
typedef struct RNode_IF {
    NODE node;
    struct RNode *nd_cond;
    struct RNode *nd_body;
    struct RNode *nd_else;
} rb_node_if_t;
typedef struct RNode_UNLESS {
    NODE node;
    struct RNode *nd_cond;
    struct RNode *nd_body;
    struct RNode *nd_else;
    rb_code_location_t keyword_loc;
    rb_code_location_t then_keyword_loc;
    rb_code_location_t end_keyword_loc;
} rb_node_unless_t;
typedef struct RNode_CASE {
    NODE node;
    struct RNode *nd_head;
    struct RNode *nd_body;
    rb_code_location_t case_keyword_loc;
    rb_code_location_t end_keyword_loc;
} rb_node_case_t;
typedef struct RNode_CASE2 {
    NODE node;
    struct RNode *nd_head;
    struct RNode *nd_body;
    rb_code_location_t case_keyword_loc;
    rb_code_location_t end_keyword_loc;
} rb_node_case2_t;
typedef struct RNode_CASE3 {
    NODE node;
    struct RNode *nd_head;
    struct RNode *nd_body;
    rb_code_location_t case_keyword_loc;
    rb_code_location_t end_keyword_loc;
} rb_node_case3_t;
typedef struct RNode_WHEN {
    NODE node;
    struct RNode *nd_head;
    struct RNode *nd_body;
    struct RNode *nd_next;
    rb_code_location_t keyword_loc;
    rb_code_location_t then_keyword_loc;
} rb_node_when_t;
typedef struct RNode_IN {
    NODE node;
    struct RNode *nd_head;
    struct RNode *nd_body;
    struct RNode *nd_next;
} rb_node_in_t;
typedef struct RNode_LOOP {
    NODE node;
    struct RNode *nd_cond;
    struct RNode *nd_body;
    long nd_state;
    rb_code_location_t keyword_loc;
    rb_code_location_t closing_loc;
} rb_node_while_t, rb_node_until_t;
typedef struct RNode_ITER {
    NODE node;
    struct RNode *nd_body;
    struct RNode *nd_iter;
} rb_node_iter_t, rb_node_for_t;
typedef struct RNode_FOR_MASGN {
    NODE node;
    struct RNode *nd_var;
} rb_node_for_masgn_t;
typedef struct RNode_EXITS {
    NODE node;
    struct RNode *nd_chain;
    struct RNode *nd_stts;
    rb_code_location_t keyword_loc;
} rb_node_exits_t, rb_node_break_t, rb_node_next_t, rb_node_redo_t;
typedef struct RNode_RETRY {
    NODE node;
} rb_node_retry_t;
typedef struct RNode_BEGIN {
    NODE node;
    struct RNode *nd_body;
} rb_node_begin_t;
typedef struct RNode_RESCUE {
    NODE node;
    struct RNode *nd_head;
    struct RNode *nd_resq;
    struct RNode *nd_else;
} rb_node_rescue_t;
typedef struct RNode_RESBODY {
    NODE node;
    struct RNode *nd_args;
    struct RNode *nd_exc_var;
    struct RNode *nd_body;
    struct RNode *nd_next;
} rb_node_resbody_t;
typedef struct RNode_ENSURE {
    NODE node;
    struct RNode *nd_head;
    struct RNode *nd_ensr;
} rb_node_ensure_t;
typedef struct {
    NODE node;
    struct RNode *nd_1st;
    struct RNode *nd_2nd;
    rb_code_location_t operator_loc;
} rb_node_and_t, rb_node_or_t;
typedef struct RNode_MASGN {
    NODE node;
    struct RNode *nd_head;
    struct RNode *nd_value;
    struct RNode *nd_args;
} rb_node_masgn_t;
typedef struct RNode_LASGN {
    NODE node;
    ID nd_vid;
    struct RNode *nd_value;
} rb_node_lasgn_t;
typedef struct RNode_DASGN {
    NODE node;
    ID nd_vid;
    struct RNode *nd_value;
} rb_node_dasgn_t;
typedef struct RNode_GASGN {
    NODE node;
    ID nd_vid;
    struct RNode *nd_value;
} rb_node_gasgn_t;
typedef struct RNode_IASGN {
    NODE node;
    ID nd_vid;
    struct RNode *nd_value;
} rb_node_iasgn_t;
typedef struct RNode_CDECL {
    NODE node;
    ID nd_vid;
    struct RNode *nd_value;
    struct RNode *nd_else;
    enum rb_parser_shareability shareability;
} rb_node_cdecl_t;
typedef struct RNode_CVASGN {
    NODE node;
    ID nd_vid;
    struct RNode *nd_value;
} rb_node_cvasgn_t;
typedef struct RNode_OP_ASGN1 {
    NODE node;
    struct RNode *nd_recv;
    ID nd_mid;
    struct RNode *nd_index;
    struct RNode *nd_rvalue;
    rb_code_location_t call_operator_loc;
    rb_code_location_t opening_loc;
    rb_code_location_t closing_loc;
    rb_code_location_t binary_operator_loc;
} rb_node_op_asgn1_t;
typedef struct RNode_OP_ASGN2 {
    NODE node;
    struct RNode *nd_recv;
    struct RNode *nd_value;
    ID nd_vid;
    ID nd_mid;
    _Bool nd_aid;
    rb_code_location_t call_operator_loc;
    rb_code_location_t message_loc;
    rb_code_location_t binary_operator_loc;
} rb_node_op_asgn2_t;
typedef struct RNode_OP_ASGN_AND {
    NODE node;
    struct RNode *nd_head;
    struct RNode *nd_value;
} rb_node_op_asgn_and_t;
typedef struct RNode_OP_ASGN_OR {
    NODE node;
    struct RNode *nd_head;
    struct RNode *nd_value;
} rb_node_op_asgn_or_t;
typedef struct RNode_OP_CDECL {
    NODE node;
    struct RNode *nd_head;
    struct RNode *nd_value;
    ID nd_aid;
    enum rb_parser_shareability shareability;
} rb_node_op_cdecl_t;
typedef struct RNode_CALL {
    NODE node;
    struct RNode *nd_recv;
    ID nd_mid;
    struct RNode *nd_args;
} rb_node_call_t;
typedef struct RNode_OPCALL {
    NODE node;
    struct RNode *nd_recv;
    ID nd_mid;
    struct RNode *nd_args;
} rb_node_opcall_t;
typedef struct RNode_FCALL {
    NODE node;
    ID nd_mid;
    struct RNode *nd_args;
} rb_node_fcall_t;
typedef struct RNode_VCALL {
    NODE node;
    ID nd_mid;
} rb_node_vcall_t;
typedef struct RNode_QCALL {
    NODE node;
    struct RNode *nd_recv;
    ID nd_mid;
    struct RNode *nd_args;
} rb_node_qcall_t;
typedef struct RNode_SUPER {
    NODE node;
    struct RNode *nd_args;
} rb_node_super_t;
typedef struct RNode_ZSUPER {
    NODE node;
} rb_node_zsuper_t;
typedef struct RNode_LIST {
    NODE node;
    struct RNode *nd_head;
    union {
        long nd_alen;
        struct RNode *nd_end;
    } as;
    struct RNode *nd_next;
} rb_node_list_t;
typedef struct RNode_ZLIST {
    NODE node;
} rb_node_zlist_t;
typedef struct RNode_HASH {
    NODE node;
    struct RNode *nd_head;
    long nd_brace;
} rb_node_hash_t;
typedef struct RNode_RETURN {
    NODE node;
    struct RNode *nd_stts;
    rb_code_location_t keyword_loc;
} rb_node_return_t;
typedef struct RNode_YIELD {
    NODE node;
    struct RNode *nd_head;
} rb_node_yield_t;
typedef struct RNode_LVAR {
    NODE node;
    ID nd_vid;
} rb_node_lvar_t;
typedef struct RNode_DVAR {
    NODE node;
    ID nd_vid;
} rb_node_dvar_t;
typedef struct RNode_GVAR {
    NODE node;
    ID nd_vid;
} rb_node_gvar_t;
typedef struct RNode_IVAR {
    NODE node;
    ID nd_vid;
} rb_node_ivar_t;
typedef struct RNode_CONST {
    NODE node;
    ID nd_vid;
} rb_node_const_t;
typedef struct RNode_CVAR {
    NODE node;
    ID nd_vid;
} rb_node_cvar_t;
typedef struct RNode_NTH_REF {
    NODE node;
    long nd_nth;
} rb_node_nth_ref_t;
typedef struct RNode_BACK_REF {
    NODE node;
    long nd_nth;
} rb_node_back_ref_t;
typedef struct RNode_MATCH2 {
    NODE node;
    struct RNode *nd_recv;
    struct RNode *nd_value;
    struct RNode *nd_args;
} rb_node_match2_t;
typedef struct RNode_MATCH3 {
    NODE node;
    struct RNode *nd_recv;
    struct RNode *nd_value;
} rb_node_match3_t;
typedef struct RNode_INTEGER {
    NODE node;
    char *val;
    int minus;
    int base;
} rb_node_integer_t;
typedef struct RNode_FLOAT {
    NODE node;
    char *val;
    int minus;
} rb_node_float_t;
typedef struct RNode_RATIONAL {
    NODE node;
    char *val;
    int minus;
    int base;
    int seen_point;
} rb_node_rational_t;
enum rb_numeric_type {
    integer_literal,
    float_literal,
    rational_literal
};
typedef struct RNode_IMAGINARY {
    NODE node;
    char *val;
    int minus;
    int base;
    int seen_point;
    enum rb_numeric_type type;
} rb_node_imaginary_t;
typedef struct RNode_STR {
    NODE node;
    struct rb_parser_string *string;
} rb_node_str_t;
typedef struct RNode_DSTR {
    NODE node;
    struct rb_parser_string *string;
    union {
        long nd_alen;
        long nd_cflag;
        struct RNode *nd_end;
    } as;
    struct RNode_LIST *nd_next;
} rb_node_dstr_t;
typedef rb_node_str_t rb_node_xstr_t;
typedef rb_node_dstr_t rb_node_dxstr_t;
typedef struct RNode_EVSTR {
    NODE node;
    struct RNode *nd_body;
} rb_node_evstr_t;
typedef struct RNode_REGX {
    NODE node;
    struct rb_parser_string *string;
    int options;
} rb_node_regx_t, rb_node_match_t;
typedef rb_node_dstr_t rb_node_dregx_t;
typedef struct RNode_ONCE {
    NODE node;
    struct RNode *nd_body;
} rb_node_once_t;
struct rb_args_info {
    NODE *pre_init;
    NODE *post_init;
    int pre_args_num;
    int post_args_num;
    ID first_post_arg;
    ID rest_arg;
    ID block_arg;
    struct RNode_KW_ARG *kw_args;
    NODE *kw_rest_arg;
    struct RNode_OPT_ARG *opt_args;
    unsigned int no_kwarg: 1;
    unsigned int ruby2_keywords: 1;
    unsigned int forwarding: 1;
};
typedef struct RNode_ARGS {
    NODE node;
    struct rb_args_info nd_ainfo;
} rb_node_args_t;
typedef struct RNode_ARGS_AUX {
    NODE node;
    ID nd_pid;
    int nd_plen;
    struct RNode *nd_next;
} rb_node_args_aux_t;
typedef struct RNode_OPT_ARG {
    NODE node;
    struct RNode *nd_body;
    struct RNode_OPT_ARG *nd_next;
} rb_node_opt_arg_t;
typedef struct RNode_KW_ARG {
    NODE node;
    struct RNode *nd_body;
    struct RNode_KW_ARG *nd_next;
} rb_node_kw_arg_t;
typedef struct RNode_POSTARG {
    NODE node;
    struct RNode *nd_1st;
    struct RNode *nd_2nd;
} rb_node_postarg_t;
typedef struct RNode_ARGSCAT {
    NODE node;
    struct RNode *nd_head;
    struct RNode *nd_body;
} rb_node_argscat_t;
typedef struct RNode_ARGSPUSH {
    NODE node;
    struct RNode *nd_head;
    struct RNode *nd_body;
} rb_node_argspush_t;
typedef struct RNode_SPLAT {
    NODE node;
    struct RNode *nd_head;
    rb_code_location_t operator_loc;
} rb_node_splat_t;
typedef struct RNode_BLOCK_PASS {
    NODE node;
    struct RNode *nd_head;
    struct RNode *nd_body;
    unsigned int forwarding: 1;
    rb_code_location_t operator_loc;
} rb_node_block_pass_t;
typedef struct RNode_DEFN {
    NODE node;
    ID nd_mid;
    struct RNode *nd_defn;
} rb_node_defn_t;
typedef struct RNode_DEFS {
    NODE node;
    struct RNode *nd_recv;
    ID nd_mid;
    struct RNode *nd_defn;
} rb_node_defs_t;
typedef struct RNode_ALIAS {
    NODE node;
    struct RNode *nd_1st;
    struct RNode *nd_2nd;
    rb_code_location_t keyword_loc;
} rb_node_alias_t;
typedef struct RNode_VALIAS {
    NODE node;
    ID nd_alias;
    ID nd_orig;
    rb_code_location_t keyword_loc;
} rb_node_valias_t;
typedef struct RNode_UNDEF {
    NODE node;
    rb_parser_ary_t *nd_undefs;
    rb_code_location_t keyword_loc;
} rb_node_undef_t;
typedef struct RNode_CLASS {
    NODE node;
    struct RNode *nd_cpath;
    struct RNode *nd_body;
    struct RNode *nd_super;
} rb_node_class_t;
typedef struct RNode_MODULE {
    NODE node;
    struct RNode *nd_cpath;
    struct RNode *nd_body;
} rb_node_module_t;
typedef struct RNode_SCLASS {
    NODE node;
    struct RNode *nd_recv;
    struct RNode *nd_body;
} rb_node_sclass_t;
typedef struct RNode_COLON2 {
    NODE node;
    struct RNode *nd_head;
    ID nd_mid;
} rb_node_colon2_t;
typedef struct RNode_COLON3 {
    NODE node;
    ID nd_mid;
} rb_node_colon3_t;
typedef struct RNode_DOTS {
    NODE node;
    struct RNode *nd_beg;
    struct RNode *nd_end;
} rb_node_dot2_t, rb_node_dot3_t, rb_node_flip2_t, rb_node_flip3_t;
typedef struct RNode_SELF {
    NODE node;
    long nd_state;
} rb_node_self_t;
typedef struct RNode_NIL {
    NODE node;
} rb_node_nil_t;
typedef struct RNode_TRUE {
    NODE node;
} rb_node_true_t;
typedef struct RNode_FALSE {
    NODE node;
} rb_node_false_t;
typedef struct RNode_ERRINFO {
    NODE node;
} rb_node_errinfo_t;
typedef struct RNode_DEFINED {
    NODE node;
    struct RNode *nd_head;
} rb_node_defined_t;
typedef struct RNode_POSTEXE {
    NODE node;
    struct RNode *nd_body;
} rb_node_postexe_t;
typedef struct RNode_SYM {
    NODE node;
    struct rb_parser_string *string;
} rb_node_sym_t;
typedef rb_node_dstr_t rb_node_dsym_t;
typedef struct RNode_ATTRASGN {
    NODE node;
    struct RNode *nd_recv;
    ID nd_mid;
    struct RNode *nd_args;
} rb_node_attrasgn_t;
typedef struct RNode_LAMBDA {
    NODE node;
    struct RNode *nd_body;
} rb_node_lambda_t;
typedef struct RNode_ARYPTN {
    NODE node;
    struct RNode *nd_pconst;
    NODE *pre_args;
    NODE *rest_arg;
    NODE *post_args;
} rb_node_aryptn_t;
typedef struct RNode_HSHPTN {
    NODE node;
    struct RNode *nd_pconst;
    struct RNode *nd_pkwargs;
    struct RNode *nd_pkwrestarg;
} rb_node_hshptn_t;
typedef struct RNode_FNDPTN {
    NODE node;
    struct RNode *nd_pconst;
    NODE *pre_rest_arg;
    NODE *args;
    NODE *post_rest_arg;
} rb_node_fndptn_t;
typedef struct RNode_LINE {
    NODE node;
} rb_node_line_t;
typedef struct RNode_FILE {
    NODE node;
    struct rb_parser_string *path;
} rb_node_file_t;
typedef struct RNode_ENCODING {
    NODE node;
    rb_encoding *enc;
} rb_node_encoding_t;
typedef struct RNode_ERROR {
    NODE node;
} rb_node_error_t;
typedef struct node_buffer_struct node_buffer_t;
typedef struct rb_ast_body_struct {
    const NODE *root;
    rb_parser_ary_t *script_lines;
    int line_count;
    signed int frozen_string_literal:2;
    signed int coverage_enabled:2;
} rb_ast_body_t;
typedef struct rb_ast_struct {
    node_buffer_t *node_buffer;
    rb_ast_body_t body;
} rb_ast_t;
typedef struct parser_params rb_parser_t;

#pragma GCC visibility push(default)

void rb_ruby_parser_free(void *ptr);

#pragma GCC visibility pop

typedef void (*bug_report_func)(const char *fmt, ...) __attribute__((format(printf, 1, 2)));
typedef struct node_buffer_elem_struct {
    struct node_buffer_elem_struct *next;
    long len;
    size_t allocated;
    size_t used;
    NODE **nodes;
    NODE *buf[];
} node_buffer_elem_t;
typedef struct {
    node_buffer_elem_t *head;
    node_buffer_elem_t *last;
} node_buffer_list_t;
struct node_buffer_struct {
    node_buffer_list_t buffer_list;
    struct rb_ast_local_table_link *local_tables;
    rb_parser_ary_t *tokens;
};

#pragma GCC visibility push(default)

rb_ast_t *rb_ast_new(void);
size_t rb_ast_memsize(const rb_ast_t*);
void rb_ast_dispose(rb_ast_t*);
const char *ruby_node_name(int node);
void rb_node_init(NODE *n, enum node_type type);
void rb_ast_update_references(rb_ast_t*);
void rb_ast_free(rb_ast_t*);
NODE *rb_ast_newnode(rb_ast_t*, enum node_type type, size_t size, size_t alignment);
void rb_ast_delete_node(rb_ast_t*, NODE *n);
rb_ast_id_table_t *rb_ast_new_local_table(rb_ast_t*, int);
rb_ast_id_table_t *rb_ast_resize_latest_local_table(rb_ast_t*, int);
VALUE rb_parser_dump_tree(const NODE *node, int comment);
const struct kwtable *rb_reserved_word(const char *, unsigned int);
struct parser_params;
__attribute__((__format__(__printf__, (2), (3)))) void rb_parser_printf(struct parser_params *parser, const char *fmt, ...);
VALUE rb_node_set_type(NODE *n, enum node_type t);

#pragma GCC visibility pop

static inline _Bool
nd_type_p(const NODE *n, enum node_type t)
{
    return (enum node_type)((int) ((((NODE *)(n))->flags & (((VALUE)0x7f)<<8))>>8)) == t;
}
typedef unsigned int rb_atomic_t;
__attribute__((__artificial__))

__attribute__((__nonnull__ (1)))
static inline rb_atomic_t
rbimpl_atomic_fetch_add(volatile rb_atomic_t *ptr, rb_atomic_t val)
{
    return __atomic_fetch_add(ptr, val, 5);
}
__attribute__((__artificial__))

__attribute__((__nonnull__ (1)))
static inline void
rbimpl_atomic_add(volatile rb_atomic_t *ptr, rb_atomic_t val)
{
    __atomic_add_fetch(ptr, val, 5);
}
__attribute__((__artificial__))

__attribute__((__nonnull__ (1)))
static inline void
rbimpl_atomic_size_add(volatile size_t *ptr, size_t val)
{
    __atomic_add_fetch(ptr, val, 5);
}
__attribute__((__artificial__))

__attribute__((__nonnull__ (1)))
static inline void
rbimpl_atomic_inc(volatile rb_atomic_t *ptr)
{
    rbimpl_atomic_add(ptr, 1);
}
__attribute__((__artificial__))

__attribute__((__nonnull__ (1)))
static inline void
rbimpl_atomic_size_inc(volatile size_t *ptr)
{
    rbimpl_atomic_size_add(ptr, 1);
}
__attribute__((__artificial__))

__attribute__((__nonnull__ (1)))
static inline rb_atomic_t
rbimpl_atomic_fetch_sub(volatile rb_atomic_t *ptr, rb_atomic_t val)
{
    return __atomic_fetch_sub(ptr, val, 5);
}
__attribute__((__artificial__))

__attribute__((__nonnull__ (1)))
static inline void
rbimpl_atomic_sub(volatile rb_atomic_t *ptr, rb_atomic_t val)
{
    __atomic_sub_fetch(ptr, val, 5);
}
__attribute__((__artificial__))

__attribute__((__nonnull__ (1)))
static inline void
rbimpl_atomic_size_sub(volatile size_t *ptr, size_t val)
{
    __atomic_sub_fetch(ptr, val, 5);
}
__attribute__((__artificial__))

__attribute__((__nonnull__ (1)))
static inline void
rbimpl_atomic_dec(volatile rb_atomic_t *ptr)
{
    rbimpl_atomic_sub(ptr, 1);
}
__attribute__((__artificial__))

__attribute__((__nonnull__ (1)))
static inline void
rbimpl_atomic_size_dec(volatile size_t *ptr)
{
    rbimpl_atomic_size_sub(ptr, 1);
}
__attribute__((__artificial__))

__attribute__((__nonnull__ (1)))
static inline void
rbimpl_atomic_or(volatile rb_atomic_t *ptr, rb_atomic_t val)
{
    __atomic_or_fetch(ptr, val, 5);
}
__attribute__((__artificial__))

__attribute__((__nonnull__ (1)))
static inline rb_atomic_t
rbimpl_atomic_exchange(volatile rb_atomic_t *ptr, rb_atomic_t val)
{
    return __atomic_exchange_n(ptr, val, 5);
}
__attribute__((__artificial__))

__attribute__((__nonnull__ (1)))
static inline size_t
rbimpl_atomic_size_exchange(volatile size_t *ptr, size_t val)
{
    return __atomic_exchange_n(ptr, val, 5);
}
__attribute__((__artificial__))

__attribute__((__nonnull__ (1)))
static inline void *
rbimpl_atomic_ptr_exchange(void *volatile *ptr, const void *val)
{
    __extension__ _Static_assert(sizeof *ptr == sizeof(size_t), "sizeof_voidp" ": " "sizeof *ptr == sizeof(size_t)");
    const size_t sval = ((size_t)val);
    volatile size_t *const sptr = ((volatile size_t *)ptr);
    const size_t sret = rbimpl_atomic_size_exchange(sptr, sval);
    return ((void *)sret);
}
__attribute__((__artificial__))

__attribute__((__nonnull__ (1)))
static inline VALUE
rbimpl_atomic_value_exchange(volatile VALUE *ptr, VALUE val)
{
    __extension__ _Static_assert(sizeof *ptr == sizeof(size_t), "sizeof_value" ": " "sizeof *ptr == sizeof(size_t)");
    const size_t sval = ((size_t)val);
    volatile size_t *const sptr = ((volatile size_t *)ptr);
    const size_t sret = rbimpl_atomic_size_exchange(sptr, sval);
    return ((VALUE)sret);
}
__attribute__((__artificial__))

__attribute__((__nonnull__ (1)))
static inline rb_atomic_t
rbimpl_atomic_load(volatile rb_atomic_t *ptr)
{
    return __atomic_load_n(ptr, 5);
}
__attribute__((__artificial__))

__attribute__((__nonnull__ (1)))
static inline void
rbimpl_atomic_set(volatile rb_atomic_t *ptr, rb_atomic_t val)
{
    __atomic_store_n(ptr, val, 5);
}
__attribute__((__artificial__))

__attribute__((__nonnull__ (1)))
static inline rb_atomic_t
rbimpl_atomic_cas(volatile rb_atomic_t *ptr, rb_atomic_t oldval, rb_atomic_t newval)
{
    __atomic_compare_exchange_n(
        ptr, &oldval, newval, 0, 5, 5);
    return oldval;
}
__attribute__((__artificial__))

__attribute__((__nonnull__ (1)))
static inline size_t
rbimpl_atomic_size_cas(volatile size_t *ptr, size_t oldval, size_t newval)
{
    __atomic_compare_exchange_n(
        ptr, &oldval, newval, 0, 5, 5);
    return oldval;
}
__attribute__((__artificial__))

__attribute__((__nonnull__ (1)))
static inline void *
rbimpl_atomic_ptr_cas(void **ptr, const void *oldval, const void *newval)
{
    __extension__ _Static_assert(sizeof *ptr == sizeof(size_t), "sizeof_voidp" ": " "sizeof *ptr == sizeof(size_t)");
    const size_t snew = ((size_t)newval);
    const size_t sold = ((size_t)oldval);
    volatile size_t *const sptr = ((volatile size_t *)ptr);
    const size_t sret = rbimpl_atomic_size_cas(sptr, sold, snew);
    return ((void *)sret);
}
__attribute__((__artificial__))

__attribute__((__nonnull__ (1)))
static inline void *
rbimpl_atomic_ptr_load(void **ptr)
{
    return __atomic_load_n(ptr, 5);
}
__attribute__((__artificial__))

__attribute__((__nonnull__ (1)))
static inline VALUE
rbimpl_atomic_value_cas(volatile VALUE *ptr, VALUE oldval, VALUE newval)
{
    __extension__ _Static_assert(sizeof *ptr == sizeof(size_t), "sizeof_value" ": " "sizeof *ptr == sizeof(size_t)");
    const size_t snew = ((size_t)newval);
    const size_t sold = ((size_t)oldval);
    volatile size_t *const sptr = ((volatile size_t *)ptr);
    const size_t sret = rbimpl_atomic_size_cas(sptr, sold, snew);
    return ((VALUE)sret);
}
struct sched_param
{
  int sched_priority;
};

extern int clone (int (*__fn) (void *__arg), void *__child_stack,
    int __flags, void *__arg, ...) __attribute__ ((__nothrow__ , __leaf__));
extern int unshare (int __flags) __attribute__ ((__nothrow__ , __leaf__));
extern int sched_getcpu (void) __attribute__ ((__nothrow__ , __leaf__));
extern int getcpu (unsigned int *, unsigned int *) __attribute__ ((__nothrow__ , __leaf__));
extern int setns (int __fd, int __nstype) __attribute__ ((__nothrow__ , __leaf__));

typedef unsigned long int __cpu_mask;
typedef struct
{
  __cpu_mask __bits[1024 / (8 * sizeof (__cpu_mask))];
} cpu_set_t;

extern int __sched_cpucount (size_t __setsize, const cpu_set_t *__setp)
     __attribute__ ((__nothrow__ , __leaf__));
extern cpu_set_t *__sched_cpualloc (size_t __count) __attribute__ ((__nothrow__ , __leaf__)) ;
extern void __sched_cpufree (cpu_set_t *__set) __attribute__ ((__nothrow__ , __leaf__));


extern int sched_setparam (__pid_t __pid, const struct sched_param *__param)
     __attribute__ ((__nothrow__ , __leaf__));
extern int sched_getparam (__pid_t __pid, struct sched_param *__param) __attribute__ ((__nothrow__ , __leaf__));
extern int sched_setscheduler (__pid_t __pid, int __policy,
          const struct sched_param *__param) __attribute__ ((__nothrow__ , __leaf__));
extern int sched_getscheduler (__pid_t __pid) __attribute__ ((__nothrow__ , __leaf__));
extern int sched_yield (void) __attribute__ ((__nothrow__ , __leaf__));
extern int sched_get_priority_max (int __algorithm) __attribute__ ((__nothrow__ , __leaf__));
extern int sched_get_priority_min (int __algorithm) __attribute__ ((__nothrow__ , __leaf__));
extern int sched_rr_get_interval (__pid_t __pid, struct timespec *__t) __attribute__ ((__nothrow__ , __leaf__));
extern int sched_setaffinity (__pid_t __pid, size_t __cpusetsize,
         const cpu_set_t *__cpuset) __attribute__ ((__nothrow__ , __leaf__));
extern int sched_getaffinity (__pid_t __pid, size_t __cpusetsize,
         cpu_set_t *__cpuset) __attribute__ ((__nothrow__ , __leaf__));

enum
{
  PTHREAD_CREATE_JOINABLE,
  PTHREAD_CREATE_DETACHED
};
enum
{
  PTHREAD_MUTEX_TIMED_NP,
  PTHREAD_MUTEX_RECURSIVE_NP,
  PTHREAD_MUTEX_ERRORCHECK_NP,
  PTHREAD_MUTEX_ADAPTIVE_NP
  ,
  PTHREAD_MUTEX_NORMAL = PTHREAD_MUTEX_TIMED_NP,
  PTHREAD_MUTEX_RECURSIVE = PTHREAD_MUTEX_RECURSIVE_NP,
  PTHREAD_MUTEX_ERRORCHECK = PTHREAD_MUTEX_ERRORCHECK_NP,
  PTHREAD_MUTEX_DEFAULT = PTHREAD_MUTEX_NORMAL
  , PTHREAD_MUTEX_FAST_NP = PTHREAD_MUTEX_TIMED_NP
};
enum
{
  PTHREAD_MUTEX_STALLED,
  PTHREAD_MUTEX_STALLED_NP = PTHREAD_MUTEX_STALLED,
  PTHREAD_MUTEX_ROBUST,
  PTHREAD_MUTEX_ROBUST_NP = PTHREAD_MUTEX_ROBUST
};
enum
{
  PTHREAD_PRIO_NONE,
  PTHREAD_PRIO_INHERIT,
  PTHREAD_PRIO_PROTECT
};
enum
{
  PTHREAD_RWLOCK_PREFER_READER_NP,
  PTHREAD_RWLOCK_PREFER_WRITER_NP,
  PTHREAD_RWLOCK_PREFER_WRITER_NONRECURSIVE_NP,
  PTHREAD_RWLOCK_DEFAULT_NP = PTHREAD_RWLOCK_PREFER_READER_NP
};
enum
{
  PTHREAD_INHERIT_SCHED,
  PTHREAD_EXPLICIT_SCHED
};
enum
{
  PTHREAD_SCOPE_SYSTEM,
  PTHREAD_SCOPE_PROCESS
};
enum
{
  PTHREAD_PROCESS_PRIVATE,
  PTHREAD_PROCESS_SHARED
};
struct _pthread_cleanup_buffer
{
  void (*__routine) (void *);
  void *__arg;
  int __canceltype;
  struct _pthread_cleanup_buffer *__prev;
};
enum
{
  PTHREAD_CANCEL_ENABLE,
  PTHREAD_CANCEL_DISABLE
};
enum
{
  PTHREAD_CANCEL_DEFERRED,
  PTHREAD_CANCEL_ASYNCHRONOUS
};

extern int pthread_create (pthread_t *__restrict __newthread,
      const pthread_attr_t *__restrict __attr,
      void *(*__start_routine) (void *),
      void *__restrict __arg) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 3)));
extern void pthread_exit (void *__retval) __attribute__ ((__noreturn__));
extern int pthread_join (pthread_t __th, void **__thread_return);
extern int pthread_tryjoin_np (pthread_t __th, void **__thread_return) __attribute__ ((__nothrow__ , __leaf__));
extern int pthread_timedjoin_np (pthread_t __th, void **__thread_return,
     const struct timespec *__abstime);
extern int pthread_clockjoin_np (pthread_t __th, void **__thread_return,
                                 clockid_t __clockid,
     const struct timespec *__abstime);
extern int pthread_detach (pthread_t __th) __attribute__ ((__nothrow__ , __leaf__));
extern pthread_t pthread_self (void) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern int pthread_equal (pthread_t __thread1, pthread_t __thread2)
  __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__const__));
extern int pthread_attr_init (pthread_attr_t *__attr) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_attr_destroy (pthread_attr_t *__attr)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_attr_getdetachstate (const pthread_attr_t *__attr,
     int *__detachstate)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int pthread_attr_setdetachstate (pthread_attr_t *__attr,
     int __detachstate)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_attr_getguardsize (const pthread_attr_t *__attr,
          size_t *__guardsize)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int pthread_attr_setguardsize (pthread_attr_t *__attr,
          size_t __guardsize)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_attr_getschedparam (const pthread_attr_t *__restrict __attr,
           struct sched_param *__restrict __param)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int pthread_attr_setschedparam (pthread_attr_t *__restrict __attr,
           const struct sched_param *__restrict
           __param) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int pthread_attr_getschedpolicy (const pthread_attr_t *__restrict
     __attr, int *__restrict __policy)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int pthread_attr_setschedpolicy (pthread_attr_t *__attr, int __policy)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_attr_getinheritsched (const pthread_attr_t *__restrict
      __attr, int *__restrict __inherit)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int pthread_attr_setinheritsched (pthread_attr_t *__attr,
      int __inherit)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_attr_getscope (const pthread_attr_t *__restrict __attr,
      int *__restrict __scope)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int pthread_attr_setscope (pthread_attr_t *__attr, int __scope)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_attr_getstackaddr (const pthread_attr_t *__restrict
          __attr, void **__restrict __stackaddr)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2))) __attribute__ ((__deprecated__));
extern int pthread_attr_setstackaddr (pthread_attr_t *__attr,
          void *__stackaddr)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1))) __attribute__ ((__deprecated__));
extern int pthread_attr_getstacksize (const pthread_attr_t *__restrict
          __attr, size_t *__restrict __stacksize)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int pthread_attr_setstacksize (pthread_attr_t *__attr,
          size_t __stacksize)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_attr_getstack (const pthread_attr_t *__restrict __attr,
      void **__restrict __stackaddr,
      size_t *__restrict __stacksize)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2, 3)));
extern int pthread_attr_setstack (pthread_attr_t *__attr, void *__stackaddr,
      size_t __stacksize) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_attr_setaffinity_np (pthread_attr_t *__attr,
     size_t __cpusetsize,
     const cpu_set_t *__cpuset)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 3)));
extern int pthread_attr_getaffinity_np (const pthread_attr_t *__attr,
     size_t __cpusetsize,
     cpu_set_t *__cpuset)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 3)));
extern int pthread_getattr_default_np (pthread_attr_t *__attr)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_attr_setsigmask_np (pthread_attr_t *__attr,
           const __sigset_t *sigmask);
extern int pthread_attr_getsigmask_np (const pthread_attr_t *__attr,
           __sigset_t *sigmask);
extern int pthread_setattr_default_np (const pthread_attr_t *__attr)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_getattr_np (pthread_t __th, pthread_attr_t *__attr)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2)));
extern int pthread_setschedparam (pthread_t __target_thread, int __policy,
      const struct sched_param *__param)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (3)));
extern int pthread_getschedparam (pthread_t __target_thread,
      int *__restrict __policy,
      struct sched_param *__restrict __param)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2, 3)));
extern int pthread_setschedprio (pthread_t __target_thread, int __prio)
     __attribute__ ((__nothrow__ , __leaf__));
extern int pthread_getname_np (pthread_t __target_thread, char *__buf,
          size_t __buflen)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2)));
extern int pthread_setname_np (pthread_t __target_thread, const char *__name)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2)));
extern int pthread_getconcurrency (void) __attribute__ ((__nothrow__ , __leaf__));
extern int pthread_setconcurrency (int __level) __attribute__ ((__nothrow__ , __leaf__));
extern int pthread_yield (void) __attribute__ ((__nothrow__ , __leaf__));
extern int pthread_yield (void) __asm__ ("" "sched_yield") __attribute__ ((__nothrow__ , __leaf__))
  __attribute__ ((__deprecated__ ("pthread_yield is deprecated, use sched_yield instead")));
extern int pthread_setaffinity_np (pthread_t __th, size_t __cpusetsize,
       const cpu_set_t *__cpuset)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (3)));
extern int pthread_getaffinity_np (pthread_t __th, size_t __cpusetsize,
       cpu_set_t *__cpuset)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (3)));
extern int pthread_once (pthread_once_t *__once_control,
    void (*__init_routine) (void)) __attribute__ ((__nonnull__ (1, 2)));
extern int pthread_setcancelstate (int __state, int *__oldstate);
extern int pthread_setcanceltype (int __type, int *__oldtype);
extern int pthread_cancel (pthread_t __th);
extern void pthread_testcancel (void);
struct __cancel_jmp_buf_tag
{
  __jmp_buf __cancel_jmp_buf;
  int __mask_was_saved;
};
typedef struct
{
  struct __cancel_jmp_buf_tag __cancel_jmp_buf[1];
  void *__pad[4];
} __pthread_unwind_buf_t __attribute__ ((__aligned__));
struct __pthread_cleanup_frame
{
  void (*__cancel_routine) (void *);
  void *__cancel_arg;
  int __do_it;
  int __cancel_type;
};
extern void __pthread_register_cancel (__pthread_unwind_buf_t *__buf)
     ;
extern void __pthread_unregister_cancel (__pthread_unwind_buf_t *__buf)
  ;
extern void __pthread_register_cancel_defer (__pthread_unwind_buf_t *__buf)
     ;
extern void __pthread_unregister_cancel_restore (__pthread_unwind_buf_t *__buf)
  ;
extern void __pthread_unwind_next (__pthread_unwind_buf_t *__buf)
     __attribute__ ((__noreturn__))
     __attribute__ ((__weak__))
     ;
extern int __sigsetjmp_cancel (struct __cancel_jmp_buf_tag __env[1], int __savemask) __asm__ ("" "__sigsetjmp") __attribute__ ((__nothrow__)) __attribute__ ((__returns_twice__));
extern int pthread_mutex_init (pthread_mutex_t *__mutex,
          const pthread_mutexattr_t *__mutexattr)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_mutex_destroy (pthread_mutex_t *__mutex)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_mutex_trylock (pthread_mutex_t *__mutex)
     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_mutex_lock (pthread_mutex_t *__mutex)
     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_mutex_timedlock (pthread_mutex_t *__restrict __mutex,
        const struct timespec *__restrict
        __abstime) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
extern int pthread_mutex_clocklock (pthread_mutex_t *__restrict __mutex,
        clockid_t __clockid,
        const struct timespec *__restrict
        __abstime) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 3)));
extern int pthread_mutex_unlock (pthread_mutex_t *__mutex)
     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_mutex_getprioceiling (const pthread_mutex_t *
      __restrict __mutex,
      int *__restrict __prioceiling)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int pthread_mutex_setprioceiling (pthread_mutex_t *__restrict __mutex,
      int __prioceiling,
      int *__restrict __old_ceiling)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 3)));
extern int pthread_mutex_consistent (pthread_mutex_t *__mutex)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_mutex_consistent_np (pthread_mutex_t *) __asm__ ("" "pthread_mutex_consistent") __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)))
  __attribute__ ((__deprecated__ ("pthread_mutex_consistent_np is deprecated, use pthread_mutex_consistent")));
extern int pthread_mutexattr_init (pthread_mutexattr_t *__attr)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_mutexattr_destroy (pthread_mutexattr_t *__attr)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_mutexattr_getpshared (const pthread_mutexattr_t *
      __restrict __attr,
      int *__restrict __pshared)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int pthread_mutexattr_setpshared (pthread_mutexattr_t *__attr,
      int __pshared)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_mutexattr_gettype (const pthread_mutexattr_t *__restrict
          __attr, int *__restrict __kind)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int pthread_mutexattr_settype (pthread_mutexattr_t *__attr, int __kind)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_mutexattr_getprotocol (const pthread_mutexattr_t *
       __restrict __attr,
       int *__restrict __protocol)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int pthread_mutexattr_setprotocol (pthread_mutexattr_t *__attr,
       int __protocol)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_mutexattr_getprioceiling (const pthread_mutexattr_t *
          __restrict __attr,
          int *__restrict __prioceiling)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int pthread_mutexattr_setprioceiling (pthread_mutexattr_t *__attr,
          int __prioceiling)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_mutexattr_getrobust (const pthread_mutexattr_t *__attr,
     int *__robustness)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int pthread_mutexattr_getrobust_np (pthread_mutexattr_t *, int *) __asm__ ("" "pthread_mutexattr_getrobust") __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)))
  __attribute__ ((__deprecated__ ("pthread_mutexattr_getrobust_np is deprecated, use pthread_mutexattr_getrobust")));
extern int pthread_mutexattr_setrobust (pthread_mutexattr_t *__attr,
     int __robustness)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_mutexattr_setrobust_np (pthread_mutexattr_t *, int) __asm__ ("" "pthread_mutexattr_setrobust") __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)))
  __attribute__ ((__deprecated__ ("pthread_mutexattr_setrobust_np is deprecated, use pthread_mutexattr_setrobust")));
extern int pthread_rwlock_init (pthread_rwlock_t *__restrict __rwlock,
    const pthread_rwlockattr_t *__restrict
    __attr) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_rwlock_destroy (pthread_rwlock_t *__rwlock)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_rwlock_rdlock (pthread_rwlock_t *__rwlock)
     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_rwlock_tryrdlock (pthread_rwlock_t *__rwlock)
  __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_rwlock_timedrdlock (pthread_rwlock_t *__restrict __rwlock,
           const struct timespec *__restrict
           __abstime) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
extern int pthread_rwlock_clockrdlock (pthread_rwlock_t *__restrict __rwlock,
           clockid_t __clockid,
           const struct timespec *__restrict
           __abstime) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 3)));
extern int pthread_rwlock_wrlock (pthread_rwlock_t *__rwlock)
     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_rwlock_trywrlock (pthread_rwlock_t *__rwlock)
     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_rwlock_timedwrlock (pthread_rwlock_t *__restrict __rwlock,
           const struct timespec *__restrict
           __abstime) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 2)));
extern int pthread_rwlock_clockwrlock (pthread_rwlock_t *__restrict __rwlock,
           clockid_t __clockid,
           const struct timespec *__restrict
           __abstime) __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1, 3)));
extern int pthread_rwlock_unlock (pthread_rwlock_t *__rwlock)
     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_rwlockattr_init (pthread_rwlockattr_t *__attr)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_rwlockattr_destroy (pthread_rwlockattr_t *__attr)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_rwlockattr_getpshared (const pthread_rwlockattr_t *
       __restrict __attr,
       int *__restrict __pshared)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int pthread_rwlockattr_setpshared (pthread_rwlockattr_t *__attr,
       int __pshared)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_rwlockattr_getkind_np (const pthread_rwlockattr_t *
       __restrict __attr,
       int *__restrict __pref)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int pthread_rwlockattr_setkind_np (pthread_rwlockattr_t *__attr,
       int __pref) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_cond_init (pthread_cond_t *__restrict __cond,
         const pthread_condattr_t *__restrict __cond_attr)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_cond_destroy (pthread_cond_t *__cond)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_cond_signal (pthread_cond_t *__cond)
     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_cond_broadcast (pthread_cond_t *__cond)
     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_cond_wait (pthread_cond_t *__restrict __cond,
         pthread_mutex_t *__restrict __mutex)
     __attribute__ ((__nonnull__ (1, 2)));
extern int pthread_cond_timedwait (pthread_cond_t *__restrict __cond,
       pthread_mutex_t *__restrict __mutex,
       const struct timespec *__restrict __abstime)
     __attribute__ ((__nonnull__ (1, 2, 3)));
extern int pthread_cond_clockwait (pthread_cond_t *__restrict __cond,
       pthread_mutex_t *__restrict __mutex,
       __clockid_t __clock_id,
       const struct timespec *__restrict __abstime)
     __attribute__ ((__nonnull__ (1, 2, 4)));
extern int pthread_condattr_init (pthread_condattr_t *__attr)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_condattr_destroy (pthread_condattr_t *__attr)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_condattr_getpshared (const pthread_condattr_t *
     __restrict __attr,
     int *__restrict __pshared)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int pthread_condattr_setpshared (pthread_condattr_t *__attr,
     int __pshared) __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_condattr_getclock (const pthread_condattr_t *
          __restrict __attr,
          __clockid_t *__restrict __clock_id)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int pthread_condattr_setclock (pthread_condattr_t *__attr,
          __clockid_t __clock_id)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_spin_init (pthread_spinlock_t *__lock, int __pshared)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_spin_destroy (pthread_spinlock_t *__lock)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_spin_lock (pthread_spinlock_t *__lock)
     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_spin_trylock (pthread_spinlock_t *__lock)
     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_spin_unlock (pthread_spinlock_t *__lock)
     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_barrier_init (pthread_barrier_t *__restrict __barrier,
     const pthread_barrierattr_t *__restrict
     __attr, unsigned int __count)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_barrier_destroy (pthread_barrier_t *__barrier)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_barrier_wait (pthread_barrier_t *__barrier)
     __attribute__ ((__nothrow__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_barrierattr_init (pthread_barrierattr_t *__attr)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_barrierattr_destroy (pthread_barrierattr_t *__attr)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_barrierattr_getpshared (const pthread_barrierattr_t *
        __restrict __attr,
        int *__restrict __pshared)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1, 2)));
extern int pthread_barrierattr_setpshared (pthread_barrierattr_t *__attr,
        int __pshared)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_key_create (pthread_key_t *__key,
          void (*__destr_function) (void *))
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (1)));
extern int pthread_key_delete (pthread_key_t __key) __attribute__ ((__nothrow__ , __leaf__));
extern void *pthread_getspecific (pthread_key_t __key) __attribute__ ((__nothrow__ , __leaf__));
extern int pthread_setspecific (pthread_key_t __key,
    const void *__pointer)
  __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__access__ (__none__, 2)));
extern int pthread_getcpuclockid (pthread_t __thread_id,
      __clockid_t *__clock_id)
     __attribute__ ((__nothrow__ , __leaf__)) __attribute__ ((__nonnull__ (2)));
extern int pthread_atfork (void (*__prepare) (void),
      void (*__parent) (void),
      void (*__child) (void)) __attribute__ ((__nothrow__ , __leaf__));

typedef pthread_t rb_nativethread_id_t;
typedef pthread_mutex_t rb_nativethread_lock_t;
typedef pthread_cond_t rb_nativethread_cond_t;

#pragma GCC visibility push(default)

rb_nativethread_id_t rb_nativethread_self(void);
void rb_nativethread_lock_initialize(rb_nativethread_lock_t *lock);
void rb_nativethread_lock_destroy(rb_nativethread_lock_t *lock);
void rb_nativethread_lock_lock(rb_nativethread_lock_t *lock);
void rb_nativethread_lock_unlock(rb_nativethread_lock_t *lock);
void rb_native_mutex_lock(rb_nativethread_lock_t *lock);
int rb_native_mutex_trylock(rb_nativethread_lock_t *lock);
void rb_native_mutex_unlock(rb_nativethread_lock_t *lock);
void rb_native_mutex_initialize(rb_nativethread_lock_t *lock);
void rb_native_mutex_destroy(rb_nativethread_lock_t *lock);
void rb_native_cond_signal(rb_nativethread_cond_t *cond);
void rb_native_cond_broadcast(rb_nativethread_cond_t *cond);
void rb_native_cond_wait(rb_nativethread_cond_t *cond, rb_nativethread_lock_t *mutex);
void rb_native_cond_timedwait(rb_nativethread_cond_t *cond, rb_nativethread_lock_t *mutex, unsigned long msec);
void rb_native_cond_initialize(rb_nativethread_cond_t *cond);
void rb_native_cond_destroy(rb_nativethread_cond_t *cond);

#pragma GCC visibility pop

void *rb_allocate_sigaltstack(void);
void *rb_register_sigaltstack(void *);
struct rb_thread_sched_waiting {
    enum thread_sched_waiting_flag {
        thread_sched_waiting_none = 0x00,
        thread_sched_waiting_timeout = 0x01,
        thread_sched_waiting_io_read = 0x02,
        thread_sched_waiting_io_write = 0x08,
        thread_sched_waiting_io_force = 0x40,
    } flags;
    struct {
        uint64_t timeout;
        int fd;
        int result;
    } data;
    struct ccan_list_node node;
};
struct rb_thread_sched_item {
    struct {
        struct ccan_list_node ubf;
        struct ccan_list_node readyq;
        struct ccan_list_node timeslice_threads;
        struct ccan_list_node running_threads;
        struct ccan_list_node zombie_threads;
    } node;
    struct rb_thread_sched_waiting waiting_reason;
    _Bool finished;
    _Bool malloc_stack;
    void *context_stack;
    struct coroutine_context *context;
};
struct rb_native_thread {
    rb_atomic_t serial;
    struct rb_vm_struct *vm;
    rb_nativethread_id_t thread_id;
    int tid;
    struct rb_thread_struct *running_thread;
    union
      {
        rb_nativethread_cond_t intr;
        rb_nativethread_cond_t readyq;
    } cond;
    void *altstack;
    struct coroutine_context *nt_context;
    int dedicated;
    size_t machine_stack_maxsize;
};
struct rb_thread_sched {
    rb_nativethread_lock_t lock_;
    struct rb_thread_struct *running;
    _Bool is_running;
    _Bool is_running_timeslice;
    _Bool enable_mn_threads;
    struct ccan_list_head readyq;
    int readyq_cnt;
    struct ccan_list_node grq_node;
};
  __attribute__((__noinline__)) void rb_current_ec_set(struct rb_execution_context_struct *);
    extern _Thread_local struct rb_execution_context_struct *ruby_current_ec;
    extern _Thread_local rb_atomic_t ruby_nt_serial;
void rb_vm_encoded_insn_data_table_init(void);
typedef unsigned long rb_num_t;
typedef signed long rb_snum_t;
enum ruby_tag_type {
    RUBY_TAG_NONE = 0x0,
    RUBY_TAG_RETURN = 0x1,
    RUBY_TAG_BREAK = 0x2,
    RUBY_TAG_NEXT = 0x3,
    RUBY_TAG_RETRY = 0x4,
    RUBY_TAG_REDO = 0x5,
    RUBY_TAG_RAISE = 0x6,
    RUBY_TAG_THROW = 0x7,
    RUBY_TAG_FATAL = 0x8,
    RUBY_TAG_MASK = 0xf
};
enum ruby_vm_throw_flags {
    VM_THROW_NO_ESCAPE_FLAG = 0x8000,
    VM_THROW_STATE_MASK = 0xff
};
struct rb_thread_struct;
struct rb_control_frame_struct;
typedef struct rb_compile_option_struct rb_compile_option_t;
union ic_serial_entry {
    rb_serial_t raw;
    VALUE data[2];
};
struct iseq_inline_constant_cache_entry {
    VALUE flags;
    VALUE value;
    VALUE _unused1;
    VALUE _unused2;
    const rb_cref_t *ic_cref;
};
__extension__ _Static_assert((__builtin_offsetof (struct iseq_inline_constant_cache_entry, ic_cref) + sizeof(const rb_cref_t *)) <= (sizeof(struct RBasic) + sizeof(VALUE[3])), "sizeof_iseq_inline_constant_cache_entry" ": " "(offsetof(struct iseq_inline_constant_cache_entry, ic_cref) + sizeof(const rb_cref_t *)) <= RVALUE_SIZE");
struct iseq_inline_constant_cache {
    struct iseq_inline_constant_cache_entry *entry;
    const ID *segments;
};
struct iseq_inline_iv_cache_entry {
    uintptr_t value;
    ID iv_set_name;
};
struct iseq_inline_cvar_cache_entry {
    struct rb_cvar_class_tbl_entry *entry;
};
union iseq_inline_storage_entry {
    struct {
        struct rb_thread_struct *running_thread;
        VALUE value;
    } once;
    struct iseq_inline_constant_cache ic_cache;
    struct iseq_inline_iv_cache_entry iv_cache;
};
struct rb_calling_info {
    const struct rb_call_data *cd;
    const struct rb_callcache *cc;
    VALUE block_handler;
    VALUE recv;
    int argc;
    _Bool kw_splat;
    VALUE heap_argv;
};
struct rb_execution_context_struct;
typedef struct rb_iseq_location_struct {
    VALUE pathobj;
    VALUE base_label;
    VALUE label;
    int first_lineno;
    int node_id;
    rb_code_location_t code_location;
} rb_iseq_location_t;
static inline VALUE
pathobj_path(VALUE pathobj)
{
    if (RB_TYPE_P(pathobj, RUBY_T_STRING)) {
        return pathobj;
    }
    else {
        ((void)0);
        return RARRAY_AREF(pathobj, 0);
    }
}
static inline VALUE
pathobj_realpath(VALUE pathobj)
{
    if (RB_TYPE_P(pathobj, RUBY_T_STRING)) {
        return pathobj;
    }
    else {
        ((void)0);
        return RARRAY_AREF(pathobj, 1);
    }
}
struct rb_rjit_unit;
typedef uintptr_t iseq_bits_t;
enum rb_iseq_type {
    ISEQ_TYPE_TOP,
    ISEQ_TYPE_METHOD,
    ISEQ_TYPE_BLOCK,
    ISEQ_TYPE_CLASS,
    ISEQ_TYPE_RESCUE,
    ISEQ_TYPE_ENSURE,
    ISEQ_TYPE_EVAL,
    ISEQ_TYPE_MAIN,
    ISEQ_TYPE_PLAIN
};
enum rb_builtin_attr {
    BUILTIN_ATTR_LEAF = 0x01,
    BUILTIN_ATTR_SINGLE_NOARG_LEAF = 0x02,
    BUILTIN_ATTR_INLINE_BLOCK = 0x04,
    BUILTIN_ATTR_C_TRACE = 0x08,
};
typedef VALUE (*rb_jit_func_t)(struct rb_execution_context_struct *, struct rb_control_frame_struct *);
struct rb_iseq_constant_body {
    enum rb_iseq_type type;
    unsigned int iseq_size;
    VALUE *iseq_encoded;
    struct {
        struct {
            unsigned int has_lead : 1;
            unsigned int has_opt : 1;
            unsigned int has_rest : 1;
            unsigned int has_post : 1;
            unsigned int has_kw : 1;
            unsigned int has_kwrest : 1;
            unsigned int has_block : 1;
            unsigned int ambiguous_param0 : 1;
            unsigned int accepts_no_kwarg : 1;
            unsigned int ruby2_keywords: 1;
            unsigned int anon_rest: 1;
            unsigned int anon_kwrest: 1;
            unsigned int use_block: 1;
            unsigned int forwardable: 1;
        } flags;
        unsigned int size;
        int lead_num;
        int opt_num;
        int rest_start;
        int post_start;
        int post_num;
        int block_start;
        const VALUE *opt_table;
        const struct rb_iseq_param_keyword {
            int num;
            int required_num;
            int bits_start;
            int rest_start;
            const ID *table;
            VALUE *default_values;
        } *keyword;
    } param;
    rb_iseq_location_t location;
    struct iseq_insn_info {
        const struct iseq_insn_info_entry *body;
        unsigned int *positions;
        unsigned int size;
        struct succ_index_table *succ_index_table;
    } insns_info;
    const ID *local_table;
    struct iseq_catch_table *catch_table;
    const struct rb_iseq_struct *parent_iseq;
    struct rb_iseq_struct *local_iseq;
    union iseq_inline_storage_entry *is_entries;
    struct rb_call_data *call_data;
    struct {
        rb_snum_t flip_count;
        VALUE script_lines;
        VALUE coverage;
        VALUE pc2branchindex;
        VALUE *original_iseq;
    } variable;
    unsigned int local_table_size;
    unsigned int ic_size;
    unsigned int ise_size;
    unsigned int ivc_size;
    unsigned int icvarc_size;
    unsigned int ci_size;
    unsigned int stack_max;
    unsigned int builtin_attrs;
    _Bool prism;
    union {
        iseq_bits_t * list;
        iseq_bits_t single;
    } mark_bits;
    struct rb_id_table *outer_variables;
    const rb_iseq_t *mandatory_only_iseq;
    rb_jit_func_t jit_entry;
    long unsigned jit_entry_calls;
    rb_jit_func_t jit_exception;
    long unsigned jit_exception_calls;
    VALUE rjit_blocks;
    void *yjit_payload;
    uint64_t yjit_calls_at_interv;
};
struct rb_iseq_struct {
    VALUE flags;
    VALUE wrapper;
    struct rb_iseq_constant_body *body;
    union {
        struct iseq_compile_data *compile_data;
        struct {
            VALUE obj;
            int index;
        } loader;
        struct {
            struct rb_hook_list_struct *local_hooks;
            rb_event_flag_t global_trace_events;
        } exec;
    } aux;
};
static inline const rb_iseq_t *rb_iseq_complete(const rb_iseq_t *iseq) {return 0;}
const rb_iseq_t *rb_iseq_complete(const rb_iseq_t *iseq);
static inline const rb_iseq_t *
rb_iseq_check(const rb_iseq_t *iseq)
{
    if (0 && ((iseq)->body) == ((void *)0)) {
        rb_iseq_complete((rb_iseq_t *)iseq);
    }
    return iseq;
}
static inline _Bool
rb_iseq_attr_p(const rb_iseq_t *iseq, enum rb_builtin_attr attr)
{
    return (((iseq)->body)->builtin_attrs & attr) == attr;
}
static inline const rb_iseq_t *
def_iseq_ptr(rb_method_definition_t *def)
{
    return rb_iseq_check(def->body.iseq.iseqptr);
}
enum ruby_special_exceptions {
    ruby_error_reenter,
    ruby_error_nomemory,
    ruby_error_sysstack,
    ruby_error_stackfatal,
    ruby_error_stream_closed,
    ruby_special_error_count
};
struct rb_vm_struct;
typedef void rb_vm_at_exit_func(struct rb_vm_struct*);
typedef struct rb_at_exit_list {
    rb_vm_at_exit_func *func;
    struct rb_at_exit_list *next;
} rb_at_exit_list;
void *rb_objspace_alloc(void);
void rb_objspace_free(void *objspace);
void rb_objspace_call_finalizer(void);
typedef struct rb_hook_list_struct {
    struct rb_event_hook_struct *hooks;
    rb_event_flag_t events;
    unsigned int running;
    _Bool need_clean;
    _Bool is_local;
} rb_hook_list_t;
typedef const struct rb_builtin_function *RB_BUILTIN;
struct global_object_list {
    VALUE *varptr;
    struct global_object_list *next;
};
typedef struct rb_vm_struct {
    VALUE self;
    struct {
        struct ccan_list_head set;
        unsigned int cnt;
        unsigned int blocking_cnt;
        struct rb_ractor_struct *main_ractor;
        struct rb_thread_struct *main_thread;
        struct {
            rb_nativethread_lock_t lock;
            struct rb_ractor_struct *lock_owner;
            unsigned int lock_rec;
            rb_nativethread_cond_t terminate_cond;
            _Bool terminate_waiting;
        } sync;
        struct {
            rb_nativethread_lock_t lock;
            struct rb_ractor_struct *lock_owner;
            _Bool locked;
            rb_nativethread_cond_t cond;
            unsigned int snt_cnt;
            unsigned int dnt_cnt;
            unsigned int running_cnt;
            unsigned int max_cpu;
            struct ccan_list_head grq;
            unsigned int grq_cnt;
            struct ccan_list_head running_threads;
            struct ccan_list_head timeslice_threads;
            struct ccan_list_head zombie_threads;
            _Bool timeslice_wait_inf;
            rb_nativethread_cond_t barrier_complete_cond;
            rb_nativethread_cond_t barrier_release_cond;
            _Bool barrier_waiting;
            unsigned int barrier_waiting_cnt;
            unsigned int barrier_serial;
        } sched;
    } ractor;
    void *main_altstack;
    rb_serial_t fork_gen;
    struct ccan_list_head waiting_fds;
    volatile int ubf_async_safe;
    unsigned int running: 1;
    unsigned int thread_abort_on_exception: 1;
    unsigned int thread_report_on_exception: 1;
    unsigned int thread_ignore_deadlock: 1;
    VALUE mark_object_ary;
    struct global_object_list *global_object_list;
    const VALUE special_exceptions[ruby_special_error_count];
    VALUE top_self;
    VALUE load_path;
    VALUE load_path_snapshot;
    VALUE load_path_check_cache;
    VALUE expanded_load_path;
    VALUE loaded_features;
    VALUE loaded_features_snapshot;
    VALUE loaded_features_realpaths;
    VALUE loaded_features_realpath_map;
    struct st_table *loaded_features_index;
    struct st_table *loading_table;
    struct st_table *static_ext_inits;
    struct {
        VALUE cmd[(64 + 1)];
    } trap_list;
    struct rb_postponed_job_queue *postponed_job_queue;
    int src_encoding_index;
    struct ccan_list_head workqueue;
    rb_nativethread_lock_t workqueue_lock;
    VALUE orig_progname, progname;
    VALUE coverages, me2counter;
    int coverage_mode;
    struct {
        struct rb_objspace *objspace;
        struct gc_mark_func_data_struct {
            void *data;
            void (*mark_func)(VALUE v, void *data);
        } *mark_func_data;
    } gc;
    rb_at_exit_list *at_exit;
    st_table *frozen_strings;
    const struct rb_builtin_function *builtin_function_table;
    st_table *ci_table;
    struct rb_id_table *negative_cme_table;
    st_table *overloaded_cme_table;
    st_table *unused_block_warning_table;
    struct rb_id_table *constant_cache;
    ID inserting_constant_cache_id;
    const struct rb_callcache *global_cc_cache_table[1023];
    struct {
        size_t thread_vm_stack_size;
        size_t thread_machine_stack_size;
        size_t fiber_vm_stack_size;
        size_t fiber_machine_stack_size;
    } default_params;
} rb_vm_t;
struct rb_captured_block {
    VALUE self;
    const VALUE *ep;
    union {
        const rb_iseq_t *iseq;
        const struct vm_ifunc *ifunc;
        VALUE val;
    } code;
};
enum rb_block_handler_type {
    block_handler_type_iseq,
    block_handler_type_ifunc,
    block_handler_type_symbol,
    block_handler_type_proc
};
enum rb_block_type {
    block_type_iseq,
    block_type_ifunc,
    block_type_symbol,
    block_type_proc
};
struct rb_block {
    union {
        struct rb_captured_block captured;
        VALUE symbol;
        VALUE proc;
    } as;
    enum rb_block_type type;
};
typedef struct rb_control_frame_struct {
    const VALUE *pc;
    VALUE *sp;
    const rb_iseq_t *iseq;
    VALUE self;
    const VALUE *ep;
    const void *block_code;
    void *jit_return;
} rb_control_frame_t;
extern const rb_data_type_t ruby_threadptr_data_type;
static inline struct rb_thread_struct *
rb_thread_ptr(VALUE thval)
{
    return (struct rb_thread_struct *)rb_check_typeddata(thval, &ruby_threadptr_data_type);
}
enum rb_thread_status {
    THREAD_RUNNABLE,
    THREAD_STOPPED,
    THREAD_STOPPED_FOREVER,
    THREAD_KILLED
};
typedef void *rb_jmpbuf_t[5];
typedef rb_jmpbuf_t rb_vm_tag_jmpbuf_t;
static inline void
rb_vm_tag_jmpbuf_init(rb_vm_tag_jmpbuf_t *jmpbuf)
{
}
static inline void
rb_vm_tag_jmpbuf_deinit(const rb_vm_tag_jmpbuf_t *jmpbuf)
{
}
struct rb_vm_tag {
    VALUE tag;
    VALUE retval;
    rb_vm_tag_jmpbuf_t buf;
    struct rb_vm_tag *prev;
    enum ruby_tag_type state;
    unsigned int lock_rec;
};
__extension__ _Static_assert(__builtin_offsetof (struct rb_vm_tag, buf) > 0, "rb_vm_tag_buf_offset" ": " "offsetof(struct rb_vm_tag, buf) > 0");
__extension__ _Static_assert(__builtin_offsetof (struct rb_vm_tag, buf) + sizeof(rb_vm_tag_jmpbuf_t) < sizeof(struct rb_vm_tag), "rb_vm_tag_buf_end" ": " "offsetof(struct rb_vm_tag, buf) + sizeof(rb_vm_tag_jmpbuf_t) < sizeof(struct rb_vm_tag)");
struct rb_unblock_callback {
    rb_unblock_function_t *func;
    void *arg;
};
struct rb_mutex_struct;
typedef struct rb_fiber_struct rb_fiber_t;
struct rb_waiting_list {
    struct rb_waiting_list *next;
    struct rb_thread_struct *thread;
    struct rb_fiber_struct *fiber;
};
struct rb_execution_context_struct {
    VALUE *vm_stack;
    size_t vm_stack_size;
    rb_control_frame_t *cfp;
    struct rb_vm_tag *tag;
    rb_atomic_t interrupt_flag;
    rb_atomic_t interrupt_mask;
    rb_fiber_t *fiber_ptr;
    struct rb_thread_struct *thread_ptr;
    struct rb_id_table *local_storage;
    VALUE local_storage_recursive_hash;
    VALUE local_storage_recursive_hash_for_trace;
    VALUE storage;
    const VALUE *root_lep;
    VALUE root_svar;
    struct rb_trace_arg_struct *trace_arg;
    VALUE errinfo;
    VALUE passed_block_handler;
    uint8_t raised_flag;
    enum method_missing_reason method_missing_reason : 8;
    VALUE private_const_reference;
    struct {
        VALUE *stack_start;
        VALUE *stack_end;
        size_t stack_maxsize;
        __attribute__((__aligned__(8))) jmp_buf regs;
    } machine;
};
typedef struct rb_execution_context_struct rb_execution_context_t;
void rb_ec_set_vm_stack(rb_execution_context_t *ec, VALUE *stack, size_t size);
void rb_ec_initialize_vm_stack(rb_execution_context_t *ec, VALUE *stack, size_t size);
void rb_ec_clear_vm_stack(rb_execution_context_t *ec);
struct rb_ext_config {
    _Bool ractor_safe;
};
typedef struct rb_ractor_struct rb_ractor_t;
struct rb_native_thread;
typedef struct rb_thread_struct {
    struct ccan_list_node lt_node;
    VALUE self;
    rb_ractor_t *ractor;
    rb_vm_t *vm;
    struct rb_native_thread *nt;
    rb_execution_context_t *ec;
    struct rb_thread_sched_item sched;
    _Bool mn_schedulable;
    rb_atomic_t serial;
    VALUE last_status;
    struct rb_calling_info *calling;
    VALUE top_self;
    VALUE top_wrapper;
    enum rb_thread_status status : 2;
    unsigned int has_dedicated_nt : 1;
    unsigned int to_kill : 1;
    unsigned int abort_on_exception: 1;
    unsigned int report_on_exception: 1;
    unsigned int pending_interrupt_queue_checked: 1;
    int8_t priority;
    uint32_t running_time_us;
    void *blocking_region_buffer;
    VALUE thgroup;
    VALUE value;
    VALUE pending_interrupt_queue;
    VALUE pending_interrupt_mask_stack;
    rb_nativethread_lock_t interrupt_lock;
    struct rb_unblock_callback unblock;
    VALUE locking_mutex;
    struct rb_mutex_struct *keeping_mutexes;
    struct ccan_list_head interrupt_exec_tasks;
    struct rb_waiting_list *join_list;
    union {
        struct {
            VALUE proc;
            VALUE args;
            int kw_splat;
        } proc;
        struct {
            VALUE (*func)(void *);
            void *arg;
        } func;
    } invoke_arg;
    enum thread_invoke_type {
        thread_invoke_type_none = 0,
        thread_invoke_type_proc,
        thread_invoke_type_ractor_proc,
        thread_invoke_type_func
    } invoke_type;
    VALUE stat_insn_usage;
    rb_fiber_t *root_fiber;
    VALUE scheduler;
    unsigned int blocking;
    VALUE name;
    void **specific_storage;
    struct rb_ext_config ext_config;
} rb_thread_t;
static inline unsigned int
rb_th_serial(const rb_thread_t *th)
{
    return th ? (unsigned int)th->serial : 0;
}
typedef enum {
    VM_DEFINECLASS_TYPE_CLASS = 0x00,
    VM_DEFINECLASS_TYPE_SINGLETON_CLASS = 0x01,
    VM_DEFINECLASS_TYPE_MODULE = 0x02,
    VM_DEFINECLASS_TYPE_MASK = 0x07
} rb_vm_defineclass_type_t;

#pragma GCC visibility push(default)

rb_iseq_t *rb_iseq_new (const VALUE ast_value, VALUE name, VALUE path, VALUE realpath, const rb_iseq_t *parent, enum rb_iseq_type);
rb_iseq_t *rb_iseq_new_top (const VALUE ast_value, VALUE name, VALUE path, VALUE realpath, const rb_iseq_t *parent);
rb_iseq_t *rb_iseq_new_main (const VALUE ast_value, VALUE path, VALUE realpath, const rb_iseq_t *parent, int opt);
rb_iseq_t *rb_iseq_new_eval (const VALUE ast_value, VALUE name, VALUE path, VALUE realpath, int first_lineno, const rb_iseq_t *parent, int isolated_depth);
rb_iseq_t *rb_iseq_new_with_opt( VALUE ast_value, VALUE name, VALUE path, VALUE realpath, int first_lineno, const rb_iseq_t *parent, int isolated_depth,
                                enum rb_iseq_type, const rb_compile_option_t*,
                                VALUE script_lines);
struct iseq_link_anchor;
struct rb_iseq_new_with_callback_callback_func {
    VALUE flags;
    VALUE reserved;
    void (*func)(rb_iseq_t *, struct iseq_link_anchor *, const void *);
    const void *data;
};
static inline struct rb_iseq_new_with_callback_callback_func *
rb_iseq_new_with_callback_new_callback(
    void (*func)(rb_iseq_t *, struct iseq_link_anchor *, const void *), const void *ptr)
{
    struct rb_iseq_new_with_callback_callback_func *memo =
        ((struct rb_iseq_new_with_callback_callback_func *)rb_imemo_new((imemo_ifunc), (((VALUE)RUBY_Qfalse))));
    memo->func = func;
    memo->data = ptr;
    return memo;
}
rb_iseq_t *rb_iseq_new_with_callback(const struct rb_iseq_new_with_callback_callback_func * ifunc,
    VALUE name, VALUE path, VALUE realpath, int first_lineno,
    const rb_iseq_t *parent, enum rb_iseq_type, const rb_compile_option_t*);
VALUE rb_iseq_disasm(const rb_iseq_t *iseq);
int rb_iseq_disasm_insn(VALUE str, const VALUE *iseqval, size_t pos, const rb_iseq_t *iseq, VALUE child);
VALUE rb_iseq_coverage(const rb_iseq_t *iseq);
extern VALUE rb_cISeq;
extern VALUE rb_cRubyVM;
extern VALUE rb_mRubyVMFrozenCore;
extern VALUE rb_block_param_proxy;

#pragma GCC visibility pop

typedef struct {
    const struct rb_block block;
    unsigned int is_from_method: 1;
    unsigned int is_lambda: 1;
    unsigned int is_isolated: 1;
} rb_proc_t;

#pragma GCC visibility push(default)

VALUE rb_proc_isolate(VALUE self);
VALUE rb_proc_isolate_bang(VALUE self);
VALUE rb_proc_ractor_make_shareable(VALUE self);

#pragma GCC visibility pop

typedef struct {
    VALUE flags;
    rb_iseq_t *iseq;
    const VALUE *ep;
    const VALUE *env;
    unsigned int env_size;
} rb_env_t;
extern const rb_data_type_t ruby_binding_data_type;
typedef struct {
    const struct rb_block block;
    const VALUE pathobj;
    int first_lineno;
} rb_binding_t;
enum vm_check_match_type {
    VM_CHECKMATCH_TYPE_WHEN = 1,
    VM_CHECKMATCH_TYPE_CASE = 2,
    VM_CHECKMATCH_TYPE_RESCUE = 3
};
enum vm_opt_newarray_send_type {
    VM_OPT_NEWARRAY_SEND_MAX = 1,
    VM_OPT_NEWARRAY_SEND_MIN = 2,
    VM_OPT_NEWARRAY_SEND_HASH = 3,
    VM_OPT_NEWARRAY_SEND_PACK = 4,
    VM_OPT_NEWARRAY_SEND_PACK_BUFFER = 5,
    VM_OPT_NEWARRAY_SEND_INCLUDE_P = 6,
};
enum vm_special_object_type {
    VM_SPECIAL_OBJECT_VMCORE = 1,
    VM_SPECIAL_OBJECT_CBASE,
    VM_SPECIAL_OBJECT_CONST_BASE
};
enum vm_svar_index {
    VM_SVAR_LASTLINE = 0,
    VM_SVAR_BACKREF = 1,
    VM_SVAR_EXTRA_START = 2,
    VM_SVAR_FLIPFLOP_START = 2
};
typedef struct iseq_inline_constant_cache *IC;
typedef struct iseq_inline_iv_cache_entry *IVC;
typedef struct iseq_inline_cvar_cache_entry *ICVARC;
typedef union iseq_inline_storage_entry *ISE;
typedef const struct rb_callinfo *CALL_INFO;
typedef const struct rb_callcache *CALL_CACHE;
typedef struct rb_call_data *CALL_DATA;
typedef VALUE CDHASH;
typedef rb_control_frame_t *
  (*rb_insn_func_t)(rb_execution_context_t *, rb_control_frame_t *);
enum vm_frame_env_flags {
    VM_FRAME_MAGIC_METHOD = 0x11110001,
    VM_FRAME_MAGIC_BLOCK = 0x22220001,
    VM_FRAME_MAGIC_CLASS = 0x33330001,
    VM_FRAME_MAGIC_TOP = 0x44440001,
    VM_FRAME_MAGIC_CFUNC = 0x55550001,
    VM_FRAME_MAGIC_IFUNC = 0x66660001,
    VM_FRAME_MAGIC_EVAL = 0x77770001,
    VM_FRAME_MAGIC_RESCUE = 0x78880001,
    VM_FRAME_MAGIC_DUMMY = 0x79990001,
    VM_FRAME_MAGIC_MASK = 0x7fff0001,
    VM_FRAME_FLAG_FINISH = 0x0020,
    VM_FRAME_FLAG_BMETHOD = 0x0040,
    VM_FRAME_FLAG_CFRAME = 0x0080,
    VM_FRAME_FLAG_LAMBDA = 0x0100,
    VM_FRAME_FLAG_MODIFIED_BLOCK_PARAM = 0x0200,
    VM_FRAME_FLAG_CFRAME_KW = 0x0400,
    VM_FRAME_FLAG_PASSED = 0x0800,
    VM_ENV_FLAG_LOCAL = 0x0002,
    VM_ENV_FLAG_ESCAPED = 0x0004,
    VM_ENV_FLAG_WB_REQUIRED = 0x0008,
    VM_ENV_FLAG_ISOLATED = 0x0010,
};
static inline void VM_FORCE_WRITE_SPECIAL_CONST(const VALUE *ptr, VALUE special_const_value);
static inline void
VM_ENV_FLAGS_SET(const VALUE *ep, VALUE flag)
{
    VALUE flags = ep[( 0)];
    ((void)0);
    VM_FORCE_WRITE_SPECIAL_CONST(&ep[( 0)], flags | flag);
}
static inline void
VM_ENV_FLAGS_UNSET(const VALUE *ep, VALUE flag)
{
    VALUE flags = ep[( 0)];
    ((void)0);
    VM_FORCE_WRITE_SPECIAL_CONST(&ep[( 0)], flags & ~flag);
}
static inline unsigned long
VM_ENV_FLAGS(const VALUE *ep, long flag)
{
    VALUE flags = ep[( 0)];
    ((void)0);
    return flags & flag;
}
static inline unsigned long
VM_FRAME_TYPE(const rb_control_frame_t *cfp)
{
    return VM_ENV_FLAGS(cfp->ep, VM_FRAME_MAGIC_MASK);
}
static inline int
VM_FRAME_LAMBDA_P(const rb_control_frame_t *cfp)
{
    return VM_ENV_FLAGS(cfp->ep, VM_FRAME_FLAG_LAMBDA) != 0;
}
static inline int
VM_FRAME_CFRAME_KW_P(const rb_control_frame_t *cfp)
{
    return VM_ENV_FLAGS(cfp->ep, VM_FRAME_FLAG_CFRAME_KW) != 0;
}
static inline int
VM_FRAME_FINISHED_P(const rb_control_frame_t *cfp)
{
    return VM_ENV_FLAGS(cfp->ep, VM_FRAME_FLAG_FINISH) != 0;
}
static inline int
VM_FRAME_BMETHOD_P(const rb_control_frame_t *cfp)
{
    return VM_ENV_FLAGS(cfp->ep, VM_FRAME_FLAG_BMETHOD) != 0;
}
static inline int
rb_obj_is_iseq(VALUE iseq)
{
    return imemo_type_p(iseq, imemo_iseq);
}
static inline int
VM_FRAME_CFRAME_P(const rb_control_frame_t *cfp)
{
    int cframe_p = VM_ENV_FLAGS(cfp->ep, VM_FRAME_FLAG_CFRAME) != 0;
    ((void)0);
    return cframe_p;
}
static inline int
VM_FRAME_RUBYFRAME_P(const rb_control_frame_t *cfp)
{
    return !VM_FRAME_CFRAME_P(cfp);
}
static inline int
VM_ENV_LOCAL_P(const VALUE *ep)
{
    return VM_ENV_FLAGS(ep, VM_ENV_FLAG_LOCAL) ? 1 : 0;
}
static inline const VALUE *
VM_ENV_PREV_EP(const VALUE *ep)
{
    ((void)0);
    return ((void *)(((ep[(-1)])) & ~0x03));
}
static inline VALUE
VM_ENV_BLOCK_HANDLER(const VALUE *ep)
{
    ((void)0);
    return ep[(-1)];
}
static inline int
VM_ENV_ESCAPED_P(const VALUE *ep)
{
    ((void)0);
    return VM_ENV_FLAGS(ep, VM_ENV_FLAG_ESCAPED) ? 1 : 0;
}
__attribute__((__nonnull__ (1)))
static inline VALUE
VM_ENV_ENVVAL(const VALUE *ep)
{
    VALUE envval = ep[( 1)];
    ((void)0);
    ((void)0);
    return envval;
}
__attribute__((__nonnull__ (1)))
static inline const rb_env_t *
VM_ENV_ENVVAL_PTR(const VALUE *ep)
{
    return (const rb_env_t *)VM_ENV_ENVVAL(ep);
}
static inline const rb_env_t *
vm_env_new(VALUE *env_ep, VALUE *env_body, unsigned int env_size, const rb_iseq_t *iseq)
{
    rb_env_t *env = ((rb_env_t *)rb_imemo_new((imemo_env), ((VALUE)iseq)));
    env->ep = env_ep;
    env->env = env_body;
    env->env_size = env_size;
    env_ep[( 1)] = (VALUE)env;
    return env;
}
static inline void
VM_FORCE_WRITE(const VALUE *ptr, VALUE v)
{
    *((VALUE *)ptr) = v;
}
static inline void
VM_FORCE_WRITE_SPECIAL_CONST(const VALUE *ptr, VALUE special_const_value)
{
    ((void)0);
    VM_FORCE_WRITE(ptr, special_const_value);
}
static inline void
VM_STACK_ENV_WRITE(const VALUE *ep, int index, VALUE v)
{
    ((void)0);
    VM_FORCE_WRITE(&ep[index], v);
}
const VALUE *rb_vm_ep_local_ep(const VALUE *ep);
const VALUE *rb_vm_proc_local_ep(VALUE proc);
void rb_vm_block_ep_update(VALUE obj, const struct rb_block *dst, const VALUE *ep);
void rb_vm_block_copy(VALUE obj, const struct rb_block *dst, const struct rb_block *src);
VALUE rb_vm_frame_block_handler(const rb_control_frame_t *cfp);
static inline const rb_control_frame_t *
RUBY_VM_END_CONTROL_FRAME(const rb_execution_context_t *ec)
{
    return (rb_control_frame_t *)(ec->vm_stack + ec->vm_stack_size);
}
static inline int
RUBY_VM_CONTROL_FRAME_STACK_OVERFLOW_P(const rb_execution_context_t *ec, const rb_control_frame_t *cfp)
{
    return !((void *)(RUBY_VM_END_CONTROL_FRAME(ec)) > (void *)(cfp));
}
static inline int
VM_BH_ISEQ_BLOCK_P(VALUE block_handler)
{
    if ((block_handler & 0x03) == 0x01) {
        return 1;
    }
    else {
        return 0;
    }
}
static inline VALUE
VM_BH_FROM_ISEQ_BLOCK(const struct rb_captured_block *captured)
{
    VALUE block_handler = ((VALUE)(captured) | (0x01));
    ((void)0);
    return block_handler;
}
static inline const struct rb_captured_block *
VM_BH_TO_ISEQ_BLOCK(VALUE block_handler)
{
    struct rb_captured_block *captured = ((void *)((block_handler) & ~0x03));
    ((void)0);
    return captured;
}
static inline int
VM_BH_IFUNC_P(VALUE block_handler)
{
    if ((block_handler & 0x03) == 0x03) {
        return 1;
    }
    else {
        return 0;
    }
}
static inline VALUE
VM_BH_FROM_IFUNC_BLOCK(const struct rb_captured_block *captured)
{
    VALUE block_handler = ((VALUE)(captured) | (0x03));
    ((void)0);
    return block_handler;
}
static inline const struct rb_captured_block *
VM_BH_TO_IFUNC_BLOCK(VALUE block_handler)
{
    struct rb_captured_block *captured = ((void *)((block_handler) & ~0x03));
    ((void)0);
    return captured;
}
static inline const struct rb_captured_block *
VM_BH_TO_CAPT_BLOCK(VALUE block_handler)
{
    struct rb_captured_block *captured = ((void *)((block_handler) & ~0x03));
    ((void)0);
    return captured;
}
static inline enum rb_block_handler_type
vm_block_handler_type(VALUE block_handler)
{
    if (VM_BH_ISEQ_BLOCK_P(block_handler)) {
        return block_handler_type_iseq;
    }
    else if (VM_BH_IFUNC_P(block_handler)) {
        return block_handler_type_ifunc;
    }
    else if (RB_SYMBOL_P(block_handler)) {
        return block_handler_type_symbol;
    }
    else {
        ((void)0);
        return block_handler_type_proc;
    }
}
static inline void
vm_block_handler_verify(__attribute__ ((__unused__)) VALUE block_handler)
{
    ((void)0);
}
static inline enum rb_block_type
vm_block_type(const struct rb_block *block)
{
    return block->type;
}
static inline void
vm_block_type_set(const struct rb_block *block, enum rb_block_type type)
{
    struct rb_block *mb = (struct rb_block *)block;
    mb->type = type;
}
static inline const struct rb_block *
vm_proc_block(VALUE procval)
{
    ((void)0);
    return &((rb_proc_t *)(((struct RTypedData *)(procval))->data))->block;
}
static inline const rb_iseq_t *vm_block_iseq(const struct rb_block *block);
static inline const VALUE *vm_block_ep(const struct rb_block *block);
static inline const rb_iseq_t *
vm_proc_iseq(VALUE procval)
{
    return vm_block_iseq(vm_proc_block(procval));
}
static inline const VALUE *
vm_proc_ep(VALUE procval)
{
    return vm_block_ep(vm_proc_block(procval));
}
static inline const rb_iseq_t *
vm_block_iseq(const struct rb_block *block)
{
    switch (vm_block_type(block)) {
      case block_type_iseq: return rb_iseq_check(block->as.captured.code.iseq);
      case block_type_proc: return vm_proc_iseq(block->as.proc);
      case block_type_ifunc:
      case block_type_symbol: return ((void *)0);
    }
    __builtin_unreachable();
    return ((void *)0);
}
static inline const VALUE *
vm_block_ep(const struct rb_block *block)
{
    switch (vm_block_type(block)) {
      case block_type_iseq:
      case block_type_ifunc: return block->as.captured.ep;
      case block_type_proc: return vm_proc_ep(block->as.proc);
      case block_type_symbol: return ((void *)0);
    }
    __builtin_unreachable();
    return ((void *)0);
}
static inline VALUE
vm_block_self(const struct rb_block *block)
{
    switch (vm_block_type(block)) {
      case block_type_iseq:
      case block_type_ifunc:
        return block->as.captured.self;
      case block_type_proc:
        return vm_block_self(vm_proc_block(block->as.proc));
      case block_type_symbol:
        return ((VALUE)RUBY_Qundef);
    }
    __builtin_unreachable();
    return ((VALUE)RUBY_Qundef);
}
static inline VALUE
VM_BH_TO_SYMBOL(VALUE block_handler)
{
    ((void)0);
    return block_handler;
}
static inline VALUE
VM_BH_FROM_SYMBOL(VALUE symbol)
{
    ((void)0);
    return symbol;
}
static inline VALUE
VM_BH_TO_PROC(VALUE block_handler)
{
    ((void)0);
    return block_handler;
}
static inline VALUE
VM_BH_FROM_PROC(VALUE procval)
{
    ((void)0);
    return procval;
}
VALUE rb_thread_alloc(VALUE klass);
VALUE rb_binding_alloc(VALUE klass);
VALUE rb_proc_alloc(VALUE klass);
VALUE rb_proc_dup(VALUE self);
extern _Bool rb_vmdebug_stack_dump_raw(const rb_execution_context_t *ec, const rb_control_frame_t *cfp, FILE *);
extern _Bool rb_vmdebug_debug_print_pre(const rb_execution_context_t *ec, const rb_control_frame_t *cfp, const VALUE *_pc, FILE *);
extern _Bool rb_vmdebug_debug_print_post(const rb_execution_context_t *ec, const rb_control_frame_t *cfp, FILE *);
_Bool rb_vm_bugreport(const void *, FILE *);
typedef void (*ruby_sighandler_t)(int);
__attribute__((__format__(__printf__, 4, 5)))
__attribute__((__noreturn__)) void rb_bug_for_fatal_signal(ruby_sighandler_t default_sighandler, int sig, const void *, const char *fmt, ...);

#pragma GCC visibility push(default)

VALUE rb_iseq_eval(const rb_iseq_t *iseq);
VALUE rb_iseq_eval_main(const rb_iseq_t *iseq);
VALUE rb_iseq_path(const rb_iseq_t *iseq);
VALUE rb_iseq_realpath(const rb_iseq_t *iseq);

#pragma GCC visibility pop

VALUE rb_iseq_pathobj_new(VALUE path, VALUE realpath);
void rb_iseq_pathobj_set(const rb_iseq_t *iseq, VALUE path, VALUE realpath);
int rb_ec_frame_method_id_and_class(const rb_execution_context_t *ec, ID *idp, ID *called_idp, VALUE *klassp);
void rb_ec_setup_exception(const rb_execution_context_t *ec, VALUE mesg, VALUE cause);
VALUE rb_vm_invoke_proc(rb_execution_context_t *ec, rb_proc_t *proc, int argc, const VALUE *argv, int kw_splat, VALUE block_handler);
VALUE rb_vm_make_proc_lambda(const rb_execution_context_t *ec, const struct rb_captured_block *captured, VALUE klass, int8_t is_lambda);
static inline VALUE
rb_vm_make_proc(const rb_execution_context_t *ec, const struct rb_captured_block *captured, VALUE klass)
{
    return rb_vm_make_proc_lambda(ec, captured, klass, 0);
}
static inline VALUE
rb_vm_make_lambda(const rb_execution_context_t *ec, const struct rb_captured_block *captured, VALUE klass)
{
    return rb_vm_make_proc_lambda(ec, captured, klass, 1);
}
VALUE rb_vm_make_binding(const rb_execution_context_t *ec, const rb_control_frame_t *src_cfp);
VALUE rb_vm_env_local_variables(const rb_env_t *env);
const rb_env_t *rb_vm_env_prev_env(const rb_env_t *env);
const VALUE *rb_binding_add_dynavars(VALUE bindval, rb_binding_t *bind, int dyncount, const ID *dynvars);
void rb_vm_inc_const_missing_count(void);
VALUE rb_vm_call_kw(rb_execution_context_t *ec, VALUE recv, VALUE id, int argc,
                 const VALUE *argv, const rb_callable_method_entry_t *me, int kw_splat);
void rb_vm_pop_frame_no_int(rb_execution_context_t *ec);
void rb_vm_pop_frame(rb_execution_context_t *ec);
void rb_thread_start_timer_thread(void);
void rb_thread_stop_timer_thread(void);
void rb_thread_reset_timer_thread(void);
void rb_thread_wakeup_timer_thread(int);
static inline void
rb_vm_living_threads_init(rb_vm_t *vm)
{
    ccan_list_head_init(&vm->waiting_fds);
    ccan_list_head_init(&vm->workqueue);
    ccan_list_head_init(&vm->ractor.set);
    ccan_list_head_init(&vm->ractor.sched.zombie_threads);
}
typedef int rb_backtrace_iter_func(void *, VALUE, int, VALUE);
rb_control_frame_t *rb_vm_get_ruby_level_next_cfp(const rb_execution_context_t *ec, const rb_control_frame_t *cfp);
rb_control_frame_t *rb_vm_get_binding_creatable_next_cfp(const rb_execution_context_t *ec, const rb_control_frame_t *cfp);
VALUE *rb_vm_svar_lep(const rb_execution_context_t *ec, const rb_control_frame_t *cfp);
int rb_vm_get_sourceline(const rb_control_frame_t *);
void rb_vm_stack_to_heap(rb_execution_context_t *ec);
void ruby_thread_init_stack(rb_thread_t *th, void *local_in_parent_frame);
rb_thread_t * ruby_thread_from_native(void);
int ruby_thread_set_native(rb_thread_t *th);
int rb_vm_control_frame_id_and_class(const rb_control_frame_t *cfp, ID *idp, ID *called_idp, VALUE *klassp);
void rb_vm_rewind_cfp(rb_execution_context_t *ec, rb_control_frame_t *cfp);
void rb_vm_env_write(const VALUE *ep, int index, VALUE v);
VALUE rb_vm_bh_to_procval(const rb_execution_context_t *ec, VALUE block_handler);
void rb_vm_register_special_exception_str(enum ruby_special_exceptions sp, VALUE exception_class, VALUE mesg);
void rb_gc_mark_machine_context(const rb_execution_context_t *ec);
void rb_vm_rewrite_cref(rb_cref_t *node, VALUE old_klass, VALUE new_klass, rb_cref_t **new_cref_ptr);
const rb_callable_method_entry_t *rb_vm_frame_method_entry(const rb_control_frame_t *cfp);
VALUE rb_catch_protect(VALUE t, rb_block_call_func *func, VALUE data, enum ruby_tag_type *stateptr);
rb_execution_context_t *rb_vm_main_ractor_ec(rb_vm_t *vm);
extern struct rb_ractor_struct *ruby_single_main_ractor;
extern rb_vm_t *ruby_current_vm_ptr;
extern rb_event_flag_t ruby_vm_event_flags;
extern rb_event_flag_t ruby_vm_event_enabled_global_flags;
extern unsigned int ruby_vm_event_local_num;
static inline rb_thread_t *
rb_ec_thread_ptr(const rb_execution_context_t *ec)
{
    return ec->thread_ptr;
}
static inline rb_ractor_t *
rb_ec_ractor_ptr(const rb_execution_context_t *ec)
{
    const rb_thread_t *th = rb_ec_thread_ptr(ec);
    if (th) {
        ((void)0);
        return th->ractor;
    }
    else {
        return ((void *)0);
    }
}
static inline rb_vm_t *
rb_ec_vm_ptr(const rb_execution_context_t *ec)
{
    const rb_thread_t *th = rb_ec_thread_ptr(ec);
    if (th) {
        return th->vm;
    }
    else {
        return ((void *)0);
    }
}
__attribute__((__noinline__)) struct rb_execution_context_struct *rb_current_ec_noinline(void);
static inline rb_execution_context_t *
rb_current_execution_context(_Bool expect_ec)
{
    rb_execution_context_t *ec = ruby_current_ec;
    ((void)0);
    ((void)0);
    return ec;
}
static inline rb_thread_t *
rb_current_thread(void)
{
    const rb_execution_context_t *ec = rb_current_execution_context(1);
    return rb_ec_thread_ptr(ec);
}
static inline rb_ractor_t *
rb_current_ractor_raw(_Bool expect)
{
    if (ruby_single_main_ractor) {
        return ruby_single_main_ractor;
    }
    else {
        const rb_execution_context_t *ec = rb_current_execution_context(expect);
        return (expect || ec) ? rb_ec_ractor_ptr(ec) : ((void *)0);
    }
}
static inline rb_ractor_t *
rb_current_ractor(void)
{
    return rb_current_ractor_raw(1);
}
static inline rb_vm_t *
rb_current_vm(void)
{
    return ruby_current_vm_ptr;
}
void rb_ec_vm_lock_rec_release(const rb_execution_context_t *ec,
                               unsigned int recorded_lock_rec,
                               unsigned int current_lock_rec);
static inline unsigned int
rb_ec_vm_lock_rec(const rb_execution_context_t *ec)
{
    rb_vm_t *vm = rb_ec_vm_ptr(ec);
    if (vm->ractor.sync.lock_owner != rb_ec_ractor_ptr(ec)) {
        return 0;
    }
    else {
        return vm->ractor.sync.lock_rec;
    }
}
enum {
    TIMER_INTERRUPT_MASK = 0x01,
    PENDING_INTERRUPT_MASK = 0x02,
    POSTPONED_JOB_INTERRUPT_MASK = 0x04,
    TRAP_INTERRUPT_MASK = 0x08,
    TERMINATE_INTERRUPT_MASK = 0x10,
    VM_BARRIER_INTERRUPT_MASK = 0x20,
};
static inline _Bool
RUBY_VM_INTERRUPTED_ANY(rb_execution_context_t *ec)
{
    return ec->interrupt_flag & ~(ec)->interrupt_mask;
}
VALUE rb_exc_set_backtrace(VALUE exc, VALUE bt);
int rb_signal_buff_size(void);
int rb_signal_exec(rb_thread_t *th, int sig);
void rb_threadptr_check_signal(rb_thread_t *mth);
void rb_threadptr_signal_raise(rb_thread_t *th, int sig);
void rb_threadptr_signal_exit(rb_thread_t *th);
int rb_threadptr_execute_interrupts(rb_thread_t *, int);
void rb_threadptr_interrupt(rb_thread_t *th);
void rb_threadptr_unlock_all_locking_mutexes(rb_thread_t *th);
void rb_threadptr_pending_interrupt_clear(rb_thread_t *th);
void rb_threadptr_pending_interrupt_enque(rb_thread_t *th, VALUE v);
VALUE rb_ec_get_errinfo(const rb_execution_context_t *ec);
void rb_ec_error_print(rb_execution_context_t * volatile ec, volatile VALUE errinfo);
void rb_execution_context_update(rb_execution_context_t *ec);
void rb_execution_context_mark(const rb_execution_context_t *ec);
void rb_fiber_close(rb_fiber_t *fib);
void Init_native_thread(rb_thread_t *th);
int rb_vm_check_ints_blocking(rb_execution_context_t *ec);
void rb_vm_cond_wait(rb_vm_t *vm, rb_nativethread_cond_t *cond);
void rb_vm_cond_timedwait(rb_vm_t *vm, rb_nativethread_cond_t *cond, unsigned long msec);
static inline void
rb_vm_check_ints(rb_execution_context_t *ec)
{
    ((void)0);
    if ((__builtin_expect(!!(RUBY_VM_INTERRUPTED_ANY(ec)), 0))) {
        rb_threadptr_execute_interrupts(rb_ec_thread_ptr(ec), 0);
    }
}
struct rb_trace_arg_struct {
    rb_event_flag_t event;
    rb_execution_context_t *ec;
    const rb_control_frame_t *cfp;
    VALUE self;
    ID id;
    ID called_id;
    VALUE klass;
    VALUE data;
    int klass_solved;
    int lineno;
    VALUE path;
};
void rb_hook_list_mark(rb_hook_list_t *hooks);
void rb_hook_list_mark_and_update(rb_hook_list_t *hooks);
void rb_hook_list_free(rb_hook_list_t *hooks);
void rb_hook_list_connect_tracepoint(VALUE target, rb_hook_list_t *list, VALUE tpval, unsigned int target_line);
void rb_hook_list_remove_tracepoint(rb_hook_list_t *list, VALUE tpval);
void rb_exec_event_hooks(struct rb_trace_arg_struct *trace_arg, rb_hook_list_t *hooks, int pop_p);
static inline void
rb_exec_event_hook_orig(rb_execution_context_t *ec, rb_hook_list_t *hooks, rb_event_flag_t flag,
                        VALUE self, ID id, ID called_id, VALUE klass, VALUE data, int pop_p)
{
    struct rb_trace_arg_struct trace_arg;
    ((void)0);
    trace_arg.event = flag;
    trace_arg.ec = ec;
    trace_arg.cfp = ec->cfp;
    trace_arg.self = self;
    trace_arg.id = id;
    trace_arg.called_id = called_id;
    trace_arg.klass = klass;
    trace_arg.data = data;
    trace_arg.path = ((VALUE)RUBY_Qundef);
    trace_arg.klass_solved = 0;
    rb_exec_event_hooks(&trace_arg, hooks, pop_p);
}
struct rb_ractor_pub {
    VALUE self;
    uint32_t id;
    rb_hook_list_t hooks;
};
static inline rb_hook_list_t *
rb_ec_ractor_hooks(const rb_execution_context_t *ec)
{
    struct rb_ractor_pub *cr_pub = (struct rb_ractor_pub *)rb_ec_ractor_ptr(ec);
    return &cr_pub->hooks;
}
static inline void
rb_exec_event_hook_script_compiled(rb_execution_context_t *ec, const rb_iseq_t *iseq, VALUE eval_script)
{
    do { const rb_event_flag_t flag_arg_ = (0x2000); rb_hook_list_t *hooks_arg_ = (rb_ec_ractor_hooks(ec)); if ((__builtin_expect(!!((hooks_arg_)->events & (flag_arg_)), 0))) { rb_exec_event_hook_orig(ec, hooks_arg_, flag_arg_, ec->cfp->self, 0, 0, 0, RB_NIL_P(eval_script) ? (VALUE)iseq : __extension__ ({ const VALUE args_to_new_ary[] = {eval_script, (VALUE)iseq}; if (__builtin_constant_p(2)) { __extension__ _Static_assert(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))) == (2), "rb_ary_new_from_args" ": " "numberof(args_to_new_ary) == (2)"); } rb_ary_new_from_values(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))), args_to_new_ary); }), 0); } } while (0);
}
void rb_vm_trap_exit(rb_vm_t *vm);
void rb_vm_postponed_job_atfork(void);
void rb_vm_postponed_job_free(void);
size_t rb_vm_memsize_postponed_job_queue(void);
void rb_vm_postponed_job_queue_init(rb_vm_t *vm);

#pragma GCC visibility push(default)

int rb_thread_check_trap_pending(void);
extern VALUE rb_get_coverages(void);
extern void rb_set_coverages(VALUE, int, VALUE);
extern void rb_clear_coverages(void);
extern void rb_reset_coverages(void);
extern void rb_resume_coverages(void);
extern void rb_suspend_coverages(void);
void rb_postponed_job_flush(rb_vm_t *vm);
extern VALUE rb_eRactorUnsafeError;
extern VALUE rb_eRactorIsolationError;

#pragma GCC visibility pop

const char *rb_obj_info(VALUE obj);
const char *rb_raw_obj_info(char *const buff, const size_t buff_size, VALUE obj);
struct rb_execution_context_struct;
struct rb_objspace;
__attribute__((__malloc__)) void *ruby_mimmalloc(size_t size);
__attribute__((__malloc__)) void *ruby_mimcalloc(size_t num, size_t size);
void ruby_mimfree(void *ptr);
void rb_gc_prepare_heap(void);
void rb_objspace_set_event_hook(const rb_event_flag_t event);
VALUE rb_objspace_gc_enable(void *objspace);
VALUE rb_objspace_gc_disable(void *objspace);
void ruby_gc_set_params(void);
void rb_gc_copy_attributes(VALUE dest, VALUE obj);
size_t rb_size_mul_or_raise(size_t, size_t, VALUE);
size_t rb_size_mul_add_or_raise(size_t, size_t, size_t, VALUE);
size_t rb_malloc_grow_capa(size_t current_capacity, size_t type_size);
__attribute__((__malloc__)) void *rb_xmalloc_mul_add(size_t, size_t, size_t);
__attribute__((__malloc__)) void *rb_xcalloc_mul_add(size_t, size_t, size_t);
void *rb_xrealloc_mul_add(const void *, size_t, size_t, size_t);
__attribute__((__malloc__)) void *rb_xmalloc_mul_add_mul(size_t, size_t, size_t, size_t);
__attribute__((__malloc__)) void *rb_xcalloc_mul_add_mul(size_t, size_t, size_t, size_t);
static inline void *ruby_sized_xrealloc_inlined(void *ptr, size_t new_size, size_t old_size) __attribute__((__returns_nonnull__)) __attribute__((__alloc_size__ (2)));
static inline void *ruby_sized_xrealloc2_inlined(void *ptr, size_t new_count, size_t elemsiz, size_t old_count) __attribute__((__returns_nonnull__)) __attribute__((__alloc_size__ (2, 3)));
static inline void ruby_sized_xfree_inlined(void *ptr, size_t size);
void *rb_gc_ractor_cache_alloc(rb_ractor_t *ractor);
void rb_gc_ractor_cache_free(void *cache);
_Bool rb_gc_size_allocatable_p(size_t size);
size_t *rb_gc_heap_sizes(void);
size_t rb_gc_heap_id_for_size(size_t size);
void rb_gc_mark_and_move(VALUE *ptr);
void rb_gc_mark_weak(VALUE *ptr);
void rb_gc_remove_weak(VALUE parent_obj, VALUE *ptr);
void rb_gc_ref_update_table_values_only(st_table *tbl);
void rb_gc_initial_stress_set(VALUE flag);
void rb_gc_before_fork(void);
void rb_gc_after_fork(pid_t pid);

#pragma GCC visibility push(default)

void rb_objspace_reachable_objects_from(VALUE obj, void (func)(VALUE, void *), void *data);
void rb_objspace_reachable_objects_from_root(void (func)(const char *category, VALUE, void *), void *data);
int rb_objspace_internal_object_p(VALUE obj);
int rb_objspace_garbage_object_p(VALUE obj);
void rb_objspace_each_objects(
    int (*callback)(void *start, void *end, size_t stride, void *data),
    void *data);
size_t rb_gc_obj_slot_size(VALUE obj);
VALUE rb_gc_disable_no_rest(void);
const char *rb_objspace_data_type_name(VALUE obj);
VALUE rb_wb_protected_newobj_of(struct rb_execution_context_struct *, VALUE, VALUE, size_t);
VALUE rb_wb_unprotected_newobj_of(VALUE, VALUE, size_t);
size_t rb_obj_memsize_of(VALUE);
size_t rb_obj_gc_flags(VALUE, ID[], size_t);
void rb_gc_mark_values(long n, const VALUE *values);
void rb_gc_mark_vm_stack_values(long n, const VALUE *values);
void rb_gc_update_values(long n, VALUE *values);
void *ruby_sized_xrealloc(void *ptr, size_t new_size, size_t old_size) __attribute__((__returns_nonnull__)) __attribute__((__alloc_size__ (2)));
void *ruby_sized_xrealloc2(void *ptr, size_t new_count, size_t element_size, size_t old_count) __attribute__((__returns_nonnull__)) __attribute__((__alloc_size__ (2, 3)));
void ruby_sized_xfree(void *x, size_t size);
const char *rb_gc_active_gc_name(void);
int rb_gc_modular_gc_loaded_p(void);

#pragma GCC visibility pop

int rb_ec_stack_check(struct rb_execution_context_struct *ec);
void rb_gc_writebarrier_remember(VALUE obj);
const char *rb_obj_info(VALUE obj);
void ruby_annotate_mmap(const void *addr, unsigned long size, const char *name);
static inline void *
ruby_sized_xrealloc_inlined(void *ptr, size_t new_size, size_t old_size)
{
    return ruby_xrealloc(ptr, new_size);
}
static inline void *
ruby_sized_xrealloc2_inlined(void *ptr, size_t new_count, size_t elemsiz, size_t old_count)
{
    return ruby_xrealloc2(ptr, new_count, elemsiz);
}
static inline void
ruby_sized_xfree_inlined(void *ptr, size_t size)
{
    ruby_xfree(ptr);
}
static inline void *
ruby_sized_realloc_n(void *ptr, size_t new_count, size_t element_size, size_t old_count)
{
    return ruby_xrealloc2(ptr, new_count, element_size);
}
struct ar_table_struct;
typedef unsigned char ar_hint_t;
enum ruby_rhash_flags {
    RHASH_PASS_AS_KEYWORDS = ((VALUE)RUBY_FL_USER1),
    RHASH_PROC_DEFAULT = ((VALUE)RUBY_FL_USER2),
    RHASH_ST_TABLE_FLAG = ((VALUE)RUBY_FL_USER3),
    RHASH_AR_TABLE_SIZE_MASK = (((VALUE)RUBY_FL_USER4)|((VALUE)RUBY_FL_USER5)|((VALUE)RUBY_FL_USER6)|((VALUE)RUBY_FL_USER7)),
    RHASH_AR_TABLE_SIZE_SHIFT = (((VALUE)RUBY_FL_USHIFT)+4),
    RHASH_AR_TABLE_BOUND_MASK = (((VALUE)RUBY_FL_USER8)|((VALUE)RUBY_FL_USER9)|((VALUE)RUBY_FL_USER10)|((VALUE)RUBY_FL_USER11)),
    RHASH_AR_TABLE_BOUND_SHIFT = (((VALUE)RUBY_FL_USHIFT)+8),
    RHASH_LEV_SHIFT = (((VALUE)RUBY_FL_USHIFT) + 13),
    RHASH_LEV_MAX = 127,
};
typedef struct ar_table_pair_struct {
    VALUE key;
    VALUE val;
} ar_table_pair;
typedef struct ar_table_struct {
    union {
        ar_hint_t ary[8];
        VALUE word;
    } ar_hint;
    ar_table_pair pairs[8];
} ar_table;
struct RHash {
    struct RBasic basic;
    const VALUE ifnone;
};
void rb_hash_st_table_set(VALUE hash, st_table *st);
VALUE rb_hash_default_value(VALUE hash, VALUE key);
VALUE rb_hash_set_default_proc(VALUE hash, VALUE proc);
long rb_dbl_long_hash(double d);
st_table *rb_init_identtable(void);
st_index_t rb_any_hash(VALUE a);
int rb_any_cmp(VALUE a, VALUE b);
VALUE rb_to_hash_type(VALUE obj);
VALUE rb_hash_key_str(VALUE);
VALUE rb_hash_values(VALUE hash);
VALUE rb_hash_rehash(VALUE hash);
int rb_hash_add_new_element(VALUE hash, VALUE key, VALUE val);
VALUE rb_hash_set_pair(VALUE hash, VALUE pair);
int rb_hash_stlike_delete(VALUE hash, st_data_t *pkey, st_data_t *pval);
int rb_hash_stlike_foreach_with_replace(VALUE hash, st_foreach_check_callback_func *func, st_update_callback_func *replace, st_data_t arg);
int rb_hash_stlike_update(VALUE hash, st_data_t key, st_update_callback_func *func, st_data_t arg);
VALUE rb_ident_hash_new_with_size(st_index_t size);
void rb_hash_free(VALUE hash);
extern VALUE rb_cHash_empty_frozen;
static inline unsigned RHASH_AR_TABLE_SIZE_RAW(VALUE h);
static inline VALUE RHASH_IFNONE(VALUE h);
static inline size_t RHASH_SIZE(VALUE h);
static inline _Bool RHASH_EMPTY_P(VALUE h);
static inline _Bool RHASH_AR_TABLE_P(VALUE h);
static inline _Bool RHASH_ST_TABLE_P(VALUE h);
static inline struct ar_table_struct *RHASH_AR_TABLE(VALUE h);
static inline st_table *RHASH_ST_TABLE(VALUE h);
static inline size_t RHASH_ST_SIZE(VALUE h);
static inline void RHASH_ST_CLEAR(VALUE h);

#pragma GCC visibility push(default)

VALUE rb_hash_delete_entry(VALUE hash, VALUE key);
VALUE rb_ident_hash_new(void);
int rb_hash_stlike_foreach(VALUE hash, st_foreach_callback_func *func, st_data_t arg);

#pragma GCC visibility pop

VALUE rb_hash_new_with_size(st_index_t size);
VALUE rb_hash_resurrect(VALUE hash);
int rb_hash_stlike_lookup(VALUE hash, st_data_t key, st_data_t *pval);
VALUE rb_hash_keys(VALUE hash);
VALUE rb_hash_has_key(VALUE hash, VALUE key);
VALUE rb_hash_compare_by_id_p(VALUE hash);
st_table *rb_hash_tbl_raw(VALUE hash, const char *file, int line);
VALUE rb_hash_compare_by_id(VALUE hash);
static inline _Bool
RHASH_AR_TABLE_P(VALUE h)
{
    return ! RB_FL_TEST_RAW(h, RHASH_ST_TABLE_FLAG);
}
__attribute__((__returns_nonnull__))
static inline struct ar_table_struct *
RHASH_AR_TABLE(VALUE h)
{
    return (struct ar_table_struct *)((uintptr_t)h + sizeof(struct RHash));
}
__attribute__((__returns_nonnull__))
static inline st_table *
RHASH_ST_TABLE(VALUE h)
{
    return (st_table *)((uintptr_t)h + sizeof(struct RHash));
}
static inline VALUE
RHASH_IFNONE(VALUE h)
{
    return ((struct RHash *)(h))->ifnone;
}
static inline size_t
RHASH_SIZE(VALUE h)
{
    if (RHASH_AR_TABLE_P(h)) {
        return RHASH_AR_TABLE_SIZE_RAW(h);
    }
    else {
        return RHASH_ST_SIZE(h);
    }
}
static inline _Bool
RHASH_EMPTY_P(VALUE h)
{
    return RHASH_SIZE(h) == 0;
}
static inline _Bool
RHASH_ST_TABLE_P(VALUE h)
{
    return ! RHASH_AR_TABLE_P(h);
}
static inline size_t
RHASH_ST_SIZE(VALUE h)
{
    return RHASH_ST_TABLE(h)->num_entries;
}
static inline void
RHASH_ST_CLEAR(VALUE h)
{
    memset(RHASH_ST_TABLE(h), 0, sizeof(st_table));
}
static inline unsigned
RHASH_AR_TABLE_SIZE_RAW(VALUE h)
{
    VALUE ret = RB_FL_TEST_RAW(h, RHASH_AR_TABLE_SIZE_MASK);
    ret >>= RHASH_AR_TABLE_SIZE_SHIFT;
    return (unsigned)ret;
}
struct rb_io;
typedef unsigned long int nfds_t;
struct pollfd
  {
    int fd;
    short int events;
    short int revents;
  };

extern int poll (struct pollfd *__fds, nfds_t __nfds, int __timeout)
    __attribute__ ((__access__ (__write_only__, 1, 2)));
extern int ppoll (struct pollfd *__fds, nfds_t __nfds,
    const struct timespec *__timeout,
    const __sigset_t *__ss)
    __attribute__ ((__access__ (__write_only__, 1, 2)));


#pragma GCC visibility push(default)

struct stat;
struct timeval;
extern VALUE rb_eIOTimeoutError;
enum rb_io_event {
    RUBY_IO_READABLE = 0x001,
    RUBY_IO_WRITABLE = 0x004,
    RUBY_IO_PRIORITY = 0x002,
};
typedef enum rb_io_event rb_io_event_t;

struct rb_io_internal_buffer {
    char *ptr;
    int off;
    int len;
    int capa;
} __attribute__((packed));
typedef struct rb_io_internal_buffer rb_io_buffer_t;
struct rb_io_encoding {
    rb_encoding *enc;
    rb_encoding *enc2;
    int ecflags;
    VALUE ecopts;
};
typedef struct rb_io rb_io_t;
typedef struct rb_io_encoding rb_io_enc_t;
VALUE rb_io_open_descriptor(VALUE klass, int descriptor, int mode, VALUE path, VALUE timeout, struct rb_io_encoding *encoding);
VALUE rb_io_closed_p(VALUE io);
rb_io_t *rb_io_make_open_file(VALUE obj);
FILE *rb_io_stdio_file(rb_io_t *fptr);
FILE *rb_fdopen(int fd, const char *modestr);
int rb_io_modestr_fmode(const char *modestr);
int rb_io_modestr_oflags(const char *modestr);
__attribute__((__const__))
int rb_io_oflags_fmode(int oflags);
void rb_io_check_writable(rb_io_t *fptr);
void rb_io_check_readable(rb_io_t *fptr);
void rb_io_check_char_readable(rb_io_t *fptr);
void rb_io_check_byte_readable(rb_io_t *fptr);
int rb_nonexistent_symbol(rb_io_t *fptr);
void rb_io_synchronized(rb_io_t *fptr);
void rb_io_check_initialized(rb_io_t *fptr);
void rb_io_check_closed(rb_io_t *fptr);
VALUE rb_io_get_io(VALUE io);
VALUE rb_io_check_io(VALUE io);
VALUE rb_io_get_write_io(VALUE io);
VALUE rb_io_set_write_io(VALUE io, VALUE w);
void rb_io_set_nonblock(rb_io_t *fptr);
VALUE rb_io_path(VALUE io);
int rb_io_descriptor(VALUE io);
int rb_io_mode(VALUE io);
int rb_io_extract_encoding_option(VALUE opt, rb_encoding **enc_p, rb_encoding **enc2_p, int *fmode_p);
void rb_io_extract_modeenc(VALUE *vmode_p, VALUE *vperm_p, VALUE opthash, int *oflags_p, int *fmode_p, rb_io_enc_t *convconfig_p);
ssize_t rb_io_bufwrite(VALUE io, const void *buf, size_t size);
int rb_io_wait_readable(int fd);
int rb_io_wait_writable(int fd);
int rb_wait_for_single_fd(int fd, int events, struct timeval *tv);
VALUE rb_io_timeout(VALUE io);
VALUE rb_io_set_timeout(VALUE io, VALUE timeout);
VALUE rb_io_wait(VALUE io, VALUE events, VALUE timeout);
VALUE rb_io_maybe_wait(int error, VALUE io, VALUE events, VALUE timeout);
int rb_io_maybe_wait_readable(int error, VALUE io, VALUE timeout);
int rb_io_maybe_wait_writable(int error, VALUE io, VALUE timeout);
VALUE rb_io_taint_check(VALUE obj);
__attribute__((__noreturn__))
void rb_eof_error(void);
void rb_io_read_check(rb_io_t *fptr);
__attribute__((__pure__))
int rb_io_read_pending(rb_io_t *fptr);
VALUE rb_stat_new(const struct stat *st);

#pragma GCC visibility pop

struct rb_io {
    VALUE self;
    FILE *stdio_file;
    int fd;
    int mode;
    pid_t pid;
    int lineno;
    VALUE pathv;
    void (*finalize)(struct rb_io*,int);
    rb_io_buffer_t wbuf;
    rb_io_buffer_t rbuf;
    VALUE tied_io_for_writing;
    struct rb_io_encoding encs;
    rb_econv_t *readconv;
    rb_io_buffer_t cbuf;
    rb_econv_t *writeconv;
    VALUE writeconv_asciicompat;
    int writeconv_initialized;
    int writeconv_pre_ecflags;
    VALUE writeconv_pre_ecopts;
    VALUE write_lock;
    VALUE timeout;
};
void ruby_set_inplace_mode(const char *);
void rb_stdio_set_default_encoding(void);
VALUE rb_io_flush_raw(VALUE, int);
size_t rb_io_memsize(const rb_io_t *);
int rb_stderr_tty_p(void);
void rb_io_fptr_finalize_internal(void *ptr);
VALUE rb_io_popen(VALUE pname, VALUE pmode, VALUE env, VALUE opt);
VALUE rb_io_prep_stdin(void);
VALUE rb_io_prep_stdout(void);
VALUE rb_io_prep_stderr(void);

#pragma GCC visibility push(default)

void rb_maygvl_fd_fix_cloexec(int fd);
int rb_gc_for_fd(int err);
void rb_write_error_str(VALUE mesg);
VALUE rb_io_blocking_region_wait(struct rb_io *io, rb_blocking_function_t *function, void *argument, enum rb_io_event events);
VALUE rb_io_blocking_region(struct rb_io *io, rb_blocking_function_t *function, void *argument);

#pragma GCC visibility pop

enum rb_int_parse_flags {
    RB_INT_PARSE_SIGN = 0x01,
    RB_INT_PARSE_UNDERSCORE = 0x02,
    RB_INT_PARSE_PREFIX = 0x04,
    RB_INT_PARSE_ALL = 0x07,
    RB_INT_PARSE_DEFAULT = 0x07,
};
struct RBignum {
    struct RBasic basic;
    union {
        struct {
            size_t len;
            unsigned int *digits;
        } heap;
        unsigned int ary[(8*3/4)];
    } as;
};
extern const char ruby_digitmap[];
double rb_big_fdiv_double(VALUE x, VALUE y);
VALUE rb_big_uminus(VALUE x);
VALUE rb_big_hash(VALUE);
VALUE rb_big_odd_p(VALUE);
VALUE rb_big_even_p(VALUE);
size_t rb_big_size(VALUE);
VALUE rb_integer_float_cmp(VALUE x, VALUE y);
VALUE rb_integer_float_eq(VALUE x, VALUE y);
VALUE rb_str_convert_to_inum(VALUE str, int base, int badcheck, int raise_exception);
VALUE rb_big_comp(VALUE x);
VALUE rb_big_aref(VALUE x, VALUE y);
VALUE rb_big_abs(VALUE x);
VALUE rb_big_size_m(VALUE big);
VALUE rb_big_bit_length(VALUE big);
VALUE rb_big_remainder(VALUE x, VALUE y);
VALUE rb_big_gt(VALUE x, VALUE y);
VALUE rb_big_ge(VALUE x, VALUE y);
VALUE rb_big_lt(VALUE x, VALUE y);
VALUE rb_big_le(VALUE x, VALUE y);
VALUE rb_int_powm(int const argc, VALUE * const argv, VALUE const num);
VALUE rb_big_isqrt(VALUE n);
static inline _Bool BIGNUM_SIGN(VALUE b);
static inline _Bool BIGNUM_POSITIVE_P(VALUE b);
static inline _Bool BIGNUM_NEGATIVE_P(VALUE b);
static inline void BIGNUM_SET_SIGN(VALUE b, _Bool sign);
static inline void BIGNUM_NEGATE(VALUE b);
static inline size_t BIGNUM_LEN(VALUE b);
static inline unsigned int *BIGNUM_DIGITS(VALUE b);
static inline int BIGNUM_LENINT(VALUE b);
static inline _Bool BIGNUM_EMBED_P(VALUE b);

#pragma GCC visibility push(default)

VALUE rb_big_mul_normal(VALUE x, VALUE y);
VALUE rb_big_mul_balance(VALUE x, VALUE y);
VALUE rb_big_mul_karatsuba(VALUE x, VALUE y);
VALUE rb_big_mul_toom3(VALUE x, VALUE y);
VALUE rb_big_sq_fast(VALUE x);
VALUE rb_big_divrem_normal(VALUE x, VALUE y);
VALUE rb_big2str_poweroftwo(VALUE x, int base);
VALUE rb_big2str_generic(VALUE x, int base);
VALUE rb_str2big_poweroftwo(VALUE arg, int base, int badcheck);
VALUE rb_str2big_normal(VALUE arg, int base, int badcheck);
VALUE rb_str2big_karatsuba(VALUE arg, int base, int badcheck);
VALUE rb_big_mul_gmp(VALUE x, VALUE y);
VALUE rb_big_divrem_gmp(VALUE x, VALUE y);
VALUE rb_big2str_gmp(VALUE x, int base);
VALUE rb_str2big_gmp(VALUE arg, int base, int badcheck);
VALUE rb_int_parse_cstr(const char *str, ssize_t len, char **endp, size_t *ndigits, int base, int flags);

#pragma GCC visibility pop

VALUE rb_int128t2big(__int128 n);
static inline _Bool
BIGNUM_SIGN(VALUE b)
{
    return RB_FL_TEST_RAW(b, ((VALUE)RUBY_FL_USER1));
}
static inline _Bool
BIGNUM_POSITIVE_P(VALUE b)
{
    return BIGNUM_SIGN(b);
}
static inline _Bool
BIGNUM_NEGATIVE_P(VALUE b)
{
    return ! BIGNUM_POSITIVE_P(b);
}
static inline void
BIGNUM_SET_SIGN(VALUE b, _Bool sign)
{
    if (sign) {
        RB_FL_SET_RAW(b, ((VALUE)RUBY_FL_USER1));
    }
    else {
        RB_FL_UNSET_RAW(b, ((VALUE)RUBY_FL_USER1));
    }
}
static inline void
BIGNUM_NEGATE(VALUE b)
{
    RB_FL_REVERSE_RAW(b, ((VALUE)RUBY_FL_USER1));
}
static inline size_t
BIGNUM_LEN(VALUE b)
{
    if (! BIGNUM_EMBED_P(b)) {
        return ((struct RBignum *)(b))->as.heap.len;
    }
    else {
        size_t ret = ((struct RBasic *)(b))->flags;
        ret &= (~(~(VALUE)0U << 3) << (((VALUE)RUBY_FL_USHIFT)+3));
        ret >>= (((VALUE)RUBY_FL_USHIFT)+3);
        return ret;
    }
}
static inline int
BIGNUM_LENINT(VALUE b)
{
    return rb_long2int_inline(BIGNUM_LEN(b));
}
static inline unsigned int *
BIGNUM_DIGITS(VALUE b)
{
    if (BIGNUM_EMBED_P(b)) {
        return ((struct RBignum *)(b))->as.ary;
    }
    else {
        return ((struct RBignum *)(b))->as.heap.digits;
    }
}
static inline _Bool
BIGNUM_EMBED_P(VALUE b)
{
    return RB_FL_TEST_RAW(b, ((VALUE)((VALUE)RUBY_FL_USER2)));
}
#pragma GCC push_options
#pragma GCC target("general-regs-only")
extern __inline int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
__bsfd (int __X)
{
  return __builtin_ctz (__X);
}
extern __inline int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
__bsrd (int __X)
{
  return __builtin_ia32_bsrsi (__X);
}
extern __inline int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
__bswapd (int __X)
{
  return __builtin_bswap32 (__X);
}
#pragma GCC push_options
#pragma GCC target("crc32")
extern __inline unsigned int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
__crc32b (unsigned int __C, unsigned char __V)
{
  return __builtin_ia32_crc32qi (__C, __V);
}
extern __inline unsigned int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
__crc32w (unsigned int __C, unsigned short __V)
{
  return __builtin_ia32_crc32hi (__C, __V);
}
extern __inline unsigned int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
__crc32d (unsigned int __C, unsigned int __V)
{
  return __builtin_ia32_crc32si (__C, __V);
}
#pragma GCC pop_options
extern __inline int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
__popcntd (unsigned int __X)
{
  return __builtin_popcount (__X);
}
extern __inline unsigned long long
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
__rdpmc (int __S)
{
  return __builtin_ia32_rdpmc (__S);
}
extern __inline unsigned long long
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
__rdtsc (void)
{
  return __builtin_ia32_rdtsc ();
}
extern __inline unsigned long long
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
__rdtscp (unsigned int *__A)
{
  return __builtin_ia32_rdtscp (__A);
}
extern __inline unsigned char
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
__rolb (unsigned char __X, int __C)
{
  return __builtin_ia32_rolqi (__X, __C);
}
extern __inline unsigned short
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
__rolw (unsigned short __X, int __C)
{
  return __builtin_ia32_rolhi (__X, __C);
}
extern __inline unsigned int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
__rold (unsigned int __X, int __C)
{
  __C &= 31;
  return (__X << __C) | (__X >> (-__C & 31));
}
extern __inline unsigned char
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
__rorb (unsigned char __X, int __C)
{
  return __builtin_ia32_rorqi (__X, __C);
}
extern __inline unsigned short
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
__rorw (unsigned short __X, int __C)
{
  return __builtin_ia32_rorhi (__X, __C);
}
extern __inline unsigned int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
__rord (unsigned int __X, int __C)
{
  __C &= 31;
  return (__X >> __C) | (__X << (-__C & 31));
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
__pause (void)
{
  __builtin_ia32_pause ();
}
extern __inline int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
__bsfq (long long __X)
{
  return __builtin_ctzll (__X);
}
extern __inline int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
__bsrq (long long __X)
{
  return __builtin_ia32_bsrdi (__X);
}
extern __inline long long
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
__bswapq (long long __X)
{
  return __builtin_bswap64 (__X);
}
#pragma GCC push_options
#pragma GCC target("crc32")
extern __inline unsigned long long
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
__crc32q (unsigned long long __C, unsigned long long __V)
{
  return __builtin_ia32_crc32di (__C, __V);
}
#pragma GCC pop_options
extern __inline long long
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
__popcntq (unsigned long long __X)
{
  return __builtin_popcountll (__X);
}
extern __inline unsigned long long
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
__rolq (unsigned long long __X, int __C)
{
  __C &= 63;
  return (__X << __C) | (__X >> (-__C & 63));
}
extern __inline unsigned long long
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
__rorq (unsigned long long __X, int __C)
{
  __C &= 63;
  return (__X >> __C) | (__X << (-__C & 63));
}
extern __inline unsigned long long
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
__readeflags (void)
{
  return __builtin_ia32_readeflags_u64 ();
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
__writeeflags (unsigned long long __X)
{
  __builtin_ia32_writeeflags_u64 (__X);
}
extern __inline unsigned char
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_subborrow_u32 (unsigned char __CF, unsigned int __X,
  unsigned int __Y, unsigned int *__P)
{
  return __builtin_ia32_sbb_u32 (__CF, __X, __Y, __P);
}
extern __inline unsigned char
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_addcarry_u32 (unsigned char __CF, unsigned int __X,
        unsigned int __Y, unsigned int *__P)
{
  return __builtin_ia32_addcarryx_u32 (__CF, __X, __Y, __P);
}
extern __inline unsigned char
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_addcarryx_u32 (unsigned char __CF, unsigned int __X,
  unsigned int __Y, unsigned int *__P)
{
  return __builtin_ia32_addcarryx_u32 (__CF, __X, __Y, __P);
}
extern __inline unsigned char
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_subborrow_u64 (unsigned char __CF, unsigned long long __X,
  unsigned long long __Y, unsigned long long *__P)
{
  return __builtin_ia32_sbb_u64 (__CF, __X, __Y, __P);
}
extern __inline unsigned char
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_addcarry_u64 (unsigned char __CF, unsigned long long __X,
        unsigned long long __Y, unsigned long long *__P)
{
  return __builtin_ia32_addcarryx_u64 (__CF, __X, __Y, __P);
}
extern __inline unsigned char
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_addcarryx_u64 (unsigned char __CF, unsigned long long __X,
  unsigned long long __Y, unsigned long long *__P)
{
  return __builtin_ia32_addcarryx_u64 (__CF, __X, __Y, __P);
}
#pragma GCC push_options
#pragma GCC target("bmi")
extern __inline unsigned short __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__tzcnt_u16 (unsigned short __X)
{
  return __builtin_ia32_tzcnt_u16 (__X);
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__andn_u32 (unsigned int __X, unsigned int __Y)
{
  return ~__X & __Y;
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__bextr_u32 (unsigned int __X, unsigned int __Y)
{
  return __builtin_ia32_bextr_u32 (__X, __Y);
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_bextr_u32 (unsigned int __X, unsigned int __Y, unsigned __Z)
{
  return __builtin_ia32_bextr_u32 (__X, ((__Y & 0xff) | ((__Z & 0xff) << 8)));
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__blsi_u32 (unsigned int __X)
{
  return __X & -__X;
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_blsi_u32 (unsigned int __X)
{
  return __blsi_u32 (__X);
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__blsmsk_u32 (unsigned int __X)
{
  return __X ^ (__X - 1);
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_blsmsk_u32 (unsigned int __X)
{
  return __blsmsk_u32 (__X);
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__blsr_u32 (unsigned int __X)
{
  return __X & (__X - 1);
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_blsr_u32 (unsigned int __X)
{
  return __blsr_u32 (__X);
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__tzcnt_u32 (unsigned int __X)
{
  return __builtin_ia32_tzcnt_u32 (__X);
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_tzcnt_u32 (unsigned int __X)
{
  return __builtin_ia32_tzcnt_u32 (__X);
}
extern __inline unsigned long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__andn_u64 (unsigned long long __X, unsigned long long __Y)
{
  return ~__X & __Y;
}
extern __inline unsigned long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__bextr_u64 (unsigned long long __X, unsigned long long __Y)
{
  return __builtin_ia32_bextr_u64 (__X, __Y);
}
extern __inline unsigned long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_bextr_u64 (unsigned long long __X, unsigned int __Y, unsigned int __Z)
{
  return __builtin_ia32_bextr_u64 (__X, ((__Y & 0xff) | ((__Z & 0xff) << 8)));
}
extern __inline unsigned long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__blsi_u64 (unsigned long long __X)
{
  return __X & -__X;
}
extern __inline unsigned long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_blsi_u64 (unsigned long long __X)
{
  return __blsi_u64 (__X);
}
extern __inline unsigned long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__blsmsk_u64 (unsigned long long __X)
{
  return __X ^ (__X - 1);
}
extern __inline unsigned long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_blsmsk_u64 (unsigned long long __X)
{
  return __blsmsk_u64 (__X);
}
extern __inline unsigned long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__blsr_u64 (unsigned long long __X)
{
  return __X & (__X - 1);
}
extern __inline unsigned long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_blsr_u64 (unsigned long long __X)
{
  return __blsr_u64 (__X);
}
extern __inline unsigned long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__tzcnt_u64 (unsigned long long __X)
{
  return __builtin_ia32_tzcnt_u64 (__X);
}
extern __inline unsigned long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_tzcnt_u64 (unsigned long long __X)
{
  return __builtin_ia32_tzcnt_u64 (__X);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("bmi2")
extern __inline unsigned int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_bzhi_u32 (unsigned int __X, unsigned int __Y)
{
  return __builtin_ia32_bzhi_si (__X, __Y);
}
extern __inline unsigned int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_pdep_u32 (unsigned int __X, unsigned int __Y)
{
  return __builtin_ia32_pdep_si (__X, __Y);
}
extern __inline unsigned int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_pext_u32 (unsigned int __X, unsigned int __Y)
{
  return __builtin_ia32_pext_si (__X, __Y);
}
extern __inline unsigned long long
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_bzhi_u64 (unsigned long long __X, unsigned long long __Y)
{
  return __builtin_ia32_bzhi_di (__X, __Y);
}
extern __inline unsigned long long
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_pdep_u64 (unsigned long long __X, unsigned long long __Y)
{
  return __builtin_ia32_pdep_di (__X, __Y);
}
extern __inline unsigned long long
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_pext_u64 (unsigned long long __X, unsigned long long __Y)
{
  return __builtin_ia32_pext_di (__X, __Y);
}
extern __inline unsigned long long
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mulx_u64 (unsigned long long __X, unsigned long long __Y,
    unsigned long long *__P)
{
  unsigned __int128 __res = (unsigned __int128) __X * __Y;
  *__P = (unsigned long long) (__res >> 64);
  return (unsigned long long) __res;
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target ("shstk")
extern __inline unsigned long long
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_get_ssp (void)
{
  return __builtin_ia32_rdsspq ();
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_inc_ssp (unsigned int __B)
{
  __builtin_ia32_incsspq ((unsigned long long) __B);
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_saveprevssp (void)
{
  __builtin_ia32_saveprevssp ();
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_rstorssp (void *__B)
{
  __builtin_ia32_rstorssp (__B);
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_wrssd (unsigned int __B, void *__C)
{
  __builtin_ia32_wrssd (__B, __C);
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_wrssq (unsigned long long __B, void *__C)
{
  __builtin_ia32_wrssq (__B, __C);
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_wrussd (unsigned int __B, void *__C)
{
  __builtin_ia32_wrussd (__B, __C);
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_wrussq (unsigned long long __B, void *__C)
{
  __builtin_ia32_wrussq (__B, __C);
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_setssbsy (void)
{
  __builtin_ia32_setssbsy ();
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_clrssbsy (void *__B)
{
  __builtin_ia32_clrssbsy (__B);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("cldemote")
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_cldemote (void *__A)
{
  __builtin_ia32_cldemote (__A);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("clflushopt")
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_clflushopt (void *__A)
{
  __builtin_ia32_clflushopt (__A);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("clwb")
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_clwb (void *__A)
{
  __builtin_ia32_clwb (__A);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("clzero")
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_clzero (void * __I)
{
  __builtin_ia32_clzero (__I);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target ("enqcmd")
extern __inline int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_enqcmd (void * __P, const void * __Q)
{
  return __builtin_ia32_enqcmd (__P, __Q);
}
extern __inline int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_enqcmds (void * __P, const void * __Q)
{
  return __builtin_ia32_enqcmds (__P, __Q);
}
#pragma GCC pop_options
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_fxsave (void *__P)
{
  __builtin_ia32_fxsave (__P);
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_fxrstor (void *__P)
{
  __builtin_ia32_fxrstor (__P);
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_fxsave64 (void *__P)
{
  __builtin_ia32_fxsave64 (__P);
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_fxrstor64 (void *__P)
{
  __builtin_ia32_fxrstor64 (__P);
}
#pragma GCC push_options
#pragma GCC target("lzcnt")
extern __inline unsigned short __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__lzcnt16 (unsigned short __X)
{
  return __builtin_ia32_lzcnt_u16 (__X);
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__lzcnt32 (unsigned int __X)
{
  return __builtin_ia32_lzcnt_u32 (__X);
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_lzcnt_u32 (unsigned int __X)
{
  return __builtin_ia32_lzcnt_u32 (__X);
}
extern __inline unsigned long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__lzcnt64 (unsigned long long __X)
{
  return __builtin_ia32_lzcnt_u64 (__X);
}
extern __inline unsigned long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_lzcnt_u64 (unsigned long long __X)
{
  return __builtin_ia32_lzcnt_u64 (__X);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("lwp")
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__llwpcb (void *__pcbAddress)
{
  __builtin_ia32_llwpcb (__pcbAddress);
}
extern __inline void * __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__slwpcb (void)
{
  return __builtin_ia32_slwpcb ();
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target ("movdiri")
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_directstoreu_u32 (void * __P, unsigned int __A)
{
  __builtin_ia32_directstoreu_u32 ((unsigned int *)__P, __A);
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_directstoreu_u64 (void * __P, unsigned long long __A)
{
  __builtin_ia32_directstoreu_u64 ((unsigned long long *)__P, __A);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target ("movdir64b")
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_movdir64b (void * __P, const void * __Q)
{
  __builtin_ia32_movdir64b (__P, __Q);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("mwait")
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_monitor (void const * __P, unsigned int __E, unsigned int __H)
{
  __builtin_ia32_monitor (__P, __E, __H);
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mwait (unsigned int __E, unsigned int __H)
{
  __builtin_ia32_mwait (__E, __H);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("mwaitx")
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_monitorx (void const * __P, unsigned int __E, unsigned int __H)
{
  __builtin_ia32_monitorx (__P, __E, __H);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mwaitx (unsigned int __E, unsigned int __H, unsigned int __C)
{
  __builtin_ia32_mwaitx (__E, __H, __C);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("pconfig")
extern __inline unsigned int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_pconfig_u32 (const unsigned int __L, size_t __D[])
{
  enum __pconfig_type
  {
    __PCONFIG_KEY_PROGRAM = 0x01,
  };
  unsigned int __R = 0;
  if (!__builtin_constant_p (__L))
    __asm__ __volatile__ ("pconfig\n\t" : "=a" (__R), "=b" (__D[0]), "=c" (__D[1]), "=d" (__D[2]) : "a" (__L), "b" (__D[0]), "c" (__D[1]), "d" (__D[2]) : "cc");
  else switch (__L)
    {
    case __PCONFIG_KEY_PROGRAM:
      __asm__ __volatile__ ("pconfig\n\t" : "=a" (__R) : "a" (__L), "b" (__D[0]) : "cc");
      break;
    default:
      __asm__ __volatile__ ("pconfig\n\t" : "=a" (__R), "=b" (__D[0]), "=c" (__D[1]), "=d" (__D[2]) : "a" (__L), "b" (__D[0]), "c" (__D[1]), "d" (__D[2]) : "cc");
    }
  return __R;
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("popcnt")
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_popcnt_u32 (unsigned int __X)
{
  return __builtin_popcount (__X);
}
extern __inline long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_popcnt_u64 (unsigned long long __X)
{
  return __builtin_popcountll (__X);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("pku")
extern __inline unsigned int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_rdpkru_u32 (void)
{
  return __builtin_ia32_rdpkru ();
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_wrpkru (unsigned int __key)
{
  __builtin_ia32_wrpkru (__key);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("rdseed")
extern __inline int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_rdseed16_step (unsigned short *__p)
{
  return __builtin_ia32_rdseed_hi_step (__p);
}
extern __inline int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_rdseed32_step (unsigned int *__p)
{
  return __builtin_ia32_rdseed_si_step (__p);
}
extern __inline int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_rdseed64_step (unsigned long long *__p)
{
  return __builtin_ia32_rdseed_di_step (__p);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("rtm")
extern __inline unsigned int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_xbegin (void)
{
  return __builtin_ia32_xbegin ();
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_xend (void)
{
  __builtin_ia32_xend ();
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("serialize")
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_serialize (void)
{
  __builtin_ia32_serialize ();
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("sgx")
extern __inline unsigned int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_encls_u32 (const unsigned int __L, size_t __D[])
{
  enum __encls_type
  {
    __SGX_ECREATE = 0x00,
    __SGX_EADD = 0x01,
    __SGX_EINIT = 0x02,
    __SGX_EREMOVE = 0x03,
    __SGX_EDBGRD = 0x04,
    __SGX_EDBGWR = 0x05,
    __SGX_EEXTEND = 0x06,
    __SGX_ELDB = 0x07,
    __SGX_ELDU = 0x08,
    __SGX_EBLOCK = 0x09,
    __SGX_EPA = 0x0A,
    __SGX_EWB = 0x0B,
    __SGX_ETRACK = 0x0C,
    __SGX_EAUG = 0x0D,
    __SGX_EMODPR = 0x0E,
    __SGX_EMODT = 0x0F,
    __SGX_ERDINFO = 0x10,
    __SGX_ETRACKC = 0x11,
    __SGX_ELDBC = 0x12,
    __SGX_ELDUC = 0x13
  };
  enum __encls_type __T = (enum __encls_type)__L;
  unsigned int __R = 0;
  if (!__builtin_constant_p (__T))
    __asm__ __volatile__("encls\n\t" : "=a" (__R), "=b" (__D[0]), "=c" (__D[1]), "=d" (__D[2]) : "a" (__L), "b" (__D[0]), "c" (__D[1]), "d" (__D[2]) : "cc");
  else switch (__T)
    {
    case __SGX_ECREATE:
    case __SGX_EADD:
    case __SGX_EDBGWR:
    case __SGX_EEXTEND:
    case __SGX_EPA:
    case __SGX_EMODPR:
    case __SGX_EMODT:
    case __SGX_EAUG:
    case __SGX_ERDINFO:
      __asm__ __volatile__ ("encls\n\t" : "=a" (__R) : "a" (__L), "b" (__D[0]), "c" (__D[1]) : "cc");
      break;
    case __SGX_EINIT:
    case __SGX_ELDB:
    case __SGX_ELDU:
    case __SGX_EWB:
    case __SGX_ELDBC:
    case __SGX_ELDUC:
      __asm__ __volatile__("encls\n\t" : "=a" (__R) : "a" (__L), "b" (__D[0]), "c" (__D[1]), "d" (__D[2]) : "cc");
      break;
    case __SGX_EREMOVE:
    case __SGX_EBLOCK:
    case __SGX_ETRACK:
    case __SGX_ETRACKC:
      __asm__ __volatile__("encls\n\t" : "=a" (__R) : "a" (__L), "c" (__D[1]) : "cc");
      break;
    case __SGX_EDBGRD:
      __asm__ __volatile__("encls\n\t" : "=a" (__R), "=b" (__D[0]) : "a" (__L), "c" (__D[1]));
      break;
    default:
      __asm__ __volatile__("encls\n\t" : "=a" (__R), "=b" (__D[0]), "=c" (__D[1]), "=d" (__D[2]) : "a" (__L), "b" (__D[0]), "c" (__D[1]), "d" (__D[2]) : "cc");
    }
  return __R;
}
extern __inline unsigned int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_enclu_u32 (const unsigned int __L, size_t __D[])
{
  enum __enclu_type
  {
    __SGX_EREPORT = 0x00,
    __SGX_EGETKEY = 0x01,
    __SGX_EENTER = 0x02,
    __SGX_ERESUME = 0x03,
    __SGX_EEXIT = 0x04,
    __SGX_EACCEPT = 0x05,
    __SGX_EMODPE = 0x06,
    __SGX_EACCEPTCOPY = 0x07
  };
  enum __enclu_type __T = (enum __enclu_type) __L;
  unsigned int __R = 0;
  if (!__builtin_constant_p (__T))
    __asm__ __volatile__("enclu\n\t" : "=a" (__R), "=b" (__D[0]), "=c" (__D[1]), "=d" (__D[2]) : "a" (__L), "b" (__D[0]), "c" (__D[1]), "d" (__D[2]) : "cc");
  else switch (__T)
    {
    case __SGX_EREPORT:
    case __SGX_EACCEPTCOPY:
      __asm__ __volatile__("enclu\n\t" : "=a" (__R) : "a" (__L), "b" (__D[0]), "c" (__D[1]), "d" (__D[2]) : "cc");
      break;
    case __SGX_EGETKEY:
    case __SGX_ERESUME:
    case __SGX_EACCEPT:
    case __SGX_EMODPE:
      __asm__ __volatile__("enclu\n\t" : "=a" (__R) : "a" (__L), "b" (__D[0]), "c" (__D[1]) : "cc");
      break;
    case __SGX_EENTER:
      __asm__ __volatile__("enclu\n\t" : "=a" (__R), "=c" (__D[1]) : "a" (__L), "b" (__D[0]), "c" (__D[1]) : "cc");
      break;
    case __SGX_EEXIT:
      __asm__ __volatile__("enclu\n\t" : "=a" (__R), "=c" (__D[1]) : "a" (__L), "b" (__D[0]) : "cc");
      break;
    default:
      __asm__ __volatile__("enclu\n\t" : "=a" (__R), "=b" (__D[0]), "=c" (__D[1]), "=d" (__D[2]) : "a" (__L), "b" (__D[0]), "c" (__D[1]), "d" (__D[2]) : "cc");
    }
  return __R;
}
extern __inline unsigned int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_enclv_u32 (const unsigned int __L, size_t __D[])
{
  enum __enclv_type
  {
    __SGX_EDECVIRTCHILD = 0x00,
    __SGX_EINCVIRTCHILD = 0x01,
    __SGX_ESETCONTEXT = 0x02
  };
  unsigned int __R = 0;
  if (!__builtin_constant_p (__L))
    __asm__ __volatile__("enclv\n\t" : "=a" (__R), "=b" (__D[0]), "=c" (__D[0]), "=d" (__D[2]) : "a" (__L), "b" (__D[0]), "c" (__D[1]), "d" (__D[2]) : "cc");
  else switch (__L)
    {
    case __SGX_EDECVIRTCHILD:
    case __SGX_EINCVIRTCHILD:
      __asm__ __volatile__("enclv\n\t" : "=a" (__R) : "a" (__L), "b" (__D[0]), "c" (__D[1]) : "cc");
      break;
    case __SGX_ESETCONTEXT:
      __asm__ __volatile__("enclv\n\t" : "=a" (__R) : "a" (__L), "c" (__D[1]), "d" (__D[2]) : "cc");
      break;
    default:
      __asm__ __volatile__("enclv\n\t" : "=a" (__R), "=b" (__D[0]), "=c" (__D[0]), "=d" (__D[2]) : "a" (__L), "b" (__D[0]), "c" (__D[1]), "d" (__D[2]) : "cc");
    }
  return __R;
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("tbm")
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__blcfill_u32 (unsigned int __X)
{
  return __X & (__X + 1);
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__blci_u32 (unsigned int __X)
{
  return __X | ~(__X + 1);
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__blcic_u32 (unsigned int __X)
{
  return ~__X & (__X + 1);
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__blcmsk_u32 (unsigned int __X)
{
  return __X ^ (__X + 1);
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__blcs_u32 (unsigned int __X)
{
  return __X | (__X + 1);
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__blsfill_u32 (unsigned int __X)
{
  return __X | (__X - 1);
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__blsic_u32 (unsigned int __X)
{
  return ~__X | (__X - 1);
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__t1mskc_u32 (unsigned int __X)
{
  return ~__X | (__X + 1);
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__tzmsk_u32 (unsigned int __X)
{
  return ~__X & (__X - 1);
}
extern __inline unsigned long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__blcfill_u64 (unsigned long long __X)
{
  return __X & (__X + 1);
}
extern __inline unsigned long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__blci_u64 (unsigned long long __X)
{
  return __X | ~(__X + 1);
}
extern __inline unsigned long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__blcic_u64 (unsigned long long __X)
{
  return ~__X & (__X + 1);
}
extern __inline unsigned long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__blcmsk_u64 (unsigned long long __X)
{
  return __X ^ (__X + 1);
}
extern __inline unsigned long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__blcs_u64 (unsigned long long __X)
{
  return __X | (__X + 1);
}
extern __inline unsigned long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__blsfill_u64 (unsigned long long __X)
{
  return __X | (__X - 1);
}
extern __inline unsigned long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__blsic_u64 (unsigned long long __X)
{
  return ~__X | (__X - 1);
}
extern __inline unsigned long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__t1mskc_u64 (unsigned long long __X)
{
  return ~__X | (__X + 1);
}
extern __inline unsigned long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
__tzmsk_u64 (unsigned long long __X)
{
  return ~__X & (__X - 1);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("tsxldtrk")
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_xsusldtrk (void)
{
  __builtin_ia32_xsusldtrk ();
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_xresldtrk (void)
{
  __builtin_ia32_xresldtrk ();
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target ("uintr")
struct __uintr_frame
{
  unsigned long long rip;
  unsigned long long rflags;
  unsigned long long rsp;
};
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_clui (void)
{
  __builtin_ia32_clui ();
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_stui (void)
{
  __builtin_ia32_stui ();
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_senduipi (unsigned long long __R)
{
  __builtin_ia32_senduipi (__R);
}
extern __inline unsigned char
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_testui (void)
{
  return __builtin_ia32_testui ();
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("waitpkg")
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_umonitor (void *__A)
{
  __builtin_ia32_umonitor (__A);
}
extern __inline unsigned char
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_umwait (unsigned int __A, unsigned long long __B)
{
  return __builtin_ia32_umwait (__A, __B);
}
extern __inline unsigned char
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_tpause (unsigned int __A, unsigned long long __B)
{
  return __builtin_ia32_tpause (__A, __B);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("wbnoinvd")
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_wbnoinvd (void)
{
  __builtin_ia32_wbnoinvd ();
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("xsave")
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_xsave (void *__P, long long __M)
{
  __builtin_ia32_xsave (__P, __M);
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_xrstor (void *__P, long long __M)
{
  __builtin_ia32_xrstor (__P, __M);
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_xsetbv (unsigned int __A, long long __V)
{
  __builtin_ia32_xsetbv (__A, __V);
}
extern __inline long long
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_xgetbv (unsigned int __A)
{
  return __builtin_ia32_xgetbv (__A);
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_xsave64 (void *__P, long long __M)
{
  __builtin_ia32_xsave64 (__P, __M);
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_xrstor64 (void *__P, long long __M)
{
  __builtin_ia32_xrstor64 (__P, __M);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("xsavec")
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_xsavec (void *__P, long long __M)
{
  __builtin_ia32_xsavec (__P, __M);
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_xsavec64 (void *__P, long long __M)
{
  __builtin_ia32_xsavec64 (__P, __M);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("xsaveopt")
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_xsaveopt (void *__P, long long __M)
{
  __builtin_ia32_xsaveopt (__P, __M);
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_xsaveopt64 (void *__P, long long __M)
{
  __builtin_ia32_xsaveopt64 (__P, __M);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("xsaves")
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_xsaves (void *__P, long long __M)
{
  __builtin_ia32_xsaves (__P, __M);
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_xrstors (void *__P, long long __M)
{
  __builtin_ia32_xrstors (__P, __M);
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_xrstors64 (void *__P, long long __M)
{
  __builtin_ia32_xrstors64 (__P, __M);
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_xsaves64 (void *__P, long long __M)
{
  __builtin_ia32_xsaves64 (__P, __M);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("rtm")
extern __inline int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_xtest (void)
{
  return __builtin_ia32_xtest ();
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target ("hreset")
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_hreset (unsigned int __EAX)
{
  __builtin_ia32_hreset (__EAX);
}
#pragma GCC pop_options
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_wbinvd (void)
{
  __builtin_ia32_wbinvd ();
}
#pragma GCC push_options
#pragma GCC target("rdrnd")
extern __inline int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_rdrand16_step (unsigned short *__P)
{
  return __builtin_ia32_rdrand16_step (__P);
}
extern __inline int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_rdrand32_step (unsigned int *__P)
{
  return __builtin_ia32_rdrand32_step (__P);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("rdpid")
extern __inline unsigned int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_rdpid_u32 (void)
{
  return __builtin_ia32_rdpid ();
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("fsgsbase")
extern __inline unsigned int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_readfsbase_u32 (void)
{
  return __builtin_ia32_rdfsbase32 ();
}
extern __inline unsigned long long
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_readfsbase_u64 (void)
{
  return __builtin_ia32_rdfsbase64 ();
}
extern __inline unsigned int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_readgsbase_u32 (void)
{
  return __builtin_ia32_rdgsbase32 ();
}
extern __inline unsigned long long
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_readgsbase_u64 (void)
{
  return __builtin_ia32_rdgsbase64 ();
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_writefsbase_u32 (unsigned int __B)
{
  __builtin_ia32_wrfsbase32 (__B);
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_writefsbase_u64 (unsigned long long __B)
{
  __builtin_ia32_wrfsbase64 (__B);
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_writegsbase_u32 (unsigned int __B)
{
  __builtin_ia32_wrgsbase32 (__B);
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_writegsbase_u64 (unsigned long long __B)
{
  __builtin_ia32_wrgsbase64 (__B);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("rdrnd")
extern __inline int
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_rdrand64_step (unsigned long long *__P)
{
  return __builtin_ia32_rdrand64_step (__P);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("ptwrite")
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_ptwrite64 (unsigned long long __B)
{
  __builtin_ia32_ptwrite64 (__B);
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_ptwrite32 (unsigned __B)
{
  __builtin_ia32_ptwrite32 (__B);
}
#pragma GCC pop_options
#pragma GCC pop_options
typedef int __m64 __attribute__ ((__vector_size__ (8), __may_alias__));
typedef int __m32 __attribute__ ((__vector_size__ (4), __may_alias__));
typedef short __m16 __attribute__ ((__vector_size__ (2), __may_alias__));
typedef int __m64_u __attribute__ ((__vector_size__ (8), __may_alias__, __aligned__ (1)));
typedef int __m32_u __attribute__ ((__vector_size__ (4), __may_alias__, __aligned__ (1)));
typedef short __m16_u __attribute__ ((__vector_size__ (2), __may_alias__, __aligned__ (1)));
typedef int __v2si __attribute__ ((__vector_size__ (8)));
typedef short __v4hi __attribute__ ((__vector_size__ (8)));
typedef char __v8qi __attribute__ ((__vector_size__ (8)));
typedef long long __v1di __attribute__ ((__vector_size__ (8)));
typedef float __v2sf __attribute__ ((__vector_size__ (8)));
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_empty (void)
{
  __builtin_ia32_emms ();
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_empty (void)
{
  _mm_empty ();
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsi32_si64 (int __i)
{
  return (__m64) __builtin_ia32_vec_init_v2si (__i, 0);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_from_int (int __i)
{
  return _mm_cvtsi32_si64 (__i);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_from_int64 (long long __i)
{
  return (__m64) __i;
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsi64_m64 (long long __i)
{
  return (__m64) __i;
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsi64x_si64 (long long __i)
{
  return (__m64) __i;
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set_pi64x (long long __i)
{
  return (__m64) __i;
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsi64_si32 (__m64 __i)
{
  return __builtin_ia32_vec_ext_v2si ((__v2si)__i, 0);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_to_int (__m64 __i)
{
  return _mm_cvtsi64_si32 (__i);
}
extern __inline long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_to_int64 (__m64 __i)
{
  return (long long)__i;
}
extern __inline long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtm64_si64 (__m64 __i)
{
  return (long long)__i;
}
extern __inline long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsi64_si64x (__m64 __i)
{
  return (long long)__i;
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_packs_pi16 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_packsswb ((__v4hi)__m1, (__v4hi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_packsswb (__m64 __m1, __m64 __m2)
{
  return _mm_packs_pi16 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_packs_pi32 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_packssdw ((__v2si)__m1, (__v2si)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_packssdw (__m64 __m1, __m64 __m2)
{
  return _mm_packs_pi32 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_packs_pu16 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_packuswb ((__v4hi)__m1, (__v4hi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_packuswb (__m64 __m1, __m64 __m2)
{
  return _mm_packs_pu16 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_unpackhi_pi8 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_punpckhbw ((__v8qi)__m1, (__v8qi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_punpckhbw (__m64 __m1, __m64 __m2)
{
  return _mm_unpackhi_pi8 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_unpackhi_pi16 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_punpckhwd ((__v4hi)__m1, (__v4hi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_punpckhwd (__m64 __m1, __m64 __m2)
{
  return _mm_unpackhi_pi16 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_unpackhi_pi32 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_punpckhdq ((__v2si)__m1, (__v2si)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_punpckhdq (__m64 __m1, __m64 __m2)
{
  return _mm_unpackhi_pi32 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_unpacklo_pi8 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_punpcklbw ((__v8qi)__m1, (__v8qi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_punpcklbw (__m64 __m1, __m64 __m2)
{
  return _mm_unpacklo_pi8 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_unpacklo_pi16 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_punpcklwd ((__v4hi)__m1, (__v4hi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_punpcklwd (__m64 __m1, __m64 __m2)
{
  return _mm_unpacklo_pi16 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_unpacklo_pi32 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_punpckldq ((__v2si)__m1, (__v2si)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_punpckldq (__m64 __m1, __m64 __m2)
{
  return _mm_unpacklo_pi32 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_add_pi8 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_paddb ((__v8qi)__m1, (__v8qi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_paddb (__m64 __m1, __m64 __m2)
{
  return _mm_add_pi8 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_add_pi16 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_paddw ((__v4hi)__m1, (__v4hi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_paddw (__m64 __m1, __m64 __m2)
{
  return _mm_add_pi16 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_add_pi32 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_paddd ((__v2si)__m1, (__v2si)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_paddd (__m64 __m1, __m64 __m2)
{
  return _mm_add_pi32 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_add_si64 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_paddq ((__v1di)__m1, (__v1di)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_adds_pi8 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_paddsb ((__v8qi)__m1, (__v8qi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_paddsb (__m64 __m1, __m64 __m2)
{
  return _mm_adds_pi8 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_adds_pi16 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_paddsw ((__v4hi)__m1, (__v4hi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_paddsw (__m64 __m1, __m64 __m2)
{
  return _mm_adds_pi16 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_adds_pu8 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_paddusb ((__v8qi)__m1, (__v8qi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_paddusb (__m64 __m1, __m64 __m2)
{
  return _mm_adds_pu8 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_adds_pu16 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_paddusw ((__v4hi)__m1, (__v4hi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_paddusw (__m64 __m1, __m64 __m2)
{
  return _mm_adds_pu16 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sub_pi8 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_psubb ((__v8qi)__m1, (__v8qi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psubb (__m64 __m1, __m64 __m2)
{
  return _mm_sub_pi8 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sub_pi16 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_psubw ((__v4hi)__m1, (__v4hi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psubw (__m64 __m1, __m64 __m2)
{
  return _mm_sub_pi16 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sub_pi32 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_psubd ((__v2si)__m1, (__v2si)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psubd (__m64 __m1, __m64 __m2)
{
  return _mm_sub_pi32 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sub_si64 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_psubq ((__v1di)__m1, (__v1di)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_subs_pi8 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_psubsb ((__v8qi)__m1, (__v8qi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psubsb (__m64 __m1, __m64 __m2)
{
  return _mm_subs_pi8 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_subs_pi16 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_psubsw ((__v4hi)__m1, (__v4hi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psubsw (__m64 __m1, __m64 __m2)
{
  return _mm_subs_pi16 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_subs_pu8 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_psubusb ((__v8qi)__m1, (__v8qi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psubusb (__m64 __m1, __m64 __m2)
{
  return _mm_subs_pu8 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_subs_pu16 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_psubusw ((__v4hi)__m1, (__v4hi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psubusw (__m64 __m1, __m64 __m2)
{
  return _mm_subs_pu16 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_madd_pi16 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_pmaddwd ((__v4hi)__m1, (__v4hi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pmaddwd (__m64 __m1, __m64 __m2)
{
  return _mm_madd_pi16 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mulhi_pi16 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_pmulhw ((__v4hi)__m1, (__v4hi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pmulhw (__m64 __m1, __m64 __m2)
{
  return _mm_mulhi_pi16 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mullo_pi16 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_pmullw ((__v4hi)__m1, (__v4hi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pmullw (__m64 __m1, __m64 __m2)
{
  return _mm_mullo_pi16 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sll_pi16 (__m64 __m, __m64 __count)
{
  return (__m64) __builtin_ia32_psllw ((__v4hi)__m, (__v4hi)__count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psllw (__m64 __m, __m64 __count)
{
  return _mm_sll_pi16 (__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_slli_pi16 (__m64 __m, int __count)
{
  return (__m64) __builtin_ia32_psllwi ((__v4hi)__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psllwi (__m64 __m, int __count)
{
  return _mm_slli_pi16 (__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sll_pi32 (__m64 __m, __m64 __count)
{
  return (__m64) __builtin_ia32_pslld ((__v2si)__m, (__v2si)__count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pslld (__m64 __m, __m64 __count)
{
  return _mm_sll_pi32 (__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_slli_pi32 (__m64 __m, int __count)
{
  return (__m64) __builtin_ia32_pslldi ((__v2si)__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pslldi (__m64 __m, int __count)
{
  return _mm_slli_pi32 (__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sll_si64 (__m64 __m, __m64 __count)
{
  return (__m64) __builtin_ia32_psllq ((__v1di)__m, (__v1di)__count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psllq (__m64 __m, __m64 __count)
{
  return _mm_sll_si64 (__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_slli_si64 (__m64 __m, int __count)
{
  return (__m64) __builtin_ia32_psllqi ((__v1di)__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psllqi (__m64 __m, int __count)
{
  return _mm_slli_si64 (__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sra_pi16 (__m64 __m, __m64 __count)
{
  return (__m64) __builtin_ia32_psraw ((__v4hi)__m, (__v4hi)__count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psraw (__m64 __m, __m64 __count)
{
  return _mm_sra_pi16 (__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_srai_pi16 (__m64 __m, int __count)
{
  return (__m64) __builtin_ia32_psrawi ((__v4hi)__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psrawi (__m64 __m, int __count)
{
  return _mm_srai_pi16 (__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sra_pi32 (__m64 __m, __m64 __count)
{
  return (__m64) __builtin_ia32_psrad ((__v2si)__m, (__v2si)__count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psrad (__m64 __m, __m64 __count)
{
  return _mm_sra_pi32 (__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_srai_pi32 (__m64 __m, int __count)
{
  return (__m64) __builtin_ia32_psradi ((__v2si)__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psradi (__m64 __m, int __count)
{
  return _mm_srai_pi32 (__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_srl_pi16 (__m64 __m, __m64 __count)
{
  return (__m64) __builtin_ia32_psrlw ((__v4hi)__m, (__v4hi)__count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psrlw (__m64 __m, __m64 __count)
{
  return _mm_srl_pi16 (__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_srli_pi16 (__m64 __m, int __count)
{
  return (__m64) __builtin_ia32_psrlwi ((__v4hi)__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psrlwi (__m64 __m, int __count)
{
  return _mm_srli_pi16 (__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_srl_pi32 (__m64 __m, __m64 __count)
{
  return (__m64) __builtin_ia32_psrld ((__v2si)__m, (__v2si)__count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psrld (__m64 __m, __m64 __count)
{
  return _mm_srl_pi32 (__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_srli_pi32 (__m64 __m, int __count)
{
  return (__m64) __builtin_ia32_psrldi ((__v2si)__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psrldi (__m64 __m, int __count)
{
  return _mm_srli_pi32 (__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_srl_si64 (__m64 __m, __m64 __count)
{
  return (__m64) __builtin_ia32_psrlq ((__v1di)__m, (__v1di)__count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psrlq (__m64 __m, __m64 __count)
{
  return _mm_srl_si64 (__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_srli_si64 (__m64 __m, int __count)
{
  return (__m64) __builtin_ia32_psrlqi ((__v1di)__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psrlqi (__m64 __m, int __count)
{
  return _mm_srli_si64 (__m, __count);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_and_si64 (__m64 __m1, __m64 __m2)
{
  return __builtin_ia32_pand (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pand (__m64 __m1, __m64 __m2)
{
  return _mm_and_si64 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_andnot_si64 (__m64 __m1, __m64 __m2)
{
  return __builtin_ia32_pandn (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pandn (__m64 __m1, __m64 __m2)
{
  return _mm_andnot_si64 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_or_si64 (__m64 __m1, __m64 __m2)
{
  return __builtin_ia32_por (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_por (__m64 __m1, __m64 __m2)
{
  return _mm_or_si64 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_xor_si64 (__m64 __m1, __m64 __m2)
{
  return __builtin_ia32_pxor (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pxor (__m64 __m1, __m64 __m2)
{
  return _mm_xor_si64 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpeq_pi8 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_pcmpeqb ((__v8qi)__m1, (__v8qi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pcmpeqb (__m64 __m1, __m64 __m2)
{
  return _mm_cmpeq_pi8 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpgt_pi8 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_pcmpgtb ((__v8qi)__m1, (__v8qi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pcmpgtb (__m64 __m1, __m64 __m2)
{
  return _mm_cmpgt_pi8 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpeq_pi16 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_pcmpeqw ((__v4hi)__m1, (__v4hi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pcmpeqw (__m64 __m1, __m64 __m2)
{
  return _mm_cmpeq_pi16 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpgt_pi16 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_pcmpgtw ((__v4hi)__m1, (__v4hi)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pcmpgtw (__m64 __m1, __m64 __m2)
{
  return _mm_cmpgt_pi16 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpeq_pi32 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_pcmpeqd ((__v2si)__m1, (__v2si)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pcmpeqd (__m64 __m1, __m64 __m2)
{
  return _mm_cmpeq_pi32 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpgt_pi32 (__m64 __m1, __m64 __m2)
{
  return (__m64) __builtin_ia32_pcmpgtd ((__v2si)__m1, (__v2si)__m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pcmpgtd (__m64 __m1, __m64 __m2)
{
  return _mm_cmpgt_pi32 (__m1, __m2);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_setzero_si64 (void)
{
  return (__m64)0LL;
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set_pi32 (int __i1, int __i0)
{
  return (__m64) __builtin_ia32_vec_init_v2si (__i0, __i1);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set_pi16 (short __w3, short __w2, short __w1, short __w0)
{
  return (__m64) __builtin_ia32_vec_init_v4hi (__w0, __w1, __w2, __w3);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set_pi8 (char __b7, char __b6, char __b5, char __b4,
      char __b3, char __b2, char __b1, char __b0)
{
  return (__m64) __builtin_ia32_vec_init_v8qi (__b0, __b1, __b2, __b3,
            __b4, __b5, __b6, __b7);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_setr_pi32 (int __i0, int __i1)
{
  return _mm_set_pi32 (__i1, __i0);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_setr_pi16 (short __w0, short __w1, short __w2, short __w3)
{
  return _mm_set_pi16 (__w3, __w2, __w1, __w0);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_setr_pi8 (char __b0, char __b1, char __b2, char __b3,
       char __b4, char __b5, char __b6, char __b7)
{
  return _mm_set_pi8 (__b7, __b6, __b5, __b4, __b3, __b2, __b1, __b0);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set1_pi32 (int __i)
{
  return _mm_set_pi32 (__i, __i);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set1_pi16 (short __w)
{
  return _mm_set_pi16 (__w, __w, __w, __w);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set1_pi8 (char __b)
{
  return _mm_set_pi8 (__b, __b, __b, __b, __b, __b, __b, __b);
}
extern int posix_memalign (void **, size_t, size_t);
static __inline void *
_mm_malloc (size_t __size, size_t __alignment)
{
  void *__ptr;
  if (__alignment == 1)
    return malloc (__size);
  if (__alignment == 2 || (sizeof (void *) == 8 && __alignment == 4))
    __alignment = sizeof (void *);
  if (posix_memalign (&__ptr, __alignment, __size) == 0)
    return __ptr;
  else
    return ((void *)0);
}
static __inline void
_mm_free (void *__ptr)
{
  free (__ptr);
}
enum _mm_hint
{
  _MM_HINT_ET0 = 7,
  _MM_HINT_ET1 = 6,
  _MM_HINT_T0 = 3,
  _MM_HINT_T1 = 2,
  _MM_HINT_T2 = 1,
  _MM_HINT_NTA = 0
};
typedef float __m128 __attribute__ ((__vector_size__ (16), __may_alias__));
typedef float __m128_u __attribute__ ((__vector_size__ (16), __may_alias__, __aligned__ (1)));
typedef float __v4sf __attribute__ ((__vector_size__ (16)));
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_undefined_ps (void)
{
  __m128 __Y = __Y;
  return __Y;
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_setzero_ps (void)
{
  return __extension__ (__m128){ 0.0f, 0.0f, 0.0f, 0.0f };
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_add_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_addss ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sub_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_subss ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mul_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_mulss ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_div_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_divss ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sqrt_ss (__m128 __A)
{
  return (__m128) __builtin_ia32_sqrtss ((__v4sf)__A);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_rcp_ss (__m128 __A)
{
  return (__m128) __builtin_ia32_rcpss ((__v4sf)__A);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_rsqrt_ss (__m128 __A)
{
  return (__m128) __builtin_ia32_rsqrtss ((__v4sf)__A);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_min_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_minss ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_max_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_maxss ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_add_ps (__m128 __A, __m128 __B)
{
  return (__m128) ((__v4sf)__A + (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sub_ps (__m128 __A, __m128 __B)
{
  return (__m128) ((__v4sf)__A - (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mul_ps (__m128 __A, __m128 __B)
{
  return (__m128) ((__v4sf)__A * (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_div_ps (__m128 __A, __m128 __B)
{
  return (__m128) ((__v4sf)__A / (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sqrt_ps (__m128 __A)
{
  return (__m128) __builtin_ia32_sqrtps ((__v4sf)__A);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_rcp_ps (__m128 __A)
{
  return (__m128) __builtin_ia32_rcpps ((__v4sf)__A);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_rsqrt_ps (__m128 __A)
{
  return (__m128) __builtin_ia32_rsqrtps ((__v4sf)__A);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_min_ps (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_minps ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_max_ps (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_maxps ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_and_ps (__m128 __A, __m128 __B)
{
  return __builtin_ia32_andps (__A, __B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_andnot_ps (__m128 __A, __m128 __B)
{
  return __builtin_ia32_andnps (__A, __B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_or_ps (__m128 __A, __m128 __B)
{
  return __builtin_ia32_orps (__A, __B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_xor_ps (__m128 __A, __m128 __B)
{
  return __builtin_ia32_xorps (__A, __B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpeq_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_cmpeqss ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmplt_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_cmpltss ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmple_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_cmpless ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpgt_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_movss ((__v4sf) __A,
     (__v4sf)
     __builtin_ia32_cmpltss ((__v4sf) __B,
        (__v4sf)
        __A));
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpge_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_movss ((__v4sf) __A,
     (__v4sf)
     __builtin_ia32_cmpless ((__v4sf) __B,
        (__v4sf)
        __A));
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpneq_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_cmpneqss ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpnlt_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_cmpnltss ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpnle_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_cmpnless ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpngt_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_movss ((__v4sf) __A,
     (__v4sf)
     __builtin_ia32_cmpnltss ((__v4sf) __B,
         (__v4sf)
         __A));
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpnge_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_movss ((__v4sf) __A,
     (__v4sf)
     __builtin_ia32_cmpnless ((__v4sf) __B,
         (__v4sf)
         __A));
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpord_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_cmpordss ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpunord_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_cmpunordss ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpeq_ps (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_cmpeqps ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmplt_ps (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_cmpltps ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmple_ps (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_cmpleps ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpgt_ps (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_cmpgtps ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpge_ps (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_cmpgeps ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpneq_ps (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_cmpneqps ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpnlt_ps (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_cmpnltps ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpnle_ps (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_cmpnleps ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpngt_ps (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_cmpngtps ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpnge_ps (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_cmpngeps ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpord_ps (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_cmpordps ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpunord_ps (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_cmpunordps ((__v4sf)__A, (__v4sf)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comieq_ss (__m128 __A, __m128 __B)
{
  return __builtin_ia32_comieq ((__v4sf)__A, (__v4sf)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comilt_ss (__m128 __A, __m128 __B)
{
  return __builtin_ia32_comilt ((__v4sf)__A, (__v4sf)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comile_ss (__m128 __A, __m128 __B)
{
  return __builtin_ia32_comile ((__v4sf)__A, (__v4sf)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comigt_ss (__m128 __A, __m128 __B)
{
  return __builtin_ia32_comigt ((__v4sf)__A, (__v4sf)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comige_ss (__m128 __A, __m128 __B)
{
  return __builtin_ia32_comige ((__v4sf)__A, (__v4sf)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comineq_ss (__m128 __A, __m128 __B)
{
  return __builtin_ia32_comineq ((__v4sf)__A, (__v4sf)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_ucomieq_ss (__m128 __A, __m128 __B)
{
  return __builtin_ia32_ucomieq ((__v4sf)__A, (__v4sf)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_ucomilt_ss (__m128 __A, __m128 __B)
{
  return __builtin_ia32_ucomilt ((__v4sf)__A, (__v4sf)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_ucomile_ss (__m128 __A, __m128 __B)
{
  return __builtin_ia32_ucomile ((__v4sf)__A, (__v4sf)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_ucomigt_ss (__m128 __A, __m128 __B)
{
  return __builtin_ia32_ucomigt ((__v4sf)__A, (__v4sf)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_ucomige_ss (__m128 __A, __m128 __B)
{
  return __builtin_ia32_ucomige ((__v4sf)__A, (__v4sf)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_ucomineq_ss (__m128 __A, __m128 __B)
{
  return __builtin_ia32_ucomineq ((__v4sf)__A, (__v4sf)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtss_si32 (__m128 __A)
{
  return __builtin_ia32_cvtss2si ((__v4sf) __A);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvt_ss2si (__m128 __A)
{
  return _mm_cvtss_si32 (__A);
}
extern __inline long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtss_si64 (__m128 __A)
{
  return __builtin_ia32_cvtss2si64 ((__v4sf) __A);
}
extern __inline long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtss_si64x (__m128 __A)
{
  return __builtin_ia32_cvtss2si64 ((__v4sf) __A);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtps_pi32 (__m128 __A)
{
  return (__m64) __builtin_ia32_cvtps2pi ((__v4sf) __A);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvt_ps2pi (__m128 __A)
{
  return _mm_cvtps_pi32 (__A);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttss_si32 (__m128 __A)
{
  return __builtin_ia32_cvttss2si ((__v4sf) __A);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtt_ss2si (__m128 __A)
{
  return _mm_cvttss_si32 (__A);
}
extern __inline long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttss_si64 (__m128 __A)
{
  return __builtin_ia32_cvttss2si64 ((__v4sf) __A);
}
extern __inline long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttss_si64x (__m128 __A)
{
  return __builtin_ia32_cvttss2si64 ((__v4sf) __A);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttps_pi32 (__m128 __A)
{
  return (__m64) __builtin_ia32_cvttps2pi ((__v4sf) __A);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtt_ps2pi (__m128 __A)
{
  return _mm_cvttps_pi32 (__A);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsi32_ss (__m128 __A, int __B)
{
  return (__m128) __builtin_ia32_cvtsi2ss ((__v4sf) __A, __B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvt_si2ss (__m128 __A, int __B)
{
  return _mm_cvtsi32_ss (__A, __B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsi64_ss (__m128 __A, long long __B)
{
  return (__m128) __builtin_ia32_cvtsi642ss ((__v4sf) __A, __B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsi64x_ss (__m128 __A, long long __B)
{
  return (__m128) __builtin_ia32_cvtsi642ss ((__v4sf) __A, __B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtpi32_ps (__m128 __A, __m64 __B)
{
  return (__m128) __builtin_ia32_cvtpi2ps ((__v4sf) __A, (__v2si)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvt_pi2ps (__m128 __A, __m64 __B)
{
  return _mm_cvtpi32_ps (__A, __B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtpi16_ps (__m64 __A)
{
  __v4hi __sign;
  __v2si __hisi, __losi;
  __v4sf __zero, __ra, __rb;
  __sign = __builtin_ia32_pcmpgtw ((__v4hi)0LL, (__v4hi)__A);
  __losi = (__v2si) __builtin_ia32_punpcklwd ((__v4hi)__A, __sign);
  __hisi = (__v2si) __builtin_ia32_punpckhwd ((__v4hi)__A, __sign);
  __zero = (__v4sf) _mm_setzero_ps ();
  __ra = __builtin_ia32_cvtpi2ps (__zero, __losi);
  __rb = __builtin_ia32_cvtpi2ps (__ra, __hisi);
  return (__m128) __builtin_ia32_movlhps (__ra, __rb);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtpu16_ps (__m64 __A)
{
  __v2si __hisi, __losi;
  __v4sf __zero, __ra, __rb;
  __losi = (__v2si) __builtin_ia32_punpcklwd ((__v4hi)__A, (__v4hi)0LL);
  __hisi = (__v2si) __builtin_ia32_punpckhwd ((__v4hi)__A, (__v4hi)0LL);
  __zero = (__v4sf) _mm_setzero_ps ();
  __ra = __builtin_ia32_cvtpi2ps (__zero, __losi);
  __rb = __builtin_ia32_cvtpi2ps (__ra, __hisi);
  return (__m128) __builtin_ia32_movlhps (__ra, __rb);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtpi8_ps (__m64 __A)
{
  __v8qi __sign;
  __sign = __builtin_ia32_pcmpgtb ((__v8qi)0LL, (__v8qi)__A);
  __A = (__m64) __builtin_ia32_punpcklbw ((__v8qi)__A, __sign);
  return _mm_cvtpi16_ps(__A);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtpu8_ps(__m64 __A)
{
  __A = (__m64) __builtin_ia32_punpcklbw ((__v8qi)__A, (__v8qi)0LL);
  return _mm_cvtpu16_ps(__A);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtpi32x2_ps(__m64 __A, __m64 __B)
{
  __v4sf __zero = (__v4sf) _mm_setzero_ps ();
  __v4sf __sfa = __builtin_ia32_cvtpi2ps (__zero, (__v2si)__A);
  __v4sf __sfb = __builtin_ia32_cvtpi2ps (__sfa, (__v2si)__B);
  return (__m128) __builtin_ia32_movlhps (__sfa, __sfb);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtps_pi16(__m128 __A)
{
  __v4sf __hisf = (__v4sf)__A;
  __v4sf __losf = __builtin_ia32_movhlps (__hisf, __hisf);
  __v2si __hisi = __builtin_ia32_cvtps2pi (__hisf);
  __v2si __losi = __builtin_ia32_cvtps2pi (__losf);
  return (__m64) __builtin_ia32_packssdw (__hisi, __losi);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtps_pi8(__m128 __A)
{
  __v4hi __tmp = (__v4hi) _mm_cvtps_pi16 (__A);
  return (__m64) __builtin_ia32_packsswb (__tmp, (__v4hi)0LL);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_unpackhi_ps (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_unpckhps ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_unpacklo_ps (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_unpcklps ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_loadh_pi (__m128 __A, __m64 const *__P)
{
  return (__m128) __builtin_ia32_loadhps ((__v4sf)__A, (const __v2sf *)__P);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_storeh_pi (__m64 *__P, __m128 __A)
{
  __builtin_ia32_storehps ((__v2sf *)__P, (__v4sf)__A);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_movehl_ps (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_movhlps ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_movelh_ps (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_movlhps ((__v4sf)__A, (__v4sf)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_loadl_pi (__m128 __A, __m64 const *__P)
{
  return (__m128) __builtin_ia32_loadlps ((__v4sf)__A, (const __v2sf *)__P);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_storel_pi (__m64 *__P, __m128 __A)
{
  __builtin_ia32_storelps ((__v2sf *)__P, (__v4sf)__A);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_movemask_ps (__m128 __A)
{
  return __builtin_ia32_movmskps ((__v4sf)__A);
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_getcsr (void)
{
  return __builtin_ia32_stmxcsr ();
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_MM_GET_EXCEPTION_STATE (void)
{
  return _mm_getcsr() & 0x003f;
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_MM_GET_EXCEPTION_MASK (void)
{
  return _mm_getcsr() & 0x1f80;
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_MM_GET_ROUNDING_MODE (void)
{
  return _mm_getcsr() & 0x6000;
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_MM_GET_FLUSH_ZERO_MODE (void)
{
  return _mm_getcsr() & 0x8000;
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_setcsr (unsigned int __I)
{
  __builtin_ia32_ldmxcsr (__I);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_MM_SET_EXCEPTION_STATE(unsigned int __mask)
{
  _mm_setcsr((_mm_getcsr() & ~0x003f) | __mask);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_MM_SET_EXCEPTION_MASK (unsigned int __mask)
{
  _mm_setcsr((_mm_getcsr() & ~0x1f80) | __mask);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_MM_SET_ROUNDING_MODE (unsigned int __mode)
{
  _mm_setcsr((_mm_getcsr() & ~0x6000) | __mode);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_MM_SET_FLUSH_ZERO_MODE (unsigned int __mode)
{
  _mm_setcsr((_mm_getcsr() & ~0x8000) | __mode);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set_ss (float __F)
{
  return __extension__ (__m128)(__v4sf){ __F, 0.0f, 0.0f, 0.0f };
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set1_ps (float __F)
{
  return __extension__ (__m128)(__v4sf){ __F, __F, __F, __F };
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set_ps1 (float __F)
{
  return _mm_set1_ps (__F);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_load_ss (float const *__P)
{
  return _mm_set_ss (*__P);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_load1_ps (float const *__P)
{
  return _mm_set1_ps (*__P);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_load_ps1 (float const *__P)
{
  return _mm_load1_ps (__P);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_load_ps (float const *__P)
{
  return *(__m128 *)__P;
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_loadu_ps (float const *__P)
{
  return *(__m128_u *)__P;
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_loadr_ps (float const *__P)
{
  __v4sf __tmp = *(__v4sf *)__P;
  return (__m128) __builtin_ia32_shufps (__tmp, __tmp, (((0) << 6) | ((1) << 4) | ((2) << 2) | (3)));
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set_ps (const float __Z, const float __Y, const float __X, const float __W)
{
  return __extension__ (__m128)(__v4sf){ __W, __X, __Y, __Z };
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_setr_ps (float __Z, float __Y, float __X, float __W)
{
  return __extension__ (__m128)(__v4sf){ __Z, __Y, __X, __W };
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_store_ss (float *__P, __m128 __A)
{
  *__P = ((__v4sf)__A)[0];
}
extern __inline float __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtss_f32 (__m128 __A)
{
  return ((__v4sf)__A)[0];
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_store_ps (float *__P, __m128 __A)
{
  *(__m128 *)__P = __A;
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_storeu_ps (float *__P, __m128 __A)
{
  *(__m128_u *)__P = __A;
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_store1_ps (float *__P, __m128 __A)
{
  __v4sf __va = (__v4sf)__A;
  __v4sf __tmp = __builtin_ia32_shufps (__va, __va, (((0) << 6) | ((0) << 4) | ((0) << 2) | (0)));
  _mm_storeu_ps (__P, __tmp);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_store_ps1 (float *__P, __m128 __A)
{
  _mm_store1_ps (__P, __A);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_storer_ps (float *__P, __m128 __A)
{
  __v4sf __va = (__v4sf)__A;
  __v4sf __tmp = __builtin_ia32_shufps (__va, __va, (((0) << 6) | ((1) << 4) | ((2) << 2) | (3)));
  _mm_store_ps (__P, __tmp);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_move_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_shuffle ((__v4sf)__A, (__v4sf)__B,
                                     __extension__
                                     (__attribute__((__vector_size__ (16))) int)
                                     {4,1,2,3});
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_max_pi16 (__m64 __A, __m64 __B)
{
  return (__m64) __builtin_ia32_pmaxsw ((__v4hi)__A, (__v4hi)__B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pmaxsw (__m64 __A, __m64 __B)
{
  return _mm_max_pi16 (__A, __B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_max_pu8 (__m64 __A, __m64 __B)
{
  return (__m64) __builtin_ia32_pmaxub ((__v8qi)__A, (__v8qi)__B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pmaxub (__m64 __A, __m64 __B)
{
  return _mm_max_pu8 (__A, __B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_min_pi16 (__m64 __A, __m64 __B)
{
  return (__m64) __builtin_ia32_pminsw ((__v4hi)__A, (__v4hi)__B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pminsw (__m64 __A, __m64 __B)
{
  return _mm_min_pi16 (__A, __B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_min_pu8 (__m64 __A, __m64 __B)
{
  return (__m64) __builtin_ia32_pminub ((__v8qi)__A, (__v8qi)__B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pminub (__m64 __A, __m64 __B)
{
  return _mm_min_pu8 (__A, __B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_movemask_pi8 (__m64 __A)
{
  return __builtin_ia32_pmovmskb ((__v8qi)__A);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pmovmskb (__m64 __A)
{
  return _mm_movemask_pi8 (__A);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mulhi_pu16 (__m64 __A, __m64 __B)
{
  return (__m64) __builtin_ia32_pmulhuw ((__v4hi)__A, (__v4hi)__B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pmulhuw (__m64 __A, __m64 __B)
{
  return _mm_mulhi_pu16 (__A, __B);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskmove_si64 (__m64 __A, __m64 __N, char *__P)
{
  typedef long long __v2di __attribute__ ((__vector_size__ (16)));
  typedef char __v16qi __attribute__ ((__vector_size__ (16)));
  __v2di __A128 = __extension__ (__v2di) { ((__v1di) __A)[0], 0 };
  __v2di __N128 = __extension__ (__v2di) { ((__v1di) __N)[0], 0 };
  long unsigned int offset = ((long unsigned int) __P) & 0xf;
  if (offset)
    {
      if (offset > 8)
 offset = 8;
      __P = (char *) (((long unsigned int) __P) - offset);
      switch (offset)
 {
 case 1:
   __A128 = __builtin_ia32_pslldqi128 (__A128, 8);
   __N128 = __builtin_ia32_pslldqi128 (__N128, 8);
   break;
 case 2:
   __A128 = __builtin_ia32_pslldqi128 (__A128, 2 * 8);
   __N128 = __builtin_ia32_pslldqi128 (__N128, 2 * 8);
   break;
 case 3:
   __A128 = __builtin_ia32_pslldqi128 (__A128, 3 * 8);
   __N128 = __builtin_ia32_pslldqi128 (__N128, 3 * 8);
   break;
 case 4:
   __A128 = __builtin_ia32_pslldqi128 (__A128, 4 * 8);
   __N128 = __builtin_ia32_pslldqi128 (__N128, 4 * 8);
   break;
 case 5:
   __A128 = __builtin_ia32_pslldqi128 (__A128, 5 * 8);
   __N128 = __builtin_ia32_pslldqi128 (__N128, 5 * 8);
   break;
 case 6:
   __A128 = __builtin_ia32_pslldqi128 (__A128, 6 * 8);
   __N128 = __builtin_ia32_pslldqi128 (__N128, 6 * 8);
   break;
 case 7:
   __A128 = __builtin_ia32_pslldqi128 (__A128, 7 * 8);
   __N128 = __builtin_ia32_pslldqi128 (__N128, 7 * 8);
   break;
 case 8:
   __A128 = __builtin_ia32_pslldqi128 (__A128, 8 * 8);
   __N128 = __builtin_ia32_pslldqi128 (__N128, 8 * 8);
   break;
 default:
   break;
 }
    }
  __builtin_ia32_maskmovdqu ((__v16qi)__A128, (__v16qi)__N128, __P);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_maskmovq (__m64 __A, __m64 __N, char *__P)
{
  _mm_maskmove_si64 (__A, __N, __P);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_avg_pu8 (__m64 __A, __m64 __B)
{
  return (__m64) __builtin_ia32_pavgb ((__v8qi)__A, (__v8qi)__B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pavgb (__m64 __A, __m64 __B)
{
  return _mm_avg_pu8 (__A, __B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_avg_pu16 (__m64 __A, __m64 __B)
{
  return (__m64) __builtin_ia32_pavgw ((__v4hi)__A, (__v4hi)__B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pavgw (__m64 __A, __m64 __B)
{
  return _mm_avg_pu16 (__A, __B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sad_pu8 (__m64 __A, __m64 __B)
{
  return (__m64) __builtin_ia32_psadbw ((__v8qi)__A, (__v8qi)__B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_psadbw (__m64 __A, __m64 __B)
{
  return _mm_sad_pu8 (__A, __B);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_stream_pi (__m64 *__P, __m64 __A)
{
  __builtin_ia32_movntq ((unsigned long long *)__P, (unsigned long long)__A);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_stream_ps (float *__P, __m128 __A)
{
  __builtin_ia32_movntps (__P, (__v4sf)__A);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sfence (void)
{
  __builtin_ia32_sfence ();
}
typedef double __v2df __attribute__ ((__vector_size__ (16)));
typedef long long __v2di __attribute__ ((__vector_size__ (16)));
typedef unsigned long long __v2du __attribute__ ((__vector_size__ (16)));
typedef int __v4si __attribute__ ((__vector_size__ (16)));
typedef unsigned int __v4su __attribute__ ((__vector_size__ (16)));
typedef short __v8hi __attribute__ ((__vector_size__ (16)));
typedef unsigned short __v8hu __attribute__ ((__vector_size__ (16)));
typedef char __v16qi __attribute__ ((__vector_size__ (16)));
typedef signed char __v16qs __attribute__ ((__vector_size__ (16)));
typedef unsigned char __v16qu __attribute__ ((__vector_size__ (16)));
typedef long long __m128i __attribute__ ((__vector_size__ (16), __may_alias__));
typedef double __m128d __attribute__ ((__vector_size__ (16), __may_alias__));
typedef long long __m128i_u __attribute__ ((__vector_size__ (16), __may_alias__, __aligned__ (1)));
typedef double __m128d_u __attribute__ ((__vector_size__ (16), __may_alias__, __aligned__ (1)));
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set_sd (double __F)
{
  return __extension__ (__m128d){ __F, 0.0 };
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set1_pd (double __F)
{
  return __extension__ (__m128d){ __F, __F };
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set_pd1 (double __F)
{
  return _mm_set1_pd (__F);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set_pd (double __W, double __X)
{
  return __extension__ (__m128d){ __X, __W };
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_setr_pd (double __W, double __X)
{
  return __extension__ (__m128d){ __W, __X };
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_undefined_pd (void)
{
  __m128d __Y = __Y;
  return __Y;
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_setzero_pd (void)
{
  return __extension__ (__m128d){ 0.0, 0.0 };
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_move_sd (__m128d __A, __m128d __B)
{
  return __extension__ (__m128d) __builtin_shuffle ((__v2df)__A, (__v2df)__B, (__v2di){2, 1});
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_load_pd (double const *__P)
{
  return *(__m128d *)__P;
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_loadu_pd (double const *__P)
{
  return *(__m128d_u *)__P;
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_load1_pd (double const *__P)
{
  return _mm_set1_pd (*__P);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_load_sd (double const *__P)
{
  return _mm_set_sd (*__P);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_load_pd1 (double const *__P)
{
  return _mm_load1_pd (__P);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_loadr_pd (double const *__P)
{
  __m128d __tmp = _mm_load_pd (__P);
  return __builtin_ia32_shufpd (__tmp, __tmp, (((0) << 1) | (1)));
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_store_pd (double *__P, __m128d __A)
{
  *(__m128d *)__P = __A;
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_storeu_pd (double *__P, __m128d __A)
{
  *(__m128d_u *)__P = __A;
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_store_sd (double *__P, __m128d __A)
{
  *__P = ((__v2df)__A)[0];
}
extern __inline double __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsd_f64 (__m128d __A)
{
  return ((__v2df)__A)[0];
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_storel_pd (double *__P, __m128d __A)
{
  _mm_store_sd (__P, __A);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_storeh_pd (double *__P, __m128d __A)
{
  *__P = ((__v2df)__A)[1];
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_store1_pd (double *__P, __m128d __A)
{
  _mm_store_pd (__P, __builtin_ia32_shufpd (__A, __A, (((0) << 1) | (0))));
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_store_pd1 (double *__P, __m128d __A)
{
  _mm_store1_pd (__P, __A);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_storer_pd (double *__P, __m128d __A)
{
  _mm_store_pd (__P, __builtin_ia32_shufpd (__A, __A, (((0) << 1) | (1))));
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsi128_si32 (__m128i __A)
{
  return __builtin_ia32_vec_ext_v4si ((__v4si)__A, 0);
}
extern __inline long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsi128_si64 (__m128i __A)
{
  return ((__v2di)__A)[0];
}
extern __inline long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsi128_si64x (__m128i __A)
{
  return ((__v2di)__A)[0];
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_add_pd (__m128d __A, __m128d __B)
{
  return (__m128d) ((__v2df)__A + (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_add_sd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_addsd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sub_pd (__m128d __A, __m128d __B)
{
  return (__m128d) ((__v2df)__A - (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sub_sd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_subsd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mul_pd (__m128d __A, __m128d __B)
{
  return (__m128d) ((__v2df)__A * (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mul_sd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_mulsd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_div_pd (__m128d __A, __m128d __B)
{
  return (__m128d) ((__v2df)__A / (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_div_sd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_divsd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sqrt_pd (__m128d __A)
{
  return (__m128d)__builtin_ia32_sqrtpd ((__v2df)__A);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sqrt_sd (__m128d __A, __m128d __B)
{
  __v2df __tmp = __builtin_ia32_movsd ((__v2df)__A, (__v2df)__B);
  return (__m128d)__builtin_ia32_sqrtsd ((__v2df)__tmp);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_min_pd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_minpd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_min_sd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_minsd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_max_pd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_maxpd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_max_sd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_maxsd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_and_pd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_andpd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_andnot_pd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_andnpd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_or_pd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_orpd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_xor_pd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_xorpd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpeq_pd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_cmpeqpd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmplt_pd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_cmpltpd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmple_pd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_cmplepd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpgt_pd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_cmpgtpd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpge_pd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_cmpgepd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpneq_pd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_cmpneqpd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpnlt_pd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_cmpnltpd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpnle_pd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_cmpnlepd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpngt_pd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_cmpngtpd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpnge_pd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_cmpngepd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpord_pd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_cmpordpd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpunord_pd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_cmpunordpd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpeq_sd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_cmpeqsd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmplt_sd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_cmpltsd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmple_sd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_cmplesd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpgt_sd (__m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_movsd ((__v2df) __A,
      (__v2df)
      __builtin_ia32_cmpltsd ((__v2df) __B,
         (__v2df)
         __A));
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpge_sd (__m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_movsd ((__v2df) __A,
      (__v2df)
      __builtin_ia32_cmplesd ((__v2df) __B,
         (__v2df)
         __A));
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpneq_sd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_cmpneqsd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpnlt_sd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_cmpnltsd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpnle_sd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_cmpnlesd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpngt_sd (__m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_movsd ((__v2df) __A,
      (__v2df)
      __builtin_ia32_cmpnltsd ((__v2df) __B,
          (__v2df)
          __A));
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpnge_sd (__m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_movsd ((__v2df) __A,
      (__v2df)
      __builtin_ia32_cmpnlesd ((__v2df) __B,
          (__v2df)
          __A));
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpord_sd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_cmpordsd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpunord_sd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_cmpunordsd ((__v2df)__A, (__v2df)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comieq_sd (__m128d __A, __m128d __B)
{
  return __builtin_ia32_comisdeq ((__v2df)__A, (__v2df)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comilt_sd (__m128d __A, __m128d __B)
{
  return __builtin_ia32_comisdlt ((__v2df)__A, (__v2df)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comile_sd (__m128d __A, __m128d __B)
{
  return __builtin_ia32_comisdle ((__v2df)__A, (__v2df)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comigt_sd (__m128d __A, __m128d __B)
{
  return __builtin_ia32_comisdgt ((__v2df)__A, (__v2df)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comige_sd (__m128d __A, __m128d __B)
{
  return __builtin_ia32_comisdge ((__v2df)__A, (__v2df)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comineq_sd (__m128d __A, __m128d __B)
{
  return __builtin_ia32_comisdneq ((__v2df)__A, (__v2df)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_ucomieq_sd (__m128d __A, __m128d __B)
{
  return __builtin_ia32_ucomisdeq ((__v2df)__A, (__v2df)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_ucomilt_sd (__m128d __A, __m128d __B)
{
  return __builtin_ia32_ucomisdlt ((__v2df)__A, (__v2df)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_ucomile_sd (__m128d __A, __m128d __B)
{
  return __builtin_ia32_ucomisdle ((__v2df)__A, (__v2df)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_ucomigt_sd (__m128d __A, __m128d __B)
{
  return __builtin_ia32_ucomisdgt ((__v2df)__A, (__v2df)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_ucomige_sd (__m128d __A, __m128d __B)
{
  return __builtin_ia32_ucomisdge ((__v2df)__A, (__v2df)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_ucomineq_sd (__m128d __A, __m128d __B)
{
  return __builtin_ia32_ucomisdneq ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set_epi64x (long long __q1, long long __q0)
{
  return __extension__ (__m128i)(__v2di){ __q0, __q1 };
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set_epi64 (__m64 __q1, __m64 __q0)
{
  return _mm_set_epi64x ((long long)__q1, (long long)__q0);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set_epi32 (int __q3, int __q2, int __q1, int __q0)
{
  return __extension__ (__m128i)(__v4si){ __q0, __q1, __q2, __q3 };
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set_epi16 (short __q7, short __q6, short __q5, short __q4,
        short __q3, short __q2, short __q1, short __q0)
{
  return __extension__ (__m128i)(__v8hi){
    __q0, __q1, __q2, __q3, __q4, __q5, __q6, __q7 };
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set_epi8 (char __q15, char __q14, char __q13, char __q12,
       char __q11, char __q10, char __q09, char __q08,
       char __q07, char __q06, char __q05, char __q04,
       char __q03, char __q02, char __q01, char __q00)
{
  return __extension__ (__m128i)(__v16qi){
    __q00, __q01, __q02, __q03, __q04, __q05, __q06, __q07,
    __q08, __q09, __q10, __q11, __q12, __q13, __q14, __q15
  };
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set1_epi64x (long long __A)
{
  return _mm_set_epi64x (__A, __A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set1_epi64 (__m64 __A)
{
  return _mm_set_epi64 (__A, __A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set1_epi32 (int __A)
{
  return _mm_set_epi32 (__A, __A, __A, __A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set1_epi16 (short __A)
{
  return _mm_set_epi16 (__A, __A, __A, __A, __A, __A, __A, __A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_set1_epi8 (char __A)
{
  return _mm_set_epi8 (__A, __A, __A, __A, __A, __A, __A, __A,
         __A, __A, __A, __A, __A, __A, __A, __A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_setr_epi64 (__m64 __q0, __m64 __q1)
{
  return _mm_set_epi64 (__q1, __q0);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_setr_epi32 (int __q0, int __q1, int __q2, int __q3)
{
  return _mm_set_epi32 (__q3, __q2, __q1, __q0);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_setr_epi16 (short __q0, short __q1, short __q2, short __q3,
         short __q4, short __q5, short __q6, short __q7)
{
  return _mm_set_epi16 (__q7, __q6, __q5, __q4, __q3, __q2, __q1, __q0);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_setr_epi8 (char __q00, char __q01, char __q02, char __q03,
        char __q04, char __q05, char __q06, char __q07,
        char __q08, char __q09, char __q10, char __q11,
        char __q12, char __q13, char __q14, char __q15)
{
  return _mm_set_epi8 (__q15, __q14, __q13, __q12, __q11, __q10, __q09, __q08,
         __q07, __q06, __q05, __q04, __q03, __q02, __q01, __q00);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_load_si128 (__m128i const *__P)
{
  return *__P;
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_loadu_si128 (__m128i_u const *__P)
{
  return *__P;
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_loadl_epi64 (__m128i_u const *__P)
{
  return _mm_set_epi64 ((__m64)0LL, *(__m64_u *)__P);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_loadu_si64 (void const *__P)
{
  return _mm_loadl_epi64 ((__m128i_u *)__P);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_loadu_si32 (void const *__P)
{
  return _mm_set_epi32 (0, 0, 0, (*(__m32_u *)__P)[0]);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_loadu_si16 (void const *__P)
{
  return _mm_set_epi16 (0, 0, 0, 0, 0, 0, 0, (*(__m16_u *)__P)[0]);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_store_si128 (__m128i *__P, __m128i __B)
{
  *__P = __B;
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_storeu_si128 (__m128i_u *__P, __m128i __B)
{
  *__P = __B;
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_storel_epi64 (__m128i_u *__P, __m128i __B)
{
  *(__m64_u *)__P = (__m64) ((__v2di)__B)[0];
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_storeu_si64 (void *__P, __m128i __B)
{
  _mm_storel_epi64 ((__m128i_u *)__P, __B);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_storeu_si32 (void *__P, __m128i __B)
{
  *(__m32_u *)__P = (__m32) ((__v4si)__B)[0];
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_storeu_si16 (void *__P, __m128i __B)
{
  *(__m16_u *)__P = (__m16) ((__v8hi)__B)[0];
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_movepi64_pi64 (__m128i __B)
{
  return (__m64) ((__v2di)__B)[0];
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_movpi64_epi64 (__m64 __A)
{
  return _mm_set_epi64 ((__m64)0LL, __A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_move_epi64 (__m128i __A)
{
  return (__m128i)__builtin_ia32_movq128 ((__v2di) __A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_undefined_si128 (void)
{
  __m128i __Y = __Y;
  return __Y;
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_setzero_si128 (void)
{
  return __extension__ (__m128i)(__v4si){ 0, 0, 0, 0 };
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepi32_pd (__m128i __A)
{
  return (__m128d)__builtin_ia32_cvtdq2pd ((__v4si) __A);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepi32_ps (__m128i __A)
{
  return (__m128)__builtin_ia32_cvtdq2ps ((__v4si) __A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtpd_epi32 (__m128d __A)
{
  return (__m128i)__builtin_ia32_cvtpd2dq ((__v2df) __A);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtpd_pi32 (__m128d __A)
{
  return (__m64)__builtin_ia32_cvtpd2pi ((__v2df) __A);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtpd_ps (__m128d __A)
{
  return (__m128)__builtin_ia32_cvtpd2ps ((__v2df) __A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttpd_epi32 (__m128d __A)
{
  return (__m128i)__builtin_ia32_cvttpd2dq ((__v2df) __A);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttpd_pi32 (__m128d __A)
{
  return (__m64)__builtin_ia32_cvttpd2pi ((__v2df) __A);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtpi32_pd (__m64 __A)
{
  return (__m128d)__builtin_ia32_cvtpi2pd ((__v2si) __A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtps_epi32 (__m128 __A)
{
  return (__m128i)__builtin_ia32_cvtps2dq ((__v4sf) __A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttps_epi32 (__m128 __A)
{
  return (__m128i)__builtin_ia32_cvttps2dq ((__v4sf) __A);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtps_pd (__m128 __A)
{
  return (__m128d)__builtin_ia32_cvtps2pd ((__v4sf) __A);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsd_si32 (__m128d __A)
{
  return __builtin_ia32_cvtsd2si ((__v2df) __A);
}
extern __inline long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsd_si64 (__m128d __A)
{
  return __builtin_ia32_cvtsd2si64 ((__v2df) __A);
}
extern __inline long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsd_si64x (__m128d __A)
{
  return __builtin_ia32_cvtsd2si64 ((__v2df) __A);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttsd_si32 (__m128d __A)
{
  return __builtin_ia32_cvttsd2si ((__v2df) __A);
}
extern __inline long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttsd_si64 (__m128d __A)
{
  return __builtin_ia32_cvttsd2si64 ((__v2df) __A);
}
extern __inline long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttsd_si64x (__m128d __A)
{
  return __builtin_ia32_cvttsd2si64 ((__v2df) __A);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsd_ss (__m128 __A, __m128d __B)
{
  return (__m128)__builtin_ia32_cvtsd2ss ((__v4sf) __A, (__v2df) __B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsi32_sd (__m128d __A, int __B)
{
  return (__m128d)__builtin_ia32_cvtsi2sd ((__v2df) __A, __B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsi64_sd (__m128d __A, long long __B)
{
  return (__m128d)__builtin_ia32_cvtsi642sd ((__v2df) __A, __B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsi64x_sd (__m128d __A, long long __B)
{
  return (__m128d)__builtin_ia32_cvtsi642sd ((__v2df) __A, __B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtss_sd (__m128d __A, __m128 __B)
{
  return (__m128d)__builtin_ia32_cvtss2sd ((__v2df) __A, (__v4sf)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_unpackhi_pd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_unpckhpd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_unpacklo_pd (__m128d __A, __m128d __B)
{
  return (__m128d)__builtin_ia32_unpcklpd ((__v2df)__A, (__v2df)__B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_loadh_pd (__m128d __A, double const *__B)
{
  return (__m128d)__builtin_ia32_loadhpd ((__v2df)__A, __B);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_loadl_pd (__m128d __A, double const *__B)
{
  return (__m128d)__builtin_ia32_loadlpd ((__v2df)__A, __B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_movemask_pd (__m128d __A)
{
  return __builtin_ia32_movmskpd ((__v2df)__A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_packs_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_packsswb128 ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_packs_epi32 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_packssdw128 ((__v4si)__A, (__v4si)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_packus_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_packuswb128 ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_unpackhi_epi8 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_punpckhbw128 ((__v16qi)__A, (__v16qi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_unpackhi_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_punpckhwd128 ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_unpackhi_epi32 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_punpckhdq128 ((__v4si)__A, (__v4si)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_unpackhi_epi64 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_punpckhqdq128 ((__v2di)__A, (__v2di)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_unpacklo_epi8 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_punpcklbw128 ((__v16qi)__A, (__v16qi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_unpacklo_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_punpcklwd128 ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_unpacklo_epi32 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_punpckldq128 ((__v4si)__A, (__v4si)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_unpacklo_epi64 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_punpcklqdq128 ((__v2di)__A, (__v2di)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_add_epi8 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v16qu)__A + (__v16qu)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_add_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v8hu)__A + (__v8hu)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_add_epi32 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v4su)__A + (__v4su)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_add_epi64 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v2du)__A + (__v2du)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_adds_epi8 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_paddsb128 ((__v16qi)__A, (__v16qi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_adds_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_paddsw128 ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_adds_epu8 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_paddusb128 ((__v16qi)__A, (__v16qi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_adds_epu16 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_paddusw128 ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sub_epi8 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v16qu)__A - (__v16qu)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sub_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v8hu)__A - (__v8hu)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sub_epi32 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v4su)__A - (__v4su)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sub_epi64 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v2du)__A - (__v2du)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_subs_epi8 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_psubsb128 ((__v16qi)__A, (__v16qi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_subs_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_psubsw128 ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_subs_epu8 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_psubusb128 ((__v16qi)__A, (__v16qi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_subs_epu16 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_psubusw128 ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_madd_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_pmaddwd128 ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mulhi_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_pmulhw128 ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mullo_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v8hu)__A * (__v8hu)__B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mul_su32 (__m64 __A, __m64 __B)
{
  return (__m64)__builtin_ia32_pmuludq ((__v2si)__A, (__v2si)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mul_epu32 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_pmuludq128 ((__v4si)__A, (__v4si)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_slli_epi16 (__m128i __A, int __B)
{
  return (__m128i)__builtin_ia32_psllwi128 ((__v8hi)__A, __B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_slli_epi32 (__m128i __A, int __B)
{
  return (__m128i)__builtin_ia32_pslldi128 ((__v4si)__A, __B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_slli_epi64 (__m128i __A, int __B)
{
  return (__m128i)__builtin_ia32_psllqi128 ((__v2di)__A, __B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_srai_epi16 (__m128i __A, int __B)
{
  return (__m128i)__builtin_ia32_psrawi128 ((__v8hi)__A, __B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_srai_epi32 (__m128i __A, int __B)
{
  return (__m128i)__builtin_ia32_psradi128 ((__v4si)__A, __B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_srli_epi16 (__m128i __A, int __B)
{
  return (__m128i)__builtin_ia32_psrlwi128 ((__v8hi)__A, __B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_srli_epi32 (__m128i __A, int __B)
{
  return (__m128i)__builtin_ia32_psrldi128 ((__v4si)__A, __B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_srli_epi64 (__m128i __A, int __B)
{
  return (__m128i)__builtin_ia32_psrlqi128 ((__v2di)__A, __B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sll_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_psllw128((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sll_epi32 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_pslld128((__v4si)__A, (__v4si)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sll_epi64 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_psllq128((__v2di)__A, (__v2di)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sra_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_psraw128 ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sra_epi32 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_psrad128 ((__v4si)__A, (__v4si)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_srl_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_psrlw128 ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_srl_epi32 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_psrld128 ((__v4si)__A, (__v4si)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_srl_epi64 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_psrlq128 ((__v2di)__A, (__v2di)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_and_si128 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v2du)__A & (__v2du)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_andnot_si128 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_pandn128 ((__v2di)__A, (__v2di)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_or_si128 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v2du)__A | (__v2du)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_xor_si128 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v2du)__A ^ (__v2du)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpeq_epi8 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v16qi)__A == (__v16qi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpeq_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v8hi)__A == (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpeq_epi32 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v4si)__A == (__v4si)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmplt_epi8 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v16qs)__A < (__v16qs)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmplt_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v8hi)__A < (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmplt_epi32 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v4si)__A < (__v4si)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpgt_epi8 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v16qs)__A > (__v16qs)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpgt_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v8hi)__A > (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpgt_epi32 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v4si)__A > (__v4si)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_max_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_pmaxsw128 ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_max_epu8 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_pmaxub128 ((__v16qi)__A, (__v16qi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_min_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_pminsw128 ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_min_epu8 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_pminub128 ((__v16qi)__A, (__v16qi)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_movemask_epi8 (__m128i __A)
{
  return __builtin_ia32_pmovmskb128 ((__v16qi)__A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mulhi_epu16 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_pmulhuw128 ((__v8hi)__A, (__v8hi)__B);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskmoveu_si128 (__m128i __A, __m128i __B, char *__C)
{
  __builtin_ia32_maskmovdqu ((__v16qi)__A, (__v16qi)__B, __C);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_avg_epu8 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_pavgb128 ((__v16qi)__A, (__v16qi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_avg_epu16 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_pavgw128 ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sad_epu8 (__m128i __A, __m128i __B)
{
  return (__m128i)__builtin_ia32_psadbw128 ((__v16qi)__A, (__v16qi)__B);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_stream_si32 (int *__A, int __B)
{
  __builtin_ia32_movnti (__A, __B);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_stream_si64 (long long int *__A, long long int __B)
{
  __builtin_ia32_movnti64 (__A, __B);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_stream_si128 (__m128i *__A, __m128i __B)
{
  __builtin_ia32_movntdq ((__v2di *)__A, (__v2di)__B);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_stream_pd (double *__A, __m128d __B)
{
  __builtin_ia32_movntpd (__A, (__v2df)__B);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_clflush (void const *__A)
{
  __builtin_ia32_clflush (__A);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_lfence (void)
{
  __builtin_ia32_lfence ();
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mfence (void)
{
  __builtin_ia32_mfence ();
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsi32_si128 (int __A)
{
  return _mm_set_epi32 (0, 0, 0, __A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsi64_si128 (long long __A)
{
  return _mm_set_epi64x (0, __A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsi64x_si128 (long long __A)
{
  return _mm_set_epi64x (0, __A);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_castpd_ps(__m128d __A)
{
  return (__m128) __A;
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_castpd_si128(__m128d __A)
{
  return (__m128i) __A;
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_castps_pd(__m128 __A)
{
  return (__m128d) __A;
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_castps_si128(__m128 __A)
{
  return (__m128i) __A;
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_castsi128_ps(__m128i __A)
{
  return (__m128) __A;
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_castsi128_pd(__m128i __A)
{
  return (__m128d) __A;
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_pause (void)
{
  __builtin_ia32_pause ();
}
#pragma GCC push_options
#pragma GCC target("sse3")
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_addsub_ps (__m128 __X, __m128 __Y)
{
  return (__m128) __builtin_ia32_addsubps ((__v4sf)__X, (__v4sf)__Y);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_hadd_ps (__m128 __X, __m128 __Y)
{
  return (__m128) __builtin_ia32_haddps ((__v4sf)__X, (__v4sf)__Y);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_hsub_ps (__m128 __X, __m128 __Y)
{
  return (__m128) __builtin_ia32_hsubps ((__v4sf)__X, (__v4sf)__Y);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_movehdup_ps (__m128 __X)
{
  return (__m128) __builtin_ia32_movshdup ((__v4sf)__X);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_moveldup_ps (__m128 __X)
{
  return (__m128) __builtin_ia32_movsldup ((__v4sf)__X);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_addsub_pd (__m128d __X, __m128d __Y)
{
  return (__m128d) __builtin_ia32_addsubpd ((__v2df)__X, (__v2df)__Y);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_hadd_pd (__m128d __X, __m128d __Y)
{
  return (__m128d) __builtin_ia32_haddpd ((__v2df)__X, (__v2df)__Y);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_hsub_pd (__m128d __X, __m128d __Y)
{
  return (__m128d) __builtin_ia32_hsubpd ((__v2df)__X, (__v2df)__Y);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_loaddup_pd (double const *__P)
{
  return _mm_load1_pd (__P);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_movedup_pd (__m128d __X)
{
  return ((__m128d)__builtin_ia32_shufpd ((__v2df)(__m128d)(__X), (__v2df)(__m128d)(__X), (int)((((0) << 1) | (0)))));
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_lddqu_si128 (__m128i const *__P)
{
  return (__m128i) __builtin_ia32_lddqu ((char const *)__P);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("ssse3")
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_hadd_epi16 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_phaddw128 ((__v8hi)__X, (__v8hi)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_hadd_epi32 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_phaddd128 ((__v4si)__X, (__v4si)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_hadds_epi16 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_phaddsw128 ((__v8hi)__X, (__v8hi)__Y);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_hadd_pi16 (__m64 __X, __m64 __Y)
{
  return (__m64) __builtin_ia32_phaddw ((__v4hi)__X, (__v4hi)__Y);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_hadd_pi32 (__m64 __X, __m64 __Y)
{
  return (__m64) __builtin_ia32_phaddd ((__v2si)__X, (__v2si)__Y);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_hadds_pi16 (__m64 __X, __m64 __Y)
{
  return (__m64) __builtin_ia32_phaddsw ((__v4hi)__X, (__v4hi)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_hsub_epi16 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_phsubw128 ((__v8hi)__X, (__v8hi)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_hsub_epi32 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_phsubd128 ((__v4si)__X, (__v4si)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_hsubs_epi16 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_phsubsw128 ((__v8hi)__X, (__v8hi)__Y);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_hsub_pi16 (__m64 __X, __m64 __Y)
{
  return (__m64) __builtin_ia32_phsubw ((__v4hi)__X, (__v4hi)__Y);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_hsub_pi32 (__m64 __X, __m64 __Y)
{
  return (__m64) __builtin_ia32_phsubd ((__v2si)__X, (__v2si)__Y);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_hsubs_pi16 (__m64 __X, __m64 __Y)
{
  return (__m64) __builtin_ia32_phsubsw ((__v4hi)__X, (__v4hi)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maddubs_epi16 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_pmaddubsw128 ((__v16qi)__X, (__v16qi)__Y);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maddubs_pi16 (__m64 __X, __m64 __Y)
{
  return (__m64) __builtin_ia32_pmaddubsw ((__v8qi)__X, (__v8qi)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mulhrs_epi16 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_pmulhrsw128 ((__v8hi)__X, (__v8hi)__Y);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mulhrs_pi16 (__m64 __X, __m64 __Y)
{
  return (__m64) __builtin_ia32_pmulhrsw ((__v4hi)__X, (__v4hi)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_shuffle_epi8 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_pshufb128 ((__v16qi)__X, (__v16qi)__Y);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_shuffle_pi8 (__m64 __X, __m64 __Y)
{
  return (__m64) __builtin_ia32_pshufb ((__v8qi)__X, (__v8qi)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sign_epi8 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_psignb128 ((__v16qi)__X, (__v16qi)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sign_epi16 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_psignw128 ((__v8hi)__X, (__v8hi)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sign_epi32 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_psignd128 ((__v4si)__X, (__v4si)__Y);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sign_pi8 (__m64 __X, __m64 __Y)
{
  return (__m64) __builtin_ia32_psignb ((__v8qi)__X, (__v8qi)__Y);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sign_pi16 (__m64 __X, __m64 __Y)
{
  return (__m64) __builtin_ia32_psignw ((__v4hi)__X, (__v4hi)__Y);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sign_pi32 (__m64 __X, __m64 __Y)
{
  return (__m64) __builtin_ia32_psignd ((__v2si)__X, (__v2si)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_abs_epi8 (__m128i __X)
{
  return (__m128i) __builtin_ia32_pabsb128 ((__v16qi)__X);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_abs_epi16 (__m128i __X)
{
  return (__m128i) __builtin_ia32_pabsw128 ((__v8hi)__X);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_abs_epi32 (__m128i __X)
{
  return (__m128i) __builtin_ia32_pabsd128 ((__v4si)__X);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_abs_pi8 (__m64 __X)
{
  return (__m64) __builtin_ia32_pabsb ((__v8qi)__X);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_abs_pi16 (__m64 __X)
{
  return (__m64) __builtin_ia32_pabsw ((__v4hi)__X);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_abs_pi32 (__m64 __X)
{
  return (__m64) __builtin_ia32_pabsd ((__v2si)__X);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("sse4.1")
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_testz_si128 (__m128i __M, __m128i __V)
{
  return __builtin_ia32_ptestz128 ((__v2di)__M, (__v2di)__V);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_testc_si128 (__m128i __M, __m128i __V)
{
  return __builtin_ia32_ptestc128 ((__v2di)__M, (__v2di)__V);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_testnzc_si128 (__m128i __M, __m128i __V)
{
  return __builtin_ia32_ptestnzc128 ((__v2di)__M, (__v2di)__V);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_blendv_epi8 (__m128i __X, __m128i __Y, __m128i __M)
{
  return (__m128i) __builtin_ia32_pblendvb128 ((__v16qi)__X,
            (__v16qi)__Y,
            (__v16qi)__M);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_blendv_ps (__m128 __X, __m128 __Y, __m128 __M)
{
  return (__m128) __builtin_ia32_blendvps ((__v4sf)__X,
        (__v4sf)__Y,
        (__v4sf)__M);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_blendv_pd (__m128d __X, __m128d __Y, __m128d __M)
{
  return (__m128d) __builtin_ia32_blendvpd ((__v2df)__X,
         (__v2df)__Y,
         (__v2df)__M);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpeq_epi64 (__m128i __X, __m128i __Y)
{
  return (__m128i) ((__v2di)__X == (__v2di)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_min_epi8 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_pminsb128 ((__v16qi)__X, (__v16qi)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_max_epi8 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_pmaxsb128 ((__v16qi)__X, (__v16qi)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_min_epu16 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_pminuw128 ((__v8hi)__X, (__v8hi)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_max_epu16 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_pmaxuw128 ((__v8hi)__X, (__v8hi)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_min_epi32 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_pminsd128 ((__v4si)__X, (__v4si)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_max_epi32 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_pmaxsd128 ((__v4si)__X, (__v4si)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_min_epu32 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_pminud128 ((__v4si)__X, (__v4si)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_max_epu32 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_pmaxud128 ((__v4si)__X, (__v4si)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mullo_epi32 (__m128i __X, __m128i __Y)
{
  return (__m128i) ((__v4su)__X * (__v4su)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mul_epi32 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_pmuldq128 ((__v4si)__X, (__v4si)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_minpos_epu16 (__m128i __X)
{
  return (__m128i) __builtin_ia32_phminposuw128 ((__v8hi)__X);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepi8_epi32 (__m128i __X)
{
  return (__m128i) __builtin_ia32_pmovsxbd128 ((__v16qi)__X);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepi16_epi32 (__m128i __X)
{
  return (__m128i) __builtin_ia32_pmovsxwd128 ((__v8hi)__X);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepi8_epi64 (__m128i __X)
{
  return (__m128i) __builtin_ia32_pmovsxbq128 ((__v16qi)__X);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepi32_epi64 (__m128i __X)
{
  return (__m128i) __builtin_ia32_pmovsxdq128 ((__v4si)__X);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepi16_epi64 (__m128i __X)
{
  return (__m128i) __builtin_ia32_pmovsxwq128 ((__v8hi)__X);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepi8_epi16 (__m128i __X)
{
  return (__m128i) __builtin_ia32_pmovsxbw128 ((__v16qi)__X);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepu8_epi32 (__m128i __X)
{
  return (__m128i) __builtin_ia32_pmovzxbd128 ((__v16qi)__X);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepu16_epi32 (__m128i __X)
{
  return (__m128i) __builtin_ia32_pmovzxwd128 ((__v8hi)__X);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepu8_epi64 (__m128i __X)
{
  return (__m128i) __builtin_ia32_pmovzxbq128 ((__v16qi)__X);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepu32_epi64 (__m128i __X)
{
  return (__m128i) __builtin_ia32_pmovzxdq128 ((__v4si)__X);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepu16_epi64 (__m128i __X)
{
  return (__m128i) __builtin_ia32_pmovzxwq128 ((__v8hi)__X);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepu8_epi16 (__m128i __X)
{
  return (__m128i) __builtin_ia32_pmovzxbw128 ((__v16qi)__X);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_packus_epi32 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_packusdw128 ((__v4si)__X, (__v4si)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_stream_load_si128 (__m128i *__X)
{
  return (__m128i) __builtin_ia32_movntdqa ((__v2di *) __X);
}
#pragma GCC push_options
#pragma GCC target("sse4.2")
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpgt_epi64 (__m128i __X, __m128i __Y)
{
  return (__m128i) ((__v2di)__X > (__v2di)__Y);
}
#pragma GCC pop_options
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("sse4.1")
#pragma GCC push_options
#pragma GCC target("sse4.2")
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_crc32_u8 (unsigned int __C, unsigned char __V)
{
  return __builtin_ia32_crc32qi (__C, __V);
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_crc32_u16 (unsigned int __C, unsigned short __V)
{
  return __builtin_ia32_crc32hi (__C, __V);
}
extern __inline unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_crc32_u32 (unsigned int __C, unsigned int __V)
{
  return __builtin_ia32_crc32si (__C, __V);
}
extern __inline unsigned long long __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_crc32_u64 (unsigned long long __C, unsigned long long __V)
{
  return __builtin_ia32_crc32di (__C, __V);
}
#pragma GCC pop_options
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("aes,sse2")
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_aesdec_si128 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_aesdec128 ((__v2di)__X, (__v2di)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_aesdeclast_si128 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_aesdeclast128 ((__v2di)__X,
       (__v2di)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_aesenc_si128 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_aesenc128 ((__v2di)__X, (__v2di)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_aesenclast_si128 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_aesenclast128 ((__v2di)__X, (__v2di)__Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_aesimc_si128 (__m128i __X)
{
  return (__m128i) __builtin_ia32_aesimc128 ((__v2di)__X);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("pclmul,sse2")
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx")
typedef double __v4df __attribute__ ((__vector_size__ (32)));
typedef float __v8sf __attribute__ ((__vector_size__ (32)));
typedef long long __v4di __attribute__ ((__vector_size__ (32)));
typedef unsigned long long __v4du __attribute__ ((__vector_size__ (32)));
typedef int __v8si __attribute__ ((__vector_size__ (32)));
typedef unsigned int __v8su __attribute__ ((__vector_size__ (32)));
typedef short __v16hi __attribute__ ((__vector_size__ (32)));
typedef unsigned short __v16hu __attribute__ ((__vector_size__ (32)));
typedef char __v32qi __attribute__ ((__vector_size__ (32)));
typedef signed char __v32qs __attribute__ ((__vector_size__ (32)));
typedef unsigned char __v32qu __attribute__ ((__vector_size__ (32)));
typedef float __m256 __attribute__ ((__vector_size__ (32),
         __may_alias__));
typedef long long __m256i __attribute__ ((__vector_size__ (32),
       __may_alias__));
typedef double __m256d __attribute__ ((__vector_size__ (32),
           __may_alias__));
typedef float __m256_u __attribute__ ((__vector_size__ (32),
           __may_alias__,
           __aligned__ (1)));
typedef long long __m256i_u __attribute__ ((__vector_size__ (32),
         __may_alias__,
         __aligned__ (1)));
typedef double __m256d_u __attribute__ ((__vector_size__ (32),
      __may_alias__,
      __aligned__ (1)));
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_add_pd (__m256d __A, __m256d __B)
{
  return (__m256d) ((__v4df)__A + (__v4df)__B);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_add_ps (__m256 __A, __m256 __B)
{
  return (__m256) ((__v8sf)__A + (__v8sf)__B);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_addsub_pd (__m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_addsubpd256 ((__v4df)__A, (__v4df)__B);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_addsub_ps (__m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_addsubps256 ((__v8sf)__A, (__v8sf)__B);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_and_pd (__m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_andpd256 ((__v4df)__A, (__v4df)__B);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_and_ps (__m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_andps256 ((__v8sf)__A, (__v8sf)__B);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_andnot_pd (__m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_andnpd256 ((__v4df)__A, (__v4df)__B);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_andnot_ps (__m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_andnps256 ((__v8sf)__A, (__v8sf)__B);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_blendv_pd (__m256d __X, __m256d __Y, __m256d __M)
{
  return (__m256d) __builtin_ia32_blendvpd256 ((__v4df)__X,
            (__v4df)__Y,
            (__v4df)__M);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_blendv_ps (__m256 __X, __m256 __Y, __m256 __M)
{
  return (__m256) __builtin_ia32_blendvps256 ((__v8sf)__X,
           (__v8sf)__Y,
           (__v8sf)__M);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_div_pd (__m256d __A, __m256d __B)
{
  return (__m256d) ((__v4df)__A / (__v4df)__B);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_div_ps (__m256 __A, __m256 __B)
{
  return (__m256) ((__v8sf)__A / (__v8sf)__B);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_hadd_pd (__m256d __X, __m256d __Y)
{
  return (__m256d) __builtin_ia32_haddpd256 ((__v4df)__X, (__v4df)__Y);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_hadd_ps (__m256 __X, __m256 __Y)
{
  return (__m256) __builtin_ia32_haddps256 ((__v8sf)__X, (__v8sf)__Y);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_hsub_pd (__m256d __X, __m256d __Y)
{
  return (__m256d) __builtin_ia32_hsubpd256 ((__v4df)__X, (__v4df)__Y);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_hsub_ps (__m256 __X, __m256 __Y)
{
  return (__m256) __builtin_ia32_hsubps256 ((__v8sf)__X, (__v8sf)__Y);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_max_pd (__m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_maxpd256 ((__v4df)__A, (__v4df)__B);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_max_ps (__m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_maxps256 ((__v8sf)__A, (__v8sf)__B);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_min_pd (__m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_minpd256 ((__v4df)__A, (__v4df)__B);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_min_ps (__m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_minps256 ((__v8sf)__A, (__v8sf)__B);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mul_pd (__m256d __A, __m256d __B)
{
  return (__m256d) ((__v4df)__A * (__v4df)__B);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mul_ps (__m256 __A, __m256 __B)
{
  return (__m256) ((__v8sf)__A * (__v8sf)__B);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_or_pd (__m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_orpd256 ((__v4df)__A, (__v4df)__B);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_or_ps (__m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_orps256 ((__v8sf)__A, (__v8sf)__B);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sub_pd (__m256d __A, __m256d __B)
{
  return (__m256d) ((__v4df)__A - (__v4df)__B);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sub_ps (__m256 __A, __m256 __B)
{
  return (__m256) ((__v8sf)__A - (__v8sf)__B);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_xor_pd (__m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_xorpd256 ((__v4df)__A, (__v4df)__B);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_xor_ps (__m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_xorps256 ((__v8sf)__A, (__v8sf)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtsi256_si32 (__m256i __A)
{
  __v8si __B = (__v8si) __A;
  return __B[0];
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepi32_pd (__m128i __A)
{
  return (__m256d)__builtin_ia32_cvtdq2pd256 ((__v4si) __A);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepi32_ps (__m256i __A)
{
  return (__m256)__builtin_ia32_cvtdq2ps256 ((__v8si) __A);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtpd_ps (__m256d __A)
{
  return (__m128)__builtin_ia32_cvtpd2ps256 ((__v4df) __A);
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtps_epi32 (__m256 __A)
{
  return (__m256i)__builtin_ia32_cvtps2dq256 ((__v8sf) __A);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtps_pd (__m128 __A)
{
  return (__m256d)__builtin_ia32_cvtps2pd256 ((__v4sf) __A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvttpd_epi32 (__m256d __A)
{
  return (__m128i)__builtin_ia32_cvttpd2dq256 ((__v4df) __A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtpd_epi32 (__m256d __A)
{
  return (__m128i)__builtin_ia32_cvtpd2dq256 ((__v4df) __A);
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvttps_epi32 (__m256 __A)
{
  return (__m256i)__builtin_ia32_cvttps2dq256 ((__v8sf) __A);
}
extern __inline double
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtsd_f64 (__m256d __A)
{
  return __A[0];
}
extern __inline float
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtss_f32 (__m256 __A)
{
  return __A[0];
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_zeroall (void)
{
  __builtin_ia32_vzeroall ();
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_zeroupper (void)
{
  __builtin_ia32_vzeroupper ();
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_permutevar_pd (__m128d __A, __m128i __C)
{
  return (__m128d) __builtin_ia32_vpermilvarpd ((__v2df)__A,
      (__v2di)__C);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_permutevar_pd (__m256d __A, __m256i __C)
{
  return (__m256d) __builtin_ia32_vpermilvarpd256 ((__v4df)__A,
         (__v4di)__C);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_permutevar_ps (__m128 __A, __m128i __C)
{
  return (__m128) __builtin_ia32_vpermilvarps ((__v4sf)__A,
            (__v4si)__C);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_permutevar_ps (__m256 __A, __m256i __C)
{
  return (__m256) __builtin_ia32_vpermilvarps256 ((__v8sf)__A,
        (__v8si)__C);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_broadcast_ss (float const *__X)
{
  return (__m128) __builtin_ia32_vbroadcastss (__X);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_broadcast_sd (double const *__X)
{
  return (__m256d) __builtin_ia32_vbroadcastsd256 (__X);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_broadcast_ss (float const *__X)
{
  return (__m256) __builtin_ia32_vbroadcastss256 (__X);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_broadcast_pd (__m128d const *__X)
{
  return (__m256d) __builtin_ia32_vbroadcastf128_pd256 (__X);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_broadcast_ps (__m128 const *__X)
{
  return (__m256) __builtin_ia32_vbroadcastf128_ps256 (__X);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_load_pd (double const *__P)
{
  return *(__m256d *)__P;
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_store_pd (double *__P, __m256d __A)
{
  *(__m256d *)__P = __A;
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_load_ps (float const *__P)
{
  return *(__m256 *)__P;
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_store_ps (float *__P, __m256 __A)
{
  *(__m256 *)__P = __A;
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_loadu_pd (double const *__P)
{
  return *(__m256d_u *)__P;
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_storeu_pd (double *__P, __m256d __A)
{
  *(__m256d_u *)__P = __A;
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_loadu_ps (float const *__P)
{
  return *(__m256_u *)__P;
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_storeu_ps (float *__P, __m256 __A)
{
  *(__m256_u *)__P = __A;
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_load_si256 (__m256i const *__P)
{
  return *__P;
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_store_si256 (__m256i *__P, __m256i __A)
{
  *__P = __A;
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_loadu_si256 (__m256i_u const *__P)
{
  return *__P;
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_storeu_si256 (__m256i_u *__P, __m256i __A)
{
  *__P = __A;
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskload_pd (double const *__P, __m128i __M)
{
  return (__m128d) __builtin_ia32_maskloadpd ((const __v2df *)__P,
           (__v2di)__M);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskstore_pd (double *__P, __m128i __M, __m128d __A)
{
  __builtin_ia32_maskstorepd ((__v2df *)__P, (__v2di)__M, (__v2df)__A);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskload_pd (double const *__P, __m256i __M)
{
  return (__m256d) __builtin_ia32_maskloadpd256 ((const __v4df *)__P,
       (__v4di)__M);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskstore_pd (double *__P, __m256i __M, __m256d __A)
{
  __builtin_ia32_maskstorepd256 ((__v4df *)__P, (__v4di)__M, (__v4df)__A);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskload_ps (float const *__P, __m128i __M)
{
  return (__m128) __builtin_ia32_maskloadps ((const __v4sf *)__P,
          (__v4si)__M);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskstore_ps (float *__P, __m128i __M, __m128 __A)
{
  __builtin_ia32_maskstoreps ((__v4sf *)__P, (__v4si)__M, (__v4sf)__A);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskload_ps (float const *__P, __m256i __M)
{
  return (__m256) __builtin_ia32_maskloadps256 ((const __v8sf *)__P,
      (__v8si)__M);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskstore_ps (float *__P, __m256i __M, __m256 __A)
{
  __builtin_ia32_maskstoreps256 ((__v8sf *)__P, (__v8si)__M, (__v8sf)__A);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_movehdup_ps (__m256 __X)
{
  return (__m256) __builtin_ia32_movshdup256 ((__v8sf)__X);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_moveldup_ps (__m256 __X)
{
  return (__m256) __builtin_ia32_movsldup256 ((__v8sf)__X);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_movedup_pd (__m256d __X)
{
  return (__m256d) __builtin_ia32_movddup256 ((__v4df)__X);
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_lddqu_si256 (__m256i const *__P)
{
  return (__m256i) __builtin_ia32_lddqu256 ((char const *)__P);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_stream_si256 (__m256i *__A, __m256i __B)
{
  __builtin_ia32_movntdq256 ((__v4di *)__A, (__v4di)__B);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_stream_pd (double *__A, __m256d __B)
{
  __builtin_ia32_movntpd256 (__A, (__v4df)__B);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_stream_ps (float *__P, __m256 __A)
{
  __builtin_ia32_movntps256 (__P, (__v8sf)__A);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_rcp_ps (__m256 __A)
{
  return (__m256) __builtin_ia32_rcpps256 ((__v8sf)__A);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_rsqrt_ps (__m256 __A)
{
  return (__m256) __builtin_ia32_rsqrtps256 ((__v8sf)__A);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sqrt_pd (__m256d __A)
{
  return (__m256d) __builtin_ia32_sqrtpd256 ((__v4df)__A);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sqrt_ps (__m256 __A)
{
  return (__m256) __builtin_ia32_sqrtps256 ((__v8sf)__A);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_unpackhi_pd (__m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_unpckhpd256 ((__v4df)__A, (__v4df)__B);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_unpacklo_pd (__m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_unpcklpd256 ((__v4df)__A, (__v4df)__B);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_unpackhi_ps (__m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_unpckhps256 ((__v8sf)__A, (__v8sf)__B);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_unpacklo_ps (__m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_unpcklps256 ((__v8sf)__A, (__v8sf)__B);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_testz_pd (__m128d __M, __m128d __V)
{
  return __builtin_ia32_vtestzpd ((__v2df)__M, (__v2df)__V);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_testc_pd (__m128d __M, __m128d __V)
{
  return __builtin_ia32_vtestcpd ((__v2df)__M, (__v2df)__V);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_testnzc_pd (__m128d __M, __m128d __V)
{
  return __builtin_ia32_vtestnzcpd ((__v2df)__M, (__v2df)__V);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_testz_ps (__m128 __M, __m128 __V)
{
  return __builtin_ia32_vtestzps ((__v4sf)__M, (__v4sf)__V);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_testc_ps (__m128 __M, __m128 __V)
{
  return __builtin_ia32_vtestcps ((__v4sf)__M, (__v4sf)__V);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_testnzc_ps (__m128 __M, __m128 __V)
{
  return __builtin_ia32_vtestnzcps ((__v4sf)__M, (__v4sf)__V);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_testz_pd (__m256d __M, __m256d __V)
{
  return __builtin_ia32_vtestzpd256 ((__v4df)__M, (__v4df)__V);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_testc_pd (__m256d __M, __m256d __V)
{
  return __builtin_ia32_vtestcpd256 ((__v4df)__M, (__v4df)__V);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_testnzc_pd (__m256d __M, __m256d __V)
{
  return __builtin_ia32_vtestnzcpd256 ((__v4df)__M, (__v4df)__V);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_testz_ps (__m256 __M, __m256 __V)
{
  return __builtin_ia32_vtestzps256 ((__v8sf)__M, (__v8sf)__V);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_testc_ps (__m256 __M, __m256 __V)
{
  return __builtin_ia32_vtestcps256 ((__v8sf)__M, (__v8sf)__V);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_testnzc_ps (__m256 __M, __m256 __V)
{
  return __builtin_ia32_vtestnzcps256 ((__v8sf)__M, (__v8sf)__V);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_testz_si256 (__m256i __M, __m256i __V)
{
  return __builtin_ia32_ptestz256 ((__v4di)__M, (__v4di)__V);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_testc_si256 (__m256i __M, __m256i __V)
{
  return __builtin_ia32_ptestc256 ((__v4di)__M, (__v4di)__V);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_testnzc_si256 (__m256i __M, __m256i __V)
{
  return __builtin_ia32_ptestnzc256 ((__v4di)__M, (__v4di)__V);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_movemask_pd (__m256d __A)
{
  return __builtin_ia32_movmskpd256 ((__v4df)__A);
}
extern __inline int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_movemask_ps (__m256 __A)
{
  return __builtin_ia32_movmskps256 ((__v8sf)__A);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_undefined_pd (void)
{
  __m256d __Y = __Y;
  return __Y;
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_undefined_ps (void)
{
  __m256 __Y = __Y;
  return __Y;
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_undefined_si256 (void)
{
  __m256i __Y = __Y;
  return __Y;
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_setzero_pd (void)
{
  return __extension__ (__m256d){ 0.0, 0.0, 0.0, 0.0 };
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_setzero_ps (void)
{
  return __extension__ (__m256){ 0.0, 0.0, 0.0, 0.0,
     0.0, 0.0, 0.0, 0.0 };
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_setzero_si256 (void)
{
  return __extension__ (__m256i)(__v4di){ 0, 0, 0, 0 };
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_set_pd (double __A, double __B, double __C, double __D)
{
  return __extension__ (__m256d){ __D, __C, __B, __A };
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_set_ps (float __A, float __B, float __C, float __D,
        float __E, float __F, float __G, float __H)
{
  return __extension__ (__m256){ __H, __G, __F, __E,
     __D, __C, __B, __A };
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_set_epi32 (int __A, int __B, int __C, int __D,
    int __E, int __F, int __G, int __H)
{
  return __extension__ (__m256i)(__v8si){ __H, __G, __F, __E,
       __D, __C, __B, __A };
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_set_epi16 (short __q15, short __q14, short __q13, short __q12,
    short __q11, short __q10, short __q09, short __q08,
    short __q07, short __q06, short __q05, short __q04,
    short __q03, short __q02, short __q01, short __q00)
{
  return __extension__ (__m256i)(__v16hi){
    __q00, __q01, __q02, __q03, __q04, __q05, __q06, __q07,
    __q08, __q09, __q10, __q11, __q12, __q13, __q14, __q15
  };
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_set_epi8 (char __q31, char __q30, char __q29, char __q28,
    char __q27, char __q26, char __q25, char __q24,
    char __q23, char __q22, char __q21, char __q20,
    char __q19, char __q18, char __q17, char __q16,
    char __q15, char __q14, char __q13, char __q12,
    char __q11, char __q10, char __q09, char __q08,
    char __q07, char __q06, char __q05, char __q04,
    char __q03, char __q02, char __q01, char __q00)
{
  return __extension__ (__m256i)(__v32qi){
    __q00, __q01, __q02, __q03, __q04, __q05, __q06, __q07,
    __q08, __q09, __q10, __q11, __q12, __q13, __q14, __q15,
    __q16, __q17, __q18, __q19, __q20, __q21, __q22, __q23,
    __q24, __q25, __q26, __q27, __q28, __q29, __q30, __q31
  };
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_set_epi64x (long long __A, long long __B, long long __C,
     long long __D)
{
  return __extension__ (__m256i)(__v4di){ __D, __C, __B, __A };
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_set1_pd (double __A)
{
  return __extension__ (__m256d){ __A, __A, __A, __A };
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_set1_ps (float __A)
{
  return __extension__ (__m256){ __A, __A, __A, __A,
     __A, __A, __A, __A };
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_set1_epi32 (int __A)
{
  return __extension__ (__m256i)(__v8si){ __A, __A, __A, __A,
       __A, __A, __A, __A };
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_set1_epi16 (short __A)
{
  return _mm256_set_epi16 (__A, __A, __A, __A, __A, __A, __A, __A,
      __A, __A, __A, __A, __A, __A, __A, __A);
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_set1_epi8 (char __A)
{
  return _mm256_set_epi8 (__A, __A, __A, __A, __A, __A, __A, __A,
     __A, __A, __A, __A, __A, __A, __A, __A,
     __A, __A, __A, __A, __A, __A, __A, __A,
     __A, __A, __A, __A, __A, __A, __A, __A);
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_set1_epi64x (long long __A)
{
  return __extension__ (__m256i)(__v4di){ __A, __A, __A, __A };
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_setr_pd (double __A, double __B, double __C, double __D)
{
  return _mm256_set_pd (__D, __C, __B, __A);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_setr_ps (float __A, float __B, float __C, float __D,
  float __E, float __F, float __G, float __H)
{
  return _mm256_set_ps (__H, __G, __F, __E, __D, __C, __B, __A);
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_setr_epi32 (int __A, int __B, int __C, int __D,
     int __E, int __F, int __G, int __H)
{
  return _mm256_set_epi32 (__H, __G, __F, __E, __D, __C, __B, __A);
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_setr_epi16 (short __q15, short __q14, short __q13, short __q12,
     short __q11, short __q10, short __q09, short __q08,
     short __q07, short __q06, short __q05, short __q04,
     short __q03, short __q02, short __q01, short __q00)
{
  return _mm256_set_epi16 (__q00, __q01, __q02, __q03,
      __q04, __q05, __q06, __q07,
      __q08, __q09, __q10, __q11,
      __q12, __q13, __q14, __q15);
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_setr_epi8 (char __q31, char __q30, char __q29, char __q28,
     char __q27, char __q26, char __q25, char __q24,
     char __q23, char __q22, char __q21, char __q20,
     char __q19, char __q18, char __q17, char __q16,
     char __q15, char __q14, char __q13, char __q12,
     char __q11, char __q10, char __q09, char __q08,
     char __q07, char __q06, char __q05, char __q04,
     char __q03, char __q02, char __q01, char __q00)
{
  return _mm256_set_epi8 (__q00, __q01, __q02, __q03,
     __q04, __q05, __q06, __q07,
     __q08, __q09, __q10, __q11,
     __q12, __q13, __q14, __q15,
     __q16, __q17, __q18, __q19,
     __q20, __q21, __q22, __q23,
     __q24, __q25, __q26, __q27,
     __q28, __q29, __q30, __q31);
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_setr_epi64x (long long __A, long long __B, long long __C,
      long long __D)
{
  return _mm256_set_epi64x (__D, __C, __B, __A);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_castpd_ps (__m256d __A)
{
  return (__m256) __A;
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_castpd_si256 (__m256d __A)
{
  return (__m256i) __A;
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_castps_pd (__m256 __A)
{
  return (__m256d) __A;
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_castps_si256(__m256 __A)
{
  return (__m256i) __A;
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_castsi256_ps (__m256i __A)
{
  return (__m256) __A;
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_castsi256_pd (__m256i __A)
{
  return (__m256d) __A;
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_castpd256_pd128 (__m256d __A)
{
  return (__m128d) __builtin_ia32_pd_pd256 ((__v4df)__A);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_castps256_ps128 (__m256 __A)
{
  return (__m128) __builtin_ia32_ps_ps256 ((__v8sf)__A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_castsi256_si128 (__m256i __A)
{
  return (__m128i) __builtin_ia32_si_si256 ((__v8si)__A);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_castpd128_pd256 (__m128d __A)
{
  return (__m256d) __builtin_ia32_pd256_pd ((__v2df)__A);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_castps128_ps256 (__m128 __A)
{
  return (__m256) __builtin_ia32_ps256_ps ((__v4sf)__A);
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_castsi128_si256 (__m128i __A)
{
  return (__m256i) __builtin_ia32_si256_si ((__v4si)__A);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_zextpd128_pd256 (__m128d __A)
{
  return ((__m256d) __builtin_ia32_vinsertf128_pd256 ((__v4df)(__m256d)(_mm256_setzero_pd ()), (__v2df)(__m128d)(__A), (int)(0)));
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_zextps128_ps256 (__m128 __A)
{
  return ((__m256) __builtin_ia32_vinsertf128_ps256 ((__v8sf)(__m256)(_mm256_setzero_ps ()), (__v4sf)(__m128)(__A), (int)(0)));
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_zextsi128_si256 (__m128i __A)
{
  return ((__m256i) __builtin_ia32_vinsertf128_si256 ((__v8si)(__m256i)(_mm256_setzero_si256 ()), (__v4si)(__m128i)(__A), (int)(0)));
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_set_m128 ( __m128 __H, __m128 __L)
{
  return ((__m256) __builtin_ia32_vinsertf128_ps256 ((__v8sf)(__m256)(_mm256_castps128_ps256 (__L)), (__v4sf)(__m128)(__H), (int)(1)));
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_set_m128d (__m128d __H, __m128d __L)
{
  return ((__m256d) __builtin_ia32_vinsertf128_pd256 ((__v4df)(__m256d)(_mm256_castpd128_pd256 (__L)), (__v2df)(__m128d)(__H), (int)(1)));
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_set_m128i (__m128i __H, __m128i __L)
{
  return ((__m256i) __builtin_ia32_vinsertf128_si256 ((__v8si)(__m256i)(_mm256_castsi128_si256 (__L)), (__v4si)(__m128i)(__H), (int)(1)));
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_setr_m128 (__m128 __L, __m128 __H)
{
  return _mm256_set_m128 (__H, __L);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_setr_m128d (__m128d __L, __m128d __H)
{
  return _mm256_set_m128d (__H, __L);
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_setr_m128i (__m128i __L, __m128i __H)
{
  return _mm256_set_m128i (__H, __L);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_loadu2_m128 (float const *__PH, float const *__PL)
{
  return ((__m256) __builtin_ia32_vinsertf128_ps256 ((__v8sf)(__m256)(_mm256_castps128_ps256 (_mm_loadu_ps (__PL))), (__v4sf)(__m128)(_mm_loadu_ps (__PH)), (int)(1)));
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_storeu2_m128 (float *__PH, float *__PL, __m256 __A)
{
  _mm_storeu_ps (__PL, _mm256_castps256_ps128 (__A));
  _mm_storeu_ps (__PH, ((__m128) __builtin_ia32_vextractf128_ps256 ((__v8sf)(__m256)(__A), (int)(1))));
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_loadu2_m128d (double const *__PH, double const *__PL)
{
  return ((__m256d) __builtin_ia32_vinsertf128_pd256 ((__v4df)(__m256d)(_mm256_castpd128_pd256 (_mm_loadu_pd (__PL))), (__v2df)(__m128d)(_mm_loadu_pd (__PH)), (int)(1)));
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_storeu2_m128d (double *__PH, double *__PL, __m256d __A)
{
  _mm_storeu_pd (__PL, _mm256_castpd256_pd128 (__A));
  _mm_storeu_pd (__PH, ((__m128d) __builtin_ia32_vextractf128_pd256 ((__v4df)(__m256d)(__A), (int)(1))));
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_loadu2_m128i (__m128i_u const *__PH, __m128i_u const *__PL)
{
  return ((__m256i) __builtin_ia32_vinsertf128_si256 ((__v8si)(__m256i)(_mm256_castsi128_si256 (_mm_loadu_si128 (__PL))), (__v4si)(__m128i)(_mm_loadu_si128 (__PH)), (int)(1)));
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_storeu2_m128i (__m128i_u *__PH, __m128i_u *__PL, __m256i __A)
{
  _mm_storeu_si128 (__PL, _mm256_castsi256_si128 (__A));
  _mm_storeu_si128 (__PH, ((__m128i) __builtin_ia32_vextractf128_si256 ((__v8si)(__m256i)(__A), (int)(1))));
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avxvnni")
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_dpbusd_avx_epi32(__m256i __A, __m256i __B, __m256i __C)
{
  return (__m256i) __builtin_ia32_vpdpbusd_v8si ((__v8si) __A,
         (__v8si) __B,
         (__v8si) __C);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_dpbusd_avx_epi32(__m128i __A, __m128i __B, __m128i __C)
{
  return (__m128i) __builtin_ia32_vpdpbusd_v4si ((__v4si) __A,
       (__v4si) __B,
       (__v4si) __C);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_dpbusds_avx_epi32(__m256i __A, __m256i __B, __m256i __C)
{
  return (__m256i) __builtin_ia32_vpdpbusds_v8si ((__v8si) __A,
        (__v8si) __B,
        (__v8si) __C);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_dpbusds_avx_epi32(__m128i __A,__m128i __B,__m128i __C)
{
  return (__m128i) __builtin_ia32_vpdpbusds_v4si ((__v4si) __A,
        (__v4si) __B,
        (__v4si) __C);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_dpwssd_avx_epi32(__m256i __A,__m256i __B,__m256i __C)
{
  return (__m256i) __builtin_ia32_vpdpwssd_v8si ((__v8si) __A,
       (__v8si) __B,
       (__v8si) __C);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_dpwssd_avx_epi32(__m128i __A,__m128i __B,__m128i __C)
{
  return (__m128i) __builtin_ia32_vpdpwssd_v4si ((__v4si) __A,
       (__v4si) __B,
       (__v4si) __C);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_dpwssds_avx_epi32(__m256i __A,__m256i __B,__m256i __C)
{
  return (__m256i) __builtin_ia32_vpdpwssds_v8si ((__v8si) __A,
        (__v8si) __B,
        (__v8si) __C);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_dpwssds_avx_epi32(__m128i __A,__m128i __B,__m128i __C)
{
  return (__m128i) __builtin_ia32_vpdpwssds_v4si ((__v4si) __A,
        (__v4si) __B,
        (__v4si) __C);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx2")
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_abs_epi8 (__m256i __A)
{
  return (__m256i)__builtin_ia32_pabsb256 ((__v32qi)__A);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_abs_epi16 (__m256i __A)
{
  return (__m256i)__builtin_ia32_pabsw256 ((__v16hi)__A);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_abs_epi32 (__m256i __A)
{
  return (__m256i)__builtin_ia32_pabsd256 ((__v8si)__A);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_packs_epi32 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_packssdw256 ((__v8si)__A, (__v8si)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_packs_epi16 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_packsswb256 ((__v16hi)__A, (__v16hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_packus_epi32 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_packusdw256 ((__v8si)__A, (__v8si)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_packus_epi16 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_packuswb256 ((__v16hi)__A, (__v16hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_add_epi8 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v32qu)__A + (__v32qu)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_add_epi16 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v16hu)__A + (__v16hu)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_add_epi32 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v8su)__A + (__v8su)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_add_epi64 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v4du)__A + (__v4du)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_adds_epi8 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_paddsb256 ((__v32qi)__A, (__v32qi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_adds_epi16 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_paddsw256 ((__v16hi)__A, (__v16hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_adds_epu8 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_paddusb256 ((__v32qi)__A, (__v32qi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_adds_epu16 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_paddusw256 ((__v16hi)__A, (__v16hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_and_si256 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v4du)__A & (__v4du)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_andnot_si256 (__m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_andnotsi256 ((__v4di)__A, (__v4di)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_avg_epu8 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_pavgb256 ((__v32qi)__A, (__v32qi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_avg_epu16 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_pavgw256 ((__v16hi)__A, (__v16hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_blendv_epi8 (__m256i __X, __m256i __Y, __m256i __M)
{
  return (__m256i) __builtin_ia32_pblendvb256 ((__v32qi)__X,
            (__v32qi)__Y,
            (__v32qi)__M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpeq_epi8 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v32qi)__A == (__v32qi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpeq_epi16 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v16hi)__A == (__v16hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpeq_epi32 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v8si)__A == (__v8si)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpeq_epi64 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v4di)__A == (__v4di)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpgt_epi8 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v32qs)__A > (__v32qs)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpgt_epi16 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v16hi)__A > (__v16hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpgt_epi32 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v8si)__A > (__v8si)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpgt_epi64 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v4di)__A > (__v4di)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_hadd_epi16 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_phaddw256 ((__v16hi)__X,
          (__v16hi)__Y);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_hadd_epi32 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_phaddd256 ((__v8si)__X, (__v8si)__Y);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_hadds_epi16 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_phaddsw256 ((__v16hi)__X,
           (__v16hi)__Y);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_hsub_epi16 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_phsubw256 ((__v16hi)__X,
          (__v16hi)__Y);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_hsub_epi32 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_phsubd256 ((__v8si)__X, (__v8si)__Y);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_hsubs_epi16 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_phsubsw256 ((__v16hi)__X,
           (__v16hi)__Y);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maddubs_epi16 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_pmaddubsw256 ((__v32qi)__X,
      (__v32qi)__Y);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_madd_epi16 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_pmaddwd256 ((__v16hi)__A,
          (__v16hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_max_epi8 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_pmaxsb256 ((__v32qi)__A, (__v32qi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_max_epi16 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_pmaxsw256 ((__v16hi)__A, (__v16hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_max_epi32 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_pmaxsd256 ((__v8si)__A, (__v8si)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_max_epu8 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_pmaxub256 ((__v32qi)__A, (__v32qi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_max_epu16 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_pmaxuw256 ((__v16hi)__A, (__v16hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_max_epu32 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_pmaxud256 ((__v8si)__A, (__v8si)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_min_epi8 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_pminsb256 ((__v32qi)__A, (__v32qi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_min_epi16 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_pminsw256 ((__v16hi)__A, (__v16hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_min_epi32 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_pminsd256 ((__v8si)__A, (__v8si)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_min_epu8 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_pminub256 ((__v32qi)__A, (__v32qi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_min_epu16 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_pminuw256 ((__v16hi)__A, (__v16hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_min_epu32 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_pminud256 ((__v8si)__A, (__v8si)__B);
}
extern __inline int
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_movemask_epi8 (__m256i __A)
{
  return __builtin_ia32_pmovmskb256 ((__v32qi)__A);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepi8_epi16 (__m128i __X)
{
  return (__m256i) __builtin_ia32_pmovsxbw256 ((__v16qi)__X);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepi8_epi32 (__m128i __X)
{
  return (__m256i) __builtin_ia32_pmovsxbd256 ((__v16qi)__X);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepi8_epi64 (__m128i __X)
{
  return (__m256i) __builtin_ia32_pmovsxbq256 ((__v16qi)__X);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepi16_epi32 (__m128i __X)
{
  return (__m256i) __builtin_ia32_pmovsxwd256 ((__v8hi)__X);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepi16_epi64 (__m128i __X)
{
  return (__m256i) __builtin_ia32_pmovsxwq256 ((__v8hi)__X);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepi32_epi64 (__m128i __X)
{
  return (__m256i) __builtin_ia32_pmovsxdq256 ((__v4si)__X);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepu8_epi16 (__m128i __X)
{
  return (__m256i) __builtin_ia32_pmovzxbw256 ((__v16qi)__X);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepu8_epi32 (__m128i __X)
{
  return (__m256i) __builtin_ia32_pmovzxbd256 ((__v16qi)__X);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepu8_epi64 (__m128i __X)
{
  return (__m256i) __builtin_ia32_pmovzxbq256 ((__v16qi)__X);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepu16_epi32 (__m128i __X)
{
  return (__m256i) __builtin_ia32_pmovzxwd256 ((__v8hi)__X);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepu16_epi64 (__m128i __X)
{
  return (__m256i) __builtin_ia32_pmovzxwq256 ((__v8hi)__X);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepu32_epi64 (__m128i __X)
{
  return (__m256i) __builtin_ia32_pmovzxdq256 ((__v4si)__X);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mul_epi32 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_pmuldq256 ((__v8si)__X, (__v8si)__Y);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mulhrs_epi16 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_pmulhrsw256 ((__v16hi)__X,
            (__v16hi)__Y);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mulhi_epu16 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_pmulhuw256 ((__v16hi)__A, (__v16hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mulhi_epi16 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_pmulhw256 ((__v16hi)__A, (__v16hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mullo_epi16 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v16hu)__A * (__v16hu)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mullo_epi32 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v8su)__A * (__v8su)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mul_epu32 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_pmuludq256 ((__v8si)__A, (__v8si)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_or_si256 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v4du)__A | (__v4du)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sad_epu8 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_psadbw256 ((__v32qi)__A, (__v32qi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_shuffle_epi8 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_pshufb256 ((__v32qi)__X,
          (__v32qi)__Y);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sign_epi8 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_psignb256 ((__v32qi)__X, (__v32qi)__Y);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sign_epi16 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_psignw256 ((__v16hi)__X, (__v16hi)__Y);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sign_epi32 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_psignd256 ((__v8si)__X, (__v8si)__Y);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_slli_epi16 (__m256i __A, int __B)
{
  return (__m256i)__builtin_ia32_psllwi256 ((__v16hi)__A, __B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sll_epi16 (__m256i __A, __m128i __B)
{
  return (__m256i)__builtin_ia32_psllw256((__v16hi)__A, (__v8hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_slli_epi32 (__m256i __A, int __B)
{
  return (__m256i)__builtin_ia32_pslldi256 ((__v8si)__A, __B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sll_epi32 (__m256i __A, __m128i __B)
{
  return (__m256i)__builtin_ia32_pslld256((__v8si)__A, (__v4si)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_slli_epi64 (__m256i __A, int __B)
{
  return (__m256i)__builtin_ia32_psllqi256 ((__v4di)__A, __B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sll_epi64 (__m256i __A, __m128i __B)
{
  return (__m256i)__builtin_ia32_psllq256((__v4di)__A, (__v2di)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_srai_epi16 (__m256i __A, int __B)
{
  return (__m256i)__builtin_ia32_psrawi256 ((__v16hi)__A, __B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sra_epi16 (__m256i __A, __m128i __B)
{
  return (__m256i)__builtin_ia32_psraw256 ((__v16hi)__A, (__v8hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_srai_epi32 (__m256i __A, int __B)
{
  return (__m256i)__builtin_ia32_psradi256 ((__v8si)__A, __B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sra_epi32 (__m256i __A, __m128i __B)
{
  return (__m256i)__builtin_ia32_psrad256 ((__v8si)__A, (__v4si)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_srli_epi16 (__m256i __A, int __B)
{
  return (__m256i)__builtin_ia32_psrlwi256 ((__v16hi)__A, __B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_srl_epi16 (__m256i __A, __m128i __B)
{
  return (__m256i)__builtin_ia32_psrlw256((__v16hi)__A, (__v8hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_srli_epi32 (__m256i __A, int __B)
{
  return (__m256i)__builtin_ia32_psrldi256 ((__v8si)__A, __B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_srl_epi32 (__m256i __A, __m128i __B)
{
  return (__m256i)__builtin_ia32_psrld256((__v8si)__A, (__v4si)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_srli_epi64 (__m256i __A, int __B)
{
  return (__m256i)__builtin_ia32_psrlqi256 ((__v4di)__A, __B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_srl_epi64 (__m256i __A, __m128i __B)
{
  return (__m256i)__builtin_ia32_psrlq256((__v4di)__A, (__v2di)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sub_epi8 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v32qu)__A - (__v32qu)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sub_epi16 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v16hu)__A - (__v16hu)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sub_epi32 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v8su)__A - (__v8su)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sub_epi64 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v4du)__A - (__v4du)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_subs_epi8 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_psubsb256 ((__v32qi)__A, (__v32qi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_subs_epi16 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_psubsw256 ((__v16hi)__A, (__v16hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_subs_epu8 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_psubusb256 ((__v32qi)__A, (__v32qi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_subs_epu16 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_psubusw256 ((__v16hi)__A, (__v16hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_unpackhi_epi8 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_punpckhbw256 ((__v32qi)__A, (__v32qi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_unpackhi_epi16 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_punpckhwd256 ((__v16hi)__A, (__v16hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_unpackhi_epi32 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_punpckhdq256 ((__v8si)__A, (__v8si)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_unpackhi_epi64 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_punpckhqdq256 ((__v4di)__A, (__v4di)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_unpacklo_epi8 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_punpcklbw256 ((__v32qi)__A, (__v32qi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_unpacklo_epi16 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_punpcklwd256 ((__v16hi)__A, (__v16hi)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_unpacklo_epi32 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_punpckldq256 ((__v8si)__A, (__v8si)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_unpacklo_epi64 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_punpcklqdq256 ((__v4di)__A, (__v4di)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_xor_si256 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v4du)__A ^ (__v4du)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_stream_load_si256 (__m256i const *__X)
{
  return (__m256i) __builtin_ia32_movntdqa256 ((__v4di *) __X);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_broadcastss_ps (__m128 __X)
{
  return (__m128) __builtin_ia32_vbroadcastss_ps ((__v4sf)__X);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_broadcastss_ps (__m128 __X)
{
  return (__m256) __builtin_ia32_vbroadcastss_ps256 ((__v4sf)__X);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_broadcastsd_pd (__m128d __X)
{
  return (__m256d) __builtin_ia32_vbroadcastsd_pd256 ((__v2df)__X);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_broadcastsi128_si256 (__m128i __X)
{
  return (__m256i) __builtin_ia32_vbroadcastsi256 ((__v2di)__X);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_broadcastb_epi8 (__m128i __X)
{
  return (__m256i) __builtin_ia32_pbroadcastb256 ((__v16qi)__X);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_broadcastw_epi16 (__m128i __X)
{
  return (__m256i) __builtin_ia32_pbroadcastw256 ((__v8hi)__X);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_broadcastd_epi32 (__m128i __X)
{
  return (__m256i) __builtin_ia32_pbroadcastd256 ((__v4si)__X);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_broadcastq_epi64 (__m128i __X)
{
  return (__m256i) __builtin_ia32_pbroadcastq256 ((__v2di)__X);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_broadcastb_epi8 (__m128i __X)
{
  return (__m128i) __builtin_ia32_pbroadcastb128 ((__v16qi)__X);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_broadcastw_epi16 (__m128i __X)
{
  return (__m128i) __builtin_ia32_pbroadcastw128 ((__v8hi)__X);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_broadcastd_epi32 (__m128i __X)
{
  return (__m128i) __builtin_ia32_pbroadcastd128 ((__v4si)__X);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_broadcastq_epi64 (__m128i __X)
{
  return (__m128i) __builtin_ia32_pbroadcastq128 ((__v2di)__X);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_permutevar8x32_epi32 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_permvarsi256 ((__v8si)__X, (__v8si)__Y);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_permutevar8x32_ps (__m256 __X, __m256i __Y)
{
  return (__m256) __builtin_ia32_permvarsf256 ((__v8sf)__X, (__v8si)__Y);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskload_epi32 (int const *__X, __m256i __M )
{
  return (__m256i) __builtin_ia32_maskloadd256 ((const __v8si *)__X,
      (__v8si)__M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskload_epi64 (long long const *__X, __m256i __M )
{
  return (__m256i) __builtin_ia32_maskloadq256 ((const __v4di *)__X,
      (__v4di)__M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskload_epi32 (int const *__X, __m128i __M )
{
  return (__m128i) __builtin_ia32_maskloadd ((const __v4si *)__X,
          (__v4si)__M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskload_epi64 (long long const *__X, __m128i __M )
{
  return (__m128i) __builtin_ia32_maskloadq ((const __v2di *)__X,
          (__v2di)__M);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskstore_epi32 (int *__X, __m256i __M, __m256i __Y )
{
  __builtin_ia32_maskstored256 ((__v8si *)__X, (__v8si)__M, (__v8si)__Y);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskstore_epi64 (long long *__X, __m256i __M, __m256i __Y )
{
  __builtin_ia32_maskstoreq256 ((__v4di *)__X, (__v4di)__M, (__v4di)__Y);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskstore_epi32 (int *__X, __m128i __M, __m128i __Y )
{
  __builtin_ia32_maskstored ((__v4si *)__X, (__v4si)__M, (__v4si)__Y);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskstore_epi64 (long long *__X, __m128i __M, __m128i __Y )
{
  __builtin_ia32_maskstoreq (( __v2di *)__X, (__v2di)__M, (__v2di)__Y);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sllv_epi32 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_psllv8si ((__v8si)__X, (__v8si)__Y);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_sllv_epi32 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_psllv4si ((__v4si)__X, (__v4si)__Y);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sllv_epi64 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_psllv4di ((__v4di)__X, (__v4di)__Y);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_sllv_epi64 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_psllv2di ((__v2di)__X, (__v2di)__Y);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_srav_epi32 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_psrav8si ((__v8si)__X, (__v8si)__Y);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_srav_epi32 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_psrav4si ((__v4si)__X, (__v4si)__Y);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_srlv_epi32 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_psrlv8si ((__v8si)__X, (__v8si)__Y);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_srlv_epi32 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_psrlv4si ((__v4si)__X, (__v4si)__Y);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_srlv_epi64 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_psrlv4di ((__v4di)__X, (__v4di)__Y);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_srlv_epi64 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_psrlv2di ((__v2di)__X, (__v2di)__Y);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx512f")
typedef double __v8df __attribute__ ((__vector_size__ (64)));
typedef float __v16sf __attribute__ ((__vector_size__ (64)));
typedef long long __v8di __attribute__ ((__vector_size__ (64)));
typedef unsigned long long __v8du __attribute__ ((__vector_size__ (64)));
typedef int __v16si __attribute__ ((__vector_size__ (64)));
typedef unsigned int __v16su __attribute__ ((__vector_size__ (64)));
typedef short __v32hi __attribute__ ((__vector_size__ (64)));
typedef unsigned short __v32hu __attribute__ ((__vector_size__ (64)));
typedef char __v64qi __attribute__ ((__vector_size__ (64)));
typedef unsigned char __v64qu __attribute__ ((__vector_size__ (64)));
typedef float __m512 __attribute__ ((__vector_size__ (64), __may_alias__));
typedef long long __m512i __attribute__ ((__vector_size__ (64), __may_alias__));
typedef double __m512d __attribute__ ((__vector_size__ (64), __may_alias__));
typedef float __m512_u __attribute__ ((__vector_size__ (64), __may_alias__, __aligned__ (1)));
typedef long long __m512i_u __attribute__ ((__vector_size__ (64), __may_alias__, __aligned__ (1)));
typedef double __m512d_u __attribute__ ((__vector_size__ (64), __may_alias__, __aligned__ (1)));
typedef unsigned char __mmask8;
typedef unsigned short __mmask16;
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_int2mask (int __M)
{
  return (__mmask16) __M;
}
extern __inline int
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask2int (__mmask16 __M)
{
  return (int) __M;
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_set_epi64 (long long __A, long long __B, long long __C,
    long long __D, long long __E, long long __F,
    long long __G, long long __H)
{
  return __extension__ (__m512i) (__v8di)
  { __H, __G, __F, __E, __D, __C, __B, __A };
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_set_epi32 (int __A, int __B, int __C, int __D,
    int __E, int __F, int __G, int __H,
    int __I, int __J, int __K, int __L,
    int __M, int __N, int __O, int __P)
{
  return __extension__ (__m512i)(__v16si)
  { __P, __O, __N, __M, __L, __K, __J, __I,
    __H, __G, __F, __E, __D, __C, __B, __A };
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_set_epi16 (short __q31, short __q30, short __q29, short __q28,
    short __q27, short __q26, short __q25, short __q24,
    short __q23, short __q22, short __q21, short __q20,
    short __q19, short __q18, short __q17, short __q16,
    short __q15, short __q14, short __q13, short __q12,
    short __q11, short __q10, short __q09, short __q08,
    short __q07, short __q06, short __q05, short __q04,
    short __q03, short __q02, short __q01, short __q00)
{
  return __extension__ (__m512i)(__v32hi){
    __q00, __q01, __q02, __q03, __q04, __q05, __q06, __q07,
    __q08, __q09, __q10, __q11, __q12, __q13, __q14, __q15,
    __q16, __q17, __q18, __q19, __q20, __q21, __q22, __q23,
    __q24, __q25, __q26, __q27, __q28, __q29, __q30, __q31
  };
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_set_epi8 (char __q63, char __q62, char __q61, char __q60,
   char __q59, char __q58, char __q57, char __q56,
   char __q55, char __q54, char __q53, char __q52,
   char __q51, char __q50, char __q49, char __q48,
   char __q47, char __q46, char __q45, char __q44,
   char __q43, char __q42, char __q41, char __q40,
   char __q39, char __q38, char __q37, char __q36,
   char __q35, char __q34, char __q33, char __q32,
   char __q31, char __q30, char __q29, char __q28,
   char __q27, char __q26, char __q25, char __q24,
   char __q23, char __q22, char __q21, char __q20,
   char __q19, char __q18, char __q17, char __q16,
   char __q15, char __q14, char __q13, char __q12,
   char __q11, char __q10, char __q09, char __q08,
   char __q07, char __q06, char __q05, char __q04,
   char __q03, char __q02, char __q01, char __q00)
{
  return __extension__ (__m512i)(__v64qi){
    __q00, __q01, __q02, __q03, __q04, __q05, __q06, __q07,
    __q08, __q09, __q10, __q11, __q12, __q13, __q14, __q15,
    __q16, __q17, __q18, __q19, __q20, __q21, __q22, __q23,
    __q24, __q25, __q26, __q27, __q28, __q29, __q30, __q31,
    __q32, __q33, __q34, __q35, __q36, __q37, __q38, __q39,
    __q40, __q41, __q42, __q43, __q44, __q45, __q46, __q47,
    __q48, __q49, __q50, __q51, __q52, __q53, __q54, __q55,
    __q56, __q57, __q58, __q59, __q60, __q61, __q62, __q63
  };
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_set_pd (double __A, double __B, double __C, double __D,
        double __E, double __F, double __G, double __H)
{
  return __extension__ (__m512d)
  { __H, __G, __F, __E, __D, __C, __B, __A };
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_set_ps (float __A, float __B, float __C, float __D,
        float __E, float __F, float __G, float __H,
        float __I, float __J, float __K, float __L,
        float __M, float __N, float __O, float __P)
{
  return __extension__ (__m512)
  { __P, __O, __N, __M, __L, __K, __J, __I,
    __H, __G, __F, __E, __D, __C, __B, __A };
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_undefined_ps (void)
{
  __m512 __Y = __Y;
  return __Y;
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_undefined_pd (void)
{
  __m512d __Y = __Y;
  return __Y;
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_undefined_epi32 (void)
{
  __m512i __Y = __Y;
  return __Y;
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_set1_epi8 (char __A)
{
  return __extension__ (__m512i)(__v64qi)
  { __A, __A, __A, __A, __A, __A, __A, __A,
    __A, __A, __A, __A, __A, __A, __A, __A,
    __A, __A, __A, __A, __A, __A, __A, __A,
    __A, __A, __A, __A, __A, __A, __A, __A,
    __A, __A, __A, __A, __A, __A, __A, __A,
    __A, __A, __A, __A, __A, __A, __A, __A,
    __A, __A, __A, __A, __A, __A, __A, __A,
    __A, __A, __A, __A, __A, __A, __A, __A };
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_set1_epi16 (short __A)
{
  return __extension__ (__m512i)(__v32hi)
  { __A, __A, __A, __A, __A, __A, __A, __A,
    __A, __A, __A, __A, __A, __A, __A, __A,
    __A, __A, __A, __A, __A, __A, __A, __A,
    __A, __A, __A, __A, __A, __A, __A, __A };
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_set1_pd (double __A)
{
  return __extension__ (__m512d)(__v8df)
    { __A, __A, __A, __A, __A, __A, __A, __A };
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_set1_ps (float __A)
{
  return __extension__ (__m512)(__v16sf)
    { __A, __A, __A, __A, __A, __A, __A, __A,
      __A, __A, __A, __A, __A, __A, __A, __A };
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_set4_epi32 (int __A, int __B, int __C, int __D)
{
  return __extension__ (__m512i)(__v16si)
  { __D, __C, __B, __A, __D, __C, __B, __A,
    __D, __C, __B, __A, __D, __C, __B, __A };
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_set4_epi64 (long long __A, long long __B, long long __C,
     long long __D)
{
  return __extension__ (__m512i) (__v8di)
  { __D, __C, __B, __A, __D, __C, __B, __A };
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_set4_pd (double __A, double __B, double __C, double __D)
{
  return __extension__ (__m512d)
  { __D, __C, __B, __A, __D, __C, __B, __A };
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_set4_ps (float __A, float __B, float __C, float __D)
{
  return __extension__ (__m512)
  { __D, __C, __B, __A, __D, __C, __B, __A,
    __D, __C, __B, __A, __D, __C, __B, __A };
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_setzero_ps (void)
{
  return __extension__ (__m512){ 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
     0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 };
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_setzero (void)
{
  return _mm512_setzero_ps ();
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_setzero_pd (void)
{
  return __extension__ (__m512d) { 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0 };
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_setzero_epi32 (void)
{
  return __extension__ (__m512i)(__v8di){ 0, 0, 0, 0, 0, 0, 0, 0 };
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_setzero_si512 (void)
{
  return __extension__ (__m512i)(__v8di){ 0, 0, 0, 0, 0, 0, 0, 0 };
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_mov_pd (__m512d __W, __mmask8 __U, __m512d __A)
{
  return (__m512d) __builtin_ia32_movapd512_mask ((__v8df) __A,
        (__v8df) __W,
        (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_mov_pd (__mmask8 __U, __m512d __A)
{
  return (__m512d) __builtin_ia32_movapd512_mask ((__v8df) __A,
        (__v8df)
        _mm512_setzero_pd (),
        (__mmask8) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_mov_ps (__m512 __W, __mmask16 __U, __m512 __A)
{
  return (__m512) __builtin_ia32_movaps512_mask ((__v16sf) __A,
       (__v16sf) __W,
       (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_mov_ps (__mmask16 __U, __m512 __A)
{
  return (__m512) __builtin_ia32_movaps512_mask ((__v16sf) __A,
       (__v16sf)
       _mm512_setzero_ps (),
       (__mmask16) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_load_pd (void const *__P)
{
  return *(__m512d *) __P;
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_load_pd (__m512d __W, __mmask8 __U, void const *__P)
{
  return (__m512d) __builtin_ia32_loadapd512_mask ((const __v8df *) __P,
         (__v8df) __W,
         (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_load_pd (__mmask8 __U, void const *__P)
{
  return (__m512d) __builtin_ia32_loadapd512_mask ((const __v8df *) __P,
         (__v8df)
         _mm512_setzero_pd (),
         (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_store_pd (void *__P, __m512d __A)
{
  *(__m512d *) __P = __A;
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_store_pd (void *__P, __mmask8 __U, __m512d __A)
{
  __builtin_ia32_storeapd512_mask ((__v8df *) __P, (__v8df) __A,
       (__mmask8) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_load_ps (void const *__P)
{
  return *(__m512 *) __P;
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_load_ps (__m512 __W, __mmask16 __U, void const *__P)
{
  return (__m512) __builtin_ia32_loadaps512_mask ((const __v16sf *) __P,
        (__v16sf) __W,
        (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_load_ps (__mmask16 __U, void const *__P)
{
  return (__m512) __builtin_ia32_loadaps512_mask ((const __v16sf *) __P,
        (__v16sf)
        _mm512_setzero_ps (),
        (__mmask16) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_store_ps (void *__P, __m512 __A)
{
  *(__m512 *) __P = __A;
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_store_ps (void *__P, __mmask16 __U, __m512 __A)
{
  __builtin_ia32_storeaps512_mask ((__v16sf *) __P, (__v16sf) __A,
       (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_mov_epi64 (__m512i __W, __mmask8 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_movdqa64_512_mask ((__v8di) __A,
           (__v8di) __W,
           (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_mov_epi64 (__mmask8 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_movdqa64_512_mask ((__v8di) __A,
           (__v8di)
           _mm512_setzero_si512 (),
           (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_load_epi64 (void const *__P)
{
  return *(__m512i *) __P;
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_load_epi64 (__m512i __W, __mmask8 __U, void const *__P)
{
  return (__m512i) __builtin_ia32_movdqa64load512_mask ((const __v8di *) __P,
       (__v8di) __W,
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_load_epi64 (__mmask8 __U, void const *__P)
{
  return (__m512i) __builtin_ia32_movdqa64load512_mask ((const __v8di *) __P,
       (__v8di)
       _mm512_setzero_si512 (),
       (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_store_epi64 (void *__P, __m512i __A)
{
  *(__m512i *) __P = __A;
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_store_epi64 (void *__P, __mmask8 __U, __m512i __A)
{
  __builtin_ia32_movdqa64store512_mask ((__v8di *) __P, (__v8di) __A,
     (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_mov_epi32 (__m512i __W, __mmask16 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_movdqa32_512_mask ((__v16si) __A,
           (__v16si) __W,
           (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_mov_epi32 (__mmask16 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_movdqa32_512_mask ((__v16si) __A,
           (__v16si)
           _mm512_setzero_si512 (),
           (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_load_si512 (void const *__P)
{
  return *(__m512i *) __P;
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_load_epi32 (void const *__P)
{
  return *(__m512i *) __P;
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_load_epi32 (__m512i __W, __mmask16 __U, void const *__P)
{
  return (__m512i) __builtin_ia32_movdqa32load512_mask ((const __v16si *) __P,
       (__v16si) __W,
       (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_load_epi32 (__mmask16 __U, void const *__P)
{
  return (__m512i) __builtin_ia32_movdqa32load512_mask ((const __v16si *) __P,
       (__v16si)
       _mm512_setzero_si512 (),
       (__mmask16) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_store_si512 (void *__P, __m512i __A)
{
  *(__m512i *) __P = __A;
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_store_epi32 (void *__P, __m512i __A)
{
  *(__m512i *) __P = __A;
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_store_epi32 (void *__P, __mmask16 __U, __m512i __A)
{
  __builtin_ia32_movdqa32store512_mask ((__v16si *) __P, (__v16si) __A,
     (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mullo_epi32 (__m512i __A, __m512i __B)
{
  return (__m512i) ((__v16su) __A * (__v16su) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_mullo_epi32 (__mmask16 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmulld512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si)
        _mm512_setzero_si512 (),
        __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_mullo_epi32 (__m512i __W, __mmask16 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmulld512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si) __W, __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mullox_epi64 (__m512i __A, __m512i __B)
{
  return (__m512i) ((__v8du) __A * (__v8du) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_mullox_epi64 (__m512i __W, __mmask8 __M, __m512i __A, __m512i __B)
{
  return _mm512_mask_mov_epi64 (__W, __M, _mm512_mullox_epi64 (__A, __B));
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_sllv_epi32 (__m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_psllv16si_mask ((__v16si) __X,
        (__v16si) __Y,
        (__v16si)
        _mm512_undefined_epi32 (),
        (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_sllv_epi32 (__m512i __W, __mmask16 __U, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_psllv16si_mask ((__v16si) __X,
        (__v16si) __Y,
        (__v16si) __W,
        (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_sllv_epi32 (__mmask16 __U, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_psllv16si_mask ((__v16si) __X,
        (__v16si) __Y,
        (__v16si)
        _mm512_setzero_si512 (),
        (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_srav_epi32 (__m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_psrav16si_mask ((__v16si) __X,
        (__v16si) __Y,
        (__v16si)
        _mm512_undefined_epi32 (),
        (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_srav_epi32 (__m512i __W, __mmask16 __U, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_psrav16si_mask ((__v16si) __X,
        (__v16si) __Y,
        (__v16si) __W,
        (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_srav_epi32 (__mmask16 __U, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_psrav16si_mask ((__v16si) __X,
        (__v16si) __Y,
        (__v16si)
        _mm512_setzero_si512 (),
        (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_srlv_epi32 (__m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_psrlv16si_mask ((__v16si) __X,
        (__v16si) __Y,
        (__v16si)
        _mm512_undefined_epi32 (),
        (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_srlv_epi32 (__m512i __W, __mmask16 __U, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_psrlv16si_mask ((__v16si) __X,
        (__v16si) __Y,
        (__v16si) __W,
        (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_srlv_epi32 (__mmask16 __U, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_psrlv16si_mask ((__v16si) __X,
        (__v16si) __Y,
        (__v16si)
        _mm512_setzero_si512 (),
        (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_add_epi64 (__m512i __A, __m512i __B)
{
  return (__m512i) ((__v8du) __A + (__v8du) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_add_epi64 (__m512i __W, __mmask8 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_paddq512_mask ((__v8di) __A,
       (__v8di) __B,
       (__v8di) __W,
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_add_epi64 (__mmask8 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_paddq512_mask ((__v8di) __A,
       (__v8di) __B,
       (__v8di)
       _mm512_setzero_si512 (),
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_sub_epi64 (__m512i __A, __m512i __B)
{
  return (__m512i) ((__v8du) __A - (__v8du) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_sub_epi64 (__m512i __W, __mmask8 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psubq512_mask ((__v8di) __A,
       (__v8di) __B,
       (__v8di) __W,
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_sub_epi64 (__mmask8 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psubq512_mask ((__v8di) __A,
       (__v8di) __B,
       (__v8di)
       _mm512_setzero_si512 (),
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_sllv_epi64 (__m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_psllv8di_mask ((__v8di) __X,
       (__v8di) __Y,
       (__v8di)
       _mm512_undefined_pd (),
       (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_sllv_epi64 (__m512i __W, __mmask8 __U, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_psllv8di_mask ((__v8di) __X,
       (__v8di) __Y,
       (__v8di) __W,
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_sllv_epi64 (__mmask8 __U, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_psllv8di_mask ((__v8di) __X,
       (__v8di) __Y,
       (__v8di)
       _mm512_setzero_si512 (),
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_srav_epi64 (__m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_psrav8di_mask ((__v8di) __X,
       (__v8di) __Y,
       (__v8di)
       _mm512_undefined_epi32 (),
       (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_srav_epi64 (__m512i __W, __mmask8 __U, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_psrav8di_mask ((__v8di) __X,
       (__v8di) __Y,
       (__v8di) __W,
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_srav_epi64 (__mmask8 __U, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_psrav8di_mask ((__v8di) __X,
       (__v8di) __Y,
       (__v8di)
       _mm512_setzero_si512 (),
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_srlv_epi64 (__m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_psrlv8di_mask ((__v8di) __X,
       (__v8di) __Y,
       (__v8di)
       _mm512_undefined_epi32 (),
       (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_srlv_epi64 (__m512i __W, __mmask8 __U, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_psrlv8di_mask ((__v8di) __X,
       (__v8di) __Y,
       (__v8di) __W,
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_srlv_epi64 (__mmask8 __U, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_psrlv8di_mask ((__v8di) __X,
       (__v8di) __Y,
       (__v8di)
       _mm512_setzero_si512 (),
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_add_epi32 (__m512i __A, __m512i __B)
{
  return (__m512i) ((__v16su) __A + (__v16su) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_add_epi32 (__m512i __W, __mmask16 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_paddd512_mask ((__v16si) __A,
       (__v16si) __B,
       (__v16si) __W,
       (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_add_epi32 (__mmask16 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_paddd512_mask ((__v16si) __A,
       (__v16si) __B,
       (__v16si)
       _mm512_setzero_si512 (),
       (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mul_epi32 (__m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_pmuldq512_mask ((__v16si) __X,
        (__v16si) __Y,
        (__v8di)
        _mm512_undefined_epi32 (),
        (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_mul_epi32 (__m512i __W, __mmask8 __M, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_pmuldq512_mask ((__v16si) __X,
        (__v16si) __Y,
        (__v8di) __W, __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_mul_epi32 (__mmask8 __M, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_pmuldq512_mask ((__v16si) __X,
        (__v16si) __Y,
        (__v8di)
        _mm512_setzero_si512 (),
        __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_sub_epi32 (__m512i __A, __m512i __B)
{
  return (__m512i) ((__v16su) __A - (__v16su) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_sub_epi32 (__m512i __W, __mmask16 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psubd512_mask ((__v16si) __A,
       (__v16si) __B,
       (__v16si) __W,
       (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_sub_epi32 (__mmask16 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psubd512_mask ((__v16si) __A,
       (__v16si) __B,
       (__v16si)
       _mm512_setzero_si512 (),
       (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mul_epu32 (__m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_pmuludq512_mask ((__v16si) __X,
         (__v16si) __Y,
         (__v8di)
         _mm512_undefined_epi32 (),
         (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_mul_epu32 (__m512i __W, __mmask8 __M, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_pmuludq512_mask ((__v16si) __X,
         (__v16si) __Y,
         (__v8di) __W, __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_mul_epu32 (__mmask8 __M, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_pmuludq512_mask ((__v16si) __X,
         (__v16si) __Y,
         (__v8di)
         _mm512_setzero_si512 (),
         __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_sll_epi64 (__m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psllq512_mask ((__v8di) __A,
       (__v2di) __B,
       (__v8di)
       _mm512_undefined_epi32 (),
       (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_sll_epi64 (__m512i __W, __mmask8 __U, __m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psllq512_mask ((__v8di) __A,
       (__v2di) __B,
       (__v8di) __W,
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_sll_epi64 (__mmask8 __U, __m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psllq512_mask ((__v8di) __A,
       (__v2di) __B,
       (__v8di)
       _mm512_setzero_si512 (),
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_srl_epi64 (__m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psrlq512_mask ((__v8di) __A,
       (__v2di) __B,
       (__v8di)
       _mm512_undefined_epi32 (),
       (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_srl_epi64 (__m512i __W, __mmask8 __U, __m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psrlq512_mask ((__v8di) __A,
       (__v2di) __B,
       (__v8di) __W,
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_srl_epi64 (__mmask8 __U, __m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psrlq512_mask ((__v8di) __A,
       (__v2di) __B,
       (__v8di)
       _mm512_setzero_si512 (),
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_sra_epi64 (__m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psraq512_mask ((__v8di) __A,
       (__v2di) __B,
       (__v8di)
       _mm512_undefined_epi32 (),
       (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_sra_epi64 (__m512i __W, __mmask8 __U, __m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psraq512_mask ((__v8di) __A,
       (__v2di) __B,
       (__v8di) __W,
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_sra_epi64 (__mmask8 __U, __m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psraq512_mask ((__v8di) __A,
       (__v2di) __B,
       (__v8di)
       _mm512_setzero_si512 (),
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_sll_epi32 (__m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_pslld512_mask ((__v16si) __A,
       (__v4si) __B,
       (__v16si)
       _mm512_undefined_epi32 (),
       (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_sll_epi32 (__m512i __W, __mmask16 __U, __m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_pslld512_mask ((__v16si) __A,
       (__v4si) __B,
       (__v16si) __W,
       (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_sll_epi32 (__mmask16 __U, __m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_pslld512_mask ((__v16si) __A,
       (__v4si) __B,
       (__v16si)
       _mm512_setzero_si512 (),
       (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_srl_epi32 (__m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psrld512_mask ((__v16si) __A,
       (__v4si) __B,
       (__v16si)
       _mm512_undefined_epi32 (),
       (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_srl_epi32 (__m512i __W, __mmask16 __U, __m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psrld512_mask ((__v16si) __A,
       (__v4si) __B,
       (__v16si) __W,
       (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_srl_epi32 (__mmask16 __U, __m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psrld512_mask ((__v16si) __A,
       (__v4si) __B,
       (__v16si)
       _mm512_setzero_si512 (),
       (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_sra_epi32 (__m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psrad512_mask ((__v16si) __A,
       (__v4si) __B,
       (__v16si)
       _mm512_undefined_epi32 (),
       (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_sra_epi32 (__m512i __W, __mmask16 __U, __m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psrad512_mask ((__v16si) __A,
       (__v4si) __B,
       (__v16si) __W,
       (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_sra_epi32 (__mmask16 __U, __m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psrad512_mask ((__v16si) __A,
       (__v4si) __B,
       (__v16si)
       _mm512_setzero_si512 (),
       (__mmask16) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_rcp14_pd (__m512d __A)
{
  return (__m512d) __builtin_ia32_rcp14pd512_mask ((__v8df) __A,
         (__v8df)
         _mm512_undefined_pd (),
         (__mmask8) -1);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_rcp14_pd (__m512d __W, __mmask8 __U, __m512d __A)
{
  return (__m512d) __builtin_ia32_rcp14pd512_mask ((__v8df) __A,
         (__v8df) __W,
         (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_rcp14_pd (__mmask8 __U, __m512d __A)
{
  return (__m512d) __builtin_ia32_rcp14pd512_mask ((__v8df) __A,
         (__v8df)
         _mm512_setzero_pd (),
         (__mmask8) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_rcp14_ps (__m512 __A)
{
  return (__m512) __builtin_ia32_rcp14ps512_mask ((__v16sf) __A,
        (__v16sf)
        _mm512_undefined_ps (),
        (__mmask16) -1);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_rcp14_ps (__m512 __W, __mmask16 __U, __m512 __A)
{
  return (__m512) __builtin_ia32_rcp14ps512_mask ((__v16sf) __A,
        (__v16sf) __W,
        (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_rcp14_ps (__mmask16 __U, __m512 __A)
{
  return (__m512) __builtin_ia32_rcp14ps512_mask ((__v16sf) __A,
        (__v16sf)
        _mm512_setzero_ps (),
        (__mmask16) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_rcp14_sd (__m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_rcp14sd ((__v2df) __B,
        (__v2df) __A);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_rcp14_sd (__m128d __W, __mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_rcp14sd_mask ((__v2df) __B,
      (__v2df) __A,
      (__v2df) __W,
      (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_rcp14_sd (__mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_rcp14sd_mask ((__v2df) __B,
      (__v2df) __A,
      (__v2df) _mm_setzero_ps (),
      (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_rcp14_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_rcp14ss ((__v4sf) __B,
       (__v4sf) __A);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_rcp14_ss (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_rcp14ss_mask ((__v4sf) __B,
      (__v4sf) __A,
      (__v4sf) __W,
      (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_rcp14_ss (__mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_rcp14ss_mask ((__v4sf) __B,
      (__v4sf) __A,
      (__v4sf) _mm_setzero_ps (),
      (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_rsqrt14_pd (__m512d __A)
{
  return (__m512d) __builtin_ia32_rsqrt14pd512_mask ((__v8df) __A,
           (__v8df)
           _mm512_undefined_pd (),
           (__mmask8) -1);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_rsqrt14_pd (__m512d __W, __mmask8 __U, __m512d __A)
{
  return (__m512d) __builtin_ia32_rsqrt14pd512_mask ((__v8df) __A,
           (__v8df) __W,
           (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_rsqrt14_pd (__mmask8 __U, __m512d __A)
{
  return (__m512d) __builtin_ia32_rsqrt14pd512_mask ((__v8df) __A,
           (__v8df)
           _mm512_setzero_pd (),
           (__mmask8) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_rsqrt14_ps (__m512 __A)
{
  return (__m512) __builtin_ia32_rsqrt14ps512_mask ((__v16sf) __A,
          (__v16sf)
          _mm512_undefined_ps (),
          (__mmask16) -1);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_rsqrt14_ps (__m512 __W, __mmask16 __U, __m512 __A)
{
  return (__m512) __builtin_ia32_rsqrt14ps512_mask ((__v16sf) __A,
          (__v16sf) __W,
          (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_rsqrt14_ps (__mmask16 __U, __m512 __A)
{
  return (__m512) __builtin_ia32_rsqrt14ps512_mask ((__v16sf) __A,
          (__v16sf)
          _mm512_setzero_ps (),
          (__mmask16) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_rsqrt14_sd (__m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_rsqrt14sd ((__v2df) __B,
          (__v2df) __A);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_rsqrt14_sd (__m128d __W, __mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_rsqrt14sd_mask ((__v2df) __B,
       (__v2df) __A,
       (__v2df) __W,
       (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_rsqrt14_sd (__mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_rsqrt14sd_mask ((__v2df) __B,
       (__v2df) __A,
       (__v2df) _mm_setzero_pd (),
       (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_rsqrt14_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_rsqrt14ss ((__v4sf) __B,
         (__v4sf) __A);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_rsqrt14_ss (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_rsqrt14ss_mask ((__v4sf) __B,
       (__v4sf) __A,
       (__v4sf) __W,
       (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_rsqrt14_ss (__mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_rsqrt14ss_mask ((__v4sf) __B,
      (__v4sf) __A,
      (__v4sf) _mm_setzero_ps (),
      (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepi8_epi32 (__m128i __A)
{
  return (__m512i) __builtin_ia32_pmovsxbd512_mask ((__v16qi) __A,
          (__v16si)
          _mm512_undefined_epi32 (),
          (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi8_epi32 (__m512i __W, __mmask16 __U, __m128i __A)
{
  return (__m512i) __builtin_ia32_pmovsxbd512_mask ((__v16qi) __A,
          (__v16si) __W,
          (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepi8_epi32 (__mmask16 __U, __m128i __A)
{
  return (__m512i) __builtin_ia32_pmovsxbd512_mask ((__v16qi) __A,
          (__v16si)
          _mm512_setzero_si512 (),
          (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepi8_epi64 (__m128i __A)
{
  return (__m512i) __builtin_ia32_pmovsxbq512_mask ((__v16qi) __A,
          (__v8di)
          _mm512_undefined_epi32 (),
          (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi8_epi64 (__m512i __W, __mmask8 __U, __m128i __A)
{
  return (__m512i) __builtin_ia32_pmovsxbq512_mask ((__v16qi) __A,
          (__v8di) __W,
          (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepi8_epi64 (__mmask8 __U, __m128i __A)
{
  return (__m512i) __builtin_ia32_pmovsxbq512_mask ((__v16qi) __A,
          (__v8di)
          _mm512_setzero_si512 (),
          (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepi16_epi32 (__m256i __A)
{
  return (__m512i) __builtin_ia32_pmovsxwd512_mask ((__v16hi) __A,
          (__v16si)
          _mm512_undefined_epi32 (),
          (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi16_epi32 (__m512i __W, __mmask16 __U, __m256i __A)
{
  return (__m512i) __builtin_ia32_pmovsxwd512_mask ((__v16hi) __A,
          (__v16si) __W,
          (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepi16_epi32 (__mmask16 __U, __m256i __A)
{
  return (__m512i) __builtin_ia32_pmovsxwd512_mask ((__v16hi) __A,
          (__v16si)
          _mm512_setzero_si512 (),
          (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepi16_epi64 (__m128i __A)
{
  return (__m512i) __builtin_ia32_pmovsxwq512_mask ((__v8hi) __A,
          (__v8di)
          _mm512_undefined_epi32 (),
          (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi16_epi64 (__m512i __W, __mmask8 __U, __m128i __A)
{
  return (__m512i) __builtin_ia32_pmovsxwq512_mask ((__v8hi) __A,
          (__v8di) __W,
          (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepi16_epi64 (__mmask8 __U, __m128i __A)
{
  return (__m512i) __builtin_ia32_pmovsxwq512_mask ((__v8hi) __A,
          (__v8di)
          _mm512_setzero_si512 (),
          (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepi32_epi64 (__m256i __X)
{
  return (__m512i) __builtin_ia32_pmovsxdq512_mask ((__v8si) __X,
          (__v8di)
          _mm512_undefined_epi32 (),
          (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi32_epi64 (__m512i __W, __mmask8 __U, __m256i __X)
{
  return (__m512i) __builtin_ia32_pmovsxdq512_mask ((__v8si) __X,
          (__v8di) __W,
          (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepi32_epi64 (__mmask8 __U, __m256i __X)
{
  return (__m512i) __builtin_ia32_pmovsxdq512_mask ((__v8si) __X,
          (__v8di)
          _mm512_setzero_si512 (),
          (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepu8_epi32 (__m128i __A)
{
  return (__m512i) __builtin_ia32_pmovzxbd512_mask ((__v16qi) __A,
          (__v16si)
          _mm512_undefined_epi32 (),
          (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepu8_epi32 (__m512i __W, __mmask16 __U, __m128i __A)
{
  return (__m512i) __builtin_ia32_pmovzxbd512_mask ((__v16qi) __A,
          (__v16si) __W,
          (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepu8_epi32 (__mmask16 __U, __m128i __A)
{
  return (__m512i) __builtin_ia32_pmovzxbd512_mask ((__v16qi) __A,
          (__v16si)
          _mm512_setzero_si512 (),
          (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepu8_epi64 (__m128i __A)
{
  return (__m512i) __builtin_ia32_pmovzxbq512_mask ((__v16qi) __A,
          (__v8di)
          _mm512_undefined_epi32 (),
          (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepu8_epi64 (__m512i __W, __mmask8 __U, __m128i __A)
{
  return (__m512i) __builtin_ia32_pmovzxbq512_mask ((__v16qi) __A,
          (__v8di) __W,
          (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepu8_epi64 (__mmask8 __U, __m128i __A)
{
  return (__m512i) __builtin_ia32_pmovzxbq512_mask ((__v16qi) __A,
          (__v8di)
          _mm512_setzero_si512 (),
          (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepu16_epi32 (__m256i __A)
{
  return (__m512i) __builtin_ia32_pmovzxwd512_mask ((__v16hi) __A,
          (__v16si)
          _mm512_undefined_epi32 (),
          (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepu16_epi32 (__m512i __W, __mmask16 __U, __m256i __A)
{
  return (__m512i) __builtin_ia32_pmovzxwd512_mask ((__v16hi) __A,
          (__v16si) __W,
          (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepu16_epi32 (__mmask16 __U, __m256i __A)
{
  return (__m512i) __builtin_ia32_pmovzxwd512_mask ((__v16hi) __A,
          (__v16si)
          _mm512_setzero_si512 (),
          (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepu16_epi64 (__m128i __A)
{
  return (__m512i) __builtin_ia32_pmovzxwq512_mask ((__v8hi) __A,
          (__v8di)
          _mm512_undefined_epi32 (),
          (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepu16_epi64 (__m512i __W, __mmask8 __U, __m128i __A)
{
  return (__m512i) __builtin_ia32_pmovzxwq512_mask ((__v8hi) __A,
          (__v8di) __W,
          (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepu16_epi64 (__mmask8 __U, __m128i __A)
{
  return (__m512i) __builtin_ia32_pmovzxwq512_mask ((__v8hi) __A,
          (__v8di)
          _mm512_setzero_si512 (),
          (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepu32_epi64 (__m256i __X)
{
  return (__m512i) __builtin_ia32_pmovzxdq512_mask ((__v8si) __X,
          (__v8di)
          _mm512_undefined_epi32 (),
          (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepu32_epi64 (__m512i __W, __mmask8 __U, __m256i __X)
{
  return (__m512i) __builtin_ia32_pmovzxdq512_mask ((__v8si) __X,
          (__v8di) __W,
          (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepu32_epi64 (__mmask8 __U, __m256i __X)
{
  return (__m512i) __builtin_ia32_pmovzxdq512_mask ((__v8si) __X,
          (__v8di)
          _mm512_setzero_si512 (),
          (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_abs_epi64 (__m512i __A)
{
  return (__m512i) __builtin_ia32_pabsq512_mask ((__v8di) __A,
       (__v8di)
       _mm512_undefined_epi32 (),
       (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_abs_epi64 (__m512i __W, __mmask8 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_pabsq512_mask ((__v8di) __A,
       (__v8di) __W,
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_abs_epi64 (__mmask8 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_pabsq512_mask ((__v8di) __A,
       (__v8di)
       _mm512_setzero_si512 (),
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_abs_epi32 (__m512i __A)
{
  return (__m512i) __builtin_ia32_pabsd512_mask ((__v16si) __A,
       (__v16si)
       _mm512_undefined_epi32 (),
       (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_abs_epi32 (__m512i __W, __mmask16 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_pabsd512_mask ((__v16si) __A,
       (__v16si) __W,
       (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_abs_epi32 (__mmask16 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_pabsd512_mask ((__v16si) __A,
       (__v16si)
       _mm512_setzero_si512 (),
       (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_broadcastss_ps (__m128 __A)
{
  return (__m512) __builtin_ia32_broadcastss512 ((__v4sf) __A,
       (__v16sf)
       _mm512_undefined_ps (),
       (__mmask16) -1);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_broadcastss_ps (__m512 __O, __mmask16 __M, __m128 __A)
{
  return (__m512) __builtin_ia32_broadcastss512 ((__v4sf) __A,
       (__v16sf) __O, __M);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_broadcastss_ps (__mmask16 __M, __m128 __A)
{
  return (__m512) __builtin_ia32_broadcastss512 ((__v4sf) __A,
       (__v16sf)
       _mm512_setzero_ps (),
       __M);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_broadcastsd_pd (__m128d __A)
{
  return (__m512d) __builtin_ia32_broadcastsd512 ((__v2df) __A,
        (__v8df)
        _mm512_undefined_pd (),
        (__mmask8) -1);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_broadcastsd_pd (__m512d __O, __mmask8 __M, __m128d __A)
{
  return (__m512d) __builtin_ia32_broadcastsd512 ((__v2df) __A,
        (__v8df) __O, __M);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_broadcastsd_pd (__mmask8 __M, __m128d __A)
{
  return (__m512d) __builtin_ia32_broadcastsd512 ((__v2df) __A,
        (__v8df)
        _mm512_setzero_pd (),
        __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_broadcastd_epi32 (__m128i __A)
{
  return (__m512i) __builtin_ia32_pbroadcastd512 ((__v4si) __A,
        (__v16si)
        _mm512_undefined_epi32 (),
        (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_broadcastd_epi32 (__m512i __O, __mmask16 __M, __m128i __A)
{
  return (__m512i) __builtin_ia32_pbroadcastd512 ((__v4si) __A,
        (__v16si) __O, __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_broadcastd_epi32 (__mmask16 __M, __m128i __A)
{
  return (__m512i) __builtin_ia32_pbroadcastd512 ((__v4si) __A,
        (__v16si)
        _mm512_setzero_si512 (),
        __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_set1_epi32 (int __A)
{
  return (__m512i)(__v16si)
    { __A, __A, __A, __A, __A, __A, __A, __A,
      __A, __A, __A, __A, __A, __A, __A, __A };
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_set1_epi32 (__m512i __O, __mmask16 __M, int __A)
{
  return (__m512i) __builtin_ia32_pbroadcastd512_gpr_mask (__A, (__v16si) __O,
          __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_set1_epi32 (__mmask16 __M, int __A)
{
  return (__m512i)
  __builtin_ia32_pbroadcastd512_gpr_mask (__A,
       (__v16si) _mm512_setzero_si512 (),
       __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_broadcastq_epi64 (__m128i __A)
{
  return (__m512i) __builtin_ia32_pbroadcastq512 ((__v2di) __A,
        (__v8di)
        _mm512_undefined_epi32 (),
        (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_broadcastq_epi64 (__m512i __O, __mmask8 __M, __m128i __A)
{
  return (__m512i) __builtin_ia32_pbroadcastq512 ((__v2di) __A,
        (__v8di) __O, __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_broadcastq_epi64 (__mmask8 __M, __m128i __A)
{
  return (__m512i) __builtin_ia32_pbroadcastq512 ((__v2di) __A,
        (__v8di)
        _mm512_setzero_si512 (),
        __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_set1_epi64 (long long __A)
{
  return (__m512i)(__v8di) { __A, __A, __A, __A, __A, __A, __A, __A };
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_set1_epi64 (__m512i __O, __mmask8 __M, long long __A)
{
  return (__m512i) __builtin_ia32_pbroadcastq512_gpr_mask (__A, (__v8di) __O,
          __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_set1_epi64 (__mmask8 __M, long long __A)
{
  return (__m512i)
  __builtin_ia32_pbroadcastq512_gpr_mask (__A,
       (__v8di) _mm512_setzero_si512 (),
       __M);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_broadcast_f32x4 (__m128 __A)
{
  return (__m512) __builtin_ia32_broadcastf32x4_512 ((__v4sf) __A,
           (__v16sf)
           _mm512_undefined_ps (),
           (__mmask16) -1);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_broadcast_f32x4 (__m512 __O, __mmask16 __M, __m128 __A)
{
  return (__m512) __builtin_ia32_broadcastf32x4_512 ((__v4sf) __A,
           (__v16sf) __O,
           __M);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_broadcast_f32x4 (__mmask16 __M, __m128 __A)
{
  return (__m512) __builtin_ia32_broadcastf32x4_512 ((__v4sf) __A,
           (__v16sf)
           _mm512_setzero_ps (),
           __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_broadcast_i32x4 (__m128i __A)
{
  return (__m512i) __builtin_ia32_broadcasti32x4_512 ((__v4si) __A,
            (__v16si)
            _mm512_undefined_epi32 (),
            (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_broadcast_i32x4 (__m512i __O, __mmask16 __M, __m128i __A)
{
  return (__m512i) __builtin_ia32_broadcasti32x4_512 ((__v4si) __A,
            (__v16si) __O,
            __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_broadcast_i32x4 (__mmask16 __M, __m128i __A)
{
  return (__m512i) __builtin_ia32_broadcasti32x4_512 ((__v4si) __A,
            (__v16si)
            _mm512_setzero_si512 (),
            __M);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_broadcast_f64x4 (__m256d __A)
{
  return (__m512d) __builtin_ia32_broadcastf64x4_512 ((__v4df) __A,
            (__v8df)
            _mm512_undefined_pd (),
            (__mmask8) -1);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_broadcast_f64x4 (__m512d __O, __mmask8 __M, __m256d __A)
{
  return (__m512d) __builtin_ia32_broadcastf64x4_512 ((__v4df) __A,
            (__v8df) __O,
            __M);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_broadcast_f64x4 (__mmask8 __M, __m256d __A)
{
  return (__m512d) __builtin_ia32_broadcastf64x4_512 ((__v4df) __A,
            (__v8df)
            _mm512_setzero_pd (),
            __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_broadcast_i64x4 (__m256i __A)
{
  return (__m512i) __builtin_ia32_broadcasti64x4_512 ((__v4di) __A,
            (__v8di)
            _mm512_undefined_epi32 (),
            (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_broadcast_i64x4 (__m512i __O, __mmask8 __M, __m256i __A)
{
  return (__m512i) __builtin_ia32_broadcasti64x4_512 ((__v4di) __A,
            (__v8di) __O,
            __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_broadcast_i64x4 (__mmask8 __M, __m256i __A)
{
  return (__m512i) __builtin_ia32_broadcasti64x4_512 ((__v4di) __A,
            (__v8di)
            _mm512_setzero_si512 (),
            __M);
}
typedef enum
{
  _MM_PERM_AAAA = 0x00, _MM_PERM_AAAB = 0x01, _MM_PERM_AAAC = 0x02,
  _MM_PERM_AAAD = 0x03, _MM_PERM_AABA = 0x04, _MM_PERM_AABB = 0x05,
  _MM_PERM_AABC = 0x06, _MM_PERM_AABD = 0x07, _MM_PERM_AACA = 0x08,
  _MM_PERM_AACB = 0x09, _MM_PERM_AACC = 0x0A, _MM_PERM_AACD = 0x0B,
  _MM_PERM_AADA = 0x0C, _MM_PERM_AADB = 0x0D, _MM_PERM_AADC = 0x0E,
  _MM_PERM_AADD = 0x0F, _MM_PERM_ABAA = 0x10, _MM_PERM_ABAB = 0x11,
  _MM_PERM_ABAC = 0x12, _MM_PERM_ABAD = 0x13, _MM_PERM_ABBA = 0x14,
  _MM_PERM_ABBB = 0x15, _MM_PERM_ABBC = 0x16, _MM_PERM_ABBD = 0x17,
  _MM_PERM_ABCA = 0x18, _MM_PERM_ABCB = 0x19, _MM_PERM_ABCC = 0x1A,
  _MM_PERM_ABCD = 0x1B, _MM_PERM_ABDA = 0x1C, _MM_PERM_ABDB = 0x1D,
  _MM_PERM_ABDC = 0x1E, _MM_PERM_ABDD = 0x1F, _MM_PERM_ACAA = 0x20,
  _MM_PERM_ACAB = 0x21, _MM_PERM_ACAC = 0x22, _MM_PERM_ACAD = 0x23,
  _MM_PERM_ACBA = 0x24, _MM_PERM_ACBB = 0x25, _MM_PERM_ACBC = 0x26,
  _MM_PERM_ACBD = 0x27, _MM_PERM_ACCA = 0x28, _MM_PERM_ACCB = 0x29,
  _MM_PERM_ACCC = 0x2A, _MM_PERM_ACCD = 0x2B, _MM_PERM_ACDA = 0x2C,
  _MM_PERM_ACDB = 0x2D, _MM_PERM_ACDC = 0x2E, _MM_PERM_ACDD = 0x2F,
  _MM_PERM_ADAA = 0x30, _MM_PERM_ADAB = 0x31, _MM_PERM_ADAC = 0x32,
  _MM_PERM_ADAD = 0x33, _MM_PERM_ADBA = 0x34, _MM_PERM_ADBB = 0x35,
  _MM_PERM_ADBC = 0x36, _MM_PERM_ADBD = 0x37, _MM_PERM_ADCA = 0x38,
  _MM_PERM_ADCB = 0x39, _MM_PERM_ADCC = 0x3A, _MM_PERM_ADCD = 0x3B,
  _MM_PERM_ADDA = 0x3C, _MM_PERM_ADDB = 0x3D, _MM_PERM_ADDC = 0x3E,
  _MM_PERM_ADDD = 0x3F, _MM_PERM_BAAA = 0x40, _MM_PERM_BAAB = 0x41,
  _MM_PERM_BAAC = 0x42, _MM_PERM_BAAD = 0x43, _MM_PERM_BABA = 0x44,
  _MM_PERM_BABB = 0x45, _MM_PERM_BABC = 0x46, _MM_PERM_BABD = 0x47,
  _MM_PERM_BACA = 0x48, _MM_PERM_BACB = 0x49, _MM_PERM_BACC = 0x4A,
  _MM_PERM_BACD = 0x4B, _MM_PERM_BADA = 0x4C, _MM_PERM_BADB = 0x4D,
  _MM_PERM_BADC = 0x4E, _MM_PERM_BADD = 0x4F, _MM_PERM_BBAA = 0x50,
  _MM_PERM_BBAB = 0x51, _MM_PERM_BBAC = 0x52, _MM_PERM_BBAD = 0x53,
  _MM_PERM_BBBA = 0x54, _MM_PERM_BBBB = 0x55, _MM_PERM_BBBC = 0x56,
  _MM_PERM_BBBD = 0x57, _MM_PERM_BBCA = 0x58, _MM_PERM_BBCB = 0x59,
  _MM_PERM_BBCC = 0x5A, _MM_PERM_BBCD = 0x5B, _MM_PERM_BBDA = 0x5C,
  _MM_PERM_BBDB = 0x5D, _MM_PERM_BBDC = 0x5E, _MM_PERM_BBDD = 0x5F,
  _MM_PERM_BCAA = 0x60, _MM_PERM_BCAB = 0x61, _MM_PERM_BCAC = 0x62,
  _MM_PERM_BCAD = 0x63, _MM_PERM_BCBA = 0x64, _MM_PERM_BCBB = 0x65,
  _MM_PERM_BCBC = 0x66, _MM_PERM_BCBD = 0x67, _MM_PERM_BCCA = 0x68,
  _MM_PERM_BCCB = 0x69, _MM_PERM_BCCC = 0x6A, _MM_PERM_BCCD = 0x6B,
  _MM_PERM_BCDA = 0x6C, _MM_PERM_BCDB = 0x6D, _MM_PERM_BCDC = 0x6E,
  _MM_PERM_BCDD = 0x6F, _MM_PERM_BDAA = 0x70, _MM_PERM_BDAB = 0x71,
  _MM_PERM_BDAC = 0x72, _MM_PERM_BDAD = 0x73, _MM_PERM_BDBA = 0x74,
  _MM_PERM_BDBB = 0x75, _MM_PERM_BDBC = 0x76, _MM_PERM_BDBD = 0x77,
  _MM_PERM_BDCA = 0x78, _MM_PERM_BDCB = 0x79, _MM_PERM_BDCC = 0x7A,
  _MM_PERM_BDCD = 0x7B, _MM_PERM_BDDA = 0x7C, _MM_PERM_BDDB = 0x7D,
  _MM_PERM_BDDC = 0x7E, _MM_PERM_BDDD = 0x7F, _MM_PERM_CAAA = 0x80,
  _MM_PERM_CAAB = 0x81, _MM_PERM_CAAC = 0x82, _MM_PERM_CAAD = 0x83,
  _MM_PERM_CABA = 0x84, _MM_PERM_CABB = 0x85, _MM_PERM_CABC = 0x86,
  _MM_PERM_CABD = 0x87, _MM_PERM_CACA = 0x88, _MM_PERM_CACB = 0x89,
  _MM_PERM_CACC = 0x8A, _MM_PERM_CACD = 0x8B, _MM_PERM_CADA = 0x8C,
  _MM_PERM_CADB = 0x8D, _MM_PERM_CADC = 0x8E, _MM_PERM_CADD = 0x8F,
  _MM_PERM_CBAA = 0x90, _MM_PERM_CBAB = 0x91, _MM_PERM_CBAC = 0x92,
  _MM_PERM_CBAD = 0x93, _MM_PERM_CBBA = 0x94, _MM_PERM_CBBB = 0x95,
  _MM_PERM_CBBC = 0x96, _MM_PERM_CBBD = 0x97, _MM_PERM_CBCA = 0x98,
  _MM_PERM_CBCB = 0x99, _MM_PERM_CBCC = 0x9A, _MM_PERM_CBCD = 0x9B,
  _MM_PERM_CBDA = 0x9C, _MM_PERM_CBDB = 0x9D, _MM_PERM_CBDC = 0x9E,
  _MM_PERM_CBDD = 0x9F, _MM_PERM_CCAA = 0xA0, _MM_PERM_CCAB = 0xA1,
  _MM_PERM_CCAC = 0xA2, _MM_PERM_CCAD = 0xA3, _MM_PERM_CCBA = 0xA4,
  _MM_PERM_CCBB = 0xA5, _MM_PERM_CCBC = 0xA6, _MM_PERM_CCBD = 0xA7,
  _MM_PERM_CCCA = 0xA8, _MM_PERM_CCCB = 0xA9, _MM_PERM_CCCC = 0xAA,
  _MM_PERM_CCCD = 0xAB, _MM_PERM_CCDA = 0xAC, _MM_PERM_CCDB = 0xAD,
  _MM_PERM_CCDC = 0xAE, _MM_PERM_CCDD = 0xAF, _MM_PERM_CDAA = 0xB0,
  _MM_PERM_CDAB = 0xB1, _MM_PERM_CDAC = 0xB2, _MM_PERM_CDAD = 0xB3,
  _MM_PERM_CDBA = 0xB4, _MM_PERM_CDBB = 0xB5, _MM_PERM_CDBC = 0xB6,
  _MM_PERM_CDBD = 0xB7, _MM_PERM_CDCA = 0xB8, _MM_PERM_CDCB = 0xB9,
  _MM_PERM_CDCC = 0xBA, _MM_PERM_CDCD = 0xBB, _MM_PERM_CDDA = 0xBC,
  _MM_PERM_CDDB = 0xBD, _MM_PERM_CDDC = 0xBE, _MM_PERM_CDDD = 0xBF,
  _MM_PERM_DAAA = 0xC0, _MM_PERM_DAAB = 0xC1, _MM_PERM_DAAC = 0xC2,
  _MM_PERM_DAAD = 0xC3, _MM_PERM_DABA = 0xC4, _MM_PERM_DABB = 0xC5,
  _MM_PERM_DABC = 0xC6, _MM_PERM_DABD = 0xC7, _MM_PERM_DACA = 0xC8,
  _MM_PERM_DACB = 0xC9, _MM_PERM_DACC = 0xCA, _MM_PERM_DACD = 0xCB,
  _MM_PERM_DADA = 0xCC, _MM_PERM_DADB = 0xCD, _MM_PERM_DADC = 0xCE,
  _MM_PERM_DADD = 0xCF, _MM_PERM_DBAA = 0xD0, _MM_PERM_DBAB = 0xD1,
  _MM_PERM_DBAC = 0xD2, _MM_PERM_DBAD = 0xD3, _MM_PERM_DBBA = 0xD4,
  _MM_PERM_DBBB = 0xD5, _MM_PERM_DBBC = 0xD6, _MM_PERM_DBBD = 0xD7,
  _MM_PERM_DBCA = 0xD8, _MM_PERM_DBCB = 0xD9, _MM_PERM_DBCC = 0xDA,
  _MM_PERM_DBCD = 0xDB, _MM_PERM_DBDA = 0xDC, _MM_PERM_DBDB = 0xDD,
  _MM_PERM_DBDC = 0xDE, _MM_PERM_DBDD = 0xDF, _MM_PERM_DCAA = 0xE0,
  _MM_PERM_DCAB = 0xE1, _MM_PERM_DCAC = 0xE2, _MM_PERM_DCAD = 0xE3,
  _MM_PERM_DCBA = 0xE4, _MM_PERM_DCBB = 0xE5, _MM_PERM_DCBC = 0xE6,
  _MM_PERM_DCBD = 0xE7, _MM_PERM_DCCA = 0xE8, _MM_PERM_DCCB = 0xE9,
  _MM_PERM_DCCC = 0xEA, _MM_PERM_DCCD = 0xEB, _MM_PERM_DCDA = 0xEC,
  _MM_PERM_DCDB = 0xED, _MM_PERM_DCDC = 0xEE, _MM_PERM_DCDD = 0xEF,
  _MM_PERM_DDAA = 0xF0, _MM_PERM_DDAB = 0xF1, _MM_PERM_DDAC = 0xF2,
  _MM_PERM_DDAD = 0xF3, _MM_PERM_DDBA = 0xF4, _MM_PERM_DDBB = 0xF5,
  _MM_PERM_DDBC = 0xF6, _MM_PERM_DDBD = 0xF7, _MM_PERM_DDCA = 0xF8,
  _MM_PERM_DDCB = 0xF9, _MM_PERM_DDCC = 0xFA, _MM_PERM_DDCD = 0xFB,
  _MM_PERM_DDDA = 0xFC, _MM_PERM_DDDB = 0xFD, _MM_PERM_DDDC = 0xFE,
  _MM_PERM_DDDD = 0xFF
} _MM_PERM_ENUM;
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_rolv_epi32 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_prolvd512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si)
        _mm512_undefined_epi32 (),
        (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_rolv_epi32 (__m512i __W, __mmask16 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_prolvd512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si) __W,
        (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_rolv_epi32 (__mmask16 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_prolvd512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si)
        _mm512_setzero_si512 (),
        (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_rorv_epi32 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_prorvd512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si)
        _mm512_undefined_epi32 (),
        (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_rorv_epi32 (__m512i __W, __mmask16 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_prorvd512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si) __W,
        (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_rorv_epi32 (__mmask16 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_prorvd512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si)
        _mm512_setzero_si512 (),
        (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_rolv_epi64 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_prolvq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di)
        _mm512_undefined_epi32 (),
        (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_rolv_epi64 (__m512i __W, __mmask8 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_prolvq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di) __W,
        (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_rolv_epi64 (__mmask8 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_prolvq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di)
        _mm512_setzero_si512 (),
        (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_rorv_epi64 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_prorvq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di)
        _mm512_undefined_epi32 (),
        (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_rorv_epi64 (__m512i __W, __mmask8 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_prorvq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di) __W,
        (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_rorv_epi64 (__mmask8 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_prorvq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di)
        _mm512_setzero_si512 (),
        (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtu32_sd (__m128d __A, unsigned __B)
{
  return (__m128d) __builtin_ia32_cvtusi2sd32 ((__v2df) __A, __B);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepi32_epi8 (__m512i __A)
{
  return (__m128i) __builtin_ia32_pmovdb512_mask ((__v16si) __A,
        (__v16qi)
        _mm_undefined_si128 (),
        (__mmask16) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi32_storeu_epi8 (void * __P, __mmask16 __M, __m512i __A)
{
  __builtin_ia32_pmovdb512mem_mask ((__v16qi *) __P, (__v16si) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi32_epi8 (__m128i __O, __mmask16 __M, __m512i __A)
{
  return (__m128i) __builtin_ia32_pmovdb512_mask ((__v16si) __A,
        (__v16qi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepi32_epi8 (__mmask16 __M, __m512i __A)
{
  return (__m128i) __builtin_ia32_pmovdb512_mask ((__v16si) __A,
        (__v16qi)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtsepi32_epi8 (__m512i __A)
{
  return (__m128i) __builtin_ia32_pmovsdb512_mask ((__v16si) __A,
         (__v16qi)
         _mm_undefined_si128 (),
         (__mmask16) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtsepi32_storeu_epi8 (void * __P, __mmask16 __M, __m512i __A)
{
  __builtin_ia32_pmovsdb512mem_mask ((__v16qi *) __P, (__v16si) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtsepi32_epi8 (__m128i __O, __mmask16 __M, __m512i __A)
{
  return (__m128i) __builtin_ia32_pmovsdb512_mask ((__v16si) __A,
         (__v16qi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtsepi32_epi8 (__mmask16 __M, __m512i __A)
{
  return (__m128i) __builtin_ia32_pmovsdb512_mask ((__v16si) __A,
         (__v16qi)
         _mm_setzero_si128 (),
         __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtusepi32_epi8 (__m512i __A)
{
  return (__m128i) __builtin_ia32_pmovusdb512_mask ((__v16si) __A,
          (__v16qi)
          _mm_undefined_si128 (),
          (__mmask16) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtusepi32_storeu_epi8 (void * __P, __mmask16 __M, __m512i __A)
{
  __builtin_ia32_pmovusdb512mem_mask ((__v16qi *) __P, (__v16si) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtusepi32_epi8 (__m128i __O, __mmask16 __M, __m512i __A)
{
  return (__m128i) __builtin_ia32_pmovusdb512_mask ((__v16si) __A,
          (__v16qi) __O,
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtusepi32_epi8 (__mmask16 __M, __m512i __A)
{
  return (__m128i) __builtin_ia32_pmovusdb512_mask ((__v16si) __A,
          (__v16qi)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepi32_epi16 (__m512i __A)
{
  return (__m256i) __builtin_ia32_pmovdw512_mask ((__v16si) __A,
        (__v16hi)
        _mm256_undefined_si256 (),
        (__mmask16) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi32_storeu_epi16 (void * __P, __mmask16 __M, __m512i __A)
{
  __builtin_ia32_pmovdw512mem_mask ((__v16hi *) __P, (__v16si) __A, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi32_epi16 (__m256i __O, __mmask16 __M, __m512i __A)
{
  return (__m256i) __builtin_ia32_pmovdw512_mask ((__v16si) __A,
        (__v16hi) __O, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepi32_epi16 (__mmask16 __M, __m512i __A)
{
  return (__m256i) __builtin_ia32_pmovdw512_mask ((__v16si) __A,
        (__v16hi)
        _mm256_setzero_si256 (),
        __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtsepi32_epi16 (__m512i __A)
{
  return (__m256i) __builtin_ia32_pmovsdw512_mask ((__v16si) __A,
         (__v16hi)
         _mm256_undefined_si256 (),
         (__mmask16) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtsepi32_storeu_epi16 (void *__P, __mmask16 __M, __m512i __A)
{
  __builtin_ia32_pmovsdw512mem_mask ((__v16hi*) __P, (__v16si) __A, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtsepi32_epi16 (__m256i __O, __mmask16 __M, __m512i __A)
{
  return (__m256i) __builtin_ia32_pmovsdw512_mask ((__v16si) __A,
         (__v16hi) __O, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtsepi32_epi16 (__mmask16 __M, __m512i __A)
{
  return (__m256i) __builtin_ia32_pmovsdw512_mask ((__v16si) __A,
         (__v16hi)
         _mm256_setzero_si256 (),
         __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtusepi32_epi16 (__m512i __A)
{
  return (__m256i) __builtin_ia32_pmovusdw512_mask ((__v16si) __A,
          (__v16hi)
          _mm256_undefined_si256 (),
          (__mmask16) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtusepi32_storeu_epi16 (void *__P, __mmask16 __M, __m512i __A)
{
  __builtin_ia32_pmovusdw512mem_mask ((__v16hi*) __P, (__v16si) __A, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtusepi32_epi16 (__m256i __O, __mmask16 __M, __m512i __A)
{
  return (__m256i) __builtin_ia32_pmovusdw512_mask ((__v16si) __A,
          (__v16hi) __O,
          __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtusepi32_epi16 (__mmask16 __M, __m512i __A)
{
  return (__m256i) __builtin_ia32_pmovusdw512_mask ((__v16si) __A,
          (__v16hi)
          _mm256_setzero_si256 (),
          __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepi64_epi32 (__m512i __A)
{
  return (__m256i) __builtin_ia32_pmovqd512_mask ((__v8di) __A,
        (__v8si)
        _mm256_undefined_si256 (),
        (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi64_storeu_epi32 (void* __P, __mmask8 __M, __m512i __A)
{
  __builtin_ia32_pmovqd512mem_mask ((__v8si *) __P, (__v8di) __A, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi64_epi32 (__m256i __O, __mmask8 __M, __m512i __A)
{
  return (__m256i) __builtin_ia32_pmovqd512_mask ((__v8di) __A,
        (__v8si) __O, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepi64_epi32 (__mmask8 __M, __m512i __A)
{
  return (__m256i) __builtin_ia32_pmovqd512_mask ((__v8di) __A,
        (__v8si)
        _mm256_setzero_si256 (),
        __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtsepi64_epi32 (__m512i __A)
{
  return (__m256i) __builtin_ia32_pmovsqd512_mask ((__v8di) __A,
         (__v8si)
         _mm256_undefined_si256 (),
         (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtsepi64_storeu_epi32 (void *__P, __mmask8 __M, __m512i __A)
{
  __builtin_ia32_pmovsqd512mem_mask ((__v8si *) __P, (__v8di) __A, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtsepi64_epi32 (__m256i __O, __mmask8 __M, __m512i __A)
{
  return (__m256i) __builtin_ia32_pmovsqd512_mask ((__v8di) __A,
         (__v8si) __O, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtsepi64_epi32 (__mmask8 __M, __m512i __A)
{
  return (__m256i) __builtin_ia32_pmovsqd512_mask ((__v8di) __A,
         (__v8si)
         _mm256_setzero_si256 (),
         __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtusepi64_epi32 (__m512i __A)
{
  return (__m256i) __builtin_ia32_pmovusqd512_mask ((__v8di) __A,
          (__v8si)
          _mm256_undefined_si256 (),
          (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtusepi64_storeu_epi32 (void* __P, __mmask8 __M, __m512i __A)
{
  __builtin_ia32_pmovusqd512mem_mask ((__v8si*) __P, (__v8di) __A, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtusepi64_epi32 (__m256i __O, __mmask8 __M, __m512i __A)
{
  return (__m256i) __builtin_ia32_pmovusqd512_mask ((__v8di) __A,
          (__v8si) __O, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtusepi64_epi32 (__mmask8 __M, __m512i __A)
{
  return (__m256i) __builtin_ia32_pmovusqd512_mask ((__v8di) __A,
          (__v8si)
          _mm256_setzero_si256 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepi64_epi16 (__m512i __A)
{
  return (__m128i) __builtin_ia32_pmovqw512_mask ((__v8di) __A,
        (__v8hi)
        _mm_undefined_si128 (),
        (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi64_storeu_epi16 (void *__P, __mmask8 __M, __m512i __A)
{
  __builtin_ia32_pmovqw512mem_mask ((__v8hi *) __P, (__v8di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi64_epi16 (__m128i __O, __mmask8 __M, __m512i __A)
{
  return (__m128i) __builtin_ia32_pmovqw512_mask ((__v8di) __A,
        (__v8hi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepi64_epi16 (__mmask8 __M, __m512i __A)
{
  return (__m128i) __builtin_ia32_pmovqw512_mask ((__v8di) __A,
        (__v8hi)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtsepi64_epi16 (__m512i __A)
{
  return (__m128i) __builtin_ia32_pmovsqw512_mask ((__v8di) __A,
         (__v8hi)
         _mm_undefined_si128 (),
         (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtsepi64_storeu_epi16 (void * __P, __mmask8 __M, __m512i __A)
{
  __builtin_ia32_pmovsqw512mem_mask ((__v8hi *) __P, (__v8di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtsepi64_epi16 (__m128i __O, __mmask8 __M, __m512i __A)
{
  return (__m128i) __builtin_ia32_pmovsqw512_mask ((__v8di) __A,
         (__v8hi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtsepi64_epi16 (__mmask8 __M, __m512i __A)
{
  return (__m128i) __builtin_ia32_pmovsqw512_mask ((__v8di) __A,
         (__v8hi)
         _mm_setzero_si128 (),
         __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtusepi64_epi16 (__m512i __A)
{
  return (__m128i) __builtin_ia32_pmovusqw512_mask ((__v8di) __A,
          (__v8hi)
          _mm_undefined_si128 (),
          (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtusepi64_storeu_epi16 (void *__P, __mmask8 __M, __m512i __A)
{
  __builtin_ia32_pmovusqw512mem_mask ((__v8hi*) __P, (__v8di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtusepi64_epi16 (__m128i __O, __mmask8 __M, __m512i __A)
{
  return (__m128i) __builtin_ia32_pmovusqw512_mask ((__v8di) __A,
          (__v8hi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtusepi64_epi16 (__mmask8 __M, __m512i __A)
{
  return (__m128i) __builtin_ia32_pmovusqw512_mask ((__v8di) __A,
          (__v8hi)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepi64_epi8 (__m512i __A)
{
  return (__m128i) __builtin_ia32_pmovqb512_mask ((__v8di) __A,
        (__v16qi)
        _mm_undefined_si128 (),
        (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi64_storeu_epi8 (void * __P, __mmask8 __M, __m512i __A)
{
  __builtin_ia32_pmovqb512mem_mask ((unsigned long long *) __P,
        (__v8di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi64_epi8 (__m128i __O, __mmask8 __M, __m512i __A)
{
  return (__m128i) __builtin_ia32_pmovqb512_mask ((__v8di) __A,
        (__v16qi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepi64_epi8 (__mmask8 __M, __m512i __A)
{
  return (__m128i) __builtin_ia32_pmovqb512_mask ((__v8di) __A,
        (__v16qi)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtsepi64_epi8 (__m512i __A)
{
  return (__m128i) __builtin_ia32_pmovsqb512_mask ((__v8di) __A,
         (__v16qi)
         _mm_undefined_si128 (),
         (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtsepi64_storeu_epi8 (void * __P, __mmask8 __M, __m512i __A)
{
  __builtin_ia32_pmovsqb512mem_mask ((unsigned long long *) __P, (__v8di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtsepi64_epi8 (__m128i __O, __mmask8 __M, __m512i __A)
{
  return (__m128i) __builtin_ia32_pmovsqb512_mask ((__v8di) __A,
         (__v16qi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtsepi64_epi8 (__mmask8 __M, __m512i __A)
{
  return (__m128i) __builtin_ia32_pmovsqb512_mask ((__v8di) __A,
         (__v16qi)
         _mm_setzero_si128 (),
         __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtusepi64_epi8 (__m512i __A)
{
  return (__m128i) __builtin_ia32_pmovusqb512_mask ((__v8di) __A,
          (__v16qi)
          _mm_undefined_si128 (),
          (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtusepi64_storeu_epi8 (void * __P, __mmask8 __M, __m512i __A)
{
  __builtin_ia32_pmovusqb512mem_mask ((unsigned long long *) __P, (__v8di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtusepi64_epi8 (__m128i __O, __mmask8 __M, __m512i __A)
{
  return (__m128i) __builtin_ia32_pmovusqb512_mask ((__v8di) __A,
          (__v16qi) __O,
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtusepi64_epi8 (__mmask8 __M, __m512i __A)
{
  return (__m128i) __builtin_ia32_pmovusqb512_mask ((__v8di) __A,
          (__v16qi)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepi32_pd (__m256i __A)
{
  return (__m512d) __builtin_ia32_cvtdq2pd512_mask ((__v8si) __A,
          (__v8df)
          _mm512_undefined_pd (),
          (__mmask8) -1);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi32_pd (__m512d __W, __mmask8 __U, __m256i __A)
{
  return (__m512d) __builtin_ia32_cvtdq2pd512_mask ((__v8si) __A,
          (__v8df) __W,
          (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepi32_pd (__mmask8 __U, __m256i __A)
{
  return (__m512d) __builtin_ia32_cvtdq2pd512_mask ((__v8si) __A,
          (__v8df)
          _mm512_setzero_pd (),
          (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepu32_pd (__m256i __A)
{
  return (__m512d) __builtin_ia32_cvtudq2pd512_mask ((__v8si) __A,
           (__v8df)
           _mm512_undefined_pd (),
           (__mmask8) -1);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepu32_pd (__m512d __W, __mmask8 __U, __m256i __A)
{
  return (__m512d) __builtin_ia32_cvtudq2pd512_mask ((__v8si) __A,
           (__v8df) __W,
           (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepu32_pd (__mmask8 __U, __m256i __A)
{
  return (__m512d) __builtin_ia32_cvtudq2pd512_mask ((__v8si) __A,
           (__v8df)
           _mm512_setzero_pd (),
           (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_loadu_pd (void const *__P)
{
  return *(__m512d_u *)__P;
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_loadu_pd (__m512d __W, __mmask8 __U, void const *__P)
{
  return (__m512d) __builtin_ia32_loadupd512_mask ((const double *) __P,
         (__v8df) __W,
         (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_loadu_pd (__mmask8 __U, void const *__P)
{
  return (__m512d) __builtin_ia32_loadupd512_mask ((const double *) __P,
         (__v8df)
         _mm512_setzero_pd (),
         (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_storeu_pd (void *__P, __m512d __A)
{
  *(__m512d_u *)__P = __A;
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_storeu_pd (void *__P, __mmask8 __U, __m512d __A)
{
  __builtin_ia32_storeupd512_mask ((double *) __P, (__v8df) __A,
       (__mmask8) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_loadu_ps (void const *__P)
{
  return *(__m512_u *)__P;
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_loadu_ps (__m512 __W, __mmask16 __U, void const *__P)
{
  return (__m512) __builtin_ia32_loadups512_mask ((const float *) __P,
        (__v16sf) __W,
        (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_loadu_ps (__mmask16 __U, void const *__P)
{
  return (__m512) __builtin_ia32_loadups512_mask ((const float *) __P,
        (__v16sf)
        _mm512_setzero_ps (),
        (__mmask16) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_storeu_ps (void *__P, __m512 __A)
{
  *(__m512_u *)__P = __A;
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_storeu_ps (void *__P, __mmask16 __U, __m512 __A)
{
  __builtin_ia32_storeups512_mask ((float *) __P, (__v16sf) __A,
       (__mmask16) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_load_ss (__m128 __W, __mmask8 __U, const float *__P)
{
  return (__m128) __builtin_ia32_loadss_mask (__P, (__v4sf) __W, __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_load_ss (__mmask8 __U, const float *__P)
{
  return (__m128) __builtin_ia32_loadss_mask (__P, (__v4sf) _mm_setzero_ps (),
           __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_load_sd (__m128d __W, __mmask8 __U, const double *__P)
{
  return (__m128d) __builtin_ia32_loadsd_mask (__P, (__v2df) __W, __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_load_sd (__mmask8 __U, const double *__P)
{
  return (__m128d) __builtin_ia32_loadsd_mask (__P, (__v2df) _mm_setzero_pd (),
            __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_move_ss (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_movess_mask ((__v4sf) __A, (__v4sf) __B,
           (__v4sf) __W, __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_move_ss (__mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_movess_mask ((__v4sf) __A, (__v4sf) __B,
           (__v4sf) _mm_setzero_ps (), __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_move_sd (__m128d __W, __mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_movesd_mask ((__v2df) __A, (__v2df) __B,
            (__v2df) __W, __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_move_sd (__mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_movesd_mask ((__v2df) __A, (__v2df) __B,
            (__v2df) _mm_setzero_pd (),
            __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_store_ss (float *__P, __mmask8 __U, __m128 __A)
{
  __builtin_ia32_storess_mask (__P, (__v4sf) __A, (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_store_sd (double *__P, __mmask8 __U, __m128d __A)
{
  __builtin_ia32_storesd_mask (__P, (__v2df) __A, (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_loadu_epi64 (void const *__P)
{
  return *(__m512i_u *) __P;
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_loadu_epi64 (__m512i __W, __mmask8 __U, void const *__P)
{
  return (__m512i) __builtin_ia32_loaddqudi512_mask ((const long long *) __P,
           (__v8di) __W,
           (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_loadu_epi64 (__mmask8 __U, void const *__P)
{
  return (__m512i) __builtin_ia32_loaddqudi512_mask ((const long long *) __P,
           (__v8di)
           _mm512_setzero_si512 (),
           (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_storeu_epi64 (void *__P, __m512i __A)
{
  *(__m512i_u *) __P = (__m512i_u) __A;
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_storeu_epi64 (void *__P, __mmask8 __U, __m512i __A)
{
  __builtin_ia32_storedqudi512_mask ((long long *) __P, (__v8di) __A,
         (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_loadu_si512 (void const *__P)
{
  return *(__m512i_u *)__P;
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_loadu_epi32 (void const *__P)
{
  return *(__m512i_u *) __P;
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_loadu_epi32 (__m512i __W, __mmask16 __U, void const *__P)
{
  return (__m512i) __builtin_ia32_loaddqusi512_mask ((const int *) __P,
           (__v16si) __W,
           (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_loadu_epi32 (__mmask16 __U, void const *__P)
{
  return (__m512i) __builtin_ia32_loaddqusi512_mask ((const int *) __P,
           (__v16si)
           _mm512_setzero_si512 (),
           (__mmask16) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_storeu_si512 (void *__P, __m512i __A)
{
  *(__m512i_u *)__P = __A;
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_storeu_epi32 (void *__P, __m512i __A)
{
  *(__m512i_u *) __P = (__m512i_u) __A;
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_storeu_epi32 (void *__P, __mmask16 __U, __m512i __A)
{
  __builtin_ia32_storedqusi512_mask ((int *) __P, (__v16si) __A,
         (__mmask16) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_permutevar_pd (__m512d __A, __m512i __C)
{
  return (__m512d) __builtin_ia32_vpermilvarpd512_mask ((__v8df) __A,
       (__v8di) __C,
       (__v8df)
       _mm512_undefined_pd (),
       (__mmask8) -1);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_permutevar_pd (__m512d __W, __mmask8 __U, __m512d __A, __m512i __C)
{
  return (__m512d) __builtin_ia32_vpermilvarpd512_mask ((__v8df) __A,
       (__v8di) __C,
       (__v8df) __W,
       (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_permutevar_pd (__mmask8 __U, __m512d __A, __m512i __C)
{
  return (__m512d) __builtin_ia32_vpermilvarpd512_mask ((__v8df) __A,
       (__v8di) __C,
       (__v8df)
       _mm512_setzero_pd (),
       (__mmask8) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_permutevar_ps (__m512 __A, __m512i __C)
{
  return (__m512) __builtin_ia32_vpermilvarps512_mask ((__v16sf) __A,
             (__v16si) __C,
             (__v16sf)
             _mm512_undefined_ps (),
             (__mmask16) -1);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_permutevar_ps (__m512 __W, __mmask16 __U, __m512 __A, __m512i __C)
{
  return (__m512) __builtin_ia32_vpermilvarps512_mask ((__v16sf) __A,
             (__v16si) __C,
             (__v16sf) __W,
             (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_permutevar_ps (__mmask16 __U, __m512 __A, __m512i __C)
{
  return (__m512) __builtin_ia32_vpermilvarps512_mask ((__v16sf) __A,
             (__v16si) __C,
             (__v16sf)
             _mm512_setzero_ps (),
             (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_permutex2var_epi64 (__m512i __A, __m512i __I, __m512i __B)
{
  return (__m512i) __builtin_ia32_vpermt2varq512_mask ((__v8di) __I
                       ,
             (__v8di) __A,
             (__v8di) __B,
             (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_permutex2var_epi64 (__m512i __A, __mmask8 __U, __m512i __I,
    __m512i __B)
{
  return (__m512i) __builtin_ia32_vpermt2varq512_mask ((__v8di) __I
                       ,
             (__v8di) __A,
             (__v8di) __B,
             (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask2_permutex2var_epi64 (__m512i __A, __m512i __I,
     __mmask8 __U, __m512i __B)
{
  return (__m512i) __builtin_ia32_vpermi2varq512_mask ((__v8di) __A,
             (__v8di) __I
                       ,
             (__v8di) __B,
             (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_permutex2var_epi64 (__mmask8 __U, __m512i __A,
     __m512i __I, __m512i __B)
{
  return (__m512i) __builtin_ia32_vpermt2varq512_maskz ((__v8di) __I
                 ,
       (__v8di) __A,
       (__v8di) __B,
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_permutex2var_epi32 (__m512i __A, __m512i __I, __m512i __B)
{
  return (__m512i) __builtin_ia32_vpermt2vard512_mask ((__v16si) __I
                       ,
             (__v16si) __A,
             (__v16si) __B,
             (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_permutex2var_epi32 (__m512i __A, __mmask16 __U,
    __m512i __I, __m512i __B)
{
  return (__m512i) __builtin_ia32_vpermt2vard512_mask ((__v16si) __I
                       ,
             (__v16si) __A,
             (__v16si) __B,
             (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask2_permutex2var_epi32 (__m512i __A, __m512i __I,
     __mmask16 __U, __m512i __B)
{
  return (__m512i) __builtin_ia32_vpermi2vard512_mask ((__v16si) __A,
             (__v16si) __I
                       ,
             (__v16si) __B,
             (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_permutex2var_epi32 (__mmask16 __U, __m512i __A,
     __m512i __I, __m512i __B)
{
  return (__m512i) __builtin_ia32_vpermt2vard512_maskz ((__v16si) __I
                 ,
       (__v16si) __A,
       (__v16si) __B,
       (__mmask16) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_permutex2var_pd (__m512d __A, __m512i __I, __m512d __B)
{
  return (__m512d) __builtin_ia32_vpermt2varpd512_mask ((__v8di) __I
                 ,
       (__v8df) __A,
       (__v8df) __B,
       (__mmask8) -1);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_permutex2var_pd (__m512d __A, __mmask8 __U, __m512i __I,
        __m512d __B)
{
  return (__m512d) __builtin_ia32_vpermt2varpd512_mask ((__v8di) __I
                 ,
       (__v8df) __A,
       (__v8df) __B,
       (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask2_permutex2var_pd (__m512d __A, __m512i __I, __mmask8 __U,
         __m512d __B)
{
  return (__m512d) __builtin_ia32_vpermi2varpd512_mask ((__v8df) __A,
       (__v8di) __I
                 ,
       (__v8df) __B,
       (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_permutex2var_pd (__mmask8 __U, __m512d __A, __m512i __I,
         __m512d __B)
{
  return (__m512d) __builtin_ia32_vpermt2varpd512_maskz ((__v8di) __I
                  ,
        (__v8df) __A,
        (__v8df) __B,
        (__mmask8) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_permutex2var_ps (__m512 __A, __m512i __I, __m512 __B)
{
  return (__m512) __builtin_ia32_vpermt2varps512_mask ((__v16si) __I
                       ,
             (__v16sf) __A,
             (__v16sf) __B,
             (__mmask16) -1);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_permutex2var_ps (__m512 __A, __mmask16 __U, __m512i __I, __m512 __B)
{
  return (__m512) __builtin_ia32_vpermt2varps512_mask ((__v16si) __I
                       ,
             (__v16sf) __A,
             (__v16sf) __B,
             (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask2_permutex2var_ps (__m512 __A, __m512i __I, __mmask16 __U,
         __m512 __B)
{
  return (__m512) __builtin_ia32_vpermi2varps512_mask ((__v16sf) __A,
             (__v16si) __I
                       ,
             (__v16sf) __B,
             (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_permutex2var_ps (__mmask16 __U, __m512 __A, __m512i __I,
         __m512 __B)
{
  return (__m512) __builtin_ia32_vpermt2varps512_maskz ((__v16si) __I
                 ,
       (__v16sf) __A,
       (__v16sf) __B,
       (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_permutexvar_epi64 (__mmask8 __M, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_permvardi512_mask ((__v8di) __Y,
           (__v8di) __X,
           (__v8di)
           _mm512_setzero_si512 (),
           __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_permutexvar_epi64 (__m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_permvardi512_mask ((__v8di) __Y,
           (__v8di) __X,
           (__v8di)
           _mm512_undefined_epi32 (),
           (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_permutexvar_epi64 (__m512i __W, __mmask8 __M, __m512i __X,
          __m512i __Y)
{
  return (__m512i) __builtin_ia32_permvardi512_mask ((__v8di) __Y,
           (__v8di) __X,
           (__v8di) __W,
           __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_permutexvar_epi32 (__mmask16 __M, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_permvarsi512_mask ((__v16si) __Y,
           (__v16si) __X,
           (__v16si)
           _mm512_setzero_si512 (),
           __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_permutexvar_epi32 (__m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_permvarsi512_mask ((__v16si) __Y,
           (__v16si) __X,
           (__v16si)
           _mm512_undefined_epi32 (),
           (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_permutexvar_epi32 (__m512i __W, __mmask16 __M, __m512i __X,
          __m512i __Y)
{
  return (__m512i) __builtin_ia32_permvarsi512_mask ((__v16si) __Y,
           (__v16si) __X,
           (__v16si) __W,
           __M);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_permutexvar_pd (__m512i __X, __m512d __Y)
{
  return (__m512d) __builtin_ia32_permvardf512_mask ((__v8df) __Y,
           (__v8di) __X,
           (__v8df)
           _mm512_undefined_pd (),
           (__mmask8) -1);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_permutexvar_pd (__m512d __W, __mmask8 __U, __m512i __X, __m512d __Y)
{
  return (__m512d) __builtin_ia32_permvardf512_mask ((__v8df) __Y,
           (__v8di) __X,
           (__v8df) __W,
           (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_permutexvar_pd (__mmask8 __U, __m512i __X, __m512d __Y)
{
  return (__m512d) __builtin_ia32_permvardf512_mask ((__v8df) __Y,
           (__v8di) __X,
           (__v8df)
           _mm512_setzero_pd (),
           (__mmask8) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_permutexvar_ps (__m512i __X, __m512 __Y)
{
  return (__m512) __builtin_ia32_permvarsf512_mask ((__v16sf) __Y,
          (__v16si) __X,
          (__v16sf)
          _mm512_undefined_ps (),
          (__mmask16) -1);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_permutexvar_ps (__m512 __W, __mmask16 __U, __m512i __X, __m512 __Y)
{
  return (__m512) __builtin_ia32_permvarsf512_mask ((__v16sf) __Y,
          (__v16si) __X,
          (__v16sf) __W,
          (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_permutexvar_ps (__mmask16 __U, __m512i __X, __m512 __Y)
{
  return (__m512) __builtin_ia32_permvarsf512_mask ((__v16sf) __Y,
          (__v16si) __X,
          (__v16sf)
          _mm512_setzero_ps (),
          (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_movehdup_ps (__m512 __A)
{
  return (__m512) __builtin_ia32_movshdup512_mask ((__v16sf) __A,
         (__v16sf)
         _mm512_undefined_ps (),
         (__mmask16) -1);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_movehdup_ps (__m512 __W, __mmask16 __U, __m512 __A)
{
  return (__m512) __builtin_ia32_movshdup512_mask ((__v16sf) __A,
         (__v16sf) __W,
         (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_movehdup_ps (__mmask16 __U, __m512 __A)
{
  return (__m512) __builtin_ia32_movshdup512_mask ((__v16sf) __A,
         (__v16sf)
         _mm512_setzero_ps (),
         (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_moveldup_ps (__m512 __A)
{
  return (__m512) __builtin_ia32_movsldup512_mask ((__v16sf) __A,
         (__v16sf)
         _mm512_undefined_ps (),
         (__mmask16) -1);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_moveldup_ps (__m512 __W, __mmask16 __U, __m512 __A)
{
  return (__m512) __builtin_ia32_movsldup512_mask ((__v16sf) __A,
         (__v16sf) __W,
         (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_moveldup_ps (__mmask16 __U, __m512 __A)
{
  return (__m512) __builtin_ia32_movsldup512_mask ((__v16sf) __A,
         (__v16sf)
         _mm512_setzero_ps (),
         (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_or_si512 (__m512i __A, __m512i __B)
{
  return (__m512i) ((__v16su) __A | (__v16su) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_or_epi32 (__m512i __A, __m512i __B)
{
  return (__m512i) ((__v16su) __A | (__v16su) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_or_epi32 (__m512i __W, __mmask16 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pord512_mask ((__v16si) __A,
      (__v16si) __B,
      (__v16si) __W,
      (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_or_epi32 (__mmask16 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pord512_mask ((__v16si) __A,
      (__v16si) __B,
      (__v16si)
      _mm512_setzero_si512 (),
      (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_or_epi64 (__m512i __A, __m512i __B)
{
  return (__m512i) ((__v8du) __A | (__v8du) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_or_epi64 (__m512i __W, __mmask8 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_porq512_mask ((__v8di) __A,
      (__v8di) __B,
      (__v8di) __W,
      (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_or_epi64 (__mmask8 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_porq512_mask ((__v8di) __A,
      (__v8di) __B,
      (__v8di)
      _mm512_setzero_si512 (),
      (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_xor_si512 (__m512i __A, __m512i __B)
{
  return (__m512i) ((__v16su) __A ^ (__v16su) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_xor_epi32 (__m512i __A, __m512i __B)
{
  return (__m512i) ((__v16su) __A ^ (__v16su) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_xor_epi32 (__m512i __W, __mmask16 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pxord512_mask ((__v16si) __A,
       (__v16si) __B,
       (__v16si) __W,
       (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_xor_epi32 (__mmask16 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pxord512_mask ((__v16si) __A,
       (__v16si) __B,
       (__v16si)
       _mm512_setzero_si512 (),
       (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_xor_epi64 (__m512i __A, __m512i __B)
{
  return (__m512i) ((__v8du) __A ^ (__v8du) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_xor_epi64 (__m512i __W, __mmask8 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pxorq512_mask ((__v8di) __A,
       (__v8di) __B,
       (__v8di) __W,
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_xor_epi64 (__mmask8 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pxorq512_mask ((__v8di) __A,
       (__v8di) __B,
       (__v8di)
       _mm512_setzero_si512 (),
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_and_si512 (__m512i __A, __m512i __B)
{
  return (__m512i) ((__v16su) __A & (__v16su) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_and_epi32 (__m512i __A, __m512i __B)
{
  return (__m512i) ((__v16su) __A & (__v16su) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_and_epi32 (__m512i __W, __mmask16 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pandd512_mask ((__v16si) __A,
       (__v16si) __B,
       (__v16si) __W,
       (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_and_epi32 (__mmask16 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pandd512_mask ((__v16si) __A,
       (__v16si) __B,
       (__v16si)
       _mm512_setzero_si512 (),
       (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_and_epi64 (__m512i __A, __m512i __B)
{
  return (__m512i) ((__v8du) __A & (__v8du) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_and_epi64 (__m512i __W, __mmask8 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pandq512_mask ((__v8di) __A,
       (__v8di) __B,
       (__v8di) __W, __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_and_epi64 (__mmask8 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pandq512_mask ((__v8di) __A,
       (__v8di) __B,
       (__v8di)
       _mm512_setzero_pd (),
       __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_andnot_si512 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pandnd512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si)
        _mm512_undefined_epi32 (),
        (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_andnot_epi32 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pandnd512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si)
        _mm512_undefined_epi32 (),
        (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_andnot_epi32 (__m512i __W, __mmask16 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pandnd512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si) __W,
        (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_andnot_epi32 (__mmask16 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pandnd512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si)
        _mm512_setzero_si512 (),
        (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_andnot_epi64 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pandnq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di)
        _mm512_undefined_epi32 (),
        (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_andnot_epi64 (__m512i __W, __mmask8 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pandnq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di) __W, __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_andnot_epi64 (__mmask8 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pandnq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di)
        _mm512_setzero_pd (),
        __U);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_test_epi32_mask (__m512i __A, __m512i __B)
{
  return (__mmask16) __builtin_ia32_ptestmd512 ((__v16si) __A,
      (__v16si) __B,
      (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_test_epi32_mask (__mmask16 __U, __m512i __A, __m512i __B)
{
  return (__mmask16) __builtin_ia32_ptestmd512 ((__v16si) __A,
      (__v16si) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_test_epi64_mask (__m512i __A, __m512i __B)
{
  return (__mmask8) __builtin_ia32_ptestmq512 ((__v8di) __A,
            (__v8di) __B,
            (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_test_epi64_mask (__mmask8 __U, __m512i __A, __m512i __B)
{
  return (__mmask8) __builtin_ia32_ptestmq512 ((__v8di) __A, (__v8di) __B, __U);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_testn_epi32_mask (__m512i __A, __m512i __B)
{
  return (__mmask16) __builtin_ia32_ptestnmd512 ((__v16si) __A,
       (__v16si) __B,
       (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_testn_epi32_mask (__mmask16 __U, __m512i __A, __m512i __B)
{
  return (__mmask16) __builtin_ia32_ptestnmd512 ((__v16si) __A,
       (__v16si) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_testn_epi64_mask (__m512i __A, __m512i __B)
{
  return (__mmask8) __builtin_ia32_ptestnmq512 ((__v8di) __A,
      (__v8di) __B,
      (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_testn_epi64_mask (__mmask8 __U, __m512i __A, __m512i __B)
{
  return (__mmask8) __builtin_ia32_ptestnmq512 ((__v8di) __A,
      (__v8di) __B, __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_abs_ps (__m512 __A)
{
  return (__m512) _mm512_and_epi32 ((__m512i) __A,
        _mm512_set1_epi32 (0x7fffffff));
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_abs_ps (__m512 __W, __mmask16 __U, __m512 __A)
{
  return (__m512) _mm512_mask_and_epi32 ((__m512i) __W, __U, (__m512i) __A,
      _mm512_set1_epi32 (0x7fffffff));
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_abs_pd (__m512d __A)
{
  return (__m512d) _mm512_and_epi64 ((__m512i) __A,
         _mm512_set1_epi64 (0x7fffffffffffffffLL));
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_abs_pd (__m512d __W, __mmask8 __U, __m512d __A)
{
  return (__m512d)
  _mm512_mask_and_epi64 ((__m512i) __W, __U, (__m512i) __A,
    _mm512_set1_epi64 (0x7fffffffffffffffLL));
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_unpackhi_epi32 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_punpckhdq512_mask ((__v16si) __A,
           (__v16si) __B,
           (__v16si)
           _mm512_undefined_epi32 (),
           (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_unpackhi_epi32 (__m512i __W, __mmask16 __U, __m512i __A,
       __m512i __B)
{
  return (__m512i) __builtin_ia32_punpckhdq512_mask ((__v16si) __A,
           (__v16si) __B,
           (__v16si) __W,
           (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_unpackhi_epi32 (__mmask16 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_punpckhdq512_mask ((__v16si) __A,
           (__v16si) __B,
           (__v16si)
           _mm512_setzero_si512 (),
           (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_unpackhi_epi64 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_punpckhqdq512_mask ((__v8di) __A,
            (__v8di) __B,
            (__v8di)
            _mm512_undefined_epi32 (),
            (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_unpackhi_epi64 (__m512i __W, __mmask8 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_punpckhqdq512_mask ((__v8di) __A,
            (__v8di) __B,
            (__v8di) __W,
            (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_unpackhi_epi64 (__mmask8 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_punpckhqdq512_mask ((__v8di) __A,
            (__v8di) __B,
            (__v8di)
            _mm512_setzero_si512 (),
            (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_unpacklo_epi32 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_punpckldq512_mask ((__v16si) __A,
           (__v16si) __B,
           (__v16si)
           _mm512_undefined_epi32 (),
           (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_unpacklo_epi32 (__m512i __W, __mmask16 __U, __m512i __A,
       __m512i __B)
{
  return (__m512i) __builtin_ia32_punpckldq512_mask ((__v16si) __A,
           (__v16si) __B,
           (__v16si) __W,
           (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_unpacklo_epi32 (__mmask16 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_punpckldq512_mask ((__v16si) __A,
           (__v16si) __B,
           (__v16si)
           _mm512_setzero_si512 (),
           (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_unpacklo_epi64 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_punpcklqdq512_mask ((__v8di) __A,
            (__v8di) __B,
            (__v8di)
            _mm512_undefined_epi32 (),
            (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_unpacklo_epi64 (__m512i __W, __mmask8 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_punpcklqdq512_mask ((__v8di) __A,
            (__v8di) __B,
            (__v8di) __W,
            (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_unpacklo_epi64 (__mmask8 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_punpcklqdq512_mask ((__v8di) __A,
            (__v8di) __B,
            (__v8di)
            _mm512_setzero_si512 (),
            (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_movedup_pd (__m512d __A)
{
  return (__m512d) __builtin_ia32_movddup512_mask ((__v8df) __A,
         (__v8df)
         _mm512_undefined_pd (),
         (__mmask8) -1);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_movedup_pd (__m512d __W, __mmask8 __U, __m512d __A)
{
  return (__m512d) __builtin_ia32_movddup512_mask ((__v8df) __A,
         (__v8df) __W,
         (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_movedup_pd (__mmask8 __U, __m512d __A)
{
  return (__m512d) __builtin_ia32_movddup512_mask ((__v8df) __A,
         (__v8df)
         _mm512_setzero_pd (),
         (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_unpacklo_pd (__m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_unpcklpd512_mask ((__v8df) __A,
          (__v8df) __B,
          (__v8df)
          _mm512_undefined_pd (),
          (__mmask8) -1);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_unpacklo_pd (__m512d __W, __mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_unpcklpd512_mask ((__v8df) __A,
          (__v8df) __B,
          (__v8df) __W,
          (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_unpacklo_pd (__mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_unpcklpd512_mask ((__v8df) __A,
          (__v8df) __B,
          (__v8df)
          _mm512_setzero_pd (),
          (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_unpackhi_pd (__m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_unpckhpd512_mask ((__v8df) __A,
          (__v8df) __B,
          (__v8df)
          _mm512_undefined_pd (),
          (__mmask8) -1);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_unpackhi_pd (__m512d __W, __mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_unpckhpd512_mask ((__v8df) __A,
          (__v8df) __B,
          (__v8df) __W,
          (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_unpackhi_pd (__mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_unpckhpd512_mask ((__v8df) __A,
          (__v8df) __B,
          (__v8df)
          _mm512_setzero_pd (),
          (__mmask8) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_unpackhi_ps (__m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_unpckhps512_mask ((__v16sf) __A,
         (__v16sf) __B,
         (__v16sf)
         _mm512_undefined_ps (),
         (__mmask16) -1);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_unpackhi_ps (__m512 __W, __mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_unpckhps512_mask ((__v16sf) __A,
         (__v16sf) __B,
         (__v16sf) __W,
         (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_unpackhi_ps (__mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_unpckhps512_mask ((__v16sf) __A,
         (__v16sf) __B,
         (__v16sf)
         _mm512_setzero_ps (),
         (__mmask16) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_stream_si512 (__m512i * __P, __m512i __A)
{
  __builtin_ia32_movntdq512 ((__v8di *) __P, (__v8di) __A);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_stream_ps (float *__P, __m512 __A)
{
  __builtin_ia32_movntps512 (__P, (__v16sf) __A);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_stream_pd (double *__P, __m512d __A)
{
  __builtin_ia32_movntpd512 (__P, (__v8df) __A);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_stream_load_si512 (void *__P)
{
  return __builtin_ia32_movntdqa512 ((__v8di *)__P);
}
typedef enum
{
  _MM_MANT_NORM_1_2,
  _MM_MANT_NORM_p5_2,
  _MM_MANT_NORM_p5_1,
  _MM_MANT_NORM_p75_1p5
} _MM_MANTISSA_NORM_ENUM;
typedef enum
{
  _MM_MANT_SIGN_src,
  _MM_MANT_SIGN_zero,
  _MM_MANT_SIGN_nan
} _MM_MANTISSA_SIGN_ENUM;
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_floor_ps (__m512 __A)
{
  return (__m512) __builtin_ia32_rndscaleps_mask ((__v16sf) __A,
        (0x01 | 0x00),
        (__v16sf) __A, -1,
        0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_floor_pd (__m512d __A)
{
  return (__m512d) __builtin_ia32_rndscalepd_mask ((__v8df) __A,
         (0x01 | 0x00),
         (__v8df) __A, -1,
         0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_ceil_ps (__m512 __A)
{
  return (__m512) __builtin_ia32_rndscaleps_mask ((__v16sf) __A,
        (0x02 | 0x00),
        (__v16sf) __A, -1,
        0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_ceil_pd (__m512d __A)
{
  return (__m512d) __builtin_ia32_rndscalepd_mask ((__v8df) __A,
         (0x02 | 0x00),
         (__v8df) __A, -1,
         0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_floor_ps (__m512 __W, __mmask16 __U, __m512 __A)
{
  return (__m512) __builtin_ia32_rndscaleps_mask ((__v16sf) __A,
        (0x01 | 0x00),
        (__v16sf) __W, __U,
        0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_floor_pd (__m512d __W, __mmask8 __U, __m512d __A)
{
  return (__m512d) __builtin_ia32_rndscalepd_mask ((__v8df) __A,
         (0x01 | 0x00),
         (__v8df) __W, __U,
         0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_ceil_ps (__m512 __W, __mmask16 __U, __m512 __A)
{
  return (__m512) __builtin_ia32_rndscaleps_mask ((__v16sf) __A,
        (0x02 | 0x00),
        (__v16sf) __W, __U,
        0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_ceil_pd (__m512d __W, __mmask8 __U, __m512d __A)
{
  return (__m512d) __builtin_ia32_rndscalepd_mask ((__v8df) __A,
         (0x02 | 0x00),
         (__v8df) __W, __U,
         0x04);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpeq_epi32_mask (__m512i __A, __m512i __B)
{
  return (__mmask16) __builtin_ia32_pcmpeqd512_mask ((__v16si) __A,
           (__v16si) __B,
           (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpeq_epi32_mask (__mmask16 __U, __m512i __A, __m512i __B)
{
  return (__mmask16) __builtin_ia32_pcmpeqd512_mask ((__v16si) __A,
           (__v16si) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpeq_epi64_mask (__mmask8 __U, __m512i __A, __m512i __B)
{
  return (__mmask8) __builtin_ia32_pcmpeqq512_mask ((__v8di) __A,
          (__v8di) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpeq_epi64_mask (__m512i __A, __m512i __B)
{
  return (__mmask8) __builtin_ia32_pcmpeqq512_mask ((__v8di) __A,
          (__v8di) __B,
          (__mmask8) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpgt_epi32_mask (__m512i __A, __m512i __B)
{
  return (__mmask16) __builtin_ia32_pcmpgtd512_mask ((__v16si) __A,
           (__v16si) __B,
           (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpgt_epi32_mask (__mmask16 __U, __m512i __A, __m512i __B)
{
  return (__mmask16) __builtin_ia32_pcmpgtd512_mask ((__v16si) __A,
           (__v16si) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpgt_epi64_mask (__mmask8 __U, __m512i __A, __m512i __B)
{
  return (__mmask8) __builtin_ia32_pcmpgtq512_mask ((__v8di) __A,
          (__v8di) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpgt_epi64_mask (__m512i __A, __m512i __B)
{
  return (__mmask8) __builtin_ia32_pcmpgtq512_mask ((__v8di) __A,
          (__v8di) __B,
          (__mmask8) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpge_epi32_mask (__m512i __X, __m512i __Y)
{
  return (__mmask16) __builtin_ia32_cmpd512_mask ((__v16si) __X,
          (__v16si) __Y, 5,
          (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpge_epi32_mask (__mmask16 __M, __m512i __X, __m512i __Y)
{
  return (__mmask16) __builtin_ia32_cmpd512_mask ((__v16si) __X,
          (__v16si) __Y, 5,
          (__mmask16) __M);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpge_epu32_mask (__mmask16 __M, __m512i __X, __m512i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpd512_mask ((__v16si) __X,
          (__v16si) __Y, 5,
          (__mmask16) __M);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpge_epu32_mask (__m512i __X, __m512i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpd512_mask ((__v16si) __X,
          (__v16si) __Y, 5,
          (__mmask16) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpge_epi64_mask (__mmask8 __M, __m512i __X, __m512i __Y)
{
  return (__mmask8) __builtin_ia32_cmpq512_mask ((__v8di) __X,
          (__v8di) __Y, 5,
          (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpge_epi64_mask (__m512i __X, __m512i __Y)
{
  return (__mmask8) __builtin_ia32_cmpq512_mask ((__v8di) __X,
          (__v8di) __Y, 5,
          (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpge_epu64_mask (__mmask8 __M, __m512i __X, __m512i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpq512_mask ((__v8di) __X,
          (__v8di) __Y, 5,
          (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpge_epu64_mask (__m512i __X, __m512i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpq512_mask ((__v8di) __X,
          (__v8di) __Y, 5,
          (__mmask8) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmple_epi32_mask (__mmask16 __M, __m512i __X, __m512i __Y)
{
  return (__mmask16) __builtin_ia32_cmpd512_mask ((__v16si) __X,
          (__v16si) __Y, 2,
          (__mmask16) __M);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmple_epi32_mask (__m512i __X, __m512i __Y)
{
  return (__mmask16) __builtin_ia32_cmpd512_mask ((__v16si) __X,
          (__v16si) __Y, 2,
          (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmple_epu32_mask (__mmask16 __M, __m512i __X, __m512i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpd512_mask ((__v16si) __X,
          (__v16si) __Y, 2,
          (__mmask16) __M);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmple_epu32_mask (__m512i __X, __m512i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpd512_mask ((__v16si) __X,
          (__v16si) __Y, 2,
          (__mmask16) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmple_epi64_mask (__mmask8 __M, __m512i __X, __m512i __Y)
{
  return (__mmask8) __builtin_ia32_cmpq512_mask ((__v8di) __X,
          (__v8di) __Y, 2,
          (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmple_epi64_mask (__m512i __X, __m512i __Y)
{
  return (__mmask8) __builtin_ia32_cmpq512_mask ((__v8di) __X,
          (__v8di) __Y, 2,
          (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmple_epu64_mask (__mmask8 __M, __m512i __X, __m512i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpq512_mask ((__v8di) __X,
          (__v8di) __Y, 2,
          (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmple_epu64_mask (__m512i __X, __m512i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpq512_mask ((__v8di) __X,
          (__v8di) __Y, 2,
          (__mmask8) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmplt_epi32_mask (__mmask16 __M, __m512i __X, __m512i __Y)
{
  return (__mmask16) __builtin_ia32_cmpd512_mask ((__v16si) __X,
          (__v16si) __Y, 1,
          (__mmask16) __M);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmplt_epi32_mask (__m512i __X, __m512i __Y)
{
  return (__mmask16) __builtin_ia32_cmpd512_mask ((__v16si) __X,
          (__v16si) __Y, 1,
          (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmplt_epu32_mask (__mmask16 __M, __m512i __X, __m512i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpd512_mask ((__v16si) __X,
          (__v16si) __Y, 1,
          (__mmask16) __M);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmplt_epu32_mask (__m512i __X, __m512i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpd512_mask ((__v16si) __X,
          (__v16si) __Y, 1,
          (__mmask16) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmplt_epi64_mask (__mmask8 __M, __m512i __X, __m512i __Y)
{
  return (__mmask8) __builtin_ia32_cmpq512_mask ((__v8di) __X,
          (__v8di) __Y, 1,
          (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmplt_epi64_mask (__m512i __X, __m512i __Y)
{
  return (__mmask8) __builtin_ia32_cmpq512_mask ((__v8di) __X,
          (__v8di) __Y, 1,
          (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmplt_epu64_mask (__mmask8 __M, __m512i __X, __m512i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpq512_mask ((__v8di) __X,
          (__v8di) __Y, 1,
          (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmplt_epu64_mask (__m512i __X, __m512i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpq512_mask ((__v8di) __X,
          (__v8di) __Y, 1,
          (__mmask8) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpneq_epi32_mask (__m512i __X, __m512i __Y)
{
  return (__mmask16) __builtin_ia32_cmpd512_mask ((__v16si) __X,
          (__v16si) __Y, 4,
          (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpneq_epi32_mask (__mmask16 __M, __m512i __X, __m512i __Y)
{
  return (__mmask16) __builtin_ia32_cmpd512_mask ((__v16si) __X,
          (__v16si) __Y, 4,
          (__mmask16) __M);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpneq_epu32_mask (__mmask16 __M, __m512i __X, __m512i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpd512_mask ((__v16si) __X,
          (__v16si) __Y, 4,
          (__mmask16) __M);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpneq_epu32_mask (__m512i __X, __m512i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpd512_mask ((__v16si) __X,
          (__v16si) __Y, 4,
          (__mmask16) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpneq_epi64_mask (__mmask8 __M, __m512i __X, __m512i __Y)
{
  return (__mmask8) __builtin_ia32_cmpq512_mask ((__v8di) __X,
          (__v8di) __Y, 4,
          (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpneq_epi64_mask (__m512i __X, __m512i __Y)
{
  return (__mmask8) __builtin_ia32_cmpq512_mask ((__v8di) __X,
          (__v8di) __Y, 4,
          (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpneq_epu64_mask (__mmask8 __M, __m512i __X, __m512i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpq512_mask ((__v8di) __X,
          (__v8di) __Y, 4,
          (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpneq_epu64_mask (__m512i __X, __m512i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpq512_mask ((__v8di) __X,
          (__v8di) __Y, 4,
          (__mmask8) -1);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_compress_pd (__m512d __W, __mmask8 __U, __m512d __A)
{
  return (__m512d) __builtin_ia32_compressdf512_mask ((__v8df) __A,
            (__v8df) __W,
            (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_compress_pd (__mmask8 __U, __m512d __A)
{
  return (__m512d) __builtin_ia32_compressdf512_mask ((__v8df) __A,
            (__v8df)
            _mm512_setzero_pd (),
            (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_compressstoreu_pd (void *__P, __mmask8 __U, __m512d __A)
{
  __builtin_ia32_compressstoredf512_mask ((__v8df *) __P, (__v8df) __A,
       (__mmask8) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_compress_ps (__m512 __W, __mmask16 __U, __m512 __A)
{
  return (__m512) __builtin_ia32_compresssf512_mask ((__v16sf) __A,
           (__v16sf) __W,
           (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_compress_ps (__mmask16 __U, __m512 __A)
{
  return (__m512) __builtin_ia32_compresssf512_mask ((__v16sf) __A,
           (__v16sf)
           _mm512_setzero_ps (),
           (__mmask16) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_compressstoreu_ps (void *__P, __mmask16 __U, __m512 __A)
{
  __builtin_ia32_compressstoresf512_mask ((__v16sf *) __P, (__v16sf) __A,
       (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_compress_epi64 (__m512i __W, __mmask8 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_compressdi512_mask ((__v8di) __A,
            (__v8di) __W,
            (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_compress_epi64 (__mmask8 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_compressdi512_mask ((__v8di) __A,
            (__v8di)
            _mm512_setzero_si512 (),
            (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_compressstoreu_epi64 (void *__P, __mmask8 __U, __m512i __A)
{
  __builtin_ia32_compressstoredi512_mask ((__v8di *) __P, (__v8di) __A,
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_compress_epi32 (__m512i __W, __mmask16 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_compresssi512_mask ((__v16si) __A,
            (__v16si) __W,
            (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_compress_epi32 (__mmask16 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_compresssi512_mask ((__v16si) __A,
            (__v16si)
            _mm512_setzero_si512 (),
            (__mmask16) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_compressstoreu_epi32 (void *__P, __mmask16 __U, __m512i __A)
{
  __builtin_ia32_compressstoresi512_mask ((__v16si *) __P, (__v16si) __A,
       (__mmask16) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_expand_pd (__m512d __W, __mmask8 __U, __m512d __A)
{
  return (__m512d) __builtin_ia32_expanddf512_mask ((__v8df) __A,
          (__v8df) __W,
          (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_expand_pd (__mmask8 __U, __m512d __A)
{
  return (__m512d) __builtin_ia32_expanddf512_maskz ((__v8df) __A,
           (__v8df)
           _mm512_setzero_pd (),
           (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_expandloadu_pd (__m512d __W, __mmask8 __U, void const *__P)
{
  return (__m512d) __builtin_ia32_expandloaddf512_mask ((const __v8df *) __P,
       (__v8df) __W,
       (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_expandloadu_pd (__mmask8 __U, void const *__P)
{
  return (__m512d) __builtin_ia32_expandloaddf512_maskz ((const __v8df *) __P,
        (__v8df)
        _mm512_setzero_pd (),
        (__mmask8) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_expand_ps (__m512 __W, __mmask16 __U, __m512 __A)
{
  return (__m512) __builtin_ia32_expandsf512_mask ((__v16sf) __A,
         (__v16sf) __W,
         (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_expand_ps (__mmask16 __U, __m512 __A)
{
  return (__m512) __builtin_ia32_expandsf512_maskz ((__v16sf) __A,
          (__v16sf)
          _mm512_setzero_ps (),
          (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_expandloadu_ps (__m512 __W, __mmask16 __U, void const *__P)
{
  return (__m512) __builtin_ia32_expandloadsf512_mask ((const __v16sf *) __P,
             (__v16sf) __W,
             (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_expandloadu_ps (__mmask16 __U, void const *__P)
{
  return (__m512) __builtin_ia32_expandloadsf512_maskz ((const __v16sf *) __P,
       (__v16sf)
       _mm512_setzero_ps (),
       (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_expand_epi64 (__m512i __W, __mmask8 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_expanddi512_mask ((__v8di) __A,
          (__v8di) __W,
          (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_expand_epi64 (__mmask8 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_expanddi512_maskz ((__v8di) __A,
           (__v8di)
           _mm512_setzero_si512 (),
           (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_expandloadu_epi64 (__m512i __W, __mmask8 __U, void const *__P)
{
  return (__m512i) __builtin_ia32_expandloaddi512_mask ((const __v8di *) __P,
       (__v8di) __W,
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_expandloadu_epi64 (__mmask8 __U, void const *__P)
{
  return (__m512i)
  __builtin_ia32_expandloaddi512_maskz ((const __v8di *) __P,
            (__v8di)
            _mm512_setzero_si512 (),
            (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_expand_epi32 (__m512i __W, __mmask16 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_expandsi512_mask ((__v16si) __A,
          (__v16si) __W,
          (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_expand_epi32 (__mmask16 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_expandsi512_maskz ((__v16si) __A,
           (__v16si)
           _mm512_setzero_si512 (),
           (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_expandloadu_epi32 (__m512i __W, __mmask16 __U, void const *__P)
{
  return (__m512i) __builtin_ia32_expandloadsi512_mask ((const __v16si *) __P,
       (__v16si) __W,
       (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_expandloadu_epi32 (__mmask16 __U, void const *__P)
{
  return (__m512i) __builtin_ia32_expandloadsi512_maskz ((const __v16si *) __P,
        (__v16si)
        _mm512_setzero_si512
        (), (__mmask16) __U);
}
extern __inline unsigned char
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_kortest_mask16_u8 (__mmask16 __A, __mmask16 __B, unsigned char *__CF)
{
  *__CF = (unsigned char) __builtin_ia32_kortestchi (__A, __B);
  return (unsigned char) __builtin_ia32_kortestzhi (__A, __B);
}
extern __inline unsigned char
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_kortestz_mask16_u8 (__mmask16 __A, __mmask16 __B)
{
  return (unsigned char) __builtin_ia32_kortestzhi ((__mmask16) __A,
          (__mmask16) __B);
}
extern __inline unsigned char
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_kortestc_mask16_u8 (__mmask16 __A, __mmask16 __B)
{
  return (unsigned char) __builtin_ia32_kortestchi ((__mmask16) __A,
          (__mmask16) __B);
}
extern __inline unsigned int
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_cvtmask16_u32 (__mmask16 __A)
{
  return (unsigned int) __builtin_ia32_kmovw ((__mmask16 ) __A);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_cvtu32_mask16 (unsigned int __A)
{
  return (__mmask16) __builtin_ia32_kmovw ((__mmask16 ) __A);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_load_mask16 (__mmask16 *__A)
{
  return (__mmask16) __builtin_ia32_kmovw (*(__mmask16 *) __A);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_store_mask16 (__mmask16 *__A, __mmask16 __B)
{
  *(__mmask16 *) __A = __builtin_ia32_kmovw (__B);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_kand (__mmask16 __A, __mmask16 __B)
{
  return (__mmask16) __builtin_ia32_kandhi ((__mmask16) __A, (__mmask16) __B);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_kandn (__mmask16 __A, __mmask16 __B)
{
  return (__mmask16) __builtin_ia32_kandnhi ((__mmask16) __A,
          (__mmask16) __B);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_kor (__mmask16 __A, __mmask16 __B)
{
  return (__mmask16) __builtin_ia32_korhi ((__mmask16) __A, (__mmask16) __B);
}
extern __inline int
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_kortestz (__mmask16 __A, __mmask16 __B)
{
  return (__mmask16) __builtin_ia32_kortestzhi ((__mmask16) __A,
      (__mmask16) __B);
}
extern __inline int
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_kortestc (__mmask16 __A, __mmask16 __B)
{
  return (__mmask16) __builtin_ia32_kortestchi ((__mmask16) __A,
      (__mmask16) __B);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_kxnor (__mmask16 __A, __mmask16 __B)
{
  return (__mmask16) __builtin_ia32_kxnorhi ((__mmask16) __A, (__mmask16) __B);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_kxor (__mmask16 __A, __mmask16 __B)
{
  return (__mmask16) __builtin_ia32_kxorhi ((__mmask16) __A, (__mmask16) __B);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_knot (__mmask16 __A)
{
  return (__mmask16) __builtin_ia32_knothi ((__mmask16) __A);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_kunpackb (__mmask16 __A, __mmask16 __B)
{
  return (__mmask16) __builtin_ia32_kunpckhi ((__mmask16) __A, (__mmask16) __B);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_kunpackb_mask16 (__mmask8 __A, __mmask8 __B)
{
  return (__mmask16) __builtin_ia32_kunpckhi ((__mmask16) __A, (__mmask16) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_max_epi64 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxsq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di)
        _mm512_undefined_epi32 (),
        (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_max_epi64 (__mmask8 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxsq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di)
        _mm512_setzero_si512 (),
        __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_max_epi64 (__m512i __W, __mmask8 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxsq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di) __W, __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_min_epi64 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pminsq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di)
        _mm512_undefined_epi32 (),
        (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_min_epi64 (__m512i __W, __mmask8 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pminsq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di) __W, __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_min_epi64 (__mmask8 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pminsq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di)
        _mm512_setzero_si512 (),
        __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_max_epu64 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxuq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di)
        _mm512_undefined_epi32 (),
        (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_max_epu64 (__mmask8 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxuq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di)
        _mm512_setzero_si512 (),
        __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_max_epu64 (__m512i __W, __mmask8 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxuq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di) __W, __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_min_epu64 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pminuq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di)
        _mm512_undefined_epi32 (),
        (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_min_epu64 (__m512i __W, __mmask8 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pminuq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di) __W, __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_min_epu64 (__mmask8 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pminuq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di)
        _mm512_setzero_si512 (),
        __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_max_epi32 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxsd512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si)
        _mm512_undefined_epi32 (),
        (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_max_epi32 (__mmask16 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxsd512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si)
        _mm512_setzero_si512 (),
        __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_max_epi32 (__m512i __W, __mmask16 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxsd512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si) __W, __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_min_epi32 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pminsd512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si)
        _mm512_undefined_epi32 (),
        (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_min_epi32 (__mmask16 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pminsd512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si)
        _mm512_setzero_si512 (),
        __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_min_epi32 (__m512i __W, __mmask16 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pminsd512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si) __W, __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_max_epu32 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxud512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si)
        _mm512_undefined_epi32 (),
        (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_max_epu32 (__mmask16 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxud512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si)
        _mm512_setzero_si512 (),
        __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_max_epu32 (__m512i __W, __mmask16 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxud512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si) __W, __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_min_epu32 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pminud512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si)
        _mm512_undefined_epi32 (),
        (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_min_epu32 (__mmask16 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pminud512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si)
        _mm512_setzero_si512 (),
        __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_min_epu32 (__m512i __W, __mmask16 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pminud512_mask ((__v16si) __A,
        (__v16si) __B,
        (__v16si) __W, __M);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_unpacklo_ps (__m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_unpcklps512_mask ((__v16sf) __A,
         (__v16sf) __B,
         (__v16sf)
         _mm512_undefined_ps (),
         (__mmask16) -1);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_unpacklo_ps (__m512 __W, __mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_unpcklps512_mask ((__v16sf) __A,
         (__v16sf) __B,
         (__v16sf) __W,
         (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_unpacklo_ps (__mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_unpcklps512_mask ((__v16sf) __A,
         (__v16sf) __B,
         (__v16sf)
         _mm512_setzero_ps (),
         (__mmask16) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_blend_pd (__mmask8 __U, __m512d __A, __m512d __W)
{
  return (__m512d) __builtin_ia32_blendmpd_512_mask ((__v8df) __A,
           (__v8df) __W,
           (__mmask8) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_blend_ps (__mmask16 __U, __m512 __A, __m512 __W)
{
  return (__m512) __builtin_ia32_blendmps_512_mask ((__v16sf) __A,
          (__v16sf) __W,
          (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_blend_epi64 (__mmask8 __U, __m512i __A, __m512i __W)
{
  return (__m512i) __builtin_ia32_blendmq_512_mask ((__v8di) __A,
          (__v8di) __W,
          (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_blend_epi32 (__mmask16 __U, __m512i __A, __m512i __W)
{
  return (__m512i) __builtin_ia32_blendmd_512_mask ((__v16si) __A,
          (__v16si) __W,
          (__mmask16) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_fmadd_sd (__m128d __W, __mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_vfmaddsd3_mask ((__v2df) __W,
        (__v2df) __A,
        (__v2df) __B,
        (__mmask8) __U,
        0x04);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_fmadd_ss (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_vfmaddss3_mask ((__v4sf) __W,
       (__v4sf) __A,
       (__v4sf) __B,
       (__mmask8) __U,
       0x04);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask3_fmadd_sd (__m128d __W, __m128d __A, __m128d __B, __mmask8 __U)
{
  return (__m128d) __builtin_ia32_vfmaddsd3_mask3 ((__v2df) __W,
         (__v2df) __A,
         (__v2df) __B,
         (__mmask8) __U,
         0x04);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask3_fmadd_ss (__m128 __W, __m128 __A, __m128 __B, __mmask8 __U)
{
  return (__m128) __builtin_ia32_vfmaddss3_mask3 ((__v4sf) __W,
        (__v4sf) __A,
        (__v4sf) __B,
        (__mmask8) __U,
        0x04);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_fmadd_sd (__mmask8 __U, __m128d __W, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_vfmaddsd3_maskz ((__v2df) __W,
         (__v2df) __A,
         (__v2df) __B,
         (__mmask8) __U,
         0x04);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_fmadd_ss (__mmask8 __U, __m128 __W, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_vfmaddss3_maskz ((__v4sf) __W,
        (__v4sf) __A,
        (__v4sf) __B,
        (__mmask8) __U,
        0x04);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_fmsub_sd (__m128d __W, __mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_vfmaddsd3_mask ((__v2df) __W,
        (__v2df) __A,
        -(__v2df) __B,
        (__mmask8) __U,
        0x04);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_fmsub_ss (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_vfmaddss3_mask ((__v4sf) __W,
       (__v4sf) __A,
       -(__v4sf) __B,
       (__mmask8) __U,
       0x04);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask3_fmsub_sd (__m128d __W, __m128d __A, __m128d __B, __mmask8 __U)
{
  return (__m128d) __builtin_ia32_vfmsubsd3_mask3 ((__v2df) __W,
         (__v2df) __A,
         (__v2df) __B,
         (__mmask8) __U,
         0x04);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask3_fmsub_ss (__m128 __W, __m128 __A, __m128 __B, __mmask8 __U)
{
  return (__m128) __builtin_ia32_vfmsubss3_mask3 ((__v4sf) __W,
        (__v4sf) __A,
        (__v4sf) __B,
        (__mmask8) __U,
        0x04);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_fmsub_sd (__mmask8 __U, __m128d __W, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_vfmaddsd3_maskz ((__v2df) __W,
         (__v2df) __A,
         -(__v2df) __B,
         (__mmask8) __U,
         0x04);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_fmsub_ss (__mmask8 __U, __m128 __W, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_vfmaddss3_maskz ((__v4sf) __W,
        (__v4sf) __A,
        -(__v4sf) __B,
        (__mmask8) __U,
        0x04);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_fnmadd_sd (__m128d __W, __mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_vfmaddsd3_mask ((__v2df) __W,
        -(__v2df) __A,
        (__v2df) __B,
        (__mmask8) __U,
        0x04);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_fnmadd_ss (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_vfmaddss3_mask ((__v4sf) __W,
       -(__v4sf) __A,
       (__v4sf) __B,
       (__mmask8) __U,
       0x04);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask3_fnmadd_sd (__m128d __W, __m128d __A, __m128d __B, __mmask8 __U)
{
  return (__m128d) __builtin_ia32_vfmaddsd3_mask3 ((__v2df) __W,
         -(__v2df) __A,
         (__v2df) __B,
         (__mmask8) __U,
         0x04);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask3_fnmadd_ss (__m128 __W, __m128 __A, __m128 __B, __mmask8 __U)
{
  return (__m128) __builtin_ia32_vfmaddss3_mask3 ((__v4sf) __W,
        -(__v4sf) __A,
        (__v4sf) __B,
        (__mmask8) __U,
        0x04);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_fnmadd_sd (__mmask8 __U, __m128d __W, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_vfmaddsd3_maskz ((__v2df) __W,
         -(__v2df) __A,
         (__v2df) __B,
         (__mmask8) __U,
         0x04);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_fnmadd_ss (__mmask8 __U, __m128 __W, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_vfmaddss3_maskz ((__v4sf) __W,
        -(__v4sf) __A,
        (__v4sf) __B,
        (__mmask8) __U,
        0x04);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_fnmsub_sd (__m128d __W, __mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_vfmaddsd3_mask ((__v2df) __W,
        -(__v2df) __A,
        -(__v2df) __B,
        (__mmask8) __U,
        0x04);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_fnmsub_ss (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_vfmaddss3_mask ((__v4sf) __W,
       -(__v4sf) __A,
       -(__v4sf) __B,
       (__mmask8) __U,
       0x04);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask3_fnmsub_sd (__m128d __W, __m128d __A, __m128d __B, __mmask8 __U)
{
  return (__m128d) __builtin_ia32_vfmsubsd3_mask3 ((__v2df) __W,
         -(__v2df) __A,
         (__v2df) __B,
         (__mmask8) __U,
         0x04);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask3_fnmsub_ss (__m128 __W, __m128 __A, __m128 __B, __mmask8 __U)
{
  return (__m128) __builtin_ia32_vfmsubss3_mask3 ((__v4sf) __W,
        -(__v4sf) __A,
        (__v4sf) __B,
        (__mmask8) __U,
        0x04);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_fnmsub_sd (__mmask8 __U, __m128d __W, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_vfmaddsd3_maskz ((__v2df) __W,
         -(__v2df) __A,
         -(__v2df) __B,
         (__mmask8) __U,
         0x04);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_fnmsub_ss (__mmask8 __U, __m128 __W, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_vfmaddss3_maskz ((__v4sf) __W,
        -(__v4sf) __A,
        -(__v4sf) __B,
        (__mmask8) __U,
        0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_sqrt_pd (__m512d __A)
{
  return (__m512d) __builtin_ia32_sqrtpd512_mask ((__v8df) __A,
        (__v8df)
        _mm512_undefined_pd (),
        (__mmask8) -1,
        0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_sqrt_pd (__m512d __W, __mmask8 __U, __m512d __A)
{
  return (__m512d) __builtin_ia32_sqrtpd512_mask ((__v8df) __A,
        (__v8df) __W,
        (__mmask8) __U,
        0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_sqrt_pd (__mmask8 __U, __m512d __A)
{
  return (__m512d) __builtin_ia32_sqrtpd512_mask ((__v8df) __A,
        (__v8df)
        _mm512_setzero_pd (),
        (__mmask8) __U,
        0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_sqrt_ps (__m512 __A)
{
  return (__m512) __builtin_ia32_sqrtps512_mask ((__v16sf) __A,
       (__v16sf)
       _mm512_undefined_ps (),
       (__mmask16) -1,
       0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_sqrt_ps (__m512 __W, __mmask16 __U, __m512 __A)
{
  return (__m512) __builtin_ia32_sqrtps512_mask ((__v16sf) __A,
       (__v16sf) __W,
       (__mmask16) __U,
       0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_sqrt_ps (__mmask16 __U, __m512 __A)
{
  return (__m512) __builtin_ia32_sqrtps512_mask ((__v16sf) __A,
       (__v16sf)
       _mm512_setzero_ps (),
       (__mmask16) __U,
       0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_add_pd (__m512d __A, __m512d __B)
{
  return (__m512d) ((__v8df)__A + (__v8df)__B);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_add_pd (__m512d __W, __mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_addpd512_mask ((__v8df) __A,
       (__v8df) __B,
       (__v8df) __W,
       (__mmask8) __U,
       0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_add_pd (__mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_addpd512_mask ((__v8df) __A,
       (__v8df) __B,
       (__v8df)
       _mm512_setzero_pd (),
       (__mmask8) __U,
       0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_add_ps (__m512 __A, __m512 __B)
{
  return (__m512) ((__v16sf)__A + (__v16sf)__B);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_add_ps (__m512 __W, __mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_addps512_mask ((__v16sf) __A,
      (__v16sf) __B,
      (__v16sf) __W,
      (__mmask16) __U,
      0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_add_ps (__mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_addps512_mask ((__v16sf) __A,
      (__v16sf) __B,
      (__v16sf)
      _mm512_setzero_ps (),
      (__mmask16) __U,
      0x04);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_add_sd (__m128d __W, __mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_addsd_mask_round ((__v2df) __A,
      (__v2df) __B,
      (__v2df) __W,
      (__mmask8) __U,
      0x04);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_add_sd (__mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_addsd_mask_round ((__v2df) __A,
      (__v2df) __B,
      (__v2df)
      _mm_setzero_pd (),
      (__mmask8) __U,
      0x04);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_add_ss (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_addss_mask_round ((__v4sf) __A,
      (__v4sf) __B,
      (__v4sf) __W,
      (__mmask8) __U,
      0x04);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_add_ss (__mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_addss_mask_round ((__v4sf) __A,
      (__v4sf) __B,
      (__v4sf)
      _mm_setzero_ps (),
      (__mmask8) __U,
      0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_sub_pd (__m512d __A, __m512d __B)
{
  return (__m512d) ((__v8df)__A - (__v8df)__B);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_sub_pd (__m512d __W, __mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_subpd512_mask ((__v8df) __A,
       (__v8df) __B,
       (__v8df) __W,
       (__mmask8) __U,
       0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_sub_pd (__mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_subpd512_mask ((__v8df) __A,
       (__v8df) __B,
       (__v8df)
       _mm512_setzero_pd (),
       (__mmask8) __U,
       0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_sub_ps (__m512 __A, __m512 __B)
{
  return (__m512) ((__v16sf)__A - (__v16sf)__B);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_sub_ps (__m512 __W, __mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_subps512_mask ((__v16sf) __A,
      (__v16sf) __B,
      (__v16sf) __W,
      (__mmask16) __U,
      0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_sub_ps (__mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_subps512_mask ((__v16sf) __A,
      (__v16sf) __B,
      (__v16sf)
      _mm512_setzero_ps (),
      (__mmask16) __U,
      0x04);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_sub_sd (__m128d __W, __mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_subsd_mask_round ((__v2df) __A,
      (__v2df) __B,
      (__v2df) __W,
      (__mmask8) __U,
      0x04);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_sub_sd (__mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_subsd_mask_round ((__v2df) __A,
      (__v2df) __B,
      (__v2df)
      _mm_setzero_pd (),
      (__mmask8) __U,
      0x04);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_sub_ss (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_subss_mask_round ((__v4sf) __A,
      (__v4sf) __B,
      (__v4sf) __W,
      (__mmask8) __U,
      0x04);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_sub_ss (__mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_subss_mask_round ((__v4sf) __A,
      (__v4sf) __B,
      (__v4sf)
      _mm_setzero_ps (),
      (__mmask8) __U,
      0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mul_pd (__m512d __A, __m512d __B)
{
  return (__m512d) ((__v8df)__A * (__v8df)__B);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_mul_pd (__m512d __W, __mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_mulpd512_mask ((__v8df) __A,
       (__v8df) __B,
       (__v8df) __W,
       (__mmask8) __U,
       0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_mul_pd (__mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_mulpd512_mask ((__v8df) __A,
       (__v8df) __B,
       (__v8df)
       _mm512_setzero_pd (),
       (__mmask8) __U,
       0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mul_ps (__m512 __A, __m512 __B)
{
  return (__m512) ((__v16sf)__A * (__v16sf)__B);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_mul_ps (__m512 __W, __mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_mulps512_mask ((__v16sf) __A,
      (__v16sf) __B,
      (__v16sf) __W,
      (__mmask16) __U,
      0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_mul_ps (__mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_mulps512_mask ((__v16sf) __A,
      (__v16sf) __B,
      (__v16sf)
      _mm512_setzero_ps (),
      (__mmask16) __U,
      0x04);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_mul_sd (__m128d __W, __mmask8 __U, __m128d __A,
     __m128d __B)
{
  return (__m128d) __builtin_ia32_mulsd_mask_round ((__v2df) __A,
       (__v2df) __B,
       (__v2df) __W,
       (__mmask8) __U,
        0x04);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_mul_sd (__mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_mulsd_mask_round ((__v2df) __A,
       (__v2df) __B,
       (__v2df)
       _mm_setzero_pd (),
       (__mmask8) __U,
        0x04);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_mul_ss (__m128 __W, __mmask8 __U, __m128 __A,
     __m128 __B)
{
  return (__m128) __builtin_ia32_mulss_mask_round ((__v4sf) __A,
       (__v4sf) __B,
       (__v4sf) __W,
       (__mmask8) __U,
        0x04);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_mul_ss (__mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_mulss_mask_round ((__v4sf) __A,
       (__v4sf) __B,
       (__v4sf)
       _mm_setzero_ps (),
       (__mmask8) __U,
        0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_div_pd (__m512d __M, __m512d __V)
{
  return (__m512d) ((__v8df)__M / (__v8df)__V);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_div_pd (__m512d __W, __mmask8 __U, __m512d __M, __m512d __V)
{
  return (__m512d) __builtin_ia32_divpd512_mask ((__v8df) __M,
       (__v8df) __V,
       (__v8df) __W,
       (__mmask8) __U,
       0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_div_pd (__mmask8 __U, __m512d __M, __m512d __V)
{
  return (__m512d) __builtin_ia32_divpd512_mask ((__v8df) __M,
       (__v8df) __V,
       (__v8df)
       _mm512_setzero_pd (),
       (__mmask8) __U,
       0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_div_ps (__m512 __A, __m512 __B)
{
  return (__m512) ((__v16sf)__A / (__v16sf)__B);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_div_ps (__m512 __W, __mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_divps512_mask ((__v16sf) __A,
      (__v16sf) __B,
      (__v16sf) __W,
      (__mmask16) __U,
      0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_div_ps (__mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_divps512_mask ((__v16sf) __A,
      (__v16sf) __B,
      (__v16sf)
      _mm512_setzero_ps (),
      (__mmask16) __U,
      0x04);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_div_sd (__m128d __W, __mmask8 __U, __m128d __A,
     __m128d __B)
{
  return (__m128d) __builtin_ia32_divsd_mask_round ((__v2df) __A,
       (__v2df) __B,
       (__v2df) __W,
       (__mmask8) __U,
        0x04);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_div_sd (__mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_divsd_mask_round ((__v2df) __A,
       (__v2df) __B,
       (__v2df)
       _mm_setzero_pd (),
       (__mmask8) __U,
        0x04);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_div_ss (__m128 __W, __mmask8 __U, __m128 __A,
     __m128 __B)
{
  return (__m128) __builtin_ia32_divss_mask_round ((__v4sf) __A,
       (__v4sf) __B,
       (__v4sf) __W,
       (__mmask8) __U,
        0x04);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_div_ss (__mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_divss_mask_round ((__v4sf) __A,
       (__v4sf) __B,
       (__v4sf)
       _mm_setzero_ps (),
       (__mmask8) __U,
        0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_max_pd (__m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_maxpd512_mask ((__v8df) __A,
       (__v8df) __B,
       (__v8df)
       _mm512_undefined_pd (),
       (__mmask8) -1,
       0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_max_pd (__m512d __W, __mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_maxpd512_mask ((__v8df) __A,
       (__v8df) __B,
       (__v8df) __W,
       (__mmask8) __U,
       0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_max_pd (__mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_maxpd512_mask ((__v8df) __A,
       (__v8df) __B,
       (__v8df)
       _mm512_setzero_pd (),
       (__mmask8) __U,
       0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_max_ps (__m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_maxps512_mask ((__v16sf) __A,
      (__v16sf) __B,
      (__v16sf)
      _mm512_undefined_ps (),
      (__mmask16) -1,
      0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_max_ps (__m512 __W, __mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_maxps512_mask ((__v16sf) __A,
      (__v16sf) __B,
      (__v16sf) __W,
      (__mmask16) __U,
      0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_max_ps (__mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_maxps512_mask ((__v16sf) __A,
      (__v16sf) __B,
      (__v16sf)
      _mm512_setzero_ps (),
      (__mmask16) __U,
      0x04);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_max_sd (__m128d __W, __mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_maxsd_mask_round ((__v2df) __A,
       (__v2df) __B,
       (__v2df) __W,
       (__mmask8) __U,
       0x04);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_max_sd (__mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_maxsd_mask_round ((__v2df) __A,
       (__v2df) __B,
       (__v2df)
       _mm_setzero_pd (),
       (__mmask8) __U,
       0x04);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_max_ss (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_maxss_mask_round ((__v4sf) __A,
      (__v4sf) __B,
      (__v4sf) __W,
      (__mmask8) __U,
      0x04);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_max_ss (__mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_maxss_mask_round ((__v4sf) __A,
      (__v4sf) __B,
      (__v4sf)
      _mm_setzero_ps (),
      (__mmask8) __U,
      0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_min_pd (__m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_minpd512_mask ((__v8df) __A,
       (__v8df) __B,
       (__v8df)
       _mm512_undefined_pd (),
       (__mmask8) -1,
       0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_min_pd (__m512d __W, __mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_minpd512_mask ((__v8df) __A,
       (__v8df) __B,
       (__v8df) __W,
       (__mmask8) __U,
       0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_min_pd (__mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_minpd512_mask ((__v8df) __A,
       (__v8df) __B,
       (__v8df)
       _mm512_setzero_pd (),
       (__mmask8) __U,
       0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_min_ps (__m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_minps512_mask ((__v16sf) __A,
      (__v16sf) __B,
      (__v16sf)
      _mm512_undefined_ps (),
      (__mmask16) -1,
      0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_min_ps (__m512 __W, __mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_minps512_mask ((__v16sf) __A,
      (__v16sf) __B,
      (__v16sf) __W,
      (__mmask16) __U,
      0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_min_ps (__mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_minps512_mask ((__v16sf) __A,
      (__v16sf) __B,
      (__v16sf)
      _mm512_setzero_ps (),
      (__mmask16) __U,
      0x04);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_min_sd (__m128d __W, __mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_minsd_mask_round ((__v2df) __A,
       (__v2df) __B,
       (__v2df) __W,
       (__mmask8) __U,
       0x04);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_min_sd (__mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_minsd_mask_round ((__v2df) __A,
       (__v2df) __B,
       (__v2df)
       _mm_setzero_pd (),
       (__mmask8) __U,
       0x04);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_min_ss (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_minss_mask_round ((__v4sf) __A,
      (__v4sf) __B,
      (__v4sf) __W,
      (__mmask8) __U,
      0x04);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_min_ss (__mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_minss_mask_round ((__v4sf) __A,
      (__v4sf) __B,
      (__v4sf)
      _mm_setzero_ps (),
      (__mmask8) __U,
      0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_scalef_pd (__m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_scalefpd512_mask ((__v8df) __A,
          (__v8df) __B,
          (__v8df)
          _mm512_undefined_pd (),
          (__mmask8) -1,
          0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_scalef_pd (__m512d __W, __mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_scalefpd512_mask ((__v8df) __A,
          (__v8df) __B,
          (__v8df) __W,
          (__mmask8) __U,
          0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_scalef_pd (__mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_scalefpd512_mask ((__v8df) __A,
          (__v8df) __B,
          (__v8df)
          _mm512_setzero_pd (),
          (__mmask8) __U,
          0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_scalef_ps (__m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_scalefps512_mask ((__v16sf) __A,
         (__v16sf) __B,
         (__v16sf)
         _mm512_undefined_ps (),
         (__mmask16) -1,
         0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_scalef_ps (__m512 __W, __mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_scalefps512_mask ((__v16sf) __A,
         (__v16sf) __B,
         (__v16sf) __W,
         (__mmask16) __U,
         0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_scalef_ps (__mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_scalefps512_mask ((__v16sf) __A,
         (__v16sf) __B,
         (__v16sf)
         _mm512_setzero_ps (),
         (__mmask16) __U,
         0x04);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_scalef_sd (__m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_scalefsd_mask_round ((__v2df) __A,
          (__v2df) __B,
          (__v2df)
          _mm_setzero_pd (),
          (__mmask8) -1,
          0x04);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_scalef_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_scalefss_mask_round ((__v4sf) __A,
         (__v4sf) __B,
         (__v4sf)
         _mm_setzero_ps (),
         (__mmask8) -1,
         0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_fmadd_pd (__m512d __A, __m512d __B, __m512d __C)
{
  return (__m512d) __builtin_ia32_vfmaddpd512_mask ((__v8df) __A,
          (__v8df) __B,
          (__v8df) __C,
          (__mmask8) -1,
          0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_fmadd_pd (__m512d __A, __mmask8 __U, __m512d __B, __m512d __C)
{
  return (__m512d) __builtin_ia32_vfmaddpd512_mask ((__v8df) __A,
          (__v8df) __B,
          (__v8df) __C,
          (__mmask8) __U,
          0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask3_fmadd_pd (__m512d __A, __m512d __B, __m512d __C, __mmask8 __U)
{
  return (__m512d) __builtin_ia32_vfmaddpd512_mask3 ((__v8df) __A,
           (__v8df) __B,
           (__v8df) __C,
           (__mmask8) __U,
           0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_fmadd_pd (__mmask8 __U, __m512d __A, __m512d __B, __m512d __C)
{
  return (__m512d) __builtin_ia32_vfmaddpd512_maskz ((__v8df) __A,
           (__v8df) __B,
           (__v8df) __C,
           (__mmask8) __U,
           0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_fmadd_ps (__m512 __A, __m512 __B, __m512 __C)
{
  return (__m512) __builtin_ia32_vfmaddps512_mask ((__v16sf) __A,
         (__v16sf) __B,
         (__v16sf) __C,
         (__mmask16) -1,
         0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_fmadd_ps (__m512 __A, __mmask16 __U, __m512 __B, __m512 __C)
{
  return (__m512) __builtin_ia32_vfmaddps512_mask ((__v16sf) __A,
         (__v16sf) __B,
         (__v16sf) __C,
         (__mmask16) __U,
         0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask3_fmadd_ps (__m512 __A, __m512 __B, __m512 __C, __mmask16 __U)
{
  return (__m512) __builtin_ia32_vfmaddps512_mask3 ((__v16sf) __A,
          (__v16sf) __B,
          (__v16sf) __C,
          (__mmask16) __U,
          0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_fmadd_ps (__mmask16 __U, __m512 __A, __m512 __B, __m512 __C)
{
  return (__m512) __builtin_ia32_vfmaddps512_maskz ((__v16sf) __A,
          (__v16sf) __B,
          (__v16sf) __C,
          (__mmask16) __U,
          0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_fmsub_pd (__m512d __A, __m512d __B, __m512d __C)
{
  return (__m512d) __builtin_ia32_vfmsubpd512_mask ((__v8df) __A,
          (__v8df) __B,
          (__v8df) __C,
          (__mmask8) -1,
          0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_fmsub_pd (__m512d __A, __mmask8 __U, __m512d __B, __m512d __C)
{
  return (__m512d) __builtin_ia32_vfmsubpd512_mask ((__v8df) __A,
          (__v8df) __B,
          (__v8df) __C,
          (__mmask8) __U,
          0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask3_fmsub_pd (__m512d __A, __m512d __B, __m512d __C, __mmask8 __U)
{
  return (__m512d) __builtin_ia32_vfmsubpd512_mask3 ((__v8df) __A,
           (__v8df) __B,
           (__v8df) __C,
           (__mmask8) __U,
           0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_fmsub_pd (__mmask8 __U, __m512d __A, __m512d __B, __m512d __C)
{
  return (__m512d) __builtin_ia32_vfmsubpd512_maskz ((__v8df) __A,
           (__v8df) __B,
           (__v8df) __C,
           (__mmask8) __U,
           0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_fmsub_ps (__m512 __A, __m512 __B, __m512 __C)
{
  return (__m512) __builtin_ia32_vfmsubps512_mask ((__v16sf) __A,
         (__v16sf) __B,
         (__v16sf) __C,
         (__mmask16) -1,
         0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_fmsub_ps (__m512 __A, __mmask16 __U, __m512 __B, __m512 __C)
{
  return (__m512) __builtin_ia32_vfmsubps512_mask ((__v16sf) __A,
         (__v16sf) __B,
         (__v16sf) __C,
         (__mmask16) __U,
         0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask3_fmsub_ps (__m512 __A, __m512 __B, __m512 __C, __mmask16 __U)
{
  return (__m512) __builtin_ia32_vfmsubps512_mask3 ((__v16sf) __A,
          (__v16sf) __B,
          (__v16sf) __C,
          (__mmask16) __U,
          0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_fmsub_ps (__mmask16 __U, __m512 __A, __m512 __B, __m512 __C)
{
  return (__m512) __builtin_ia32_vfmsubps512_maskz ((__v16sf) __A,
          (__v16sf) __B,
          (__v16sf) __C,
          (__mmask16) __U,
          0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_fmaddsub_pd (__m512d __A, __m512d __B, __m512d __C)
{
  return (__m512d) __builtin_ia32_vfmaddsubpd512_mask ((__v8df) __A,
             (__v8df) __B,
             (__v8df) __C,
             (__mmask8) -1,
             0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_fmaddsub_pd (__m512d __A, __mmask8 __U, __m512d __B, __m512d __C)
{
  return (__m512d) __builtin_ia32_vfmaddsubpd512_mask ((__v8df) __A,
             (__v8df) __B,
             (__v8df) __C,
             (__mmask8) __U,
             0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask3_fmaddsub_pd (__m512d __A, __m512d __B, __m512d __C, __mmask8 __U)
{
  return (__m512d) __builtin_ia32_vfmaddsubpd512_mask3 ((__v8df) __A,
       (__v8df) __B,
       (__v8df) __C,
       (__mmask8) __U,
       0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_fmaddsub_pd (__mmask8 __U, __m512d __A, __m512d __B, __m512d __C)
{
  return (__m512d) __builtin_ia32_vfmaddsubpd512_maskz ((__v8df) __A,
       (__v8df) __B,
       (__v8df) __C,
       (__mmask8) __U,
       0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_fmaddsub_ps (__m512 __A, __m512 __B, __m512 __C)
{
  return (__m512) __builtin_ia32_vfmaddsubps512_mask ((__v16sf) __A,
            (__v16sf) __B,
            (__v16sf) __C,
            (__mmask16) -1,
            0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_fmaddsub_ps (__m512 __A, __mmask16 __U, __m512 __B, __m512 __C)
{
  return (__m512) __builtin_ia32_vfmaddsubps512_mask ((__v16sf) __A,
            (__v16sf) __B,
            (__v16sf) __C,
            (__mmask16) __U,
            0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask3_fmaddsub_ps (__m512 __A, __m512 __B, __m512 __C, __mmask16 __U)
{
  return (__m512) __builtin_ia32_vfmaddsubps512_mask3 ((__v16sf) __A,
             (__v16sf) __B,
             (__v16sf) __C,
             (__mmask16) __U,
             0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_fmaddsub_ps (__mmask16 __U, __m512 __A, __m512 __B, __m512 __C)
{
  return (__m512) __builtin_ia32_vfmaddsubps512_maskz ((__v16sf) __A,
             (__v16sf) __B,
             (__v16sf) __C,
             (__mmask16) __U,
             0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_fmsubadd_pd (__m512d __A, __m512d __B, __m512d __C)
{
  return (__m512d) __builtin_ia32_vfmaddsubpd512_mask ((__v8df) __A,
             (__v8df) __B,
             -(__v8df) __C,
             (__mmask8) -1,
             0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_fmsubadd_pd (__m512d __A, __mmask8 __U, __m512d __B, __m512d __C)
{
  return (__m512d) __builtin_ia32_vfmaddsubpd512_mask ((__v8df) __A,
             (__v8df) __B,
             -(__v8df) __C,
             (__mmask8) __U,
             0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask3_fmsubadd_pd (__m512d __A, __m512d __B, __m512d __C, __mmask8 __U)
{
  return (__m512d) __builtin_ia32_vfmsubaddpd512_mask3 ((__v8df) __A,
       (__v8df) __B,
       (__v8df) __C,
       (__mmask8) __U,
       0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_fmsubadd_pd (__mmask8 __U, __m512d __A, __m512d __B, __m512d __C)
{
  return (__m512d) __builtin_ia32_vfmaddsubpd512_maskz ((__v8df) __A,
       (__v8df) __B,
       -(__v8df) __C,
       (__mmask8) __U,
       0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_fmsubadd_ps (__m512 __A, __m512 __B, __m512 __C)
{
  return (__m512) __builtin_ia32_vfmaddsubps512_mask ((__v16sf) __A,
            (__v16sf) __B,
            -(__v16sf) __C,
            (__mmask16) -1,
            0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_fmsubadd_ps (__m512 __A, __mmask16 __U, __m512 __B, __m512 __C)
{
  return (__m512) __builtin_ia32_vfmaddsubps512_mask ((__v16sf) __A,
            (__v16sf) __B,
            -(__v16sf) __C,
            (__mmask16) __U,
            0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask3_fmsubadd_ps (__m512 __A, __m512 __B, __m512 __C, __mmask16 __U)
{
  return (__m512) __builtin_ia32_vfmsubaddps512_mask3 ((__v16sf) __A,
             (__v16sf) __B,
             (__v16sf) __C,
             (__mmask16) __U,
             0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_fmsubadd_ps (__mmask16 __U, __m512 __A, __m512 __B, __m512 __C)
{
  return (__m512) __builtin_ia32_vfmaddsubps512_maskz ((__v16sf) __A,
             (__v16sf) __B,
             -(__v16sf) __C,
             (__mmask16) __U,
             0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_fnmadd_pd (__m512d __A, __m512d __B, __m512d __C)
{
  return (__m512d) __builtin_ia32_vfnmaddpd512_mask ((__v8df) __A,
           (__v8df) __B,
           (__v8df) __C,
           (__mmask8) -1,
           0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_fnmadd_pd (__m512d __A, __mmask8 __U, __m512d __B, __m512d __C)
{
  return (__m512d) __builtin_ia32_vfnmaddpd512_mask ((__v8df) __A,
           (__v8df) __B,
           (__v8df) __C,
           (__mmask8) __U,
           0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask3_fnmadd_pd (__m512d __A, __m512d __B, __m512d __C, __mmask8 __U)
{
  return (__m512d) __builtin_ia32_vfnmaddpd512_mask3 ((__v8df) __A,
            (__v8df) __B,
            (__v8df) __C,
            (__mmask8) __U,
            0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_fnmadd_pd (__mmask8 __U, __m512d __A, __m512d __B, __m512d __C)
{
  return (__m512d) __builtin_ia32_vfnmaddpd512_maskz ((__v8df) __A,
            (__v8df) __B,
            (__v8df) __C,
            (__mmask8) __U,
            0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_fnmadd_ps (__m512 __A, __m512 __B, __m512 __C)
{
  return (__m512) __builtin_ia32_vfnmaddps512_mask ((__v16sf) __A,
          (__v16sf) __B,
          (__v16sf) __C,
          (__mmask16) -1,
          0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_fnmadd_ps (__m512 __A, __mmask16 __U, __m512 __B, __m512 __C)
{
  return (__m512) __builtin_ia32_vfnmaddps512_mask ((__v16sf) __A,
          (__v16sf) __B,
          (__v16sf) __C,
          (__mmask16) __U,
          0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask3_fnmadd_ps (__m512 __A, __m512 __B, __m512 __C, __mmask16 __U)
{
  return (__m512) __builtin_ia32_vfnmaddps512_mask3 ((__v16sf) __A,
           (__v16sf) __B,
           (__v16sf) __C,
           (__mmask16) __U,
           0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_fnmadd_ps (__mmask16 __U, __m512 __A, __m512 __B, __m512 __C)
{
  return (__m512) __builtin_ia32_vfnmaddps512_maskz ((__v16sf) __A,
           (__v16sf) __B,
           (__v16sf) __C,
           (__mmask16) __U,
           0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_fnmsub_pd (__m512d __A, __m512d __B, __m512d __C)
{
  return (__m512d) __builtin_ia32_vfnmsubpd512_mask ((__v8df) __A,
           (__v8df) __B,
           (__v8df) __C,
           (__mmask8) -1,
           0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_fnmsub_pd (__m512d __A, __mmask8 __U, __m512d __B, __m512d __C)
{
  return (__m512d) __builtin_ia32_vfnmsubpd512_mask ((__v8df) __A,
           (__v8df) __B,
           (__v8df) __C,
           (__mmask8) __U,
           0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask3_fnmsub_pd (__m512d __A, __m512d __B, __m512d __C, __mmask8 __U)
{
  return (__m512d) __builtin_ia32_vfnmsubpd512_mask3 ((__v8df) __A,
            (__v8df) __B,
            (__v8df) __C,
            (__mmask8) __U,
            0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_fnmsub_pd (__mmask8 __U, __m512d __A, __m512d __B, __m512d __C)
{
  return (__m512d) __builtin_ia32_vfnmsubpd512_maskz ((__v8df) __A,
            (__v8df) __B,
            (__v8df) __C,
            (__mmask8) __U,
            0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_fnmsub_ps (__m512 __A, __m512 __B, __m512 __C)
{
  return (__m512) __builtin_ia32_vfnmsubps512_mask ((__v16sf) __A,
          (__v16sf) __B,
          (__v16sf) __C,
          (__mmask16) -1,
          0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_fnmsub_ps (__m512 __A, __mmask16 __U, __m512 __B, __m512 __C)
{
  return (__m512) __builtin_ia32_vfnmsubps512_mask ((__v16sf) __A,
          (__v16sf) __B,
          (__v16sf) __C,
          (__mmask16) __U,
          0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask3_fnmsub_ps (__m512 __A, __m512 __B, __m512 __C, __mmask16 __U)
{
  return (__m512) __builtin_ia32_vfnmsubps512_mask3 ((__v16sf) __A,
           (__v16sf) __B,
           (__v16sf) __C,
           (__mmask16) __U,
           0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_fnmsub_ps (__mmask16 __U, __m512 __A, __m512 __B, __m512 __C)
{
  return (__m512) __builtin_ia32_vfnmsubps512_maskz ((__v16sf) __A,
           (__v16sf) __B,
           (__v16sf) __C,
           (__mmask16) __U,
           0x04);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvttpd_epi32 (__m512d __A)
{
  return (__m256i) __builtin_ia32_cvttpd2dq512_mask ((__v8df) __A,
           (__v8si)
           _mm256_undefined_si256 (),
           (__mmask8) -1,
           0x04);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvttpd_epi32 (__m256i __W, __mmask8 __U, __m512d __A)
{
  return (__m256i) __builtin_ia32_cvttpd2dq512_mask ((__v8df) __A,
           (__v8si) __W,
           (__mmask8) __U,
           0x04);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvttpd_epi32 (__mmask8 __U, __m512d __A)
{
  return (__m256i) __builtin_ia32_cvttpd2dq512_mask ((__v8df) __A,
           (__v8si)
           _mm256_setzero_si256 (),
           (__mmask8) __U,
           0x04);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvttpd_epu32 (__m512d __A)
{
  return (__m256i) __builtin_ia32_cvttpd2udq512_mask ((__v8df) __A,
            (__v8si)
            _mm256_undefined_si256 (),
            (__mmask8) -1,
            0x04);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvttpd_epu32 (__m256i __W, __mmask8 __U, __m512d __A)
{
  return (__m256i) __builtin_ia32_cvttpd2udq512_mask ((__v8df) __A,
            (__v8si) __W,
            (__mmask8) __U,
            0x04);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvttpd_epu32 (__mmask8 __U, __m512d __A)
{
  return (__m256i) __builtin_ia32_cvttpd2udq512_mask ((__v8df) __A,
            (__v8si)
            _mm256_setzero_si256 (),
            (__mmask8) __U,
            0x04);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtpd_epi32 (__m512d __A)
{
  return (__m256i) __builtin_ia32_cvtpd2dq512_mask ((__v8df) __A,
          (__v8si)
          _mm256_undefined_si256 (),
          (__mmask8) -1,
          0x04);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtpd_epi32 (__m256i __W, __mmask8 __U, __m512d __A)
{
  return (__m256i) __builtin_ia32_cvtpd2dq512_mask ((__v8df) __A,
          (__v8si) __W,
          (__mmask8) __U,
          0x04);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtpd_epi32 (__mmask8 __U, __m512d __A)
{
  return (__m256i) __builtin_ia32_cvtpd2dq512_mask ((__v8df) __A,
          (__v8si)
          _mm256_setzero_si256 (),
          (__mmask8) __U,
          0x04);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtpd_epu32 (__m512d __A)
{
  return (__m256i) __builtin_ia32_cvtpd2udq512_mask ((__v8df) __A,
           (__v8si)
           _mm256_undefined_si256 (),
           (__mmask8) -1,
           0x04);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtpd_epu32 (__m256i __W, __mmask8 __U, __m512d __A)
{
  return (__m256i) __builtin_ia32_cvtpd2udq512_mask ((__v8df) __A,
           (__v8si) __W,
           (__mmask8) __U,
           0x04);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtpd_epu32 (__mmask8 __U, __m512d __A)
{
  return (__m256i) __builtin_ia32_cvtpd2udq512_mask ((__v8df) __A,
           (__v8si)
           _mm256_setzero_si256 (),
           (__mmask8) __U,
           0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvttps_epi32 (__m512 __A)
{
  return (__m512i) __builtin_ia32_cvttps2dq512_mask ((__v16sf) __A,
           (__v16si)
           _mm512_undefined_epi32 (),
           (__mmask16) -1,
           0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvttps_epi32 (__m512i __W, __mmask16 __U, __m512 __A)
{
  return (__m512i) __builtin_ia32_cvttps2dq512_mask ((__v16sf) __A,
           (__v16si) __W,
           (__mmask16) __U,
           0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvttps_epi32 (__mmask16 __U, __m512 __A)
{
  return (__m512i) __builtin_ia32_cvttps2dq512_mask ((__v16sf) __A,
           (__v16si)
           _mm512_setzero_si512 (),
           (__mmask16) __U,
           0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvttps_epu32 (__m512 __A)
{
  return (__m512i) __builtin_ia32_cvttps2udq512_mask ((__v16sf) __A,
            (__v16si)
            _mm512_undefined_epi32 (),
            (__mmask16) -1,
            0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvttps_epu32 (__m512i __W, __mmask16 __U, __m512 __A)
{
  return (__m512i) __builtin_ia32_cvttps2udq512_mask ((__v16sf) __A,
            (__v16si) __W,
            (__mmask16) __U,
            0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvttps_epu32 (__mmask16 __U, __m512 __A)
{
  return (__m512i) __builtin_ia32_cvttps2udq512_mask ((__v16sf) __A,
            (__v16si)
            _mm512_setzero_si512 (),
            (__mmask16) __U,
            0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtps_epi32 (__m512 __A)
{
  return (__m512i) __builtin_ia32_cvtps2dq512_mask ((__v16sf) __A,
          (__v16si)
          _mm512_undefined_epi32 (),
          (__mmask16) -1,
          0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtps_epi32 (__m512i __W, __mmask16 __U, __m512 __A)
{
  return (__m512i) __builtin_ia32_cvtps2dq512_mask ((__v16sf) __A,
          (__v16si) __W,
          (__mmask16) __U,
          0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtps_epi32 (__mmask16 __U, __m512 __A)
{
  return (__m512i) __builtin_ia32_cvtps2dq512_mask ((__v16sf) __A,
          (__v16si)
          _mm512_setzero_si512 (),
          (__mmask16) __U,
          0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtps_epu32 (__m512 __A)
{
  return (__m512i) __builtin_ia32_cvtps2udq512_mask ((__v16sf) __A,
           (__v16si)
           _mm512_undefined_epi32 (),
           (__mmask16) -1,
           0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtps_epu32 (__m512i __W, __mmask16 __U, __m512 __A)
{
  return (__m512i) __builtin_ia32_cvtps2udq512_mask ((__v16sf) __A,
           (__v16si) __W,
           (__mmask16) __U,
           0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtps_epu32 (__mmask16 __U, __m512 __A)
{
  return (__m512i) __builtin_ia32_cvtps2udq512_mask ((__v16sf) __A,
           (__v16si)
           _mm512_setzero_si512 (),
           (__mmask16) __U,
           0x04);
}
extern __inline double
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtsd_f64 (__m512d __A)
{
  return __A[0];
}
extern __inline float
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtss_f32 (__m512 __A)
{
  return __A[0];
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtu64_ss (__m128 __A, unsigned long long __B)
{
  return (__m128) __builtin_ia32_cvtusi2ss64 ((__v4sf) __A, __B,
           0x04);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtu64_sd (__m128d __A, unsigned long long __B)
{
  return (__m128d) __builtin_ia32_cvtusi2sd64 ((__v2df) __A, __B,
            0x04);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtu32_ss (__m128 __A, unsigned __B)
{
  return (__m128) __builtin_ia32_cvtusi2ss32 ((__v4sf) __A, __B,
           0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepi32_ps (__m512i __A)
{
  return (__m512) __builtin_ia32_cvtdq2ps512_mask ((__v16si) __A,
         (__v16sf)
         _mm512_undefined_ps (),
         (__mmask16) -1,
         0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi32_ps (__m512 __W, __mmask16 __U, __m512i __A)
{
  return (__m512) __builtin_ia32_cvtdq2ps512_mask ((__v16si) __A,
         (__v16sf) __W,
         (__mmask16) __U,
         0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepi32_ps (__mmask16 __U, __m512i __A)
{
  return (__m512) __builtin_ia32_cvtdq2ps512_mask ((__v16si) __A,
         (__v16sf)
         _mm512_setzero_ps (),
         (__mmask16) __U,
         0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepu32_ps (__m512i __A)
{
  return (__m512) __builtin_ia32_cvtudq2ps512_mask ((__v16si) __A,
          (__v16sf)
          _mm512_undefined_ps (),
          (__mmask16) -1,
          0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepu32_ps (__m512 __W, __mmask16 __U, __m512i __A)
{
  return (__m512) __builtin_ia32_cvtudq2ps512_mask ((__v16si) __A,
          (__v16sf) __W,
          (__mmask16) __U,
          0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepu32_ps (__mmask16 __U, __m512i __A)
{
  return (__m512) __builtin_ia32_cvtudq2ps512_mask ((__v16si) __A,
          (__v16sf)
          _mm512_setzero_ps (),
          (__mmask16) __U,
          0x04);
}
extern __inline unsigned long long
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtss_u64 (__m128 __A)
{
  return (unsigned long long) __builtin_ia32_vcvtss2usi64 ((__v4sf)
          __A,
          0x04);
}
extern __inline unsigned long long
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttss_u64 (__m128 __A)
{
  return (unsigned long long) __builtin_ia32_vcvttss2usi64 ((__v4sf)
           __A,
           0x04);
}
extern __inline long long
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttss_i64 (__m128 __A)
{
  return (long long) __builtin_ia32_vcvttss2si64 ((__v4sf) __A,
        0x04);
}
extern __inline int
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtsi512_si32 (__m512i __A)
{
  __v16si __B = (__v16si) __A;
  return __B[0];
}
extern __inline unsigned
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtss_u32 (__m128 __A)
{
  return (unsigned) __builtin_ia32_vcvtss2usi32 ((__v4sf) __A,
       0x04);
}
extern __inline unsigned
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttss_u32 (__m128 __A)
{
  return (unsigned) __builtin_ia32_vcvttss2usi32 ((__v4sf) __A,
        0x04);
}
extern __inline int
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttss_i32 (__m128 __A)
{
  return (int) __builtin_ia32_vcvttss2si32 ((__v4sf) __A,
         0x04);
}
extern __inline int
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsd_i32 (__m128d __A)
{
  return (int) __builtin_ia32_cvtsd2si ((__v2df) __A);
}
extern __inline int
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtss_i32 (__m128 __A)
{
  return (int) __builtin_ia32_cvtss2si ((__v4sf) __A);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvti32_sd (__m128d __A, int __B)
{
  return (__m128d) __builtin_ia32_cvtsi2sd ((__v2df) __A, __B);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvti32_ss (__m128 __A, int __B)
{
  return (__m128) __builtin_ia32_cvtsi2ss ((__v4sf) __A, __B);
}
extern __inline unsigned long long
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsd_u64 (__m128d __A)
{
  return (unsigned long long) __builtin_ia32_vcvtsd2usi64 ((__v2df)
          __A,
          0x04);
}
extern __inline unsigned long long
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttsd_u64 (__m128d __A)
{
  return (unsigned long long) __builtin_ia32_vcvttsd2usi64 ((__v2df)
           __A,
           0x04);
}
extern __inline long long
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttsd_i64 (__m128d __A)
{
  return (long long) __builtin_ia32_vcvttsd2si64 ((__v2df) __A,
        0x04);
}
extern __inline long long
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsd_i64 (__m128d __A)
{
  return (long long) __builtin_ia32_cvtsd2si64 ((__v2df) __A);
}
extern __inline long long
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtss_i64 (__m128 __A)
{
  return (long long) __builtin_ia32_cvtss2si64 ((__v4sf) __A);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvti64_sd (__m128d __A, long long __B)
{
  return (__m128d) __builtin_ia32_cvtsi642sd ((__v2df) __A, __B);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvti64_ss (__m128 __A, long long __B)
{
  return (__m128) __builtin_ia32_cvtsi642ss ((__v4sf) __A, __B);
}
extern __inline unsigned
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsd_u32 (__m128d __A)
{
  return (unsigned) __builtin_ia32_vcvtsd2usi32 ((__v2df) __A,
       0x04);
}
extern __inline unsigned
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttsd_u32 (__m128d __A)
{
  return (unsigned) __builtin_ia32_vcvttsd2usi32 ((__v2df) __A,
        0x04);
}
extern __inline int
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttsd_i32 (__m128d __A)
{
  return (int) __builtin_ia32_vcvttsd2si32 ((__v2df) __A,
         0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtps_pd (__m256 __A)
{
  return (__m512d) __builtin_ia32_cvtps2pd512_mask ((__v8sf) __A,
          (__v8df)
          _mm512_undefined_pd (),
          (__mmask8) -1,
          0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtps_pd (__m512d __W, __mmask8 __U, __m256 __A)
{
  return (__m512d) __builtin_ia32_cvtps2pd512_mask ((__v8sf) __A,
          (__v8df) __W,
          (__mmask8) __U,
          0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtps_pd (__mmask8 __U, __m256 __A)
{
  return (__m512d) __builtin_ia32_cvtps2pd512_mask ((__v8sf) __A,
          (__v8df)
          _mm512_setzero_pd (),
          (__mmask8) __U,
          0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtph_ps (__m256i __A)
{
  return (__m512) __builtin_ia32_vcvtph2ps512_mask ((__v16hi) __A,
          (__v16sf)
          _mm512_undefined_ps (),
          (__mmask16) -1,
          0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtph_ps (__m512 __W, __mmask16 __U, __m256i __A)
{
  return (__m512) __builtin_ia32_vcvtph2ps512_mask ((__v16hi) __A,
          (__v16sf) __W,
          (__mmask16) __U,
          0x04);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtph_ps (__mmask16 __U, __m256i __A)
{
  return (__m512) __builtin_ia32_vcvtph2ps512_mask ((__v16hi) __A,
          (__v16sf)
          _mm512_setzero_ps (),
          (__mmask16) __U,
          0x04);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtpd_ps (__m512d __A)
{
  return (__m256) __builtin_ia32_cvtpd2ps512_mask ((__v8df) __A,
         (__v8sf)
         _mm256_undefined_ps (),
         (__mmask8) -1,
         0x04);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtpd_ps (__m256 __W, __mmask8 __U, __m512d __A)
{
  return (__m256) __builtin_ia32_cvtpd2ps512_mask ((__v8df) __A,
         (__v8sf) __W,
         (__mmask8) __U,
         0x04);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtpd_ps (__mmask8 __U, __m512d __A)
{
  return (__m256) __builtin_ia32_cvtpd2ps512_mask ((__v8df) __A,
         (__v8sf)
         _mm256_setzero_ps (),
         (__mmask8) __U,
         0x04);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpeq_pd_mask (__m512d __X, __m512d __Y)
{
  return (__mmask8) __builtin_ia32_cmppd512_mask ((__v8df) __X,
        (__v8df) __Y, 0x00,
        (__mmask8) -1,
        0x04);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpeq_pd_mask (__mmask8 __U, __m512d __X, __m512d __Y)
{
  return (__mmask8) __builtin_ia32_cmppd512_mask ((__v8df) __X,
        (__v8df) __Y, 0x00,
        (__mmask8) __U,
        0x04);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmplt_pd_mask (__m512d __X, __m512d __Y)
{
  return (__mmask8) __builtin_ia32_cmppd512_mask ((__v8df) __X,
        (__v8df) __Y, 0x01,
        (__mmask8) -1,
        0x04);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmplt_pd_mask (__mmask8 __U, __m512d __X, __m512d __Y)
{
  return (__mmask8) __builtin_ia32_cmppd512_mask ((__v8df) __X,
        (__v8df) __Y, 0x01,
        (__mmask8) __U,
        0x04);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmple_pd_mask (__m512d __X, __m512d __Y)
{
  return (__mmask8) __builtin_ia32_cmppd512_mask ((__v8df) __X,
        (__v8df) __Y, 0x02,
        (__mmask8) -1,
        0x04);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmple_pd_mask (__mmask8 __U, __m512d __X, __m512d __Y)
{
  return (__mmask8) __builtin_ia32_cmppd512_mask ((__v8df) __X,
        (__v8df) __Y, 0x02,
        (__mmask8) __U,
        0x04);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpunord_pd_mask (__m512d __X, __m512d __Y)
{
  return (__mmask8) __builtin_ia32_cmppd512_mask ((__v8df) __X,
        (__v8df) __Y, 0x03,
        (__mmask8) -1,
        0x04);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpunord_pd_mask (__mmask8 __U, __m512d __X, __m512d __Y)
{
  return (__mmask8) __builtin_ia32_cmppd512_mask ((__v8df) __X,
        (__v8df) __Y, 0x03,
        (__mmask8) __U,
        0x04);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpneq_pd_mask (__m512d __X, __m512d __Y)
{
  return (__mmask8) __builtin_ia32_cmppd512_mask ((__v8df) __X,
        (__v8df) __Y, 0x04,
        (__mmask8) -1,
        0x04);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpneq_pd_mask (__mmask8 __U, __m512d __X, __m512d __Y)
{
  return (__mmask8) __builtin_ia32_cmppd512_mask ((__v8df) __X,
        (__v8df) __Y, 0x04,
        (__mmask8) __U,
        0x04);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpnlt_pd_mask (__m512d __X, __m512d __Y)
{
  return (__mmask8) __builtin_ia32_cmppd512_mask ((__v8df) __X,
        (__v8df) __Y, 0x05,
        (__mmask8) -1,
        0x04);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpnlt_pd_mask (__mmask8 __U, __m512d __X, __m512d __Y)
{
  return (__mmask8) __builtin_ia32_cmppd512_mask ((__v8df) __X,
        (__v8df) __Y, 0x05,
        (__mmask8) __U,
        0x04);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpnle_pd_mask (__m512d __X, __m512d __Y)
{
  return (__mmask8) __builtin_ia32_cmppd512_mask ((__v8df) __X,
        (__v8df) __Y, 0x06,
        (__mmask8) -1,
        0x04);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpnle_pd_mask (__mmask8 __U, __m512d __X, __m512d __Y)
{
  return (__mmask8) __builtin_ia32_cmppd512_mask ((__v8df) __X,
        (__v8df) __Y, 0x06,
        (__mmask8) __U,
        0x04);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpord_pd_mask (__m512d __X, __m512d __Y)
{
  return (__mmask8) __builtin_ia32_cmppd512_mask ((__v8df) __X,
        (__v8df) __Y, 0x07,
        (__mmask8) -1,
        0x04);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpord_pd_mask (__mmask8 __U, __m512d __X, __m512d __Y)
{
  return (__mmask8) __builtin_ia32_cmppd512_mask ((__v8df) __X,
        (__v8df) __Y, 0x07,
        (__mmask8) __U,
        0x04);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpeq_ps_mask (__m512 __X, __m512 __Y)
{
  return (__mmask16) __builtin_ia32_cmpps512_mask ((__v16sf) __X,
         (__v16sf) __Y, 0x00,
         (__mmask16) -1,
         0x04);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpeq_ps_mask (__mmask16 __U, __m512 __X, __m512 __Y)
{
   return (__mmask16) __builtin_ia32_cmpps512_mask ((__v16sf) __X,
         (__v16sf) __Y, 0x00,
         (__mmask16) __U,
         0x04);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmplt_ps_mask (__m512 __X, __m512 __Y)
{
  return (__mmask16) __builtin_ia32_cmpps512_mask ((__v16sf) __X,
         (__v16sf) __Y, 0x01,
         (__mmask16) -1,
         0x04);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmplt_ps_mask (__mmask16 __U, __m512 __X, __m512 __Y)
{
   return (__mmask16) __builtin_ia32_cmpps512_mask ((__v16sf) __X,
         (__v16sf) __Y, 0x01,
         (__mmask16) __U,
         0x04);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmple_ps_mask (__m512 __X, __m512 __Y)
{
  return (__mmask16) __builtin_ia32_cmpps512_mask ((__v16sf) __X,
         (__v16sf) __Y, 0x02,
         (__mmask16) -1,
         0x04);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmple_ps_mask (__mmask16 __U, __m512 __X, __m512 __Y)
{
   return (__mmask16) __builtin_ia32_cmpps512_mask ((__v16sf) __X,
         (__v16sf) __Y, 0x02,
         (__mmask16) __U,
         0x04);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpunord_ps_mask (__m512 __X, __m512 __Y)
{
  return (__mmask16) __builtin_ia32_cmpps512_mask ((__v16sf) __X,
         (__v16sf) __Y, 0x03,
         (__mmask16) -1,
         0x04);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpunord_ps_mask (__mmask16 __U, __m512 __X, __m512 __Y)
{
   return (__mmask16) __builtin_ia32_cmpps512_mask ((__v16sf) __X,
         (__v16sf) __Y, 0x03,
         (__mmask16) __U,
         0x04);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpneq_ps_mask (__m512 __X, __m512 __Y)
{
  return (__mmask16) __builtin_ia32_cmpps512_mask ((__v16sf) __X,
         (__v16sf) __Y, 0x04,
         (__mmask16) -1,
         0x04);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpneq_ps_mask (__mmask16 __U, __m512 __X, __m512 __Y)
{
   return (__mmask16) __builtin_ia32_cmpps512_mask ((__v16sf) __X,
         (__v16sf) __Y, 0x04,
         (__mmask16) __U,
         0x04);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpnlt_ps_mask (__m512 __X, __m512 __Y)
{
  return (__mmask16) __builtin_ia32_cmpps512_mask ((__v16sf) __X,
         (__v16sf) __Y, 0x05,
         (__mmask16) -1,
         0x04);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpnlt_ps_mask (__mmask16 __U, __m512 __X, __m512 __Y)
{
   return (__mmask16) __builtin_ia32_cmpps512_mask ((__v16sf) __X,
         (__v16sf) __Y, 0x05,
         (__mmask16) __U,
         0x04);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpnle_ps_mask (__m512 __X, __m512 __Y)
{
  return (__mmask16) __builtin_ia32_cmpps512_mask ((__v16sf) __X,
         (__v16sf) __Y, 0x06,
         (__mmask16) -1,
         0x04);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpnle_ps_mask (__mmask16 __U, __m512 __X, __m512 __Y)
{
   return (__mmask16) __builtin_ia32_cmpps512_mask ((__v16sf) __X,
         (__v16sf) __Y, 0x06,
         (__mmask16) __U,
         0x04);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpord_ps_mask (__m512 __X, __m512 __Y)
{
  return (__mmask16) __builtin_ia32_cmpps512_mask ((__v16sf) __X,
         (__v16sf) __Y, 0x07,
         (__mmask16) -1,
         0x04);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpord_ps_mask (__mmask16 __U, __m512 __X, __m512 __Y)
{
   return (__mmask16) __builtin_ia32_cmpps512_mask ((__v16sf) __X,
         (__v16sf) __Y, 0x07,
         (__mmask16) __U,
         0x04);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_kmov (__mmask16 __A)
{
  return __builtin_ia32_kmovw (__A);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_castpd_ps (__m512d __A)
{
  return (__m512) (__A);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_castpd_si512 (__m512d __A)
{
  return (__m512i) (__A);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_castps_pd (__m512 __A)
{
  return (__m512d) (__A);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_castps_si512 (__m512 __A)
{
  return (__m512i) (__A);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_castsi512_ps (__m512i __A)
{
  return (__m512) (__A);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_castsi512_pd (__m512i __A)
{
  return (__m512d) (__A);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_castpd512_pd128 (__m512d __A)
{
  return (__m128d)((__m128) __builtin_ia32_extractf32x4_mask ((__v16sf)(__m512) ((__m512)__A), (int) (0), (__v4sf)(__m128)_mm_undefined_ps(), (__mmask8)-1));
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_castps512_ps128 (__m512 __A)
{
  return ((__m128) __builtin_ia32_extractf32x4_mask ((__v16sf)(__m512) (__A), (int) (0), (__v4sf)(__m128)_mm_undefined_ps(), (__mmask8)-1));
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_castsi512_si128 (__m512i __A)
{
  return (__m128i)((__m128i) __builtin_ia32_extracti32x4_mask ((__v16si)(__m512i) ((__m512i)__A), (int) (0), (__v4si)(__m128i)_mm_undefined_si128 (), (__mmask8)-1));
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_castpd512_pd256 (__m512d __A)
{
  return ((__m256d) __builtin_ia32_extractf64x4_mask ((__v8df)(__m512d) (__A), (int) (0), (__v4df)(__m256d)_mm256_undefined_pd(), (__mmask8)-1));
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_castps512_ps256 (__m512 __A)
{
  return (__m256)((__m256d) __builtin_ia32_extractf64x4_mask ((__v8df)(__m512d) ((__m512d)__A), (int) (0), (__v4df)(__m256d)_mm256_undefined_pd(), (__mmask8)-1));
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_castsi512_si256 (__m512i __A)
{
  return (__m256i)((__m256d) __builtin_ia32_extractf64x4_mask ((__v8df)(__m512d) ((__m512d)__A), (int) (0), (__v4df)(__m256d)_mm256_undefined_pd(), (__mmask8)-1));
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_castpd128_pd512 (__m128d __A)
{
  return (__m512d) __builtin_ia32_pd512_pd((__m128d)__A);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_castps128_ps512 (__m128 __A)
{
  return (__m512) __builtin_ia32_ps512_ps((__m128)__A);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_castsi128_si512 (__m128i __A)
{
  return (__m512i) __builtin_ia32_si512_si((__v4si)__A);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_castpd256_pd512 (__m256d __A)
{
  return __builtin_ia32_pd512_256pd (__A);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_castps256_ps512 (__m256 __A)
{
  return __builtin_ia32_ps512_256ps (__A);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_castsi256_si512 (__m256i __A)
{
  return (__m512i)__builtin_ia32_si512_256si ((__v8si)__A);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_zextpd128_pd512 (__m128d __A)
{
  return (__m512d) ((__m512) __builtin_ia32_insertf32x4_mask ((__v16sf)(__m512) (_mm512_setzero_ps ()), (__v4sf)(__m128) ((__m128) __A), (int) (0), (__v16sf)(__m512) (_mm512_setzero_ps ()), (__mmask16)(-1)));
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_zextps128_ps512 (__m128 __A)
{
  return ((__m512) __builtin_ia32_insertf32x4_mask ((__v16sf)(__m512) (_mm512_setzero_ps ()), (__v4sf)(__m128) (__A), (int) (0), (__v16sf)(__m512) (_mm512_setzero_ps ()), (__mmask16)(-1)));
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_zextsi128_si512 (__m128i __A)
{
  return ((__m512i) __builtin_ia32_inserti32x4_mask ((__v16si)(__m512i) (_mm512_setzero_si512 ()), (__v4si)(__m128i) (__A), (int) (0), (__v16si)(__m512i) (_mm512_setzero_si512 ()), (__mmask16)(-1)));
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_zextpd256_pd512 (__m256d __A)
{
  return ((__m512d) __builtin_ia32_insertf64x4_mask ((__v8df)(__m512d) (_mm512_setzero_pd ()), (__v4df)(__m256d) (__A), (int) (0), (__v8df)(__m512d)_mm512_undefined_pd(), (__mmask8)-1));
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_zextps256_ps512 (__m256 __A)
{
  return (__m512) ((__m512d) __builtin_ia32_insertf64x4_mask ((__v8df)(__m512d) (_mm512_setzero_pd ()), (__v4df)(__m256d) ((__m256d) __A), (int) (0), (__v8df)(__m512d)_mm512_undefined_pd(), (__mmask8)-1));
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_zextsi256_si512 (__m256i __A)
{
  return ((__m512i) __builtin_ia32_inserti64x4_mask ((__v8di)(__m512i) (_mm512_setzero_si512 ()), (__v4di)(__m256i) (__A), (int) (0), (__v8di)(__m512i)_mm512_undefined_epi32 (), (__mmask8)-1));
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpeq_epu32_mask (__m512i __A, __m512i __B)
{
  return (__mmask16) __builtin_ia32_ucmpd512_mask ((__v16si) __A,
           (__v16si) __B, 0,
           (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpeq_epu32_mask (__mmask16 __U, __m512i __A, __m512i __B)
{
  return (__mmask16) __builtin_ia32_ucmpd512_mask ((__v16si) __A,
           (__v16si) __B, 0, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpeq_epu64_mask (__mmask8 __U, __m512i __A, __m512i __B)
{
  return (__mmask8) __builtin_ia32_ucmpq512_mask ((__v8di) __A,
          (__v8di) __B, 0, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpeq_epu64_mask (__m512i __A, __m512i __B)
{
  return (__mmask8) __builtin_ia32_ucmpq512_mask ((__v8di) __A,
          (__v8di) __B, 0,
          (__mmask8) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpgt_epu32_mask (__m512i __A, __m512i __B)
{
  return (__mmask16) __builtin_ia32_ucmpd512_mask ((__v16si) __A,
           (__v16si) __B, 6,
           (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpgt_epu32_mask (__mmask16 __U, __m512i __A, __m512i __B)
{
  return (__mmask16) __builtin_ia32_ucmpd512_mask ((__v16si) __A,
           (__v16si) __B, 6, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpgt_epu64_mask (__mmask8 __U, __m512i __A, __m512i __B)
{
  return (__mmask8) __builtin_ia32_ucmpq512_mask ((__v8di) __A,
          (__v8di) __B, 6, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpgt_epu64_mask (__m512i __A, __m512i __B)
{
  return (__mmask8) __builtin_ia32_ucmpq512_mask ((__v8di) __A,
          (__v8di) __B, 6,
          (__mmask8) -1);
}
extern __inline int
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_reduce_add_epi32 (__m512i __A)
{
  __v8si __T1 = (__v8si) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (1), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __v8si __T2 = (__v8si) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (0), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __m256i __T3 = (__m256i) (__T1 + __T2); __v4si __T4 = (__v4si) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(1))); __v4si __T5 = (__v4si) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(0))); __v4si __T6 = __T4 + __T5; __v4si __T7 = __builtin_shuffle (__T6, (__v4si) { 2, 3, 0, 1 }); __v4si __T8 = __T6 + __T7; return __T8[0] + __T8[1];
}
extern __inline int
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_reduce_mul_epi32 (__m512i __A)
{
  __v8si __T1 = (__v8si) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (1), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __v8si __T2 = (__v8si) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (0), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __m256i __T3 = (__m256i) (__T1 * __T2); __v4si __T4 = (__v4si) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(1))); __v4si __T5 = (__v4si) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(0))); __v4si __T6 = __T4 * __T5; __v4si __T7 = __builtin_shuffle (__T6, (__v4si) { 2, 3, 0, 1 }); __v4si __T8 = __T6 * __T7; return __T8[0] * __T8[1];
}
extern __inline int
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_reduce_and_epi32 (__m512i __A)
{
  __v8si __T1 = (__v8si) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (1), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __v8si __T2 = (__v8si) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (0), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __m256i __T3 = (__m256i) (__T1 & __T2); __v4si __T4 = (__v4si) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(1))); __v4si __T5 = (__v4si) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(0))); __v4si __T6 = __T4 & __T5; __v4si __T7 = __builtin_shuffle (__T6, (__v4si) { 2, 3, 0, 1 }); __v4si __T8 = __T6 & __T7; return __T8[0] & __T8[1];
}
extern __inline int
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_reduce_or_epi32 (__m512i __A)
{
  __v8si __T1 = (__v8si) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (1), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __v8si __T2 = (__v8si) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (0), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __m256i __T3 = (__m256i) (__T1 | __T2); __v4si __T4 = (__v4si) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(1))); __v4si __T5 = (__v4si) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(0))); __v4si __T6 = __T4 | __T5; __v4si __T7 = __builtin_shuffle (__T6, (__v4si) { 2, 3, 0, 1 }); __v4si __T8 = __T6 | __T7; return __T8[0] | __T8[1];
}
extern __inline int
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_reduce_add_epi32 (__mmask16 __U, __m512i __A)
{
  __A = _mm512_maskz_mov_epi32 (__U, __A);
  __v8si __T1 = (__v8si) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (1), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __v8si __T2 = (__v8si) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (0), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __m256i __T3 = (__m256i) (__T1 + __T2); __v4si __T4 = (__v4si) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(1))); __v4si __T5 = (__v4si) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(0))); __v4si __T6 = __T4 + __T5; __v4si __T7 = __builtin_shuffle (__T6, (__v4si) { 2, 3, 0, 1 }); __v4si __T8 = __T6 + __T7; return __T8[0] + __T8[1];
}
extern __inline int
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_reduce_mul_epi32 (__mmask16 __U, __m512i __A)
{
  __A = _mm512_mask_mov_epi32 (_mm512_set1_epi32 (1), __U, __A);
  __v8si __T1 = (__v8si) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (1), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __v8si __T2 = (__v8si) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (0), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __m256i __T3 = (__m256i) (__T1 * __T2); __v4si __T4 = (__v4si) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(1))); __v4si __T5 = (__v4si) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(0))); __v4si __T6 = __T4 * __T5; __v4si __T7 = __builtin_shuffle (__T6, (__v4si) { 2, 3, 0, 1 }); __v4si __T8 = __T6 * __T7; return __T8[0] * __T8[1];
}
extern __inline int
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_reduce_and_epi32 (__mmask16 __U, __m512i __A)
{
  __A = _mm512_mask_mov_epi32 (_mm512_set1_epi32 (~0), __U, __A);
  __v8si __T1 = (__v8si) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (1), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __v8si __T2 = (__v8si) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (0), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __m256i __T3 = (__m256i) (__T1 & __T2); __v4si __T4 = (__v4si) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(1))); __v4si __T5 = (__v4si) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(0))); __v4si __T6 = __T4 & __T5; __v4si __T7 = __builtin_shuffle (__T6, (__v4si) { 2, 3, 0, 1 }); __v4si __T8 = __T6 & __T7; return __T8[0] & __T8[1];
}
extern __inline int
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_reduce_or_epi32 (__mmask16 __U, __m512i __A)
{
  __A = _mm512_maskz_mov_epi32 (__U, __A);
  __v8si __T1 = (__v8si) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (1), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __v8si __T2 = (__v8si) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (0), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __m256i __T3 = (__m256i) (__T1 | __T2); __v4si __T4 = (__v4si) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(1))); __v4si __T5 = (__v4si) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(0))); __v4si __T6 = __T4 | __T5; __v4si __T7 = __builtin_shuffle (__T6, (__v4si) { 2, 3, 0, 1 }); __v4si __T8 = __T6 | __T7; return __T8[0] | __T8[1];
}
extern __inline int
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_reduce_min_epi32 (__m512i __A)
{
  __m256i __T1 = (__m256i) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (1), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __m256i __T2 = (__m256i) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (0), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __m256i __T3 = _mm256_min_epi32 (__T1, __T2); __m128i __T4 = (__m128i) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(1))); __m128i __T5 = (__m128i) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(0))); __m128i __T6 = _mm_min_epi32 (__T4, __T5); __m128i __T7 = (__m128i) __builtin_shuffle ((__v4si) __T6, (__v4si) { 2, 3, 0, 1 }); __m128i __T8 = _mm_min_epi32 (__T6, __T7); __m128i __T9 = (__m128i) __builtin_shuffle ((__v4si) __T8, (__v4si) { 1, 0, 1, 0 }); __v4si __T10 = (__v4si) _mm_min_epi32 (__T8, __T9); return __T10[0];
}
extern __inline int
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_reduce_max_epi32 (__m512i __A)
{
  __m256i __T1 = (__m256i) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (1), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __m256i __T2 = (__m256i) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (0), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __m256i __T3 = _mm256_max_epi32 (__T1, __T2); __m128i __T4 = (__m128i) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(1))); __m128i __T5 = (__m128i) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(0))); __m128i __T6 = _mm_max_epi32 (__T4, __T5); __m128i __T7 = (__m128i) __builtin_shuffle ((__v4si) __T6, (__v4si) { 2, 3, 0, 1 }); __m128i __T8 = _mm_max_epi32 (__T6, __T7); __m128i __T9 = (__m128i) __builtin_shuffle ((__v4si) __T8, (__v4si) { 1, 0, 1, 0 }); __v4si __T10 = (__v4si) _mm_max_epi32 (__T8, __T9); return __T10[0];
}
extern __inline unsigned int
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_reduce_min_epu32 (__m512i __A)
{
  __m256i __T1 = (__m256i) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (1), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __m256i __T2 = (__m256i) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (0), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __m256i __T3 = _mm256_min_epu32 (__T1, __T2); __m128i __T4 = (__m128i) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(1))); __m128i __T5 = (__m128i) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(0))); __m128i __T6 = _mm_min_epu32 (__T4, __T5); __m128i __T7 = (__m128i) __builtin_shuffle ((__v4si) __T6, (__v4si) { 2, 3, 0, 1 }); __m128i __T8 = _mm_min_epu32 (__T6, __T7); __m128i __T9 = (__m128i) __builtin_shuffle ((__v4si) __T8, (__v4si) { 1, 0, 1, 0 }); __v4si __T10 = (__v4si) _mm_min_epu32 (__T8, __T9); return __T10[0];
}
extern __inline unsigned int
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_reduce_max_epu32 (__m512i __A)
{
  __m256i __T1 = (__m256i) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (1), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __m256i __T2 = (__m256i) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (0), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __m256i __T3 = _mm256_max_epu32 (__T1, __T2); __m128i __T4 = (__m128i) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(1))); __m128i __T5 = (__m128i) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(0))); __m128i __T6 = _mm_max_epu32 (__T4, __T5); __m128i __T7 = (__m128i) __builtin_shuffle ((__v4si) __T6, (__v4si) { 2, 3, 0, 1 }); __m128i __T8 = _mm_max_epu32 (__T6, __T7); __m128i __T9 = (__m128i) __builtin_shuffle ((__v4si) __T8, (__v4si) { 1, 0, 1, 0 }); __v4si __T10 = (__v4si) _mm_max_epu32 (__T8, __T9); return __T10[0];
}
extern __inline int
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_reduce_min_epi32 (__mmask16 __U, __m512i __A)
{
  __A = _mm512_mask_mov_epi32 (_mm512_set1_epi32 (0x7fffffff), __U, __A);
  __m256i __T1 = (__m256i) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (1), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __m256i __T2 = (__m256i) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (0), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __m256i __T3 = _mm256_min_epi32 (__T1, __T2); __m128i __T4 = (__m128i) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(1))); __m128i __T5 = (__m128i) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(0))); __m128i __T6 = _mm_min_epi32 (__T4, __T5); __m128i __T7 = (__m128i) __builtin_shuffle ((__v4si) __T6, (__v4si) { 2, 3, 0, 1 }); __m128i __T8 = _mm_min_epi32 (__T6, __T7); __m128i __T9 = (__m128i) __builtin_shuffle ((__v4si) __T8, (__v4si) { 1, 0, 1, 0 }); __v4si __T10 = (__v4si) _mm_min_epi32 (__T8, __T9); return __T10[0];
}
extern __inline int
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_reduce_max_epi32 (__mmask16 __U, __m512i __A)
{
  __A = _mm512_mask_mov_epi32 (_mm512_set1_epi32 (-0x7fffffff - 1), __U, __A);
  __m256i __T1 = (__m256i) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (1), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __m256i __T2 = (__m256i) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (0), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __m256i __T3 = _mm256_max_epi32 (__T1, __T2); __m128i __T4 = (__m128i) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(1))); __m128i __T5 = (__m128i) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(0))); __m128i __T6 = _mm_max_epi32 (__T4, __T5); __m128i __T7 = (__m128i) __builtin_shuffle ((__v4si) __T6, (__v4si) { 2, 3, 0, 1 }); __m128i __T8 = _mm_max_epi32 (__T6, __T7); __m128i __T9 = (__m128i) __builtin_shuffle ((__v4si) __T8, (__v4si) { 1, 0, 1, 0 }); __v4si __T10 = (__v4si) _mm_max_epi32 (__T8, __T9); return __T10[0];
}
extern __inline unsigned int
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_reduce_min_epu32 (__mmask16 __U, __m512i __A)
{
  __A = _mm512_mask_mov_epi32 (_mm512_set1_epi32 (~0), __U, __A);
  __m256i __T1 = (__m256i) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (1), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __m256i __T2 = (__m256i) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (0), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __m256i __T3 = _mm256_min_epu32 (__T1, __T2); __m128i __T4 = (__m128i) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(1))); __m128i __T5 = (__m128i) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(0))); __m128i __T6 = _mm_min_epu32 (__T4, __T5); __m128i __T7 = (__m128i) __builtin_shuffle ((__v4si) __T6, (__v4si) { 2, 3, 0, 1 }); __m128i __T8 = _mm_min_epu32 (__T6, __T7); __m128i __T9 = (__m128i) __builtin_shuffle ((__v4si) __T8, (__v4si) { 1, 0, 1, 0 }); __v4si __T10 = (__v4si) _mm_min_epu32 (__T8, __T9); return __T10[0];
}
extern __inline unsigned int
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_reduce_max_epu32 (__mmask16 __U, __m512i __A)
{
  __A = _mm512_maskz_mov_epi32 (__U, __A);
  __m256i __T1 = (__m256i) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (1), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __m256i __T2 = (__m256i) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (0), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __m256i __T3 = _mm256_max_epu32 (__T1, __T2); __m128i __T4 = (__m128i) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(1))); __m128i __T5 = (__m128i) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(0))); __m128i __T6 = _mm_max_epu32 (__T4, __T5); __m128i __T7 = (__m128i) __builtin_shuffle ((__v4si) __T6, (__v4si) { 2, 3, 0, 1 }); __m128i __T8 = _mm_max_epu32 (__T6, __T7); __m128i __T9 = (__m128i) __builtin_shuffle ((__v4si) __T8, (__v4si) { 1, 0, 1, 0 }); __v4si __T10 = (__v4si) _mm_max_epu32 (__T8, __T9); return __T10[0];
}
extern __inline float
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_reduce_add_ps (__m512 __A)
{
  __m256 __T1 = (__m256) ((__m256d) __builtin_ia32_extractf64x4_mask ((__v8df)(__m512d) ((__m512d) __A), (int) (1), (__v4df)(__m256d)_mm256_undefined_pd(), (__mmask8)-1)); __m256 __T2 = (__m256) ((__m256d) __builtin_ia32_extractf64x4_mask ((__v8df)(__m512d) ((__m512d) __A), (int) (0), (__v4df)(__m256d)_mm256_undefined_pd(), (__mmask8)-1)); __m256 __T3 = __T1 + __T2; __m128 __T4 = ((__m128) __builtin_ia32_vextractf128_ps256 ((__v8sf)(__m256)(__T3), (int)(1))); __m128 __T5 = ((__m128) __builtin_ia32_vextractf128_ps256 ((__v8sf)(__m256)(__T3), (int)(0))); __m128 __T6 = __T4 + __T5; __m128 __T7 = __builtin_shuffle (__T6, (__v4si) { 2, 3, 0, 1 }); __m128 __T8 = __T6 + __T7; return __T8[0] + __T8[1];
}
extern __inline float
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_reduce_mul_ps (__m512 __A)
{
  __m256 __T1 = (__m256) ((__m256d) __builtin_ia32_extractf64x4_mask ((__v8df)(__m512d) ((__m512d) __A), (int) (1), (__v4df)(__m256d)_mm256_undefined_pd(), (__mmask8)-1)); __m256 __T2 = (__m256) ((__m256d) __builtin_ia32_extractf64x4_mask ((__v8df)(__m512d) ((__m512d) __A), (int) (0), (__v4df)(__m256d)_mm256_undefined_pd(), (__mmask8)-1)); __m256 __T3 = __T1 * __T2; __m128 __T4 = ((__m128) __builtin_ia32_vextractf128_ps256 ((__v8sf)(__m256)(__T3), (int)(1))); __m128 __T5 = ((__m128) __builtin_ia32_vextractf128_ps256 ((__v8sf)(__m256)(__T3), (int)(0))); __m128 __T6 = __T4 * __T5; __m128 __T7 = __builtin_shuffle (__T6, (__v4si) { 2, 3, 0, 1 }); __m128 __T8 = __T6 * __T7; return __T8[0] * __T8[1];
}
extern __inline float
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_reduce_add_ps (__mmask16 __U, __m512 __A)
{
  __A = _mm512_maskz_mov_ps (__U, __A);
  __m256 __T1 = (__m256) ((__m256d) __builtin_ia32_extractf64x4_mask ((__v8df)(__m512d) ((__m512d) __A), (int) (1), (__v4df)(__m256d)_mm256_undefined_pd(), (__mmask8)-1)); __m256 __T2 = (__m256) ((__m256d) __builtin_ia32_extractf64x4_mask ((__v8df)(__m512d) ((__m512d) __A), (int) (0), (__v4df)(__m256d)_mm256_undefined_pd(), (__mmask8)-1)); __m256 __T3 = __T1 + __T2; __m128 __T4 = ((__m128) __builtin_ia32_vextractf128_ps256 ((__v8sf)(__m256)(__T3), (int)(1))); __m128 __T5 = ((__m128) __builtin_ia32_vextractf128_ps256 ((__v8sf)(__m256)(__T3), (int)(0))); __m128 __T6 = __T4 + __T5; __m128 __T7 = __builtin_shuffle (__T6, (__v4si) { 2, 3, 0, 1 }); __m128 __T8 = __T6 + __T7; return __T8[0] + __T8[1];
}
extern __inline float
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_reduce_mul_ps (__mmask16 __U, __m512 __A)
{
  __A = _mm512_mask_mov_ps (_mm512_set1_ps (1.0f), __U, __A);
  __m256 __T1 = (__m256) ((__m256d) __builtin_ia32_extractf64x4_mask ((__v8df)(__m512d) ((__m512d) __A), (int) (1), (__v4df)(__m256d)_mm256_undefined_pd(), (__mmask8)-1)); __m256 __T2 = (__m256) ((__m256d) __builtin_ia32_extractf64x4_mask ((__v8df)(__m512d) ((__m512d) __A), (int) (0), (__v4df)(__m256d)_mm256_undefined_pd(), (__mmask8)-1)); __m256 __T3 = __T1 * __T2; __m128 __T4 = ((__m128) __builtin_ia32_vextractf128_ps256 ((__v8sf)(__m256)(__T3), (int)(1))); __m128 __T5 = ((__m128) __builtin_ia32_vextractf128_ps256 ((__v8sf)(__m256)(__T3), (int)(0))); __m128 __T6 = __T4 * __T5; __m128 __T7 = __builtin_shuffle (__T6, (__v4si) { 2, 3, 0, 1 }); __m128 __T8 = __T6 * __T7; return __T8[0] * __T8[1];
}
extern __inline float
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_reduce_min_ps (__m512 __A)
{
  __m256 __T1 = (__m256) ((__m256d) __builtin_ia32_extractf64x4_mask ((__v8df)(__m512d) ((__m512d) __A), (int) (1), (__v4df)(__m256d)_mm256_undefined_pd(), (__mmask8)-1)); __m256 __T2 = (__m256) ((__m256d) __builtin_ia32_extractf64x4_mask ((__v8df)(__m512d) ((__m512d) __A), (int) (0), (__v4df)(__m256d)_mm256_undefined_pd(), (__mmask8)-1)); __m256 __T3 = _mm256_min_ps (__T1, __T2); __m128 __T4 = ((__m128) __builtin_ia32_vextractf128_ps256 ((__v8sf)(__m256)(__T3), (int)(1))); __m128 __T5 = ((__m128) __builtin_ia32_vextractf128_ps256 ((__v8sf)(__m256)(__T3), (int)(0))); __m128 __T6 = _mm_min_ps (__T4, __T5); __m128 __T7 = __builtin_shuffle (__T6, (__v4si) { 2, 3, 0, 1 }); __m128 __T8 = _mm_min_ps (__T6, __T7); __m128 __T9 = __builtin_shuffle (__T8, (__v4si) { 1, 0, 1, 0 }); __m128 __T10 = _mm_min_ps (__T8, __T9); return __T10[0];
}
extern __inline float
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_reduce_max_ps (__m512 __A)
{
  __m256 __T1 = (__m256) ((__m256d) __builtin_ia32_extractf64x4_mask ((__v8df)(__m512d) ((__m512d) __A), (int) (1), (__v4df)(__m256d)_mm256_undefined_pd(), (__mmask8)-1)); __m256 __T2 = (__m256) ((__m256d) __builtin_ia32_extractf64x4_mask ((__v8df)(__m512d) ((__m512d) __A), (int) (0), (__v4df)(__m256d)_mm256_undefined_pd(), (__mmask8)-1)); __m256 __T3 = _mm256_max_ps (__T1, __T2); __m128 __T4 = ((__m128) __builtin_ia32_vextractf128_ps256 ((__v8sf)(__m256)(__T3), (int)(1))); __m128 __T5 = ((__m128) __builtin_ia32_vextractf128_ps256 ((__v8sf)(__m256)(__T3), (int)(0))); __m128 __T6 = _mm_max_ps (__T4, __T5); __m128 __T7 = __builtin_shuffle (__T6, (__v4si) { 2, 3, 0, 1 }); __m128 __T8 = _mm_max_ps (__T6, __T7); __m128 __T9 = __builtin_shuffle (__T8, (__v4si) { 1, 0, 1, 0 }); __m128 __T10 = _mm_max_ps (__T8, __T9); return __T10[0];
}
extern __inline float
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_reduce_min_ps (__mmask16 __U, __m512 __A)
{
  __A = _mm512_mask_mov_ps (_mm512_set1_ps (__builtin_inff ()), __U, __A);
  __m256 __T1 = (__m256) ((__m256d) __builtin_ia32_extractf64x4_mask ((__v8df)(__m512d) ((__m512d) __A), (int) (1), (__v4df)(__m256d)_mm256_undefined_pd(), (__mmask8)-1)); __m256 __T2 = (__m256) ((__m256d) __builtin_ia32_extractf64x4_mask ((__v8df)(__m512d) ((__m512d) __A), (int) (0), (__v4df)(__m256d)_mm256_undefined_pd(), (__mmask8)-1)); __m256 __T3 = _mm256_min_ps (__T1, __T2); __m128 __T4 = ((__m128) __builtin_ia32_vextractf128_ps256 ((__v8sf)(__m256)(__T3), (int)(1))); __m128 __T5 = ((__m128) __builtin_ia32_vextractf128_ps256 ((__v8sf)(__m256)(__T3), (int)(0))); __m128 __T6 = _mm_min_ps (__T4, __T5); __m128 __T7 = __builtin_shuffle (__T6, (__v4si) { 2, 3, 0, 1 }); __m128 __T8 = _mm_min_ps (__T6, __T7); __m128 __T9 = __builtin_shuffle (__T8, (__v4si) { 1, 0, 1, 0 }); __m128 __T10 = _mm_min_ps (__T8, __T9); return __T10[0];
}
extern __inline float
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_reduce_max_ps (__mmask16 __U, __m512 __A)
{
  __A = _mm512_mask_mov_ps (_mm512_set1_ps (-__builtin_inff ()), __U, __A);
  __m256 __T1 = (__m256) ((__m256d) __builtin_ia32_extractf64x4_mask ((__v8df)(__m512d) ((__m512d) __A), (int) (1), (__v4df)(__m256d)_mm256_undefined_pd(), (__mmask8)-1)); __m256 __T2 = (__m256) ((__m256d) __builtin_ia32_extractf64x4_mask ((__v8df)(__m512d) ((__m512d) __A), (int) (0), (__v4df)(__m256d)_mm256_undefined_pd(), (__mmask8)-1)); __m256 __T3 = _mm256_max_ps (__T1, __T2); __m128 __T4 = ((__m128) __builtin_ia32_vextractf128_ps256 ((__v8sf)(__m256)(__T3), (int)(1))); __m128 __T5 = ((__m128) __builtin_ia32_vextractf128_ps256 ((__v8sf)(__m256)(__T3), (int)(0))); __m128 __T6 = _mm_max_ps (__T4, __T5); __m128 __T7 = __builtin_shuffle (__T6, (__v4si) { 2, 3, 0, 1 }); __m128 __T8 = _mm_max_ps (__T6, __T7); __m128 __T9 = __builtin_shuffle (__T8, (__v4si) { 1, 0, 1, 0 }); __m128 __T10 = _mm_max_ps (__T8, __T9); return __T10[0];
}
extern __inline long long
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_reduce_add_epi64 (__m512i __A)
{
  __v4di __T1 = (__v4di) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (1), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __v4di __T2 = (__v4di) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (0), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __m256i __T3 = (__m256i) (__T1 + __T2); __v2di __T4 = (__v2di) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(1))); __v2di __T5 = (__v2di) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(0))); __v2di __T6 = __T4 + __T5; return __T6[0] + __T6[1];
}
extern __inline long long
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_reduce_mul_epi64 (__m512i __A)
{
  __v4di __T1 = (__v4di) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (1), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __v4di __T2 = (__v4di) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (0), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __m256i __T3 = (__m256i) (__T1 * __T2); __v2di __T4 = (__v2di) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(1))); __v2di __T5 = (__v2di) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(0))); __v2di __T6 = __T4 * __T5; return __T6[0] * __T6[1];
}
extern __inline long long
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_reduce_and_epi64 (__m512i __A)
{
  __v4di __T1 = (__v4di) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (1), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __v4di __T2 = (__v4di) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (0), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __m256i __T3 = (__m256i) (__T1 & __T2); __v2di __T4 = (__v2di) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(1))); __v2di __T5 = (__v2di) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(0))); __v2di __T6 = __T4 & __T5; return __T6[0] & __T6[1];
}
extern __inline long long
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_reduce_or_epi64 (__m512i __A)
{
  __v4di __T1 = (__v4di) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (1), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __v4di __T2 = (__v4di) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (0), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __m256i __T3 = (__m256i) (__T1 | __T2); __v2di __T4 = (__v2di) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(1))); __v2di __T5 = (__v2di) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(0))); __v2di __T6 = __T4 | __T5; return __T6[0] | __T6[1];
}
extern __inline long long
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_reduce_add_epi64 (__mmask8 __U, __m512i __A)
{
  __A = _mm512_maskz_mov_epi64 (__U, __A);
  __v4di __T1 = (__v4di) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (1), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __v4di __T2 = (__v4di) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (0), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __m256i __T3 = (__m256i) (__T1 + __T2); __v2di __T4 = (__v2di) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(1))); __v2di __T5 = (__v2di) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(0))); __v2di __T6 = __T4 + __T5; return __T6[0] + __T6[1];
}
extern __inline long long
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_reduce_mul_epi64 (__mmask8 __U, __m512i __A)
{
  __A = _mm512_mask_mov_epi64 (_mm512_set1_epi64 (1LL), __U, __A);
  __v4di __T1 = (__v4di) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (1), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __v4di __T2 = (__v4di) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (0), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __m256i __T3 = (__m256i) (__T1 * __T2); __v2di __T4 = (__v2di) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(1))); __v2di __T5 = (__v2di) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(0))); __v2di __T6 = __T4 * __T5; return __T6[0] * __T6[1];
}
extern __inline long long
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_reduce_and_epi64 (__mmask8 __U, __m512i __A)
{
  __A = _mm512_mask_mov_epi64 (_mm512_set1_epi64 (~0LL), __U, __A);
  __v4di __T1 = (__v4di) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (1), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __v4di __T2 = (__v4di) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (0), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __m256i __T3 = (__m256i) (__T1 & __T2); __v2di __T4 = (__v2di) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(1))); __v2di __T5 = (__v2di) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(0))); __v2di __T6 = __T4 & __T5; return __T6[0] & __T6[1];
}
extern __inline long long
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_reduce_or_epi64 (__mmask8 __U, __m512i __A)
{
  __A = _mm512_maskz_mov_epi64 (__U, __A);
  __v4di __T1 = (__v4di) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (1), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __v4di __T2 = (__v4di) ((__m256i) __builtin_ia32_extracti64x4_mask ((__v8di)(__m512i) (__A), (int) (0), (__v4di)(__m256i)_mm256_undefined_si256 (), (__mmask8)-1)); __m256i __T3 = (__m256i) (__T1 | __T2); __v2di __T4 = (__v2di) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(1))); __v2di __T5 = (__v2di) ((__m128i) __builtin_ia32_extract128i256 ((__v4di)(__m256i)(__T3), (int)(0))); __v2di __T6 = __T4 | __T5; return __T6[0] | __T6[1];
}
extern __inline long long
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_reduce_min_epi64 (__m512i __A)
{
  __m512i __T1 = ((__m512i) __builtin_ia32_shuf_i64x2_mask ((__v8di)(__m512i)(__A), (__v8di)(__m512i)(__A), (int)(0x4e), (__v8di)(__m512i)_mm512_undefined_epi32 (), (__mmask8)-1)); __m512i __T2 = _mm512_min_epi64 (__A, __T1); __m512i __T3 = (__m512i) __builtin_shuffle ((__v8di) __T2, (__v8di) { 2, 3, 0, 1, 6, 7, 4, 5 }); __m512i __T4 = _mm512_min_epi64 (__T2, __T3); __m512i __T5 = (__m512i) __builtin_shuffle ((__v8di) __T4, (__v8di) { 1, 0, 3, 2, 5, 4, 7, 6 }); __v8di __T6 = (__v8di) _mm512_min_epi64 (__T4, __T5); return __T6[0];
}
extern __inline long long
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_reduce_max_epi64 (__m512i __A)
{
  __m512i __T1 = ((__m512i) __builtin_ia32_shuf_i64x2_mask ((__v8di)(__m512i)(__A), (__v8di)(__m512i)(__A), (int)(0x4e), (__v8di)(__m512i)_mm512_undefined_epi32 (), (__mmask8)-1)); __m512i __T2 = _mm512_max_epi64 (__A, __T1); __m512i __T3 = (__m512i) __builtin_shuffle ((__v8di) __T2, (__v8di) { 2, 3, 0, 1, 6, 7, 4, 5 }); __m512i __T4 = _mm512_max_epi64 (__T2, __T3); __m512i __T5 = (__m512i) __builtin_shuffle ((__v8di) __T4, (__v8di) { 1, 0, 3, 2, 5, 4, 7, 6 }); __v8di __T6 = (__v8di) _mm512_max_epi64 (__T4, __T5); return __T6[0];
}
extern __inline long long
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_reduce_min_epi64 (__mmask8 __U, __m512i __A)
{
  __A = _mm512_mask_mov_epi64 (_mm512_set1_epi64 (0x7fffffffffffffffLL),
          __U, __A);
  __m512i __T1 = ((__m512i) __builtin_ia32_shuf_i64x2_mask ((__v8di)(__m512i)(__A), (__v8di)(__m512i)(__A), (int)(0x4e), (__v8di)(__m512i)_mm512_undefined_epi32 (), (__mmask8)-1)); __m512i __T2 = _mm512_min_epi64 (__A, __T1); __m512i __T3 = (__m512i) __builtin_shuffle ((__v8di) __T2, (__v8di) { 2, 3, 0, 1, 6, 7, 4, 5 }); __m512i __T4 = _mm512_min_epi64 (__T2, __T3); __m512i __T5 = (__m512i) __builtin_shuffle ((__v8di) __T4, (__v8di) { 1, 0, 3, 2, 5, 4, 7, 6 }); __v8di __T6 = (__v8di) _mm512_min_epi64 (__T4, __T5); return __T6[0];
}
extern __inline long long
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_reduce_max_epi64 (__mmask8 __U, __m512i __A)
{
  __A = _mm512_mask_mov_epi64 (_mm512_set1_epi64 (-0x7fffffffffffffffLL - 1),
          __U, __A);
  __m512i __T1 = ((__m512i) __builtin_ia32_shuf_i64x2_mask ((__v8di)(__m512i)(__A), (__v8di)(__m512i)(__A), (int)(0x4e), (__v8di)(__m512i)_mm512_undefined_epi32 (), (__mmask8)-1)); __m512i __T2 = _mm512_max_epi64 (__A, __T1); __m512i __T3 = (__m512i) __builtin_shuffle ((__v8di) __T2, (__v8di) { 2, 3, 0, 1, 6, 7, 4, 5 }); __m512i __T4 = _mm512_max_epi64 (__T2, __T3); __m512i __T5 = (__m512i) __builtin_shuffle ((__v8di) __T4, (__v8di) { 1, 0, 3, 2, 5, 4, 7, 6 }); __v8di __T6 = (__v8di) _mm512_max_epi64 (__T4, __T5); return __T6[0];
}
extern __inline unsigned long long
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_reduce_min_epu64 (__m512i __A)
{
  __m512i __T1 = ((__m512i) __builtin_ia32_shuf_i64x2_mask ((__v8di)(__m512i)(__A), (__v8di)(__m512i)(__A), (int)(0x4e), (__v8di)(__m512i)_mm512_undefined_epi32 (), (__mmask8)-1)); __m512i __T2 = _mm512_min_epu64 (__A, __T1); __m512i __T3 = (__m512i) __builtin_shuffle ((__v8di) __T2, (__v8di) { 2, 3, 0, 1, 6, 7, 4, 5 }); __m512i __T4 = _mm512_min_epu64 (__T2, __T3); __m512i __T5 = (__m512i) __builtin_shuffle ((__v8di) __T4, (__v8di) { 1, 0, 3, 2, 5, 4, 7, 6 }); __v8di __T6 = (__v8di) _mm512_min_epu64 (__T4, __T5); return __T6[0];
}
extern __inline unsigned long long
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_reduce_max_epu64 (__m512i __A)
{
  __m512i __T1 = ((__m512i) __builtin_ia32_shuf_i64x2_mask ((__v8di)(__m512i)(__A), (__v8di)(__m512i)(__A), (int)(0x4e), (__v8di)(__m512i)_mm512_undefined_epi32 (), (__mmask8)-1)); __m512i __T2 = _mm512_max_epu64 (__A, __T1); __m512i __T3 = (__m512i) __builtin_shuffle ((__v8di) __T2, (__v8di) { 2, 3, 0, 1, 6, 7, 4, 5 }); __m512i __T4 = _mm512_max_epu64 (__T2, __T3); __m512i __T5 = (__m512i) __builtin_shuffle ((__v8di) __T4, (__v8di) { 1, 0, 3, 2, 5, 4, 7, 6 }); __v8di __T6 = (__v8di) _mm512_max_epu64 (__T4, __T5); return __T6[0];
}
extern __inline unsigned long long
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_reduce_min_epu64 (__mmask8 __U, __m512i __A)
{
  __A = _mm512_mask_mov_epi64 (_mm512_set1_epi64 (~0LL), __U, __A);
  __m512i __T1 = ((__m512i) __builtin_ia32_shuf_i64x2_mask ((__v8di)(__m512i)(__A), (__v8di)(__m512i)(__A), (int)(0x4e), (__v8di)(__m512i)_mm512_undefined_epi32 (), (__mmask8)-1)); __m512i __T2 = _mm512_min_epu64 (__A, __T1); __m512i __T3 = (__m512i) __builtin_shuffle ((__v8di) __T2, (__v8di) { 2, 3, 0, 1, 6, 7, 4, 5 }); __m512i __T4 = _mm512_min_epu64 (__T2, __T3); __m512i __T5 = (__m512i) __builtin_shuffle ((__v8di) __T4, (__v8di) { 1, 0, 3, 2, 5, 4, 7, 6 }); __v8di __T6 = (__v8di) _mm512_min_epu64 (__T4, __T5); return __T6[0];
}
extern __inline unsigned long long
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_reduce_max_epu64 (__mmask8 __U, __m512i __A)
{
  __A = _mm512_maskz_mov_epi64 (__U, __A);
  __m512i __T1 = ((__m512i) __builtin_ia32_shuf_i64x2_mask ((__v8di)(__m512i)(__A), (__v8di)(__m512i)(__A), (int)(0x4e), (__v8di)(__m512i)_mm512_undefined_epi32 (), (__mmask8)-1)); __m512i __T2 = _mm512_max_epu64 (__A, __T1); __m512i __T3 = (__m512i) __builtin_shuffle ((__v8di) __T2, (__v8di) { 2, 3, 0, 1, 6, 7, 4, 5 }); __m512i __T4 = _mm512_max_epu64 (__T2, __T3); __m512i __T5 = (__m512i) __builtin_shuffle ((__v8di) __T4, (__v8di) { 1, 0, 3, 2, 5, 4, 7, 6 }); __v8di __T6 = (__v8di) _mm512_max_epu64 (__T4, __T5); return __T6[0];
}
extern __inline double
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_reduce_add_pd (__m512d __A)
{
  __m256d __T1 = (__m256d) ((__m256d) __builtin_ia32_extractf64x4_mask ((__v8df)(__m512d) (__A), (int) (1), (__v4df)(__m256d)_mm256_undefined_pd(), (__mmask8)-1)); __m256d __T2 = (__m256d) ((__m256d) __builtin_ia32_extractf64x4_mask ((__v8df)(__m512d) (__A), (int) (0), (__v4df)(__m256d)_mm256_undefined_pd(), (__mmask8)-1)); __m256d __T3 = __T1 + __T2; __m128d __T4 = ((__m128d) __builtin_ia32_vextractf128_pd256 ((__v4df)(__m256d)(__T3), (int)(1))); __m128d __T5 = ((__m128d) __builtin_ia32_vextractf128_pd256 ((__v4df)(__m256d)(__T3), (int)(0))); __m128d __T6 = __T4 + __T5; return __T6[0] + __T6[1];
}
extern __inline double
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_reduce_mul_pd (__m512d __A)
{
  __m256d __T1 = (__m256d) ((__m256d) __builtin_ia32_extractf64x4_mask ((__v8df)(__m512d) (__A), (int) (1), (__v4df)(__m256d)_mm256_undefined_pd(), (__mmask8)-1)); __m256d __T2 = (__m256d) ((__m256d) __builtin_ia32_extractf64x4_mask ((__v8df)(__m512d) (__A), (int) (0), (__v4df)(__m256d)_mm256_undefined_pd(), (__mmask8)-1)); __m256d __T3 = __T1 * __T2; __m128d __T4 = ((__m128d) __builtin_ia32_vextractf128_pd256 ((__v4df)(__m256d)(__T3), (int)(1))); __m128d __T5 = ((__m128d) __builtin_ia32_vextractf128_pd256 ((__v4df)(__m256d)(__T3), (int)(0))); __m128d __T6 = __T4 * __T5; return __T6[0] * __T6[1];
}
extern __inline double
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_reduce_add_pd (__mmask8 __U, __m512d __A)
{
  __A = _mm512_maskz_mov_pd (__U, __A);
  __m256d __T1 = (__m256d) ((__m256d) __builtin_ia32_extractf64x4_mask ((__v8df)(__m512d) (__A), (int) (1), (__v4df)(__m256d)_mm256_undefined_pd(), (__mmask8)-1)); __m256d __T2 = (__m256d) ((__m256d) __builtin_ia32_extractf64x4_mask ((__v8df)(__m512d) (__A), (int) (0), (__v4df)(__m256d)_mm256_undefined_pd(), (__mmask8)-1)); __m256d __T3 = __T1 + __T2; __m128d __T4 = ((__m128d) __builtin_ia32_vextractf128_pd256 ((__v4df)(__m256d)(__T3), (int)(1))); __m128d __T5 = ((__m128d) __builtin_ia32_vextractf128_pd256 ((__v4df)(__m256d)(__T3), (int)(0))); __m128d __T6 = __T4 + __T5; return __T6[0] + __T6[1];
}
extern __inline double
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_reduce_mul_pd (__mmask8 __U, __m512d __A)
{
  __A = _mm512_mask_mov_pd (_mm512_set1_pd (1.0), __U, __A);
  __m256d __T1 = (__m256d) ((__m256d) __builtin_ia32_extractf64x4_mask ((__v8df)(__m512d) (__A), (int) (1), (__v4df)(__m256d)_mm256_undefined_pd(), (__mmask8)-1)); __m256d __T2 = (__m256d) ((__m256d) __builtin_ia32_extractf64x4_mask ((__v8df)(__m512d) (__A), (int) (0), (__v4df)(__m256d)_mm256_undefined_pd(), (__mmask8)-1)); __m256d __T3 = __T1 * __T2; __m128d __T4 = ((__m128d) __builtin_ia32_vextractf128_pd256 ((__v4df)(__m256d)(__T3), (int)(1))); __m128d __T5 = ((__m128d) __builtin_ia32_vextractf128_pd256 ((__v4df)(__m256d)(__T3), (int)(0))); __m128d __T6 = __T4 * __T5; return __T6[0] * __T6[1];
}
extern __inline double
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_reduce_min_pd (__m512d __A)
{
  __m256d __T1 = (__m256d) ((__m256d) __builtin_ia32_extractf64x4_mask ((__v8df)(__m512d) (__A), (int) (1), (__v4df)(__m256d)_mm256_undefined_pd(), (__mmask8)-1)); __m256d __T2 = (__m256d) ((__m256d) __builtin_ia32_extractf64x4_mask ((__v8df)(__m512d) (__A), (int) (0), (__v4df)(__m256d)_mm256_undefined_pd(), (__mmask8)-1)); __m256d __T3 = _mm256_min_pd (__T1, __T2); __m128d __T4 = ((__m128d) __builtin_ia32_vextractf128_pd256 ((__v4df)(__m256d)(__T3), (int)(1))); __m128d __T5 = ((__m128d) __builtin_ia32_vextractf128_pd256 ((__v4df)(__m256d)(__T3), (int)(0))); __m128d __T6 = _mm_min_pd (__T4, __T5); __m128d __T7 = (__m128d) __builtin_shuffle (__T6, (__v2di) { 1, 0 }); __m128d __T8 = _mm_min_pd (__T6, __T7); return __T8[0];
}
extern __inline double
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_reduce_max_pd (__m512d __A)
{
  __m256d __T1 = (__m256d) ((__m256d) __builtin_ia32_extractf64x4_mask ((__v8df)(__m512d) (__A), (int) (1), (__v4df)(__m256d)_mm256_undefined_pd(), (__mmask8)-1)); __m256d __T2 = (__m256d) ((__m256d) __builtin_ia32_extractf64x4_mask ((__v8df)(__m512d) (__A), (int) (0), (__v4df)(__m256d)_mm256_undefined_pd(), (__mmask8)-1)); __m256d __T3 = _mm256_max_pd (__T1, __T2); __m128d __T4 = ((__m128d) __builtin_ia32_vextractf128_pd256 ((__v4df)(__m256d)(__T3), (int)(1))); __m128d __T5 = ((__m128d) __builtin_ia32_vextractf128_pd256 ((__v4df)(__m256d)(__T3), (int)(0))); __m128d __T6 = _mm_max_pd (__T4, __T5); __m128d __T7 = (__m128d) __builtin_shuffle (__T6, (__v2di) { 1, 0 }); __m128d __T8 = _mm_max_pd (__T6, __T7); return __T8[0];
}
extern __inline double
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_reduce_min_pd (__mmask8 __U, __m512d __A)
{
  __A = _mm512_mask_mov_pd (_mm512_set1_pd (__builtin_inf ()), __U, __A);
  __m256d __T1 = (__m256d) ((__m256d) __builtin_ia32_extractf64x4_mask ((__v8df)(__m512d) (__A), (int) (1), (__v4df)(__m256d)_mm256_undefined_pd(), (__mmask8)-1)); __m256d __T2 = (__m256d) ((__m256d) __builtin_ia32_extractf64x4_mask ((__v8df)(__m512d) (__A), (int) (0), (__v4df)(__m256d)_mm256_undefined_pd(), (__mmask8)-1)); __m256d __T3 = _mm256_min_pd (__T1, __T2); __m128d __T4 = ((__m128d) __builtin_ia32_vextractf128_pd256 ((__v4df)(__m256d)(__T3), (int)(1))); __m128d __T5 = ((__m128d) __builtin_ia32_vextractf128_pd256 ((__v4df)(__m256d)(__T3), (int)(0))); __m128d __T6 = _mm_min_pd (__T4, __T5); __m128d __T7 = (__m128d) __builtin_shuffle (__T6, (__v2di) { 1, 0 }); __m128d __T8 = _mm_min_pd (__T6, __T7); return __T8[0];
}
extern __inline double
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_reduce_max_pd (__mmask8 __U, __m512d __A)
{
  __A = _mm512_mask_mov_pd (_mm512_set1_pd (-__builtin_inf ()), __U, __A);
  __m256d __T1 = (__m256d) ((__m256d) __builtin_ia32_extractf64x4_mask ((__v8df)(__m512d) (__A), (int) (1), (__v4df)(__m256d)_mm256_undefined_pd(), (__mmask8)-1)); __m256d __T2 = (__m256d) ((__m256d) __builtin_ia32_extractf64x4_mask ((__v8df)(__m512d) (__A), (int) (0), (__v4df)(__m256d)_mm256_undefined_pd(), (__mmask8)-1)); __m256d __T3 = _mm256_max_pd (__T1, __T2); __m128d __T4 = ((__m128d) __builtin_ia32_vextractf128_pd256 ((__v4df)(__m256d)(__T3), (int)(1))); __m128d __T5 = ((__m128d) __builtin_ia32_vextractf128_pd256 ((__v4df)(__m256d)(__T3), (int)(0))); __m128d __T6 = _mm_max_pd (__T4, __T5); __m128d __T7 = (__m128d) __builtin_shuffle (__T6, (__v2di) { 1, 0 }); __m128d __T8 = _mm_max_pd (__T6, __T7); return __T8[0];
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx512er")
typedef double __v8df __attribute__ ((__vector_size__ (64)));
typedef float __v16sf __attribute__ ((__vector_size__ (64)));
typedef float __m512 __attribute__ ((__vector_size__ (64), __may_alias__));
typedef double __m512d __attribute__ ((__vector_size__ (64), __may_alias__));
typedef unsigned char __mmask8;
typedef unsigned short __mmask16;
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx512pf")
typedef long long __v8di __attribute__ ((__vector_size__ (64)));
typedef int __v16si __attribute__ ((__vector_size__ (64)));
typedef long long __m512i __attribute__ ((__vector_size__ (64), __may_alias__));
typedef unsigned char __mmask8;
typedef unsigned short __mmask16;
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx512cd")
typedef long long __v8di __attribute__ ((__vector_size__ (64)));
typedef int __v16si __attribute__ ((__vector_size__ (64)));
typedef long long __m512i __attribute__ ((__vector_size__ (64), __may_alias__));
typedef double __m512d __attribute__ ((__vector_size__ (64), __may_alias__));
typedef unsigned char __mmask8;
typedef unsigned short __mmask16;
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_conflict_epi32 (__m512i __A)
{
  return (__m512i)
  __builtin_ia32_vpconflictsi_512_mask ((__v16si) __A,
            (__v16si) _mm512_setzero_si512 (),
            (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_conflict_epi32 (__m512i __W, __mmask16 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_vpconflictsi_512_mask ((__v16si) __A,
        (__v16si) __W,
        (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_conflict_epi32 (__mmask16 __U, __m512i __A)
{
  return (__m512i)
  __builtin_ia32_vpconflictsi_512_mask ((__v16si) __A,
            (__v16si) _mm512_setzero_si512 (),
            (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_conflict_epi64 (__m512i __A)
{
  return (__m512i)
  __builtin_ia32_vpconflictdi_512_mask ((__v8di) __A,
            (__v8di) _mm512_setzero_si512 (),
            (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_conflict_epi64 (__m512i __W, __mmask8 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_vpconflictdi_512_mask ((__v8di) __A,
        (__v8di) __W,
        (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_conflict_epi64 (__mmask8 __U, __m512i __A)
{
  return (__m512i)
  __builtin_ia32_vpconflictdi_512_mask ((__v8di) __A,
            (__v8di) _mm512_setzero_si512 (),
            (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_lzcnt_epi64 (__m512i __A)
{
  return (__m512i)
  __builtin_ia32_vplzcntq_512_mask ((__v8di) __A,
        (__v8di) _mm512_setzero_si512 (),
        (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_lzcnt_epi64 (__m512i __W, __mmask8 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_vplzcntq_512_mask ((__v8di) __A,
           (__v8di) __W,
           (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_lzcnt_epi64 (__mmask8 __U, __m512i __A)
{
  return (__m512i)
  __builtin_ia32_vplzcntq_512_mask ((__v8di) __A,
        (__v8di) _mm512_setzero_si512 (),
        (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_lzcnt_epi32 (__m512i __A)
{
  return (__m512i)
  __builtin_ia32_vplzcntd_512_mask ((__v16si) __A,
        (__v16si) _mm512_setzero_si512 (),
        (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_lzcnt_epi32 (__m512i __W, __mmask16 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_vplzcntd_512_mask ((__v16si) __A,
           (__v16si) __W,
           (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_lzcnt_epi32 (__mmask16 __U, __m512i __A)
{
  return (__m512i)
  __builtin_ia32_vplzcntd_512_mask ((__v16si) __A,
        (__v16si) _mm512_setzero_si512 (),
        (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_broadcastmb_epi64 (__mmask8 __A)
{
  return (__m512i) __builtin_ia32_broadcastmb512 (__A);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_broadcastmw_epi32 (__mmask16 __A)
{
  return (__m512i) __builtin_ia32_broadcastmw512 (__A);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx512vl")
typedef unsigned int __mmask32;
typedef int __v4si_u __attribute__ ((__vector_size__ (16), __may_alias__, __aligned__ (1)));
typedef int __v8si_u __attribute__ ((__vector_size__ (32), __may_alias__, __aligned__ (1)));
typedef long long __v2di_u __attribute__ ((__vector_size__ (16), __may_alias__, __aligned__ (1)));
typedef long long __v4di_u __attribute__ ((__vector_size__ (32), __may_alias__, __aligned__ (1)));
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_mov_pd (__m256d __W, __mmask8 __U, __m256d __A)
{
  return (__m256d) __builtin_ia32_movapd256_mask ((__v4df) __A,
        (__v4df) __W,
        (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_mov_pd (__mmask8 __U, __m256d __A)
{
  return (__m256d) __builtin_ia32_movapd256_mask ((__v4df) __A,
        (__v4df)
        _mm256_setzero_pd (),
        (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_mov_pd (__m128d __W, __mmask8 __U, __m128d __A)
{
  return (__m128d) __builtin_ia32_movapd128_mask ((__v2df) __A,
        (__v2df) __W,
        (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_mov_pd (__mmask8 __U, __m128d __A)
{
  return (__m128d) __builtin_ia32_movapd128_mask ((__v2df) __A,
        (__v2df)
        _mm_setzero_pd (),
        (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_load_pd (__m256d __W, __mmask8 __U, void const *__P)
{
  return (__m256d) __builtin_ia32_loadapd256_mask ((__v4df *) __P,
         (__v4df) __W,
         (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_load_pd (__mmask8 __U, void const *__P)
{
  return (__m256d) __builtin_ia32_loadapd256_mask ((__v4df *) __P,
         (__v4df)
         _mm256_setzero_pd (),
         (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_load_pd (__m128d __W, __mmask8 __U, void const *__P)
{
  return (__m128d) __builtin_ia32_loadapd128_mask ((__v2df *) __P,
         (__v2df) __W,
         (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_load_pd (__mmask8 __U, void const *__P)
{
  return (__m128d) __builtin_ia32_loadapd128_mask ((__v2df *) __P,
         (__v2df)
         _mm_setzero_pd (),
         (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_store_pd (void *__P, __mmask8 __U, __m256d __A)
{
  __builtin_ia32_storeapd256_mask ((__v4df *) __P,
       (__v4df) __A,
       (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_store_pd (void *__P, __mmask8 __U, __m128d __A)
{
  __builtin_ia32_storeapd128_mask ((__v2df *) __P,
       (__v2df) __A,
       (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_mov_ps (__m256 __W, __mmask8 __U, __m256 __A)
{
  return (__m256) __builtin_ia32_movaps256_mask ((__v8sf) __A,
       (__v8sf) __W,
       (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_mov_ps (__mmask8 __U, __m256 __A)
{
  return (__m256) __builtin_ia32_movaps256_mask ((__v8sf) __A,
       (__v8sf)
       _mm256_setzero_ps (),
       (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_mov_ps (__m128 __W, __mmask8 __U, __m128 __A)
{
  return (__m128) __builtin_ia32_movaps128_mask ((__v4sf) __A,
       (__v4sf) __W,
       (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_mov_ps (__mmask8 __U, __m128 __A)
{
  return (__m128) __builtin_ia32_movaps128_mask ((__v4sf) __A,
       (__v4sf)
       _mm_setzero_ps (),
       (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_load_ps (__m256 __W, __mmask8 __U, void const *__P)
{
  return (__m256) __builtin_ia32_loadaps256_mask ((__v8sf *) __P,
        (__v8sf) __W,
        (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_load_ps (__mmask8 __U, void const *__P)
{
  return (__m256) __builtin_ia32_loadaps256_mask ((__v8sf *) __P,
        (__v8sf)
        _mm256_setzero_ps (),
        (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_load_ps (__m128 __W, __mmask8 __U, void const *__P)
{
  return (__m128) __builtin_ia32_loadaps128_mask ((__v4sf *) __P,
        (__v4sf) __W,
        (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_load_ps (__mmask8 __U, void const *__P)
{
  return (__m128) __builtin_ia32_loadaps128_mask ((__v4sf *) __P,
        (__v4sf)
        _mm_setzero_ps (),
        (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_store_ps (void *__P, __mmask8 __U, __m256 __A)
{
  __builtin_ia32_storeaps256_mask ((__v8sf *) __P,
       (__v8sf) __A,
       (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_store_ps (void *__P, __mmask8 __U, __m128 __A)
{
  __builtin_ia32_storeaps128_mask ((__v4sf *) __P,
       (__v4sf) __A,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_mov_epi64 (__m256i __W, __mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_movdqa64_256_mask ((__v4di) __A,
           (__v4di) __W,
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_mov_epi64 (__mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_movdqa64_256_mask ((__v4di) __A,
           (__v4di)
           _mm256_setzero_si256 (),
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_mov_epi64 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_movdqa64_128_mask ((__v2di) __A,
           (__v2di) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_mov_epi64 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_movdqa64_128_mask ((__v2di) __A,
           (__v2di)
           _mm_setzero_si128 (),
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_load_epi64 (void const *__P)
{
  return (__m256i) (*(__v4di *) __P);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_load_epi64 (__m256i __W, __mmask8 __U, void const *__P)
{
  return (__m256i) __builtin_ia32_movdqa64load256_mask ((__v4di *) __P,
       (__v4di) __W,
       (__mmask8)
       __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_load_epi64 (__mmask8 __U, void const *__P)
{
  return (__m256i) __builtin_ia32_movdqa64load256_mask ((__v4di *) __P,
       (__v4di)
       _mm256_setzero_si256 (),
       (__mmask8)
       __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_load_epi64 (void const *__P)
{
  return (__m128i) (*(__v2di *) __P);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_load_epi64 (__m128i __W, __mmask8 __U, void const *__P)
{
  return (__m128i) __builtin_ia32_movdqa64load128_mask ((__v2di *) __P,
       (__v2di) __W,
       (__mmask8)
       __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_load_epi64 (__mmask8 __U, void const *__P)
{
  return (__m128i) __builtin_ia32_movdqa64load128_mask ((__v2di *) __P,
       (__v2di)
       _mm_setzero_si128 (),
       (__mmask8)
       __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_store_epi64 (void *__P, __mmask8 __U, __m256i __A)
{
  __builtin_ia32_movdqa64store256_mask ((__v4di *) __P,
     (__v4di) __A,
     (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_store_epi64 (void *__P, __mmask8 __U, __m128i __A)
{
  __builtin_ia32_movdqa64store128_mask ((__v2di *) __P,
     (__v2di) __A,
     (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_mov_epi32 (__m256i __W, __mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_movdqa32_256_mask ((__v8si) __A,
           (__v8si) __W,
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_mov_epi32 (__mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_movdqa32_256_mask ((__v8si) __A,
           (__v8si)
           _mm256_setzero_si256 (),
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_mov_epi32 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_movdqa32_128_mask ((__v4si) __A,
           (__v4si) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_mov_epi32 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_movdqa32_128_mask ((__v4si) __A,
           (__v4si)
           _mm_setzero_si128 (),
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_load_epi32 (void const *__P)
{
  return (__m256i) (*(__v8si *) __P);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_load_epi32 (__m256i __W, __mmask8 __U, void const *__P)
{
  return (__m256i) __builtin_ia32_movdqa32load256_mask ((__v8si *) __P,
       (__v8si) __W,
       (__mmask8)
       __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_load_epi32 (__mmask8 __U, void const *__P)
{
  return (__m256i) __builtin_ia32_movdqa32load256_mask ((__v8si *) __P,
       (__v8si)
       _mm256_setzero_si256 (),
       (__mmask8)
       __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_load_epi32 (void const *__P)
{
  return (__m128i) (*(__v4si *) __P);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_load_epi32 (__m128i __W, __mmask8 __U, void const *__P)
{
  return (__m128i) __builtin_ia32_movdqa32load128_mask ((__v4si *) __P,
       (__v4si) __W,
       (__mmask8)
       __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_load_epi32 (__mmask8 __U, void const *__P)
{
  return (__m128i) __builtin_ia32_movdqa32load128_mask ((__v4si *) __P,
       (__v4si)
       _mm_setzero_si128 (),
       (__mmask8)
       __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_store_epi32 (void *__P, __m256i __A)
{
  *(__v8si *) __P = (__v8si) __A;
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_store_epi32 (void *__P, __mmask8 __U, __m256i __A)
{
  __builtin_ia32_movdqa32store256_mask ((__v8si *) __P,
     (__v8si) __A,
     (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_store_epi32 (void *__P, __m128i __A)
{
  *(__v4si *) __P = (__v4si) __A;
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_store_epi32 (void *__P, __mmask8 __U, __m128i __A)
{
  __builtin_ia32_movdqa32store128_mask ((__v4si *) __P,
     (__v4si) __A,
     (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_add_pd (__m128d __W, __mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_addpd128_mask ((__v2df) __A,
       (__v2df) __B,
       (__v2df) __W,
       (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_add_pd (__mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_addpd128_mask ((__v2df) __A,
       (__v2df) __B,
       (__v2df)
       _mm_setzero_pd (),
       (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_add_pd (__m256d __W, __mmask8 __U, __m256d __A,
      __m256d __B)
{
  return (__m256d) __builtin_ia32_addpd256_mask ((__v4df) __A,
       (__v4df) __B,
       (__v4df) __W,
       (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_add_pd (__mmask8 __U, __m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_addpd256_mask ((__v4df) __A,
       (__v4df) __B,
       (__v4df)
       _mm256_setzero_pd (),
       (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_add_ps (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_addps128_mask ((__v4sf) __A,
      (__v4sf) __B,
      (__v4sf) __W,
      (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_add_ps (__mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_addps128_mask ((__v4sf) __A,
      (__v4sf) __B,
      (__v4sf)
      _mm_setzero_ps (),
      (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_add_ps (__m256 __W, __mmask8 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_addps256_mask ((__v8sf) __A,
      (__v8sf) __B,
      (__v8sf) __W,
      (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_add_ps (__mmask8 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_addps256_mask ((__v8sf) __A,
      (__v8sf) __B,
      (__v8sf)
      _mm256_setzero_ps (),
      (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_sub_pd (__m128d __W, __mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_subpd128_mask ((__v2df) __A,
       (__v2df) __B,
       (__v2df) __W,
       (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_sub_pd (__mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_subpd128_mask ((__v2df) __A,
       (__v2df) __B,
       (__v2df)
       _mm_setzero_pd (),
       (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_sub_pd (__m256d __W, __mmask8 __U, __m256d __A,
      __m256d __B)
{
  return (__m256d) __builtin_ia32_subpd256_mask ((__v4df) __A,
       (__v4df) __B,
       (__v4df) __W,
       (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_sub_pd (__mmask8 __U, __m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_subpd256_mask ((__v4df) __A,
       (__v4df) __B,
       (__v4df)
       _mm256_setzero_pd (),
       (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_sub_ps (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_subps128_mask ((__v4sf) __A,
      (__v4sf) __B,
      (__v4sf) __W,
      (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_sub_ps (__mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_subps128_mask ((__v4sf) __A,
      (__v4sf) __B,
      (__v4sf)
      _mm_setzero_ps (),
      (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_sub_ps (__m256 __W, __mmask8 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_subps256_mask ((__v8sf) __A,
      (__v8sf) __B,
      (__v8sf) __W,
      (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_sub_ps (__mmask8 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_subps256_mask ((__v8sf) __A,
      (__v8sf) __B,
      (__v8sf)
      _mm256_setzero_ps (),
      (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_store_epi64 (void *__P, __m256i __A)
{
  *(__m256i *) __P = __A;
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_store_epi64 (void *__P, __m128i __A)
{
  *(__m128i *) __P = __A;
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_loadu_pd (__m256d __W, __mmask8 __U, void const *__P)
{
  return (__m256d) __builtin_ia32_loadupd256_mask ((const double *) __P,
         (__v4df) __W,
         (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_loadu_pd (__mmask8 __U, void const *__P)
{
  return (__m256d) __builtin_ia32_loadupd256_mask ((const double *) __P,
         (__v4df)
         _mm256_setzero_pd (),
         (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_loadu_pd (__m128d __W, __mmask8 __U, void const *__P)
{
  return (__m128d) __builtin_ia32_loadupd128_mask ((const double *) __P,
         (__v2df) __W,
         (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_loadu_pd (__mmask8 __U, void const *__P)
{
  return (__m128d) __builtin_ia32_loadupd128_mask ((const double *) __P,
         (__v2df)
         _mm_setzero_pd (),
         (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_storeu_pd (void *__P, __mmask8 __U, __m256d __A)
{
  __builtin_ia32_storeupd256_mask ((double *) __P,
       (__v4df) __A,
       (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_storeu_pd (void *__P, __mmask8 __U, __m128d __A)
{
  __builtin_ia32_storeupd128_mask ((double *) __P,
       (__v2df) __A,
       (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_loadu_ps (__m256 __W, __mmask8 __U, void const *__P)
{
  return (__m256) __builtin_ia32_loadups256_mask ((const float *) __P,
        (__v8sf) __W,
        (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_loadu_ps (__mmask8 __U, void const *__P)
{
  return (__m256) __builtin_ia32_loadups256_mask ((const float *) __P,
        (__v8sf)
        _mm256_setzero_ps (),
        (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_loadu_ps (__m128 __W, __mmask8 __U, void const *__P)
{
  return (__m128) __builtin_ia32_loadups128_mask ((const float *) __P,
        (__v4sf) __W,
        (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_loadu_ps (__mmask8 __U, void const *__P)
{
  return (__m128) __builtin_ia32_loadups128_mask ((const float *) __P,
        (__v4sf)
        _mm_setzero_ps (),
        (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_storeu_ps (void *__P, __mmask8 __U, __m256 __A)
{
  __builtin_ia32_storeups256_mask ((float *) __P,
       (__v8sf) __A,
       (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_storeu_ps (void *__P, __mmask8 __U, __m128 __A)
{
  __builtin_ia32_storeups128_mask ((float *) __P,
       (__v4sf) __A,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_loadu_epi64 (void const *__P)
{
  return (__m256i) (*(__v4di_u *) __P);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_loadu_epi64 (__m256i __W, __mmask8 __U, void const *__P)
{
  return (__m256i) __builtin_ia32_loaddqudi256_mask ((const long long *) __P,
           (__v4di) __W,
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_loadu_epi64 (__mmask8 __U, void const *__P)
{
  return (__m256i) __builtin_ia32_loaddqudi256_mask ((const long long *) __P,
           (__v4di)
           _mm256_setzero_si256 (),
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_loadu_epi64 (void const *__P)
{
  return (__m128i) (*(__v2di_u *) __P);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_loadu_epi64 (__m128i __W, __mmask8 __U, void const *__P)
{
  return (__m128i) __builtin_ia32_loaddqudi128_mask ((const long long *) __P,
           (__v2di) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_loadu_epi64 (__mmask8 __U, void const *__P)
{
  return (__m128i) __builtin_ia32_loaddqudi128_mask ((const long long *) __P,
           (__v2di)
           _mm_setzero_si128 (),
           (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_storeu_epi64 (void *__P, __m256i __A)
{
  *(__m256i_u *) __P = (__m256i_u) __A;
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_storeu_epi64 (void *__P, __mmask8 __U, __m256i __A)
{
  __builtin_ia32_storedqudi256_mask ((long long *) __P,
         (__v4di) __A,
         (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_storeu_epi64 (void *__P, __m128i __A)
{
  *(__m128i_u *) __P = (__m128i_u) __A;
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_storeu_epi64 (void *__P, __mmask8 __U, __m128i __A)
{
  __builtin_ia32_storedqudi128_mask ((long long *) __P,
         (__v2di) __A,
         (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_loadu_epi32 (void const *__P)
{
  return (__m256i) (*(__v8si_u *) __P);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_loadu_epi32 (__m256i __W, __mmask8 __U, void const *__P)
{
  return (__m256i) __builtin_ia32_loaddqusi256_mask ((const int *) __P,
           (__v8si) __W,
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_loadu_epi32 (__mmask8 __U, void const *__P)
{
  return (__m256i) __builtin_ia32_loaddqusi256_mask ((const int *) __P,
           (__v8si)
           _mm256_setzero_si256 (),
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_loadu_epi32 (void const *__P)
{
  return (__m128i) (*(__v4si_u *) __P);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_loadu_epi32 (__m128i __W, __mmask8 __U, void const *__P)
{
  return (__m128i) __builtin_ia32_loaddqusi128_mask ((const int *) __P,
           (__v4si) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_loadu_epi32 (__mmask8 __U, void const *__P)
{
  return (__m128i) __builtin_ia32_loaddqusi128_mask ((const int *) __P,
           (__v4si)
           _mm_setzero_si128 (),
           (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_storeu_epi32 (void *__P, __m256i __A)
{
  *(__m256i_u *) __P = (__m256i_u) __A;
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_storeu_epi32 (void *__P, __mmask8 __U, __m256i __A)
{
  __builtin_ia32_storedqusi256_mask ((int *) __P,
         (__v8si) __A,
         (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_storeu_epi32 (void *__P, __m128i __A)
{
  *(__m128i_u *) __P = (__m128i_u) __A;
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_storeu_epi32 (void *__P, __mmask8 __U, __m128i __A)
{
  __builtin_ia32_storedqusi128_mask ((int *) __P,
         (__v4si) __A,
         (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_abs_epi32 (__m256i __W, __mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_pabsd256_mask ((__v8si) __A,
       (__v8si) __W,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_abs_epi32 (__mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_pabsd256_mask ((__v8si) __A,
       (__v8si)
       _mm256_setzero_si256 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_abs_epi32 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pabsd128_mask ((__v4si) __A,
       (__v4si) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_abs_epi32 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pabsd128_mask ((__v4si) __A,
       (__v4si)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_abs_epi64 (__m256i __A)
{
  return (__m256i) __builtin_ia32_pabsq256_mask ((__v4di) __A,
       (__v4di)
       _mm256_setzero_si256 (),
       (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_abs_epi64 (__m256i __W, __mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_pabsq256_mask ((__v4di) __A,
       (__v4di) __W,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_abs_epi64 (__mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_pabsq256_mask ((__v4di) __A,
       (__v4di)
       _mm256_setzero_si256 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_abs_epi64 (__m128i __A)
{
  return (__m128i) __builtin_ia32_pabsq128_mask ((__v2di) __A,
       (__v2di)
       _mm_setzero_si128 (),
       (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_abs_epi64 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pabsq128_mask ((__v2di) __A,
       (__v2di) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_abs_epi64 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pabsq128_mask ((__v2di) __A,
       (__v2di)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtpd_epu32 (__m256d __A)
{
  return (__m128i) __builtin_ia32_cvtpd2udq256_mask ((__v4df) __A,
           (__v4si)
           _mm_setzero_si128 (),
           (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtpd_epu32 (__m128i __W, __mmask8 __U, __m256d __A)
{
  return (__m128i) __builtin_ia32_cvtpd2udq256_mask ((__v4df) __A,
           (__v4si) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtpd_epu32 (__mmask8 __U, __m256d __A)
{
  return (__m128i) __builtin_ia32_cvtpd2udq256_mask ((__v4df) __A,
           (__v4si)
           _mm_setzero_si128 (),
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtpd_epu32 (__m128d __A)
{
  return (__m128i) __builtin_ia32_cvtpd2udq128_mask ((__v2df) __A,
           (__v4si)
           _mm_setzero_si128 (),
           (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtpd_epu32 (__m128i __W, __mmask8 __U, __m128d __A)
{
  return (__m128i) __builtin_ia32_cvtpd2udq128_mask ((__v2df) __A,
           (__v4si) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtpd_epu32 (__mmask8 __U, __m128d __A)
{
  return (__m128i) __builtin_ia32_cvtpd2udq128_mask ((__v2df) __A,
           (__v4si)
           _mm_setzero_si128 (),
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvttps_epi32 (__m256i __W, __mmask8 __U, __m256 __A)
{
  return (__m256i) __builtin_ia32_cvttps2dq256_mask ((__v8sf) __A,
           (__v8si) __W,
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvttps_epi32 (__mmask8 __U, __m256 __A)
{
  return (__m256i) __builtin_ia32_cvttps2dq256_mask ((__v8sf) __A,
           (__v8si)
           _mm256_setzero_si256 (),
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvttps_epi32 (__m128i __W, __mmask8 __U, __m128 __A)
{
  return (__m128i) __builtin_ia32_cvttps2dq128_mask ((__v4sf) __A,
           (__v4si) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvttps_epi32 (__mmask8 __U, __m128 __A)
{
  return (__m128i) __builtin_ia32_cvttps2dq128_mask ((__v4sf) __A,
           (__v4si)
           _mm_setzero_si128 (),
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvttps_epu32 (__m256 __A)
{
  return (__m256i) __builtin_ia32_cvttps2udq256_mask ((__v8sf) __A,
            (__v8si)
            _mm256_setzero_si256 (),
            (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvttps_epu32 (__m256i __W, __mmask8 __U, __m256 __A)
{
  return (__m256i) __builtin_ia32_cvttps2udq256_mask ((__v8sf) __A,
            (__v8si) __W,
            (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvttps_epu32 (__mmask8 __U, __m256 __A)
{
  return (__m256i) __builtin_ia32_cvttps2udq256_mask ((__v8sf) __A,
            (__v8si)
            _mm256_setzero_si256 (),
            (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttps_epu32 (__m128 __A)
{
  return (__m128i) __builtin_ia32_cvttps2udq128_mask ((__v4sf) __A,
            (__v4si)
            _mm_setzero_si128 (),
            (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvttps_epu32 (__m128i __W, __mmask8 __U, __m128 __A)
{
  return (__m128i) __builtin_ia32_cvttps2udq128_mask ((__v4sf) __A,
            (__v4si) __W,
            (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvttps_epu32 (__mmask8 __U, __m128 __A)
{
  return (__m128i) __builtin_ia32_cvttps2udq128_mask ((__v4sf) __A,
            (__v4si)
            _mm_setzero_si128 (),
            (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvttpd_epi32 (__m128i __W, __mmask8 __U, __m256d __A)
{
  return (__m128i) __builtin_ia32_cvttpd2dq256_mask ((__v4df) __A,
           (__v4si) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvttpd_epi32 (__mmask8 __U, __m256d __A)
{
  return (__m128i) __builtin_ia32_cvttpd2dq256_mask ((__v4df) __A,
           (__v4si)
           _mm_setzero_si128 (),
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvttpd_epi32 (__m128i __W, __mmask8 __U, __m128d __A)
{
  return (__m128i) __builtin_ia32_cvttpd2dq128_mask ((__v2df) __A,
           (__v4si) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvttpd_epi32 (__mmask8 __U, __m128d __A)
{
  return (__m128i) __builtin_ia32_cvttpd2dq128_mask ((__v2df) __A,
           (__v4si)
           _mm_setzero_si128 (),
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvttpd_epu32 (__m256d __A)
{
  return (__m128i) __builtin_ia32_cvttpd2udq256_mask ((__v4df) __A,
            (__v4si)
            _mm_setzero_si128 (),
            (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvttpd_epu32 (__m128i __W, __mmask8 __U, __m256d __A)
{
  return (__m128i) __builtin_ia32_cvttpd2udq256_mask ((__v4df) __A,
            (__v4si) __W,
            (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvttpd_epu32 (__mmask8 __U, __m256d __A)
{
  return (__m128i) __builtin_ia32_cvttpd2udq256_mask ((__v4df) __A,
            (__v4si)
            _mm_setzero_si128 (),
            (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttpd_epu32 (__m128d __A)
{
  return (__m128i) __builtin_ia32_cvttpd2udq128_mask ((__v2df) __A,
            (__v4si)
            _mm_setzero_si128 (),
            (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvttpd_epu32 (__m128i __W, __mmask8 __U, __m128d __A)
{
  return (__m128i) __builtin_ia32_cvttpd2udq128_mask ((__v2df) __A,
            (__v4si) __W,
            (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvttpd_epu32 (__mmask8 __U, __m128d __A)
{
  return (__m128i) __builtin_ia32_cvttpd2udq128_mask ((__v2df) __A,
            (__v4si)
            _mm_setzero_si128 (),
            (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtpd_epi32 (__m128i __W, __mmask8 __U, __m256d __A)
{
  return (__m128i) __builtin_ia32_cvtpd2dq256_mask ((__v4df) __A,
          (__v4si) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtpd_epi32 (__mmask8 __U, __m256d __A)
{
  return (__m128i) __builtin_ia32_cvtpd2dq256_mask ((__v4df) __A,
          (__v4si)
          _mm_setzero_si128 (),
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtpd_epi32 (__m128i __W, __mmask8 __U, __m128d __A)
{
  return (__m128i) __builtin_ia32_cvtpd2dq128_mask ((__v2df) __A,
          (__v4si) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtpd_epi32 (__mmask8 __U, __m128d __A)
{
  return (__m128i) __builtin_ia32_cvtpd2dq128_mask ((__v2df) __A,
          (__v4si)
          _mm_setzero_si128 (),
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi32_pd (__m256d __W, __mmask8 __U, __m128i __A)
{
  return (__m256d) __builtin_ia32_cvtdq2pd256_mask ((__v4si) __A,
          (__v4df) __W,
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepi32_pd (__mmask8 __U, __m128i __A)
{
  return (__m256d) __builtin_ia32_cvtdq2pd256_mask ((__v4si) __A,
          (__v4df)
          _mm256_setzero_pd (),
          (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi32_pd (__m128d __W, __mmask8 __U, __m128i __A)
{
  return (__m128d) __builtin_ia32_cvtdq2pd128_mask ((__v4si) __A,
          (__v2df) __W,
          (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepi32_pd (__mmask8 __U, __m128i __A)
{
  return (__m128d) __builtin_ia32_cvtdq2pd128_mask ((__v4si) __A,
          (__v2df)
          _mm_setzero_pd (),
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepu32_pd (__m128i __A)
{
  return (__m256d) __builtin_ia32_cvtudq2pd256_mask ((__v4si) __A,
           (__v4df)
           _mm256_setzero_pd (),
           (__mmask8) -1);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepu32_pd (__m256d __W, __mmask8 __U, __m128i __A)
{
  return (__m256d) __builtin_ia32_cvtudq2pd256_mask ((__v4si) __A,
           (__v4df) __W,
           (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepu32_pd (__mmask8 __U, __m128i __A)
{
  return (__m256d) __builtin_ia32_cvtudq2pd256_mask ((__v4si) __A,
           (__v4df)
           _mm256_setzero_pd (),
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepu32_pd (__m128i __A)
{
  return (__m128d) __builtin_ia32_cvtudq2pd128_mask ((__v4si) __A,
           (__v2df)
           _mm_setzero_pd (),
           (__mmask8) -1);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepu32_pd (__m128d __W, __mmask8 __U, __m128i __A)
{
  return (__m128d) __builtin_ia32_cvtudq2pd128_mask ((__v4si) __A,
           (__v2df) __W,
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepu32_pd (__mmask8 __U, __m128i __A)
{
  return (__m128d) __builtin_ia32_cvtudq2pd128_mask ((__v4si) __A,
           (__v2df)
           _mm_setzero_pd (),
           (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi32_ps (__m256 __W, __mmask8 __U, __m256i __A)
{
  return (__m256) __builtin_ia32_cvtdq2ps256_mask ((__v8si) __A,
         (__v8sf) __W,
         (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepi32_ps (__mmask8 __U, __m256i __A)
{
  return (__m256) __builtin_ia32_cvtdq2ps256_mask ((__v8si) __A,
         (__v8sf)
         _mm256_setzero_ps (),
         (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi32_ps (__m128 __W, __mmask8 __U, __m128i __A)
{
  return (__m128) __builtin_ia32_cvtdq2ps128_mask ((__v4si) __A,
         (__v4sf) __W,
         (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepi32_ps (__mmask8 __U, __m128i __A)
{
  return (__m128) __builtin_ia32_cvtdq2ps128_mask ((__v4si) __A,
         (__v4sf)
         _mm_setzero_ps (),
         (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepu32_ps (__m256i __A)
{
  return (__m256) __builtin_ia32_cvtudq2ps256_mask ((__v8si) __A,
          (__v8sf)
          _mm256_setzero_ps (),
          (__mmask8) -1);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepu32_ps (__m256 __W, __mmask8 __U, __m256i __A)
{
  return (__m256) __builtin_ia32_cvtudq2ps256_mask ((__v8si) __A,
          (__v8sf) __W,
          (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepu32_ps (__mmask8 __U, __m256i __A)
{
  return (__m256) __builtin_ia32_cvtudq2ps256_mask ((__v8si) __A,
          (__v8sf)
          _mm256_setzero_ps (),
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepu32_ps (__m128i __A)
{
  return (__m128) __builtin_ia32_cvtudq2ps128_mask ((__v4si) __A,
          (__v4sf)
          _mm_setzero_ps (),
          (__mmask8) -1);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepu32_ps (__m128 __W, __mmask8 __U, __m128i __A)
{
  return (__m128) __builtin_ia32_cvtudq2ps128_mask ((__v4si) __A,
          (__v4sf) __W,
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepu32_ps (__mmask8 __U, __m128i __A)
{
  return (__m128) __builtin_ia32_cvtudq2ps128_mask ((__v4si) __A,
          (__v4sf)
          _mm_setzero_ps (),
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtps_pd (__m256d __W, __mmask8 __U, __m128 __A)
{
  return (__m256d) __builtin_ia32_cvtps2pd256_mask ((__v4sf) __A,
          (__v4df) __W,
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtps_pd (__mmask8 __U, __m128 __A)
{
  return (__m256d) __builtin_ia32_cvtps2pd256_mask ((__v4sf) __A,
          (__v4df)
          _mm256_setzero_pd (),
          (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtps_pd (__m128d __W, __mmask8 __U, __m128 __A)
{
  return (__m128d) __builtin_ia32_cvtps2pd128_mask ((__v4sf) __A,
          (__v2df) __W,
          (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtps_pd (__mmask8 __U, __m128 __A)
{
  return (__m128d) __builtin_ia32_cvtps2pd128_mask ((__v4sf) __A,
          (__v2df)
          _mm_setzero_pd (),
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepi32_epi8 (__m128i __A)
{
  return (__m128i) __builtin_ia32_pmovdb128_mask ((__v4si) __A,
        (__v16qi)
        _mm_undefined_si128 (),
        (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi32_storeu_epi8 (void * __P, __mmask8 __M, __m128i __A)
{
  __builtin_ia32_pmovdb128mem_mask ((unsigned int *) __P, (__v4si) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi32_epi8 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovdb128_mask ((__v4si) __A,
        (__v16qi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepi32_epi8 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovdb128_mask ((__v4si) __A,
        (__v16qi)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepi32_epi8 (__m256i __A)
{
  return (__m128i) __builtin_ia32_pmovdb256_mask ((__v8si) __A,
        (__v16qi)
        _mm_undefined_si128 (),
        (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi32_epi8 (__m128i __O, __mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovdb256_mask ((__v8si) __A,
        (__v16qi) __O, __M);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi32_storeu_epi8 (void * __P, __mmask8 __M, __m256i __A)
{
  __builtin_ia32_pmovdb256mem_mask ((unsigned long long *) __P, (__v8si) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepi32_epi8 (__mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovdb256_mask ((__v8si) __A,
        (__v16qi)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsepi32_epi8 (__m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsdb128_mask ((__v4si) __A,
         (__v16qi)
         _mm_undefined_si128 (),
         (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtsepi32_storeu_epi8 (void * __P, __mmask8 __M, __m128i __A)
{
  __builtin_ia32_pmovsdb128mem_mask ((unsigned int *) __P, (__v4si) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtsepi32_epi8 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsdb128_mask ((__v4si) __A,
         (__v16qi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtsepi32_epi8 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsdb128_mask ((__v4si) __A,
         (__v16qi)
         _mm_setzero_si128 (),
         __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtsepi32_epi8 (__m256i __A)
{
  return (__m128i) __builtin_ia32_pmovsdb256_mask ((__v8si) __A,
         (__v16qi)
         _mm_undefined_si128 (),
         (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtsepi32_storeu_epi8 (void * __P, __mmask8 __M, __m256i __A)
{
  __builtin_ia32_pmovsdb256mem_mask ((unsigned long long *) __P, (__v8si) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtsepi32_epi8 (__m128i __O, __mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovsdb256_mask ((__v8si) __A,
         (__v16qi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtsepi32_epi8 (__mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovsdb256_mask ((__v8si) __A,
         (__v16qi)
         _mm_setzero_si128 (),
         __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtusepi32_epi8 (__m128i __A)
{
  return (__m128i) __builtin_ia32_pmovusdb128_mask ((__v4si) __A,
          (__v16qi)
          _mm_undefined_si128 (),
          (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtusepi32_storeu_epi8 (void * __P, __mmask8 __M, __m128i __A)
{
  __builtin_ia32_pmovusdb128mem_mask ((unsigned int *) __P, (__v4si) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtusepi32_epi8 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovusdb128_mask ((__v4si) __A,
          (__v16qi) __O,
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtusepi32_epi8 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovusdb128_mask ((__v4si) __A,
          (__v16qi)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtusepi32_epi8 (__m256i __A)
{
  return (__m128i) __builtin_ia32_pmovusdb256_mask ((__v8si) __A,
          (__v16qi)
          _mm_undefined_si128 (),
          (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtusepi32_storeu_epi8 (void * __P, __mmask8 __M, __m256i __A)
{
  __builtin_ia32_pmovusdb256mem_mask ((unsigned long long *) __P, (__v8si) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtusepi32_epi8 (__m128i __O, __mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovusdb256_mask ((__v8si) __A,
          (__v16qi) __O,
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtusepi32_epi8 (__mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovusdb256_mask ((__v8si) __A,
          (__v16qi)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepi32_epi16 (__m128i __A)
{
  return (__m128i) __builtin_ia32_pmovdw128_mask ((__v4si) __A,
        (__v8hi)
        _mm_setzero_si128 (),
        (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi32_storeu_epi16 (void * __P, __mmask8 __M, __m128i __A)
{
  __builtin_ia32_pmovdw128mem_mask ((unsigned long long *) __P, (__v4si) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi32_epi16 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovdw128_mask ((__v4si) __A,
        (__v8hi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepi32_epi16 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovdw128_mask ((__v4si) __A,
        (__v8hi)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepi32_epi16 (__m256i __A)
{
  return (__m128i) __builtin_ia32_pmovdw256_mask ((__v8si) __A,
        (__v8hi)
        _mm_setzero_si128 (),
        (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi32_storeu_epi16 (void * __P, __mmask8 __M, __m256i __A)
{
  __builtin_ia32_pmovdw256mem_mask ((__v8hi *) __P, (__v8si) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi32_epi16 (__m128i __O, __mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovdw256_mask ((__v8si) __A,
        (__v8hi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepi32_epi16 (__mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovdw256_mask ((__v8si) __A,
        (__v8hi)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsepi32_epi16 (__m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsdw128_mask ((__v4si) __A,
         (__v8hi)
         _mm_setzero_si128 (),
         (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtsepi32_storeu_epi16 (void * __P, __mmask8 __M, __m128i __A)
{
  __builtin_ia32_pmovsdw128mem_mask ((unsigned long long *) __P, (__v4si) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtsepi32_epi16 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsdw128_mask ((__v4si) __A,
         (__v8hi)__O,
         __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtsepi32_epi16 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsdw128_mask ((__v4si) __A,
         (__v8hi)
         _mm_setzero_si128 (),
         __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtsepi32_epi16 (__m256i __A)
{
  return (__m128i) __builtin_ia32_pmovsdw256_mask ((__v8si) __A,
         (__v8hi)
         _mm_undefined_si128 (),
         (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtsepi32_storeu_epi16 (void * __P, __mmask8 __M, __m256i __A)
{
  __builtin_ia32_pmovsdw256mem_mask ((__v8hi *) __P, (__v8si) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtsepi32_epi16 (__m128i __O, __mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovsdw256_mask ((__v8si) __A,
         (__v8hi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtsepi32_epi16 (__mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovsdw256_mask ((__v8si) __A,
         (__v8hi)
         _mm_setzero_si128 (),
         __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtusepi32_epi16 (__m128i __A)
{
  return (__m128i) __builtin_ia32_pmovusdw128_mask ((__v4si) __A,
          (__v8hi)
          _mm_undefined_si128 (),
          (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtusepi32_storeu_epi16 (void * __P, __mmask8 __M, __m128i __A)
{
  __builtin_ia32_pmovusdw128mem_mask ((unsigned long long *) __P, (__v4si) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtusepi32_epi16 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovusdw128_mask ((__v4si) __A,
          (__v8hi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtusepi32_epi16 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovusdw128_mask ((__v4si) __A,
          (__v8hi)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtusepi32_epi16 (__m256i __A)
{
  return (__m128i) __builtin_ia32_pmovusdw256_mask ((__v8si) __A,
          (__v8hi)
          _mm_undefined_si128 (),
          (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtusepi32_storeu_epi16 (void * __P, __mmask8 __M, __m256i __A)
{
  __builtin_ia32_pmovusdw256mem_mask ((__v8hi *) __P, (__v8si) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtusepi32_epi16 (__m128i __O, __mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovusdw256_mask ((__v8si) __A,
          (__v8hi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtusepi32_epi16 (__mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovusdw256_mask ((__v8si) __A,
          (__v8hi)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepi64_epi8 (__m128i __A)
{
  return (__m128i) __builtin_ia32_pmovqb128_mask ((__v2di) __A,
        (__v16qi)
        _mm_undefined_si128 (),
        (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi64_storeu_epi8 (void * __P, __mmask8 __M, __m128i __A)
{
  __builtin_ia32_pmovqb128mem_mask ((unsigned short *) __P, (__v2di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi64_epi8 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovqb128_mask ((__v2di) __A,
        (__v16qi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepi64_epi8 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovqb128_mask ((__v2di) __A,
        (__v16qi)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepi64_epi8 (__m256i __A)
{
  return (__m128i) __builtin_ia32_pmovqb256_mask ((__v4di) __A,
        (__v16qi)
        _mm_undefined_si128 (),
        (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi64_storeu_epi8 (void * __P, __mmask8 __M, __m256i __A)
{
  __builtin_ia32_pmovqb256mem_mask ((unsigned int *) __P, (__v4di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi64_epi8 (__m128i __O, __mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovqb256_mask ((__v4di) __A,
        (__v16qi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepi64_epi8 (__mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovqb256_mask ((__v4di) __A,
        (__v16qi)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsepi64_epi8 (__m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsqb128_mask ((__v2di) __A,
         (__v16qi)
         _mm_undefined_si128 (),
         (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtsepi64_storeu_epi8 (void * __P, __mmask8 __M, __m128i __A)
{
  __builtin_ia32_pmovsqb128mem_mask ((unsigned short *) __P, (__v2di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtsepi64_epi8 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsqb128_mask ((__v2di) __A,
         (__v16qi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtsepi64_epi8 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsqb128_mask ((__v2di) __A,
         (__v16qi)
         _mm_setzero_si128 (),
         __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtsepi64_epi8 (__m256i __A)
{
  return (__m128i) __builtin_ia32_pmovsqb256_mask ((__v4di) __A,
         (__v16qi)
         _mm_undefined_si128 (),
         (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtsepi64_storeu_epi8 (void * __P, __mmask8 __M, __m256i __A)
{
  __builtin_ia32_pmovsqb256mem_mask ((unsigned int *) __P, (__v4di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtsepi64_epi8 (__m128i __O, __mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovsqb256_mask ((__v4di) __A,
         (__v16qi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtsepi64_epi8 (__mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovsqb256_mask ((__v4di) __A,
         (__v16qi)
         _mm_setzero_si128 (),
         __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtusepi64_epi8 (__m128i __A)
{
  return (__m128i) __builtin_ia32_pmovusqb128_mask ((__v2di) __A,
          (__v16qi)
          _mm_undefined_si128 (),
          (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtusepi64_storeu_epi8 (void * __P, __mmask8 __M, __m128i __A)
{
  __builtin_ia32_pmovusqb128mem_mask ((unsigned short *) __P, (__v2di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtusepi64_epi8 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovusqb128_mask ((__v2di) __A,
          (__v16qi) __O,
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtusepi64_epi8 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovusqb128_mask ((__v2di) __A,
          (__v16qi)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtusepi64_epi8 (__m256i __A)
{
  return (__m128i) __builtin_ia32_pmovusqb256_mask ((__v4di) __A,
          (__v16qi)
          _mm_undefined_si128 (),
          (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtusepi64_storeu_epi8 (void * __P, __mmask8 __M, __m256i __A)
{
  __builtin_ia32_pmovusqb256mem_mask ((unsigned int *) __P, (__v4di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtusepi64_epi8 (__m128i __O, __mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovusqb256_mask ((__v4di) __A,
          (__v16qi) __O,
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtusepi64_epi8 (__mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovusqb256_mask ((__v4di) __A,
          (__v16qi)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepi64_epi16 (__m128i __A)
{
  return (__m128i) __builtin_ia32_pmovqw128_mask ((__v2di) __A,
        (__v8hi)
        _mm_undefined_si128 (),
        (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi64_storeu_epi16 (void * __P, __mmask8 __M, __m128i __A)
{
  __builtin_ia32_pmovqw128mem_mask ((unsigned int *) __P, (__v2di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi64_epi16 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovqw128_mask ((__v2di) __A,
        (__v8hi)__O,
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepi64_epi16 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovqw128_mask ((__v2di) __A,
        (__v8hi)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepi64_epi16 (__m256i __A)
{
  return (__m128i) __builtin_ia32_pmovqw256_mask ((__v4di) __A,
        (__v8hi)
        _mm_undefined_si128 (),
        (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi64_storeu_epi16 (void * __P, __mmask8 __M, __m256i __A)
{
  __builtin_ia32_pmovqw256mem_mask ((unsigned long long *) __P, (__v4di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi64_epi16 (__m128i __O, __mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovqw256_mask ((__v4di) __A,
        (__v8hi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepi64_epi16 (__mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovqw256_mask ((__v4di) __A,
        (__v8hi)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsepi64_epi16 (__m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsqw128_mask ((__v2di) __A,
         (__v8hi)
         _mm_undefined_si128 (),
         (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtsepi64_storeu_epi16 (void * __P, __mmask8 __M, __m128i __A)
{
  __builtin_ia32_pmovsqw128mem_mask ((unsigned int *) __P, (__v2di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtsepi64_epi16 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsqw128_mask ((__v2di) __A,
         (__v8hi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtsepi64_epi16 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsqw128_mask ((__v2di) __A,
         (__v8hi)
         _mm_setzero_si128 (),
         __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtsepi64_epi16 (__m256i __A)
{
  return (__m128i) __builtin_ia32_pmovsqw256_mask ((__v4di) __A,
         (__v8hi)
         _mm_undefined_si128 (),
         (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtsepi64_storeu_epi16 (void * __P, __mmask8 __M, __m256i __A)
{
  __builtin_ia32_pmovsqw256mem_mask ((unsigned long long *) __P, (__v4di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtsepi64_epi16 (__m128i __O, __mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovsqw256_mask ((__v4di) __A,
         (__v8hi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtsepi64_epi16 (__mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovsqw256_mask ((__v4di) __A,
         (__v8hi)
         _mm_setzero_si128 (),
         __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtusepi64_epi16 (__m128i __A)
{
  return (__m128i) __builtin_ia32_pmovusqw128_mask ((__v2di) __A,
          (__v8hi)
          _mm_undefined_si128 (),
          (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtusepi64_storeu_epi16 (void * __P, __mmask8 __M, __m128i __A)
{
  __builtin_ia32_pmovusqw128mem_mask ((unsigned int *) __P, (__v2di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtusepi64_epi16 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovusqw128_mask ((__v2di) __A,
          (__v8hi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtusepi64_epi16 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovusqw128_mask ((__v2di) __A,
          (__v8hi)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtusepi64_epi16 (__m256i __A)
{
  return (__m128i) __builtin_ia32_pmovusqw256_mask ((__v4di) __A,
          (__v8hi)
          _mm_undefined_si128 (),
          (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtusepi64_storeu_epi16 (void * __P, __mmask8 __M, __m256i __A)
{
  __builtin_ia32_pmovusqw256mem_mask ((unsigned long long *) __P, (__v4di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtusepi64_epi16 (__m128i __O, __mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovusqw256_mask ((__v4di) __A,
          (__v8hi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtusepi64_epi16 (__mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovusqw256_mask ((__v4di) __A,
          (__v8hi)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepi64_epi32 (__m128i __A)
{
  return (__m128i) __builtin_ia32_pmovqd128_mask ((__v2di) __A,
        (__v4si)
        _mm_undefined_si128 (),
        (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi64_storeu_epi32 (void * __P, __mmask8 __M, __m128i __A)
{
  __builtin_ia32_pmovqd128mem_mask ((unsigned long long *) __P,
        (__v2di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi64_epi32 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovqd128_mask ((__v2di) __A,
        (__v4si) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepi64_epi32 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovqd128_mask ((__v2di) __A,
        (__v4si)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepi64_epi32 (__m256i __A)
{
  return (__m128i) __builtin_ia32_pmovqd256_mask ((__v4di) __A,
        (__v4si)
        _mm_undefined_si128 (),
        (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi64_storeu_epi32 (void * __P, __mmask8 __M, __m256i __A)
{
  __builtin_ia32_pmovqd256mem_mask ((__v4si *) __P, (__v4di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi64_epi32 (__m128i __O, __mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovqd256_mask ((__v4di) __A,
        (__v4si) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepi64_epi32 (__mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovqd256_mask ((__v4di) __A,
        (__v4si)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsepi64_epi32 (__m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsqd128_mask ((__v2di) __A,
         (__v4si)
         _mm_undefined_si128 (),
         (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtsepi64_storeu_epi32 (void * __P, __mmask8 __M, __m128i __A)
{
  __builtin_ia32_pmovsqd128mem_mask ((unsigned long long *) __P, (__v2di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtsepi64_epi32 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsqd128_mask ((__v2di) __A,
         (__v4si) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtsepi64_epi32 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsqd128_mask ((__v2di) __A,
         (__v4si)
         _mm_setzero_si128 (),
         __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtsepi64_epi32 (__m256i __A)
{
  return (__m128i) __builtin_ia32_pmovsqd256_mask ((__v4di) __A,
         (__v4si)
         _mm_undefined_si128 (),
         (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtsepi64_storeu_epi32 (void * __P, __mmask8 __M, __m256i __A)
{
  __builtin_ia32_pmovsqd256mem_mask ((__v4si *) __P, (__v4di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtsepi64_epi32 (__m128i __O, __mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovsqd256_mask ((__v4di) __A,
         (__v4si)__O,
         __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtsepi64_epi32 (__mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovsqd256_mask ((__v4di) __A,
         (__v4si)
         _mm_setzero_si128 (),
         __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtusepi64_epi32 (__m128i __A)
{
  return (__m128i) __builtin_ia32_pmovusqd128_mask ((__v2di) __A,
          (__v4si)
          _mm_undefined_si128 (),
          (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtusepi64_storeu_epi32 (void * __P, __mmask8 __M, __m128i __A)
{
  __builtin_ia32_pmovusqd128mem_mask ((unsigned long long *) __P, (__v2di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtusepi64_epi32 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovusqd128_mask ((__v2di) __A,
          (__v4si) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtusepi64_epi32 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovusqd128_mask ((__v2di) __A,
          (__v4si)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtusepi64_epi32 (__m256i __A)
{
  return (__m128i) __builtin_ia32_pmovusqd256_mask ((__v4di) __A,
          (__v4si)
          _mm_undefined_si128 (),
          (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtusepi64_storeu_epi32 (void * __P, __mmask8 __M, __m256i __A)
{
  __builtin_ia32_pmovusqd256mem_mask ((__v4si *) __P, (__v4di) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtusepi64_epi32 (__m128i __O, __mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovusqd256_mask ((__v4di) __A,
          (__v4si) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtusepi64_epi32 (__mmask8 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovusqd256_mask ((__v4di) __A,
          (__v4si)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_broadcastss_ps (__m256 __O, __mmask8 __M, __m128 __A)
{
  return (__m256) __builtin_ia32_broadcastss256_mask ((__v4sf) __A,
            (__v8sf) __O,
            __M);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_broadcastss_ps (__mmask8 __M, __m128 __A)
{
  return (__m256) __builtin_ia32_broadcastss256_mask ((__v4sf) __A,
            (__v8sf)
            _mm256_setzero_ps (),
            __M);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_broadcastss_ps (__m128 __O, __mmask8 __M, __m128 __A)
{
  return (__m128) __builtin_ia32_broadcastss128_mask ((__v4sf) __A,
            (__v4sf) __O,
            __M);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_broadcastss_ps (__mmask8 __M, __m128 __A)
{
  return (__m128) __builtin_ia32_broadcastss128_mask ((__v4sf) __A,
            (__v4sf)
            _mm_setzero_ps (),
            __M);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_broadcastsd_pd (__m256d __O, __mmask8 __M, __m128d __A)
{
  return (__m256d) __builtin_ia32_broadcastsd256_mask ((__v2df) __A,
             (__v4df) __O,
             __M);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_broadcastsd_pd (__mmask8 __M, __m128d __A)
{
  return (__m256d) __builtin_ia32_broadcastsd256_mask ((__v2df) __A,
             (__v4df)
             _mm256_setzero_pd (),
             __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_broadcastd_epi32 (__m256i __O, __mmask8 __M, __m128i __A)
{
  return (__m256i) __builtin_ia32_pbroadcastd256_mask ((__v4si) __A,
             (__v8si) __O,
             __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_broadcastd_epi32 (__mmask8 __M, __m128i __A)
{
  return (__m256i) __builtin_ia32_pbroadcastd256_mask ((__v4si) __A,
             (__v8si)
             _mm256_setzero_si256 (),
             __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_set1_epi32 (__m256i __O, __mmask8 __M, int __A)
{
  return (__m256i) __builtin_ia32_pbroadcastd256_gpr_mask (__A, (__v8si) __O,
          __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_set1_epi32 (__mmask8 __M, int __A)
{
  return (__m256i) __builtin_ia32_pbroadcastd256_gpr_mask (__A,
          (__v8si)
          _mm256_setzero_si256 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_broadcastd_epi32 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pbroadcastd128_mask ((__v4si) __A,
             (__v4si) __O,
             __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_broadcastd_epi32 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pbroadcastd128_mask ((__v4si) __A,
             (__v4si)
             _mm_setzero_si128 (),
             __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_set1_epi32 (__m128i __O, __mmask8 __M, int __A)
{
  return (__m128i) __builtin_ia32_pbroadcastd128_gpr_mask (__A, (__v4si) __O,
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_set1_epi32 (__mmask8 __M, int __A)
{
  return (__m128i)
  __builtin_ia32_pbroadcastd128_gpr_mask (__A,
       (__v4si) _mm_setzero_si128 (),
       __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_broadcastq_epi64 (__m256i __O, __mmask8 __M, __m128i __A)
{
  return (__m256i) __builtin_ia32_pbroadcastq256_mask ((__v2di) __A,
             (__v4di) __O,
             __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_broadcastq_epi64 (__mmask8 __M, __m128i __A)
{
  return (__m256i) __builtin_ia32_pbroadcastq256_mask ((__v2di) __A,
             (__v4di)
             _mm256_setzero_si256 (),
             __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_set1_epi64 (__m256i __O, __mmask8 __M, long long __A)
{
  return (__m256i) __builtin_ia32_pbroadcastq256_gpr_mask (__A, (__v4di) __O,
          __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_set1_epi64 (__mmask8 __M, long long __A)
{
  return (__m256i) __builtin_ia32_pbroadcastq256_gpr_mask (__A,
          (__v4di)
          _mm256_setzero_si256 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_broadcastq_epi64 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pbroadcastq128_mask ((__v2di) __A,
             (__v2di) __O,
             __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_broadcastq_epi64 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pbroadcastq128_mask ((__v2di) __A,
             (__v2di)
             _mm_setzero_si128 (),
             __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_set1_epi64 (__m128i __O, __mmask8 __M, long long __A)
{
  return (__m128i) __builtin_ia32_pbroadcastq128_gpr_mask (__A, (__v2di) __O,
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_set1_epi64 (__mmask8 __M, long long __A)
{
  return (__m128i)
  __builtin_ia32_pbroadcastq128_gpr_mask (__A,
       (__v2di) _mm_setzero_si128 (),
       __M);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_broadcast_f32x4 (__m128 __A)
{
  return (__m256) __builtin_ia32_broadcastf32x4_256_mask ((__v4sf) __A,
                (__v8sf)_mm256_undefined_pd (),
         (__mmask8) -1);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_broadcast_f32x4 (__m256 __O, __mmask8 __M, __m128 __A)
{
  return (__m256) __builtin_ia32_broadcastf32x4_256_mask ((__v4sf) __A,
         (__v8sf) __O,
         __M);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_broadcast_f32x4 (__mmask8 __M, __m128 __A)
{
  return (__m256) __builtin_ia32_broadcastf32x4_256_mask ((__v4sf) __A,
         (__v8sf)
         _mm256_setzero_ps (),
         __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_broadcast_i32x4 (__m128i __A)
{
  return (__m256i) __builtin_ia32_broadcasti32x4_256_mask ((__v4si)
          __A,
                 (__v8si)_mm256_undefined_si256 (),
          (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_broadcast_i32x4 (__m256i __O, __mmask8 __M, __m128i __A)
{
  return (__m256i) __builtin_ia32_broadcasti32x4_256_mask ((__v4si)
          __A,
          (__v8si)
          __O, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_broadcast_i32x4 (__mmask8 __M, __m128i __A)
{
  return (__m256i) __builtin_ia32_broadcasti32x4_256_mask ((__v4si)
          __A,
          (__v8si)
          _mm256_setzero_si256 (),
          __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi8_epi32 (__m256i __W, __mmask8 __U, __m128i __A)
{
  return (__m256i) __builtin_ia32_pmovsxbd256_mask ((__v16qi) __A,
          (__v8si) __W,
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepi8_epi32 (__mmask8 __U, __m128i __A)
{
  return (__m256i) __builtin_ia32_pmovsxbd256_mask ((__v16qi) __A,
          (__v8si)
          _mm256_setzero_si256 (),
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi8_epi32 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsxbd128_mask ((__v16qi) __A,
          (__v4si) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepi8_epi32 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsxbd128_mask ((__v16qi) __A,
          (__v4si)
          _mm_setzero_si128 (),
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi8_epi64 (__m256i __W, __mmask8 __U, __m128i __A)
{
  return (__m256i) __builtin_ia32_pmovsxbq256_mask ((__v16qi) __A,
          (__v4di) __W,
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepi8_epi64 (__mmask8 __U, __m128i __A)
{
  return (__m256i) __builtin_ia32_pmovsxbq256_mask ((__v16qi) __A,
          (__v4di)
          _mm256_setzero_si256 (),
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi8_epi64 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsxbq128_mask ((__v16qi) __A,
          (__v2di) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepi8_epi64 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsxbq128_mask ((__v16qi) __A,
          (__v2di)
          _mm_setzero_si128 (),
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi16_epi32 (__m256i __W, __mmask8 __U, __m128i __A)
{
  return (__m256i) __builtin_ia32_pmovsxwd256_mask ((__v8hi) __A,
          (__v8si) __W,
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepi16_epi32 (__mmask8 __U, __m128i __A)
{
  return (__m256i) __builtin_ia32_pmovsxwd256_mask ((__v8hi) __A,
          (__v8si)
          _mm256_setzero_si256 (),
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi16_epi32 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsxwd128_mask ((__v8hi) __A,
          (__v4si) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepi16_epi32 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsxwd128_mask ((__v8hi) __A,
          (__v4si)
          _mm_setzero_si128 (),
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi16_epi64 (__m256i __W, __mmask8 __U, __m128i __A)
{
  return (__m256i) __builtin_ia32_pmovsxwq256_mask ((__v8hi) __A,
          (__v4di) __W,
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepi16_epi64 (__mmask8 __U, __m128i __A)
{
  return (__m256i) __builtin_ia32_pmovsxwq256_mask ((__v8hi) __A,
          (__v4di)
          _mm256_setzero_si256 (),
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi16_epi64 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsxwq128_mask ((__v8hi) __A,
          (__v2di) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepi16_epi64 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsxwq128_mask ((__v8hi) __A,
          (__v2di)
          _mm_setzero_si128 (),
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi32_epi64 (__m256i __W, __mmask8 __U, __m128i __X)
{
  return (__m256i) __builtin_ia32_pmovsxdq256_mask ((__v4si) __X,
          (__v4di) __W,
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepi32_epi64 (__mmask8 __U, __m128i __X)
{
  return (__m256i) __builtin_ia32_pmovsxdq256_mask ((__v4si) __X,
          (__v4di)
          _mm256_setzero_si256 (),
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi32_epi64 (__m128i __W, __mmask8 __U, __m128i __X)
{
  return (__m128i) __builtin_ia32_pmovsxdq128_mask ((__v4si) __X,
          (__v2di) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepi32_epi64 (__mmask8 __U, __m128i __X)
{
  return (__m128i) __builtin_ia32_pmovsxdq128_mask ((__v4si) __X,
          (__v2di)
          _mm_setzero_si128 (),
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepu8_epi32 (__m256i __W, __mmask8 __U, __m128i __A)
{
  return (__m256i) __builtin_ia32_pmovzxbd256_mask ((__v16qi) __A,
          (__v8si) __W,
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepu8_epi32 (__mmask8 __U, __m128i __A)
{
  return (__m256i) __builtin_ia32_pmovzxbd256_mask ((__v16qi) __A,
          (__v8si)
          _mm256_setzero_si256 (),
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepu8_epi32 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovzxbd128_mask ((__v16qi) __A,
          (__v4si) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepu8_epi32 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovzxbd128_mask ((__v16qi) __A,
          (__v4si)
          _mm_setzero_si128 (),
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepu8_epi64 (__m256i __W, __mmask8 __U, __m128i __A)
{
  return (__m256i) __builtin_ia32_pmovzxbq256_mask ((__v16qi) __A,
          (__v4di) __W,
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepu8_epi64 (__mmask8 __U, __m128i __A)
{
  return (__m256i) __builtin_ia32_pmovzxbq256_mask ((__v16qi) __A,
          (__v4di)
          _mm256_setzero_si256 (),
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepu8_epi64 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovzxbq128_mask ((__v16qi) __A,
          (__v2di) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepu8_epi64 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovzxbq128_mask ((__v16qi) __A,
          (__v2di)
          _mm_setzero_si128 (),
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepu16_epi32 (__m256i __W, __mmask8 __U, __m128i __A)
{
  return (__m256i) __builtin_ia32_pmovzxwd256_mask ((__v8hi) __A,
          (__v8si) __W,
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepu16_epi32 (__mmask8 __U, __m128i __A)
{
  return (__m256i) __builtin_ia32_pmovzxwd256_mask ((__v8hi) __A,
          (__v8si)
          _mm256_setzero_si256 (),
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepu16_epi32 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovzxwd128_mask ((__v8hi) __A,
          (__v4si) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepu16_epi32 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovzxwd128_mask ((__v8hi) __A,
          (__v4si)
          _mm_setzero_si128 (),
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepu16_epi64 (__m256i __W, __mmask8 __U, __m128i __A)
{
  return (__m256i) __builtin_ia32_pmovzxwq256_mask ((__v8hi) __A,
          (__v4di) __W,
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepu16_epi64 (__mmask8 __U, __m128i __A)
{
  return (__m256i) __builtin_ia32_pmovzxwq256_mask ((__v8hi) __A,
          (__v4di)
          _mm256_setzero_si256 (),
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepu16_epi64 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovzxwq128_mask ((__v8hi) __A,
          (__v2di) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepu16_epi64 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovzxwq128_mask ((__v8hi) __A,
          (__v2di)
          _mm_setzero_si128 (),
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepu32_epi64 (__m256i __W, __mmask8 __U, __m128i __X)
{
  return (__m256i) __builtin_ia32_pmovzxdq256_mask ((__v4si) __X,
          (__v4di) __W,
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepu32_epi64 (__mmask8 __U, __m128i __X)
{
  return (__m256i) __builtin_ia32_pmovzxdq256_mask ((__v4si) __X,
          (__v4di)
          _mm256_setzero_si256 (),
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepu32_epi64 (__m128i __W, __mmask8 __U, __m128i __X)
{
  return (__m128i) __builtin_ia32_pmovzxdq128_mask ((__v4si) __X,
          (__v2di) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepu32_epi64 (__mmask8 __U, __m128i __X)
{
  return (__m128i) __builtin_ia32_pmovzxdq128_mask ((__v4si) __X,
          (__v2di)
          _mm_setzero_si128 (),
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_rcp14_pd (__m256d __A)
{
  return (__m256d) __builtin_ia32_rcp14pd256_mask ((__v4df) __A,
           (__v4df)
           _mm256_setzero_pd (),
           (__mmask8) -1);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_rcp14_pd (__m256d __W, __mmask8 __U, __m256d __A)
{
  return (__m256d) __builtin_ia32_rcp14pd256_mask ((__v4df) __A,
           (__v4df) __W,
           (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_rcp14_pd (__mmask8 __U, __m256d __A)
{
  return (__m256d) __builtin_ia32_rcp14pd256_mask ((__v4df) __A,
           (__v4df)
           _mm256_setzero_pd (),
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_rcp14_pd (__m128d __A)
{
  return (__m128d) __builtin_ia32_rcp14pd128_mask ((__v2df) __A,
           (__v2df)
           _mm_setzero_pd (),
           (__mmask8) -1);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_rcp14_pd (__m128d __W, __mmask8 __U, __m128d __A)
{
  return (__m128d) __builtin_ia32_rcp14pd128_mask ((__v2df) __A,
           (__v2df) __W,
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_rcp14_pd (__mmask8 __U, __m128d __A)
{
  return (__m128d) __builtin_ia32_rcp14pd128_mask ((__v2df) __A,
           (__v2df)
           _mm_setzero_pd (),
           (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_rcp14_ps (__m256 __A)
{
  return (__m256) __builtin_ia32_rcp14ps256_mask ((__v8sf) __A,
          (__v8sf)
          _mm256_setzero_ps (),
          (__mmask8) -1);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_rcp14_ps (__m256 __W, __mmask8 __U, __m256 __A)
{
  return (__m256) __builtin_ia32_rcp14ps256_mask ((__v8sf) __A,
          (__v8sf) __W,
          (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_rcp14_ps (__mmask8 __U, __m256 __A)
{
  return (__m256) __builtin_ia32_rcp14ps256_mask ((__v8sf) __A,
          (__v8sf)
          _mm256_setzero_ps (),
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_rcp14_ps (__m128 __A)
{
  return (__m128) __builtin_ia32_rcp14ps128_mask ((__v4sf) __A,
          (__v4sf)
          _mm_setzero_ps (),
          (__mmask8) -1);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_rcp14_ps (__m128 __W, __mmask8 __U, __m128 __A)
{
  return (__m128) __builtin_ia32_rcp14ps128_mask ((__v4sf) __A,
          (__v4sf) __W,
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_rcp14_ps (__mmask8 __U, __m128 __A)
{
  return (__m128) __builtin_ia32_rcp14ps128_mask ((__v4sf) __A,
          (__v4sf)
          _mm_setzero_ps (),
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_rsqrt14_pd (__m256d __A)
{
  return (__m256d) __builtin_ia32_rsqrt14pd256_mask ((__v4df) __A,
           (__v4df)
           _mm256_setzero_pd (),
           (__mmask8) -1);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_rsqrt14_pd (__m256d __W, __mmask8 __U, __m256d __A)
{
  return (__m256d) __builtin_ia32_rsqrt14pd256_mask ((__v4df) __A,
           (__v4df) __W,
           (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_rsqrt14_pd (__mmask8 __U, __m256d __A)
{
  return (__m256d) __builtin_ia32_rsqrt14pd256_mask ((__v4df) __A,
           (__v4df)
           _mm256_setzero_pd (),
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_rsqrt14_pd (__m128d __A)
{
  return (__m128d) __builtin_ia32_rsqrt14pd128_mask ((__v2df) __A,
           (__v2df)
           _mm_setzero_pd (),
           (__mmask8) -1);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_rsqrt14_pd (__m128d __W, __mmask8 __U, __m128d __A)
{
  return (__m128d) __builtin_ia32_rsqrt14pd128_mask ((__v2df) __A,
           (__v2df) __W,
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_rsqrt14_pd (__mmask8 __U, __m128d __A)
{
  return (__m128d) __builtin_ia32_rsqrt14pd128_mask ((__v2df) __A,
           (__v2df)
           _mm_setzero_pd (),
           (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_rsqrt14_ps (__m256 __A)
{
  return (__m256) __builtin_ia32_rsqrt14ps256_mask ((__v8sf) __A,
          (__v8sf)
          _mm256_setzero_ps (),
          (__mmask8) -1);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_rsqrt14_ps (__m256 __W, __mmask8 __U, __m256 __A)
{
  return (__m256) __builtin_ia32_rsqrt14ps256_mask ((__v8sf) __A,
          (__v8sf) __W,
          (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_rsqrt14_ps (__mmask8 __U, __m256 __A)
{
  return (__m256) __builtin_ia32_rsqrt14ps256_mask ((__v8sf) __A,
          (__v8sf)
          _mm256_setzero_ps (),
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_rsqrt14_ps (__m128 __A)
{
  return (__m128) __builtin_ia32_rsqrt14ps128_mask ((__v4sf) __A,
          (__v4sf)
          _mm_setzero_ps (),
          (__mmask8) -1);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_rsqrt14_ps (__m128 __W, __mmask8 __U, __m128 __A)
{
  return (__m128) __builtin_ia32_rsqrt14ps128_mask ((__v4sf) __A,
          (__v4sf) __W,
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_rsqrt14_ps (__mmask8 __U, __m128 __A)
{
  return (__m128) __builtin_ia32_rsqrt14ps128_mask ((__v4sf) __A,
          (__v4sf)
          _mm_setzero_ps (),
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_sqrt_pd (__m256d __W, __mmask8 __U, __m256d __A)
{
  return (__m256d) __builtin_ia32_sqrtpd256_mask ((__v4df) __A,
        (__v4df) __W,
        (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_sqrt_pd (__mmask8 __U, __m256d __A)
{
  return (__m256d) __builtin_ia32_sqrtpd256_mask ((__v4df) __A,
        (__v4df)
        _mm256_setzero_pd (),
        (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_sqrt_pd (__m128d __W, __mmask8 __U, __m128d __A)
{
  return (__m128d) __builtin_ia32_sqrtpd128_mask ((__v2df) __A,
        (__v2df) __W,
        (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_sqrt_pd (__mmask8 __U, __m128d __A)
{
  return (__m128d) __builtin_ia32_sqrtpd128_mask ((__v2df) __A,
        (__v2df)
        _mm_setzero_pd (),
        (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_sqrt_ps (__m256 __W, __mmask8 __U, __m256 __A)
{
  return (__m256) __builtin_ia32_sqrtps256_mask ((__v8sf) __A,
       (__v8sf) __W,
       (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_sqrt_ps (__mmask8 __U, __m256 __A)
{
  return (__m256) __builtin_ia32_sqrtps256_mask ((__v8sf) __A,
       (__v8sf)
       _mm256_setzero_ps (),
       (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_sqrt_ps (__m128 __W, __mmask8 __U, __m128 __A)
{
  return (__m128) __builtin_ia32_sqrtps128_mask ((__v4sf) __A,
       (__v4sf) __W,
       (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_sqrt_ps (__mmask8 __U, __m128 __A)
{
  return (__m128) __builtin_ia32_sqrtps128_mask ((__v4sf) __A,
       (__v4sf)
       _mm_setzero_ps (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_add_epi32 (__m256i __W, __mmask8 __U, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_paddd256_mask ((__v8si) __A,
       (__v8si) __B,
       (__v8si) __W,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_add_epi32 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_paddd256_mask ((__v8si) __A,
       (__v8si) __B,
       (__v8si)
       _mm256_setzero_si256 (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_add_epi64 (__m256i __W, __mmask8 __U, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_paddq256_mask ((__v4di) __A,
       (__v4di) __B,
       (__v4di) __W,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_add_epi64 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_paddq256_mask ((__v4di) __A,
       (__v4di) __B,
       (__v4di)
       _mm256_setzero_si256 (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_sub_epi32 (__m256i __W, __mmask8 __U, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_psubd256_mask ((__v8si) __A,
       (__v8si) __B,
       (__v8si) __W,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_sub_epi32 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_psubd256_mask ((__v8si) __A,
       (__v8si) __B,
       (__v8si)
       _mm256_setzero_si256 (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_sub_epi64 (__m256i __W, __mmask8 __U, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_psubq256_mask ((__v4di) __A,
       (__v4di) __B,
       (__v4di) __W,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_sub_epi64 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_psubq256_mask ((__v4di) __A,
       (__v4di) __B,
       (__v4di)
       _mm256_setzero_si256 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_add_epi32 (__m128i __W, __mmask8 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_paddd128_mask ((__v4si) __A,
       (__v4si) __B,
       (__v4si) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_add_epi32 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_paddd128_mask ((__v4si) __A,
       (__v4si) __B,
       (__v4si)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_add_epi64 (__m128i __W, __mmask8 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_paddq128_mask ((__v2di) __A,
       (__v2di) __B,
       (__v2di) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_add_epi64 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_paddq128_mask ((__v2di) __A,
       (__v2di) __B,
       (__v2di)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_sub_epi32 (__m128i __W, __mmask8 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_psubd128_mask ((__v4si) __A,
       (__v4si) __B,
       (__v4si) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_sub_epi32 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psubd128_mask ((__v4si) __A,
       (__v4si) __B,
       (__v4si)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_sub_epi64 (__m128i __W, __mmask8 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_psubq128_mask ((__v2di) __A,
       (__v2di) __B,
       (__v2di) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_sub_epi64 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psubq128_mask ((__v2di) __A,
       (__v2di) __B,
       (__v2di)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_getexp_ps (__m256 __A)
{
  return (__m256) __builtin_ia32_getexpps256_mask ((__v8sf) __A,
         (__v8sf)
         _mm256_setzero_ps (),
         (__mmask8) -1);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_getexp_ps (__m256 __W, __mmask8 __U, __m256 __A)
{
  return (__m256) __builtin_ia32_getexpps256_mask ((__v8sf) __A,
         (__v8sf) __W,
         (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_getexp_ps (__mmask8 __U, __m256 __A)
{
  return (__m256) __builtin_ia32_getexpps256_mask ((__v8sf) __A,
         (__v8sf)
         _mm256_setzero_ps (),
         (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_getexp_pd (__m256d __A)
{
  return (__m256d) __builtin_ia32_getexppd256_mask ((__v4df) __A,
          (__v4df)
          _mm256_setzero_pd (),
          (__mmask8) -1);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_getexp_pd (__m256d __W, __mmask8 __U, __m256d __A)
{
  return (__m256d) __builtin_ia32_getexppd256_mask ((__v4df) __A,
          (__v4df) __W,
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_getexp_pd (__mmask8 __U, __m256d __A)
{
  return (__m256d) __builtin_ia32_getexppd256_mask ((__v4df) __A,
          (__v4df)
          _mm256_setzero_pd (),
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_getexp_ps (__m128 __A)
{
  return (__m128) __builtin_ia32_getexpps128_mask ((__v4sf) __A,
         (__v4sf)
         _mm_setzero_ps (),
         (__mmask8) -1);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_getexp_ps (__m128 __W, __mmask8 __U, __m128 __A)
{
  return (__m128) __builtin_ia32_getexpps128_mask ((__v4sf) __A,
         (__v4sf) __W,
         (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_getexp_ps (__mmask8 __U, __m128 __A)
{
  return (__m128) __builtin_ia32_getexpps128_mask ((__v4sf) __A,
         (__v4sf)
         _mm_setzero_ps (),
         (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_getexp_pd (__m128d __A)
{
  return (__m128d) __builtin_ia32_getexppd128_mask ((__v2df) __A,
          (__v2df)
          _mm_setzero_pd (),
          (__mmask8) -1);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_getexp_pd (__m128d __W, __mmask8 __U, __m128d __A)
{
  return (__m128d) __builtin_ia32_getexppd128_mask ((__v2df) __A,
          (__v2df) __W,
          (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_getexp_pd (__mmask8 __U, __m128d __A)
{
  return (__m128d) __builtin_ia32_getexppd128_mask ((__v2df) __A,
          (__v2df)
          _mm_setzero_pd (),
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_srl_epi32 (__m256i __W, __mmask8 __U, __m256i __A,
         __m128i __B)
{
  return (__m256i) __builtin_ia32_psrld256_mask ((__v8si) __A,
       (__v4si) __B,
       (__v8si) __W,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_srl_epi32 (__mmask8 __U, __m256i __A, __m128i __B)
{
  return (__m256i) __builtin_ia32_psrld256_mask ((__v8si) __A,
       (__v4si) __B,
       (__v8si)
       _mm256_setzero_si256 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_srl_epi32 (__m128i __W, __mmask8 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_psrld128_mask ((__v4si) __A,
       (__v4si) __B,
       (__v4si) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_srl_epi32 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psrld128_mask ((__v4si) __A,
       (__v4si) __B,
       (__v4si)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_srl_epi64 (__m256i __W, __mmask8 __U, __m256i __A,
         __m128i __B)
{
  return (__m256i) __builtin_ia32_psrlq256_mask ((__v4di) __A,
       (__v2di) __B,
       (__v4di) __W,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_srl_epi64 (__mmask8 __U, __m256i __A, __m128i __B)
{
  return (__m256i) __builtin_ia32_psrlq256_mask ((__v4di) __A,
       (__v2di) __B,
       (__v4di)
       _mm256_setzero_si256 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_srl_epi64 (__m128i __W, __mmask8 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_psrlq128_mask ((__v2di) __A,
       (__v2di) __B,
       (__v2di) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_srl_epi64 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psrlq128_mask ((__v2di) __A,
       (__v2di) __B,
       (__v2di)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_and_epi32 (__m256i __W, __mmask8 __U, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_pandd256_mask ((__v8si) __A,
       (__v8si) __B,
       (__v8si) __W,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_and_epi32 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pandd256_mask ((__v8si) __A,
       (__v8si) __B,
       (__v8si)
       _mm256_setzero_si256 (),
       (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_scalef_pd (__m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_scalefpd256_mask ((__v4df) __A,
          (__v4df) __B,
          (__v4df)
          _mm256_setzero_pd (),
          (__mmask8) -1);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_scalef_pd (__m256d __W, __mmask8 __U, __m256d __A,
         __m256d __B)
{
  return (__m256d) __builtin_ia32_scalefpd256_mask ((__v4df) __A,
          (__v4df) __B,
          (__v4df) __W,
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_scalef_pd (__mmask8 __U, __m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_scalefpd256_mask ((__v4df) __A,
          (__v4df) __B,
          (__v4df)
          _mm256_setzero_pd (),
          (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_scalef_ps (__m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_scalefps256_mask ((__v8sf) __A,
         (__v8sf) __B,
         (__v8sf)
         _mm256_setzero_ps (),
         (__mmask8) -1);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_scalef_ps (__m256 __W, __mmask8 __U, __m256 __A,
         __m256 __B)
{
  return (__m256) __builtin_ia32_scalefps256_mask ((__v8sf) __A,
         (__v8sf) __B,
         (__v8sf) __W,
         (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_scalef_ps (__mmask8 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_scalefps256_mask ((__v8sf) __A,
         (__v8sf) __B,
         (__v8sf)
         _mm256_setzero_ps (),
         (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_scalef_pd (__m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_scalefpd128_mask ((__v2df) __A,
          (__v2df) __B,
          (__v2df)
          _mm_setzero_pd (),
          (__mmask8) -1);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_scalef_pd (__m128d __W, __mmask8 __U, __m128d __A,
      __m128d __B)
{
  return (__m128d) __builtin_ia32_scalefpd128_mask ((__v2df) __A,
          (__v2df) __B,
          (__v2df) __W,
          (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_scalef_pd (__mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_scalefpd128_mask ((__v2df) __A,
          (__v2df) __B,
          (__v2df)
          _mm_setzero_pd (),
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_scalef_ps (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_scalefps128_mask ((__v4sf) __A,
         (__v4sf) __B,
         (__v4sf)
         _mm_setzero_ps (),
         (__mmask8) -1);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_scalef_ps (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_scalefps128_mask ((__v4sf) __A,
         (__v4sf) __B,
         (__v4sf) __W,
         (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_scalef_ps (__mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_scalefps128_mask ((__v4sf) __A,
         (__v4sf) __B,
         (__v4sf)
         _mm_setzero_ps (),
         (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_fmadd_pd (__m256d __A, __mmask8 __U, __m256d __B,
        __m256d __C)
{
  return (__m256d) __builtin_ia32_vfmaddpd256_mask ((__v4df) __A,
          (__v4df) __B,
          (__v4df) __C,
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask3_fmadd_pd (__m256d __A, __m256d __B, __m256d __C,
         __mmask8 __U)
{
  return (__m256d) __builtin_ia32_vfmaddpd256_mask3 ((__v4df) __A,
           (__v4df) __B,
           (__v4df) __C,
           (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_fmadd_pd (__mmask8 __U, __m256d __A, __m256d __B,
         __m256d __C)
{
  return (__m256d) __builtin_ia32_vfmaddpd256_maskz ((__v4df) __A,
           (__v4df) __B,
           (__v4df) __C,
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_fmadd_pd (__m128d __A, __mmask8 __U, __m128d __B, __m128d __C)
{
  return (__m128d) __builtin_ia32_vfmaddpd128_mask ((__v2df) __A,
          (__v2df) __B,
          (__v2df) __C,
          (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask3_fmadd_pd (__m128d __A, __m128d __B, __m128d __C,
      __mmask8 __U)
{
  return (__m128d) __builtin_ia32_vfmaddpd128_mask3 ((__v2df) __A,
           (__v2df) __B,
           (__v2df) __C,
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_fmadd_pd (__mmask8 __U, __m128d __A, __m128d __B,
      __m128d __C)
{
  return (__m128d) __builtin_ia32_vfmaddpd128_maskz ((__v2df) __A,
           (__v2df) __B,
           (__v2df) __C,
           (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_fmadd_ps (__m256 __A, __mmask8 __U, __m256 __B, __m256 __C)
{
  return (__m256) __builtin_ia32_vfmaddps256_mask ((__v8sf) __A,
         (__v8sf) __B,
         (__v8sf) __C,
         (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask3_fmadd_ps (__m256 __A, __m256 __B, __m256 __C,
         __mmask8 __U)
{
  return (__m256) __builtin_ia32_vfmaddps256_mask3 ((__v8sf) __A,
          (__v8sf) __B,
          (__v8sf) __C,
          (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_fmadd_ps (__mmask8 __U, __m256 __A, __m256 __B,
         __m256 __C)
{
  return (__m256) __builtin_ia32_vfmaddps256_maskz ((__v8sf) __A,
          (__v8sf) __B,
          (__v8sf) __C,
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_fmadd_ps (__m128 __A, __mmask8 __U, __m128 __B, __m128 __C)
{
  return (__m128) __builtin_ia32_vfmaddps128_mask ((__v4sf) __A,
         (__v4sf) __B,
         (__v4sf) __C,
         (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask3_fmadd_ps (__m128 __A, __m128 __B, __m128 __C, __mmask8 __U)
{
  return (__m128) __builtin_ia32_vfmaddps128_mask3 ((__v4sf) __A,
          (__v4sf) __B,
          (__v4sf) __C,
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_fmadd_ps (__mmask8 __U, __m128 __A, __m128 __B, __m128 __C)
{
  return (__m128) __builtin_ia32_vfmaddps128_maskz ((__v4sf) __A,
          (__v4sf) __B,
          (__v4sf) __C,
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_fmsub_pd (__m256d __A, __mmask8 __U, __m256d __B,
        __m256d __C)
{
  return (__m256d) __builtin_ia32_vfmsubpd256_mask ((__v4df) __A,
          (__v4df) __B,
          (__v4df) __C,
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask3_fmsub_pd (__m256d __A, __m256d __B, __m256d __C,
         __mmask8 __U)
{
  return (__m256d) __builtin_ia32_vfmsubpd256_mask3 ((__v4df) __A,
           (__v4df) __B,
           (__v4df) __C,
           (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_fmsub_pd (__mmask8 __U, __m256d __A, __m256d __B,
         __m256d __C)
{
  return (__m256d) __builtin_ia32_vfmsubpd256_maskz ((__v4df) __A,
           (__v4df) __B,
           (__v4df) __C,
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_fmsub_pd (__m128d __A, __mmask8 __U, __m128d __B, __m128d __C)
{
  return (__m128d) __builtin_ia32_vfmsubpd128_mask ((__v2df) __A,
          (__v2df) __B,
          (__v2df) __C,
          (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask3_fmsub_pd (__m128d __A, __m128d __B, __m128d __C,
      __mmask8 __U)
{
  return (__m128d) __builtin_ia32_vfmsubpd128_mask3 ((__v2df) __A,
           (__v2df) __B,
           (__v2df) __C,
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_fmsub_pd (__mmask8 __U, __m128d __A, __m128d __B,
      __m128d __C)
{
  return (__m128d) __builtin_ia32_vfmsubpd128_maskz ((__v2df) __A,
           (__v2df) __B,
           (__v2df) __C,
           (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_fmsub_ps (__m256 __A, __mmask8 __U, __m256 __B, __m256 __C)
{
  return (__m256) __builtin_ia32_vfmsubps256_mask ((__v8sf) __A,
         (__v8sf) __B,
         (__v8sf) __C,
         (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask3_fmsub_ps (__m256 __A, __m256 __B, __m256 __C,
         __mmask8 __U)
{
  return (__m256) __builtin_ia32_vfmsubps256_mask3 ((__v8sf) __A,
          (__v8sf) __B,
          (__v8sf) __C,
          (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_fmsub_ps (__mmask8 __U, __m256 __A, __m256 __B,
         __m256 __C)
{
  return (__m256) __builtin_ia32_vfmsubps256_maskz ((__v8sf) __A,
          (__v8sf) __B,
          (__v8sf) __C,
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_fmsub_ps (__m128 __A, __mmask8 __U, __m128 __B, __m128 __C)
{
  return (__m128) __builtin_ia32_vfmsubps128_mask ((__v4sf) __A,
         (__v4sf) __B,
         (__v4sf) __C,
         (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask3_fmsub_ps (__m128 __A, __m128 __B, __m128 __C, __mmask8 __U)
{
  return (__m128) __builtin_ia32_vfmsubps128_mask3 ((__v4sf) __A,
          (__v4sf) __B,
          (__v4sf) __C,
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_fmsub_ps (__mmask8 __U, __m128 __A, __m128 __B, __m128 __C)
{
  return (__m128) __builtin_ia32_vfmsubps128_maskz ((__v4sf) __A,
          (__v4sf) __B,
          (__v4sf) __C,
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_fmaddsub_pd (__m256d __A, __mmask8 __U, __m256d __B,
    __m256d __C)
{
  return (__m256d) __builtin_ia32_vfmaddsubpd256_mask ((__v4df) __A,
             (__v4df) __B,
             (__v4df) __C,
             (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask3_fmaddsub_pd (__m256d __A, __m256d __B, __m256d __C,
     __mmask8 __U)
{
  return (__m256d) __builtin_ia32_vfmaddsubpd256_mask3 ((__v4df) __A,
       (__v4df) __B,
       (__v4df) __C,
       (__mmask8)
       __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_fmaddsub_pd (__mmask8 __U, __m256d __A, __m256d __B,
     __m256d __C)
{
  return (__m256d) __builtin_ia32_vfmaddsubpd256_maskz ((__v4df) __A,
       (__v4df) __B,
       (__v4df) __C,
       (__mmask8)
       __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_fmaddsub_pd (__m128d __A, __mmask8 __U, __m128d __B,
        __m128d __C)
{
  return (__m128d) __builtin_ia32_vfmaddsubpd128_mask ((__v2df) __A,
             (__v2df) __B,
             (__v2df) __C,
             (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask3_fmaddsub_pd (__m128d __A, __m128d __B, __m128d __C,
         __mmask8 __U)
{
  return (__m128d) __builtin_ia32_vfmaddsubpd128_mask3 ((__v2df) __A,
       (__v2df) __B,
       (__v2df) __C,
       (__mmask8)
       __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_fmaddsub_pd (__mmask8 __U, __m128d __A, __m128d __B,
         __m128d __C)
{
  return (__m128d) __builtin_ia32_vfmaddsubpd128_maskz ((__v2df) __A,
       (__v2df) __B,
       (__v2df) __C,
       (__mmask8)
       __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_fmaddsub_ps (__m256 __A, __mmask8 __U, __m256 __B,
    __m256 __C)
{
  return (__m256) __builtin_ia32_vfmaddsubps256_mask ((__v8sf) __A,
            (__v8sf) __B,
            (__v8sf) __C,
            (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask3_fmaddsub_ps (__m256 __A, __m256 __B, __m256 __C,
     __mmask8 __U)
{
  return (__m256) __builtin_ia32_vfmaddsubps256_mask3 ((__v8sf) __A,
             (__v8sf) __B,
             (__v8sf) __C,
             (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_fmaddsub_ps (__mmask8 __U, __m256 __A, __m256 __B,
     __m256 __C)
{
  return (__m256) __builtin_ia32_vfmaddsubps256_maskz ((__v8sf) __A,
             (__v8sf) __B,
             (__v8sf) __C,
             (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_fmaddsub_ps (__m128 __A, __mmask8 __U, __m128 __B, __m128 __C)
{
  return (__m128) __builtin_ia32_vfmaddsubps128_mask ((__v4sf) __A,
            (__v4sf) __B,
            (__v4sf) __C,
            (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask3_fmaddsub_ps (__m128 __A, __m128 __B, __m128 __C,
         __mmask8 __U)
{
  return (__m128) __builtin_ia32_vfmaddsubps128_mask3 ((__v4sf) __A,
             (__v4sf) __B,
             (__v4sf) __C,
             (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_fmaddsub_ps (__mmask8 __U, __m128 __A, __m128 __B,
         __m128 __C)
{
  return (__m128) __builtin_ia32_vfmaddsubps128_maskz ((__v4sf) __A,
             (__v4sf) __B,
             (__v4sf) __C,
             (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_fmsubadd_pd (__m256d __A, __mmask8 __U, __m256d __B,
    __m256d __C)
{
  return (__m256d) __builtin_ia32_vfmaddsubpd256_mask ((__v4df) __A,
             (__v4df) __B,
             -(__v4df) __C,
             (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask3_fmsubadd_pd (__m256d __A, __m256d __B, __m256d __C,
     __mmask8 __U)
{
  return (__m256d) __builtin_ia32_vfmsubaddpd256_mask3 ((__v4df) __A,
       (__v4df) __B,
       (__v4df) __C,
       (__mmask8)
       __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_fmsubadd_pd (__mmask8 __U, __m256d __A, __m256d __B,
     __m256d __C)
{
  return (__m256d) __builtin_ia32_vfmaddsubpd256_maskz ((__v4df) __A,
       (__v4df) __B,
       -(__v4df) __C,
       (__mmask8)
       __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_fmsubadd_pd (__m128d __A, __mmask8 __U, __m128d __B,
        __m128d __C)
{
  return (__m128d) __builtin_ia32_vfmaddsubpd128_mask ((__v2df) __A,
             (__v2df) __B,
             -(__v2df) __C,
             (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask3_fmsubadd_pd (__m128d __A, __m128d __B, __m128d __C,
         __mmask8 __U)
{
  return (__m128d) __builtin_ia32_vfmsubaddpd128_mask3 ((__v2df) __A,
       (__v2df) __B,
       (__v2df) __C,
       (__mmask8)
       __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_fmsubadd_pd (__mmask8 __U, __m128d __A, __m128d __B,
         __m128d __C)
{
  return (__m128d) __builtin_ia32_vfmaddsubpd128_maskz ((__v2df) __A,
       (__v2df) __B,
       -(__v2df) __C,
       (__mmask8)
       __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_fmsubadd_ps (__m256 __A, __mmask8 __U, __m256 __B,
    __m256 __C)
{
  return (__m256) __builtin_ia32_vfmaddsubps256_mask ((__v8sf) __A,
            (__v8sf) __B,
            -(__v8sf) __C,
            (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask3_fmsubadd_ps (__m256 __A, __m256 __B, __m256 __C,
     __mmask8 __U)
{
  return (__m256) __builtin_ia32_vfmsubaddps256_mask3 ((__v8sf) __A,
             (__v8sf) __B,
             (__v8sf) __C,
             (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_fmsubadd_ps (__mmask8 __U, __m256 __A, __m256 __B,
     __m256 __C)
{
  return (__m256) __builtin_ia32_vfmaddsubps256_maskz ((__v8sf) __A,
             (__v8sf) __B,
             -(__v8sf) __C,
             (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_fmsubadd_ps (__m128 __A, __mmask8 __U, __m128 __B, __m128 __C)
{
  return (__m128) __builtin_ia32_vfmaddsubps128_mask ((__v4sf) __A,
            (__v4sf) __B,
            -(__v4sf) __C,
            (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask3_fmsubadd_ps (__m128 __A, __m128 __B, __m128 __C,
         __mmask8 __U)
{
  return (__m128) __builtin_ia32_vfmsubaddps128_mask3 ((__v4sf) __A,
             (__v4sf) __B,
             (__v4sf) __C,
             (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_fmsubadd_ps (__mmask8 __U, __m128 __A, __m128 __B,
         __m128 __C)
{
  return (__m128) __builtin_ia32_vfmaddsubps128_maskz ((__v4sf) __A,
             (__v4sf) __B,
             -(__v4sf) __C,
             (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_fnmadd_pd (__m256d __A, __mmask8 __U, __m256d __B,
         __m256d __C)
{
  return (__m256d) __builtin_ia32_vfnmaddpd256_mask ((__v4df) __A,
           (__v4df) __B,
           (__v4df) __C,
           (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask3_fnmadd_pd (__m256d __A, __m256d __B, __m256d __C,
   __mmask8 __U)
{
  return (__m256d) __builtin_ia32_vfnmaddpd256_mask3 ((__v4df) __A,
            (__v4df) __B,
            (__v4df) __C,
            (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_fnmadd_pd (__mmask8 __U, __m256d __A, __m256d __B,
   __m256d __C)
{
  return (__m256d) __builtin_ia32_vfnmaddpd256_maskz ((__v4df) __A,
            (__v4df) __B,
            (__v4df) __C,
            (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_fnmadd_pd (__m128d __A, __mmask8 __U, __m128d __B,
      __m128d __C)
{
  return (__m128d) __builtin_ia32_vfnmaddpd128_mask ((__v2df) __A,
           (__v2df) __B,
           (__v2df) __C,
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask3_fnmadd_pd (__m128d __A, __m128d __B, __m128d __C,
       __mmask8 __U)
{
  return (__m128d) __builtin_ia32_vfnmaddpd128_mask3 ((__v2df) __A,
            (__v2df) __B,
            (__v2df) __C,
            (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_fnmadd_pd (__mmask8 __U, __m128d __A, __m128d __B,
       __m128d __C)
{
  return (__m128d) __builtin_ia32_vfnmaddpd128_maskz ((__v2df) __A,
            (__v2df) __B,
            (__v2df) __C,
            (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_fnmadd_ps (__m256 __A, __mmask8 __U, __m256 __B,
         __m256 __C)
{
  return (__m256) __builtin_ia32_vfnmaddps256_mask ((__v8sf) __A,
          (__v8sf) __B,
          (__v8sf) __C,
          (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask3_fnmadd_ps (__m256 __A, __m256 __B, __m256 __C,
   __mmask8 __U)
{
  return (__m256) __builtin_ia32_vfnmaddps256_mask3 ((__v8sf) __A,
           (__v8sf) __B,
           (__v8sf) __C,
           (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_fnmadd_ps (__mmask8 __U, __m256 __A, __m256 __B,
   __m256 __C)
{
  return (__m256) __builtin_ia32_vfnmaddps256_maskz ((__v8sf) __A,
           (__v8sf) __B,
           (__v8sf) __C,
           (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_fnmadd_ps (__m128 __A, __mmask8 __U, __m128 __B, __m128 __C)
{
  return (__m128) __builtin_ia32_vfnmaddps128_mask ((__v4sf) __A,
          (__v4sf) __B,
          (__v4sf) __C,
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask3_fnmadd_ps (__m128 __A, __m128 __B, __m128 __C, __mmask8 __U)
{
  return (__m128) __builtin_ia32_vfnmaddps128_mask3 ((__v4sf) __A,
           (__v4sf) __B,
           (__v4sf) __C,
           (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_fnmadd_ps (__mmask8 __U, __m128 __A, __m128 __B, __m128 __C)
{
  return (__m128) __builtin_ia32_vfnmaddps128_maskz ((__v4sf) __A,
           (__v4sf) __B,
           (__v4sf) __C,
           (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_fnmsub_pd (__m256d __A, __mmask8 __U, __m256d __B,
         __m256d __C)
{
  return (__m256d) __builtin_ia32_vfnmsubpd256_mask ((__v4df) __A,
           (__v4df) __B,
           (__v4df) __C,
           (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask3_fnmsub_pd (__m256d __A, __m256d __B, __m256d __C,
   __mmask8 __U)
{
  return (__m256d) __builtin_ia32_vfnmsubpd256_mask3 ((__v4df) __A,
            (__v4df) __B,
            (__v4df) __C,
            (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_fnmsub_pd (__mmask8 __U, __m256d __A, __m256d __B,
   __m256d __C)
{
  return (__m256d) __builtin_ia32_vfnmsubpd256_maskz ((__v4df) __A,
            (__v4df) __B,
            (__v4df) __C,
            (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_fnmsub_pd (__m128d __A, __mmask8 __U, __m128d __B,
      __m128d __C)
{
  return (__m128d) __builtin_ia32_vfnmsubpd128_mask ((__v2df) __A,
           (__v2df) __B,
           (__v2df) __C,
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask3_fnmsub_pd (__m128d __A, __m128d __B, __m128d __C,
       __mmask8 __U)
{
  return (__m128d) __builtin_ia32_vfnmsubpd128_mask3 ((__v2df) __A,
            (__v2df) __B,
            (__v2df) __C,
            (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_fnmsub_pd (__mmask8 __U, __m128d __A, __m128d __B,
       __m128d __C)
{
  return (__m128d) __builtin_ia32_vfnmsubpd128_maskz ((__v2df) __A,
            (__v2df) __B,
            (__v2df) __C,
            (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_fnmsub_ps (__m256 __A, __mmask8 __U, __m256 __B,
         __m256 __C)
{
  return (__m256) __builtin_ia32_vfnmsubps256_mask ((__v8sf) __A,
          (__v8sf) __B,
          (__v8sf) __C,
          (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask3_fnmsub_ps (__m256 __A, __m256 __B, __m256 __C,
   __mmask8 __U)
{
  return (__m256) __builtin_ia32_vfnmsubps256_mask3 ((__v8sf) __A,
           (__v8sf) __B,
           (__v8sf) __C,
           (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_fnmsub_ps (__mmask8 __U, __m256 __A, __m256 __B,
   __m256 __C)
{
  return (__m256) __builtin_ia32_vfnmsubps256_maskz ((__v8sf) __A,
           (__v8sf) __B,
           (__v8sf) __C,
           (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_fnmsub_ps (__m128 __A, __mmask8 __U, __m128 __B, __m128 __C)
{
  return (__m128) __builtin_ia32_vfnmsubps128_mask ((__v4sf) __A,
          (__v4sf) __B,
          (__v4sf) __C,
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask3_fnmsub_ps (__m128 __A, __m128 __B, __m128 __C, __mmask8 __U)
{
  return (__m128) __builtin_ia32_vfnmsubps128_mask3 ((__v4sf) __A,
           (__v4sf) __B,
           (__v4sf) __C,
           (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_fnmsub_ps (__mmask8 __U, __m128 __A, __m128 __B, __m128 __C)
{
  return (__m128) __builtin_ia32_vfnmsubps128_maskz ((__v4sf) __A,
           (__v4sf) __B,
           (__v4sf) __C,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_and_epi32 (__m128i __W, __mmask8 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_pandd128_mask ((__v4si) __A,
       (__v4si) __B,
       (__v4si) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_and_epi32 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pandd128_mask ((__v4si) __A,
       (__v4si) __B,
       (__v4si)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_andnot_epi32 (__m256i __W, __mmask8 __U, __m256i __A,
     __m256i __B)
{
  return (__m256i) __builtin_ia32_pandnd256_mask ((__v8si) __A,
        (__v8si) __B,
        (__v8si) __W,
        (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_andnot_epi32 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pandnd256_mask ((__v8si) __A,
        (__v8si) __B,
        (__v8si)
        _mm256_setzero_si256 (),
        (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_andnot_epi32 (__m128i __W, __mmask8 __U, __m128i __A,
         __m128i __B)
{
  return (__m128i) __builtin_ia32_pandnd128_mask ((__v4si) __A,
        (__v4si) __B,
        (__v4si) __W,
        (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_andnot_epi32 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pandnd128_mask ((__v4si) __A,
        (__v4si) __B,
        (__v4si)
        _mm_setzero_si128 (),
        (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_or_epi32 (__m256i __W, __mmask8 __U, __m256i __A,
        __m256i __B)
{
  return (__m256i) __builtin_ia32_pord256_mask ((__v8si) __A,
      (__v8si) __B,
      (__v8si) __W,
      (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_or_epi32 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pord256_mask ((__v8si) __A,
      (__v8si) __B,
      (__v8si)
      _mm256_setzero_si256 (),
      (__mmask8) __U);
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_or_epi32 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v8su)__A | (__v8su)__B);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_or_epi32 (__m128i __W, __mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pord128_mask ((__v4si) __A,
      (__v4si) __B,
      (__v4si) __W,
      (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_or_epi32 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pord128_mask ((__v4si) __A,
      (__v4si) __B,
      (__v4si)
      _mm_setzero_si128 (),
      (__mmask8) __U);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_or_epi32 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v4su)__A | (__v4su)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_xor_epi32 (__m256i __W, __mmask8 __U, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_pxord256_mask ((__v8si) __A,
       (__v8si) __B,
       (__v8si) __W,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_xor_epi32 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pxord256_mask ((__v8si) __A,
       (__v8si) __B,
       (__v8si)
       _mm256_setzero_si256 (),
       (__mmask8) __U);
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_xor_epi32 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v8su)__A ^ (__v8su)__B);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_xor_epi32 (__m128i __W, __mmask8 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_pxord128_mask ((__v4si) __A,
       (__v4si) __B,
       (__v4si) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_xor_epi32 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pxord128_mask ((__v4si) __A,
       (__v4si) __B,
       (__v4si)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_xor_epi32 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v4su)__A ^ (__v4su)__B);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtpd_ps (__m128 __W, __mmask8 __U, __m128d __A)
{
  return (__m128) __builtin_ia32_cvtpd2ps_mask ((__v2df) __A,
      (__v4sf) __W,
      (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtpd_ps (__mmask8 __U, __m128d __A)
{
  return (__m128) __builtin_ia32_cvtpd2ps_mask ((__v2df) __A,
      (__v4sf)
      _mm_setzero_ps (),
      (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtpd_ps (__m128 __W, __mmask8 __U, __m256d __A)
{
  return (__m128) __builtin_ia32_cvtpd2ps256_mask ((__v4df) __A,
         (__v4sf) __W,
         (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtpd_ps (__mmask8 __U, __m256d __A)
{
  return (__m128) __builtin_ia32_cvtpd2ps256_mask ((__v4df) __A,
         (__v4sf)
         _mm_setzero_ps (),
         (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtps_epi32 (__m256i __W, __mmask8 __U, __m256 __A)
{
  return (__m256i) __builtin_ia32_cvtps2dq256_mask ((__v8sf) __A,
          (__v8si) __W,
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtps_epi32 (__mmask8 __U, __m256 __A)
{
  return (__m256i) __builtin_ia32_cvtps2dq256_mask ((__v8sf) __A,
          (__v8si)
          _mm256_setzero_si256 (),
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtps_epi32 (__m128i __W, __mmask8 __U, __m128 __A)
{
  return (__m128i) __builtin_ia32_cvtps2dq128_mask ((__v4sf) __A,
          (__v4si) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtps_epi32 (__mmask8 __U, __m128 __A)
{
  return (__m128i) __builtin_ia32_cvtps2dq128_mask ((__v4sf) __A,
          (__v4si)
          _mm_setzero_si128 (),
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtps_epu32 (__m256 __A)
{
  return (__m256i) __builtin_ia32_cvtps2udq256_mask ((__v8sf) __A,
           (__v8si)
           _mm256_setzero_si256 (),
           (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtps_epu32 (__m256i __W, __mmask8 __U, __m256 __A)
{
  return (__m256i) __builtin_ia32_cvtps2udq256_mask ((__v8sf) __A,
           (__v8si) __W,
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtps_epu32 (__mmask8 __U, __m256 __A)
{
  return (__m256i) __builtin_ia32_cvtps2udq256_mask ((__v8sf) __A,
           (__v8si)
           _mm256_setzero_si256 (),
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtps_epu32 (__m128 __A)
{
  return (__m128i) __builtin_ia32_cvtps2udq128_mask ((__v4sf) __A,
           (__v4si)
           _mm_setzero_si128 (),
           (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtps_epu32 (__m128i __W, __mmask8 __U, __m128 __A)
{
  return (__m128i) __builtin_ia32_cvtps2udq128_mask ((__v4sf) __A,
           (__v4si) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtps_epu32 (__mmask8 __U, __m128 __A)
{
  return (__m128i) __builtin_ia32_cvtps2udq128_mask ((__v4sf) __A,
           (__v4si)
           _mm_setzero_si128 (),
           (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_movedup_pd (__m256d __W, __mmask8 __U, __m256d __A)
{
  return (__m256d) __builtin_ia32_movddup256_mask ((__v4df) __A,
         (__v4df) __W,
         (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_movedup_pd (__mmask8 __U, __m256d __A)
{
  return (__m256d) __builtin_ia32_movddup256_mask ((__v4df) __A,
         (__v4df)
         _mm256_setzero_pd (),
         (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_movedup_pd (__m128d __W, __mmask8 __U, __m128d __A)
{
  return (__m128d) __builtin_ia32_movddup128_mask ((__v2df) __A,
         (__v2df) __W,
         (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_movedup_pd (__mmask8 __U, __m128d __A)
{
  return (__m128d) __builtin_ia32_movddup128_mask ((__v2df) __A,
         (__v2df)
         _mm_setzero_pd (),
         (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_movehdup_ps (__m256 __W, __mmask8 __U, __m256 __A)
{
  return (__m256) __builtin_ia32_movshdup256_mask ((__v8sf) __A,
         (__v8sf) __W,
         (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_movehdup_ps (__mmask8 __U, __m256 __A)
{
  return (__m256) __builtin_ia32_movshdup256_mask ((__v8sf) __A,
         (__v8sf)
         _mm256_setzero_ps (),
         (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_movehdup_ps (__m128 __W, __mmask8 __U, __m128 __A)
{
  return (__m128) __builtin_ia32_movshdup128_mask ((__v4sf) __A,
         (__v4sf) __W,
         (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_movehdup_ps (__mmask8 __U, __m128 __A)
{
  return (__m128) __builtin_ia32_movshdup128_mask ((__v4sf) __A,
         (__v4sf)
         _mm_setzero_ps (),
         (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_moveldup_ps (__m256 __W, __mmask8 __U, __m256 __A)
{
  return (__m256) __builtin_ia32_movsldup256_mask ((__v8sf) __A,
         (__v8sf) __W,
         (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_moveldup_ps (__mmask8 __U, __m256 __A)
{
  return (__m256) __builtin_ia32_movsldup256_mask ((__v8sf) __A,
         (__v8sf)
         _mm256_setzero_ps (),
         (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_moveldup_ps (__m128 __W, __mmask8 __U, __m128 __A)
{
  return (__m128) __builtin_ia32_movsldup128_mask ((__v4sf) __A,
         (__v4sf) __W,
         (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_moveldup_ps (__mmask8 __U, __m128 __A)
{
  return (__m128) __builtin_ia32_movsldup128_mask ((__v4sf) __A,
         (__v4sf)
         _mm_setzero_ps (),
         (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_unpackhi_epi32 (__m128i __W, __mmask8 __U, __m128i __A,
    __m128i __B)
{
  return (__m128i) __builtin_ia32_punpckhdq128_mask ((__v4si) __A,
           (__v4si) __B,
           (__v4si) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_unpackhi_epi32 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_punpckhdq128_mask ((__v4si) __A,
           (__v4si) __B,
           (__v4si)
           _mm_setzero_si128 (),
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_unpackhi_epi32 (__m256i __W, __mmask8 __U, __m256i __A,
       __m256i __B)
{
  return (__m256i) __builtin_ia32_punpckhdq256_mask ((__v8si) __A,
           (__v8si) __B,
           (__v8si) __W,
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_unpackhi_epi32 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_punpckhdq256_mask ((__v8si) __A,
           (__v8si) __B,
           (__v8si)
           _mm256_setzero_si256 (),
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_unpackhi_epi64 (__m128i __W, __mmask8 __U, __m128i __A,
    __m128i __B)
{
  return (__m128i) __builtin_ia32_punpckhqdq128_mask ((__v2di) __A,
            (__v2di) __B,
            (__v2di) __W,
            (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_unpackhi_epi64 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_punpckhqdq128_mask ((__v2di) __A,
            (__v2di) __B,
            (__v2di)
            _mm_setzero_si128 (),
            (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_unpackhi_epi64 (__m256i __W, __mmask8 __U, __m256i __A,
       __m256i __B)
{
  return (__m256i) __builtin_ia32_punpckhqdq256_mask ((__v4di) __A,
            (__v4di) __B,
            (__v4di) __W,
            (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_unpackhi_epi64 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_punpckhqdq256_mask ((__v4di) __A,
            (__v4di) __B,
            (__v4di)
            _mm256_setzero_si256 (),
            (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_unpacklo_epi32 (__m128i __W, __mmask8 __U, __m128i __A,
    __m128i __B)
{
  return (__m128i) __builtin_ia32_punpckldq128_mask ((__v4si) __A,
           (__v4si) __B,
           (__v4si) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_unpacklo_epi32 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_punpckldq128_mask ((__v4si) __A,
           (__v4si) __B,
           (__v4si)
           _mm_setzero_si128 (),
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_unpacklo_epi32 (__m256i __W, __mmask8 __U, __m256i __A,
       __m256i __B)
{
  return (__m256i) __builtin_ia32_punpckldq256_mask ((__v8si) __A,
           (__v8si) __B,
           (__v8si) __W,
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_unpacklo_epi32 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_punpckldq256_mask ((__v8si) __A,
           (__v8si) __B,
           (__v8si)
           _mm256_setzero_si256 (),
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_unpacklo_epi64 (__m128i __W, __mmask8 __U, __m128i __A,
    __m128i __B)
{
  return (__m128i) __builtin_ia32_punpcklqdq128_mask ((__v2di) __A,
            (__v2di) __B,
            (__v2di) __W,
            (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_unpacklo_epi64 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_punpcklqdq128_mask ((__v2di) __A,
            (__v2di) __B,
            (__v2di)
            _mm_setzero_si128 (),
            (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_unpacklo_epi64 (__m256i __W, __mmask8 __U, __m256i __A,
       __m256i __B)
{
  return (__m256i) __builtin_ia32_punpcklqdq256_mask ((__v4di) __A,
            (__v4di) __B,
            (__v4di) __W,
            (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_unpacklo_epi64 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_punpcklqdq256_mask ((__v4di) __A,
            (__v4di) __B,
            (__v4di)
            _mm256_setzero_si256 (),
            (__mmask8) __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpeq_epu32_mask (__m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ucmpd128_mask ((__v4si) __A,
         (__v4si) __B, 0,
         (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpeq_epi32_mask (__m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_pcmpeqd128_mask ((__v4si) __A,
          (__v4si) __B,
          (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpeq_epu32_mask (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ucmpd128_mask ((__v4si) __A,
         (__v4si) __B, 0, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpeq_epi32_mask (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_pcmpeqd128_mask ((__v4si) __A,
          (__v4si) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpeq_epu32_mask (__m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_ucmpd256_mask ((__v8si) __A,
         (__v8si) __B, 0,
         (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpeq_epi32_mask (__m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_pcmpeqd256_mask ((__v8si) __A,
          (__v8si) __B,
          (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpeq_epu32_mask (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_ucmpd256_mask ((__v8si) __A,
         (__v8si) __B, 0, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpeq_epi32_mask (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_pcmpeqd256_mask ((__v8si) __A,
          (__v8si) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpeq_epu64_mask (__m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ucmpq128_mask ((__v2di) __A,
         (__v2di) __B, 0,
         (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpeq_epi64_mask (__m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_pcmpeqq128_mask ((__v2di) __A,
          (__v2di) __B,
          (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpeq_epu64_mask (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ucmpq128_mask ((__v2di) __A,
         (__v2di) __B, 0, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpeq_epi64_mask (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_pcmpeqq128_mask ((__v2di) __A,
          (__v2di) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpeq_epu64_mask (__m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_ucmpq256_mask ((__v4di) __A,
         (__v4di) __B, 0,
         (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpeq_epi64_mask (__m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_pcmpeqq256_mask ((__v4di) __A,
          (__v4di) __B,
          (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpeq_epu64_mask (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_ucmpq256_mask ((__v4di) __A,
         (__v4di) __B, 0, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpeq_epi64_mask (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_pcmpeqq256_mask ((__v4di) __A,
          (__v4di) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpgt_epu32_mask (__m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ucmpd128_mask ((__v4si) __A,
         (__v4si) __B, 6,
         (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpgt_epi32_mask (__m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_pcmpgtd128_mask ((__v4si) __A,
          (__v4si) __B,
          (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpgt_epu32_mask (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ucmpd128_mask ((__v4si) __A,
         (__v4si) __B, 6, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpgt_epi32_mask (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_pcmpgtd128_mask ((__v4si) __A,
          (__v4si) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpgt_epu32_mask (__m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_ucmpd256_mask ((__v8si) __A,
         (__v8si) __B, 6,
         (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpgt_epi32_mask (__m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_pcmpgtd256_mask ((__v8si) __A,
          (__v8si) __B,
          (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpgt_epu32_mask (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_ucmpd256_mask ((__v8si) __A,
         (__v8si) __B, 6, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpgt_epi32_mask (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_pcmpgtd256_mask ((__v8si) __A,
          (__v8si) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpgt_epu64_mask (__m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ucmpq128_mask ((__v2di) __A,
         (__v2di) __B, 6,
         (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpgt_epi64_mask (__m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_pcmpgtq128_mask ((__v2di) __A,
          (__v2di) __B,
          (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpgt_epu64_mask (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ucmpq128_mask ((__v2di) __A,
         (__v2di) __B, 6, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpgt_epi64_mask (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_pcmpgtq128_mask ((__v2di) __A,
          (__v2di) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpgt_epu64_mask (__m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_ucmpq256_mask ((__v4di) __A,
         (__v4di) __B, 6,
         (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpgt_epi64_mask (__m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_pcmpgtq256_mask ((__v4di) __A,
          (__v4di) __B,
          (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpgt_epu64_mask (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_ucmpq256_mask ((__v4di) __A,
         (__v4di) __B, 6, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpgt_epi64_mask (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_pcmpgtq256_mask ((__v4di) __A,
          (__v4di) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_test_epi32_mask (__m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ptestmd128 ((__v4si) __A,
            (__v4si) __B,
            (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_test_epi32_mask (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ptestmd128 ((__v4si) __A,
            (__v4si) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_test_epi32_mask (__m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_ptestmd256 ((__v8si) __A,
            (__v8si) __B,
            (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_test_epi32_mask (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_ptestmd256 ((__v8si) __A,
            (__v8si) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_test_epi64_mask (__m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ptestmq128 ((__v2di) __A,
            (__v2di) __B,
            (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_test_epi64_mask (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ptestmq128 ((__v2di) __A,
            (__v2di) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_test_epi64_mask (__m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_ptestmq256 ((__v4di) __A,
            (__v4di) __B,
            (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_test_epi64_mask (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_ptestmq256 ((__v4di) __A,
            (__v4di) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_testn_epi32_mask (__m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ptestnmd128 ((__v4si) __A,
      (__v4si) __B,
      (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_testn_epi32_mask (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ptestnmd128 ((__v4si) __A,
      (__v4si) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_testn_epi32_mask (__m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_ptestnmd256 ((__v8si) __A,
      (__v8si) __B,
      (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_testn_epi32_mask (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_ptestnmd256 ((__v8si) __A,
      (__v8si) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_testn_epi64_mask (__m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ptestnmq128 ((__v2di) __A,
      (__v2di) __B,
      (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_testn_epi64_mask (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ptestnmq128 ((__v2di) __A,
      (__v2di) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_testn_epi64_mask (__m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_ptestnmq256 ((__v4di) __A,
      (__v4di) __B,
      (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_testn_epi64_mask (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__mmask8) __builtin_ia32_ptestnmq256 ((__v4di) __A,
      (__v4di) __B, __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_compress_pd (__m256d __W, __mmask8 __U, __m256d __A)
{
  return (__m256d) __builtin_ia32_compressdf256_mask ((__v4df) __A,
            (__v4df) __W,
            (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_compress_pd (__mmask8 __U, __m256d __A)
{
  return (__m256d) __builtin_ia32_compressdf256_mask ((__v4df) __A,
            (__v4df)
            _mm256_setzero_pd (),
            (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_compressstoreu_pd (void *__P, __mmask8 __U, __m256d __A)
{
  __builtin_ia32_compressstoredf256_mask ((__v4df *) __P,
       (__v4df) __A,
       (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_compress_pd (__m128d __W, __mmask8 __U, __m128d __A)
{
  return (__m128d) __builtin_ia32_compressdf128_mask ((__v2df) __A,
            (__v2df) __W,
            (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_compress_pd (__mmask8 __U, __m128d __A)
{
  return (__m128d) __builtin_ia32_compressdf128_mask ((__v2df) __A,
            (__v2df)
            _mm_setzero_pd (),
            (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_compressstoreu_pd (void *__P, __mmask8 __U, __m128d __A)
{
  __builtin_ia32_compressstoredf128_mask ((__v2df *) __P,
       (__v2df) __A,
       (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_compress_ps (__m256 __W, __mmask8 __U, __m256 __A)
{
  return (__m256) __builtin_ia32_compresssf256_mask ((__v8sf) __A,
           (__v8sf) __W,
           (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_compress_ps (__mmask8 __U, __m256 __A)
{
  return (__m256) __builtin_ia32_compresssf256_mask ((__v8sf) __A,
           (__v8sf)
           _mm256_setzero_ps (),
           (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_compressstoreu_ps (void *__P, __mmask8 __U, __m256 __A)
{
  __builtin_ia32_compressstoresf256_mask ((__v8sf *) __P,
       (__v8sf) __A,
       (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_compress_ps (__m128 __W, __mmask8 __U, __m128 __A)
{
  return (__m128) __builtin_ia32_compresssf128_mask ((__v4sf) __A,
           (__v4sf) __W,
           (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_compress_ps (__mmask8 __U, __m128 __A)
{
  return (__m128) __builtin_ia32_compresssf128_mask ((__v4sf) __A,
           (__v4sf)
           _mm_setzero_ps (),
           (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_compressstoreu_ps (void *__P, __mmask8 __U, __m128 __A)
{
  __builtin_ia32_compressstoresf128_mask ((__v4sf *) __P,
       (__v4sf) __A,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_compress_epi64 (__m256i __W, __mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_compressdi256_mask ((__v4di) __A,
            (__v4di) __W,
            (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_compress_epi64 (__mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_compressdi256_mask ((__v4di) __A,
            (__v4di)
            _mm256_setzero_si256 (),
            (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_compressstoreu_epi64 (void *__P, __mmask8 __U, __m256i __A)
{
  __builtin_ia32_compressstoredi256_mask ((__v4di *) __P,
       (__v4di) __A,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_compress_epi64 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_compressdi128_mask ((__v2di) __A,
            (__v2di) __W,
            (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_compress_epi64 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_compressdi128_mask ((__v2di) __A,
            (__v2di)
            _mm_setzero_si128 (),
            (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_compressstoreu_epi64 (void *__P, __mmask8 __U, __m128i __A)
{
  __builtin_ia32_compressstoredi128_mask ((__v2di *) __P,
       (__v2di) __A,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_compress_epi32 (__m256i __W, __mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_compresssi256_mask ((__v8si) __A,
            (__v8si) __W,
            (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_compress_epi32 (__mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_compresssi256_mask ((__v8si) __A,
            (__v8si)
            _mm256_setzero_si256 (),
            (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_compressstoreu_epi32 (void *__P, __mmask8 __U, __m256i __A)
{
  __builtin_ia32_compressstoresi256_mask ((__v8si *) __P,
       (__v8si) __A,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_compress_epi32 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_compresssi128_mask ((__v4si) __A,
            (__v4si) __W,
            (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_compress_epi32 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_compresssi128_mask ((__v4si) __A,
            (__v4si)
            _mm_setzero_si128 (),
            (__mmask8) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_compressstoreu_epi32 (void *__P, __mmask8 __U, __m128i __A)
{
  __builtin_ia32_compressstoresi128_mask ((__v4si *) __P,
       (__v4si) __A,
       (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_expand_pd (__m256d __W, __mmask8 __U, __m256d __A)
{
  return (__m256d) __builtin_ia32_expanddf256_mask ((__v4df) __A,
          (__v4df) __W,
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_expand_pd (__mmask8 __U, __m256d __A)
{
  return (__m256d) __builtin_ia32_expanddf256_maskz ((__v4df) __A,
           (__v4df)
           _mm256_setzero_pd (),
           (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_expandloadu_pd (__m256d __W, __mmask8 __U, void const *__P)
{
  return (__m256d) __builtin_ia32_expandloaddf256_mask ((__v4df *) __P,
       (__v4df) __W,
       (__mmask8)
       __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_expandloadu_pd (__mmask8 __U, void const *__P)
{
  return (__m256d) __builtin_ia32_expandloaddf256_maskz ((__v4df *) __P,
        (__v4df)
        _mm256_setzero_pd (),
        (__mmask8)
        __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_expand_pd (__m128d __W, __mmask8 __U, __m128d __A)
{
  return (__m128d) __builtin_ia32_expanddf128_mask ((__v2df) __A,
          (__v2df) __W,
          (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_expand_pd (__mmask8 __U, __m128d __A)
{
  return (__m128d) __builtin_ia32_expanddf128_maskz ((__v2df) __A,
           (__v2df)
           _mm_setzero_pd (),
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_expandloadu_pd (__m128d __W, __mmask8 __U, void const *__P)
{
  return (__m128d) __builtin_ia32_expandloaddf128_mask ((__v2df *) __P,
       (__v2df) __W,
       (__mmask8)
       __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_expandloadu_pd (__mmask8 __U, void const *__P)
{
  return (__m128d) __builtin_ia32_expandloaddf128_maskz ((__v2df *) __P,
        (__v2df)
        _mm_setzero_pd (),
        (__mmask8)
        __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_expand_ps (__m256 __W, __mmask8 __U, __m256 __A)
{
  return (__m256) __builtin_ia32_expandsf256_mask ((__v8sf) __A,
         (__v8sf) __W,
         (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_expand_ps (__mmask8 __U, __m256 __A)
{
  return (__m256) __builtin_ia32_expandsf256_maskz ((__v8sf) __A,
          (__v8sf)
          _mm256_setzero_ps (),
          (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_expandloadu_ps (__m256 __W, __mmask8 __U, void const *__P)
{
  return (__m256) __builtin_ia32_expandloadsf256_mask ((__v8sf *) __P,
             (__v8sf) __W,
             (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_expandloadu_ps (__mmask8 __U, void const *__P)
{
  return (__m256) __builtin_ia32_expandloadsf256_maskz ((__v8sf *) __P,
       (__v8sf)
       _mm256_setzero_ps (),
       (__mmask8)
       __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_expand_ps (__m128 __W, __mmask8 __U, __m128 __A)
{
  return (__m128) __builtin_ia32_expandsf128_mask ((__v4sf) __A,
         (__v4sf) __W,
         (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_expand_ps (__mmask8 __U, __m128 __A)
{
  return (__m128) __builtin_ia32_expandsf128_maskz ((__v4sf) __A,
          (__v4sf)
          _mm_setzero_ps (),
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_expandloadu_ps (__m128 __W, __mmask8 __U, void const *__P)
{
  return (__m128) __builtin_ia32_expandloadsf128_mask ((__v4sf *) __P,
             (__v4sf) __W,
             (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_expandloadu_ps (__mmask8 __U, void const *__P)
{
  return (__m128) __builtin_ia32_expandloadsf128_maskz ((__v4sf *) __P,
       (__v4sf)
       _mm_setzero_ps (),
       (__mmask8)
       __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_expand_epi64 (__m256i __W, __mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_expanddi256_mask ((__v4di) __A,
          (__v4di) __W,
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_expand_epi64 (__mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_expanddi256_maskz ((__v4di) __A,
           (__v4di)
           _mm256_setzero_si256 (),
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_expandloadu_epi64 (__m256i __W, __mmask8 __U,
          void const *__P)
{
  return (__m256i) __builtin_ia32_expandloaddi256_mask ((__v4di *) __P,
       (__v4di) __W,
       (__mmask8)
       __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_expandloadu_epi64 (__mmask8 __U, void const *__P)
{
  return (__m256i) __builtin_ia32_expandloaddi256_maskz ((__v4di *) __P,
        (__v4di)
        _mm256_setzero_si256 (),
        (__mmask8)
        __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_expand_epi64 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_expanddi128_mask ((__v2di) __A,
          (__v2di) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_expand_epi64 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_expanddi128_maskz ((__v2di) __A,
           (__v2di)
           _mm_setzero_si128 (),
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_expandloadu_epi64 (__m128i __W, __mmask8 __U, void const *__P)
{
  return (__m128i) __builtin_ia32_expandloaddi128_mask ((__v2di *) __P,
       (__v2di) __W,
       (__mmask8)
       __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_expandloadu_epi64 (__mmask8 __U, void const *__P)
{
  return (__m128i) __builtin_ia32_expandloaddi128_maskz ((__v2di *) __P,
        (__v2di)
        _mm_setzero_si128 (),
        (__mmask8)
        __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_expand_epi32 (__m256i __W, __mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_expandsi256_mask ((__v8si) __A,
          (__v8si) __W,
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_expand_epi32 (__mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_expandsi256_maskz ((__v8si) __A,
           (__v8si)
           _mm256_setzero_si256 (),
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_expandloadu_epi32 (__m256i __W, __mmask8 __U,
          void const *__P)
{
  return (__m256i) __builtin_ia32_expandloadsi256_mask ((__v8si *) __P,
       (__v8si) __W,
       (__mmask8)
       __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_expandloadu_epi32 (__mmask8 __U, void const *__P)
{
  return (__m256i) __builtin_ia32_expandloadsi256_maskz ((__v8si *) __P,
        (__v8si)
        _mm256_setzero_si256 (),
        (__mmask8)
        __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_expand_epi32 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_expandsi128_mask ((__v4si) __A,
          (__v4si) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_expand_epi32 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_expandsi128_maskz ((__v4si) __A,
           (__v4si)
           _mm_setzero_si128 (),
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_expandloadu_epi32 (__m128i __W, __mmask8 __U, void const *__P)
{
  return (__m128i) __builtin_ia32_expandloadsi128_mask ((__v4si *) __P,
       (__v4si) __W,
       (__mmask8)
       __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_expandloadu_epi32 (__mmask8 __U, void const *__P)
{
  return (__m128i) __builtin_ia32_expandloadsi128_maskz ((__v4si *) __P,
        (__v4si)
        _mm_setzero_si128 (),
        (__mmask8)
        __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_permutex2var_pd (__m256d __A, __m256i __I, __m256d __B)
{
  return (__m256d) __builtin_ia32_vpermt2varpd256_mask ((__v4di) __I
                 ,
       (__v4df) __A,
       (__v4df) __B,
       (__mmask8) -1);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_permutex2var_pd (__m256d __A, __mmask8 __U, __m256i __I,
        __m256d __B)
{
  return (__m256d) __builtin_ia32_vpermt2varpd256_mask ((__v4di) __I
                 ,
       (__v4df) __A,
       (__v4df) __B,
       (__mmask8)
       __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask2_permutex2var_pd (__m256d __A, __m256i __I, __mmask8 __U,
         __m256d __B)
{
  return (__m256d) __builtin_ia32_vpermi2varpd256_mask ((__v4df) __A,
       (__v4di) __I
                 ,
       (__v4df) __B,
       (__mmask8)
       __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_permutex2var_pd (__mmask8 __U, __m256d __A, __m256i __I,
         __m256d __B)
{
  return (__m256d) __builtin_ia32_vpermt2varpd256_maskz ((__v4di) __I
                  ,
        (__v4df) __A,
        (__v4df) __B,
        (__mmask8)
        __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_permutex2var_ps (__m256 __A, __m256i __I, __m256 __B)
{
  return (__m256) __builtin_ia32_vpermt2varps256_mask ((__v8si) __I
                       ,
             (__v8sf) __A,
             (__v8sf) __B,
             (__mmask8) -1);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_permutex2var_ps (__m256 __A, __mmask8 __U, __m256i __I,
        __m256 __B)
{
  return (__m256) __builtin_ia32_vpermt2varps256_mask ((__v8si) __I
                       ,
             (__v8sf) __A,
             (__v8sf) __B,
             (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask2_permutex2var_ps (__m256 __A, __m256i __I, __mmask8 __U,
         __m256 __B)
{
  return (__m256) __builtin_ia32_vpermi2varps256_mask ((__v8sf) __A,
             (__v8si) __I
                       ,
             (__v8sf) __B,
             (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_permutex2var_ps (__mmask8 __U, __m256 __A, __m256i __I,
         __m256 __B)
{
  return (__m256) __builtin_ia32_vpermt2varps256_maskz ((__v8si) __I
                 ,
       (__v8sf) __A,
       (__v8sf) __B,
       (__mmask8)
       __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_permutex2var_epi64 (__m128i __A, __m128i __I, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpermt2varq128_mask ((__v2di) __I
                       ,
             (__v2di) __A,
             (__v2di) __B,
             (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_permutex2var_epi64 (__m128i __A, __mmask8 __U, __m128i __I,
        __m128i __B)
{
  return (__m128i) __builtin_ia32_vpermt2varq128_mask ((__v2di) __I
                       ,
             (__v2di) __A,
             (__v2di) __B,
             (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask2_permutex2var_epi64 (__m128i __A, __m128i __I, __mmask8 __U,
         __m128i __B)
{
  return (__m128i) __builtin_ia32_vpermi2varq128_mask ((__v2di) __A,
             (__v2di) __I
                       ,
             (__v2di) __B,
             (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_permutex2var_epi64 (__mmask8 __U, __m128i __A, __m128i __I,
         __m128i __B)
{
  return (__m128i) __builtin_ia32_vpermt2varq128_maskz ((__v2di) __I
                 ,
       (__v2di) __A,
       (__v2di) __B,
       (__mmask8)
       __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_permutex2var_epi32 (__m128i __A, __m128i __I, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpermt2vard128_mask ((__v4si) __I
                       ,
             (__v4si) __A,
             (__v4si) __B,
             (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_permutex2var_epi32 (__m128i __A, __mmask8 __U, __m128i __I,
        __m128i __B)
{
  return (__m128i) __builtin_ia32_vpermt2vard128_mask ((__v4si) __I
                       ,
             (__v4si) __A,
             (__v4si) __B,
             (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask2_permutex2var_epi32 (__m128i __A, __m128i __I, __mmask8 __U,
         __m128i __B)
{
  return (__m128i) __builtin_ia32_vpermi2vard128_mask ((__v4si) __A,
             (__v4si) __I
                       ,
             (__v4si) __B,
             (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_permutex2var_epi32 (__mmask8 __U, __m128i __A, __m128i __I,
         __m128i __B)
{
  return (__m128i) __builtin_ia32_vpermt2vard128_maskz ((__v4si) __I
                 ,
       (__v4si) __A,
       (__v4si) __B,
       (__mmask8)
       __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_permutex2var_epi64 (__m256i __A, __m256i __I, __m256i __B)
{
  return (__m256i) __builtin_ia32_vpermt2varq256_mask ((__v4di) __I
                       ,
             (__v4di) __A,
             (__v4di) __B,
             (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_permutex2var_epi64 (__m256i __A, __mmask8 __U, __m256i __I,
    __m256i __B)
{
  return (__m256i) __builtin_ia32_vpermt2varq256_mask ((__v4di) __I
                       ,
             (__v4di) __A,
             (__v4di) __B,
             (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask2_permutex2var_epi64 (__m256i __A, __m256i __I,
     __mmask8 __U, __m256i __B)
{
  return (__m256i) __builtin_ia32_vpermi2varq256_mask ((__v4di) __A,
             (__v4di) __I
                       ,
             (__v4di) __B,
             (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_permutex2var_epi64 (__mmask8 __U, __m256i __A,
     __m256i __I, __m256i __B)
{
  return (__m256i) __builtin_ia32_vpermt2varq256_maskz ((__v4di) __I
                 ,
       (__v4di) __A,
       (__v4di) __B,
       (__mmask8)
       __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_permutex2var_epi32 (__m256i __A, __m256i __I, __m256i __B)
{
  return (__m256i) __builtin_ia32_vpermt2vard256_mask ((__v8si) __I
                       ,
             (__v8si) __A,
             (__v8si) __B,
             (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_permutex2var_epi32 (__m256i __A, __mmask8 __U, __m256i __I,
    __m256i __B)
{
  return (__m256i) __builtin_ia32_vpermt2vard256_mask ((__v8si) __I
                       ,
             (__v8si) __A,
             (__v8si) __B,
             (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask2_permutex2var_epi32 (__m256i __A, __m256i __I,
     __mmask8 __U, __m256i __B)
{
  return (__m256i) __builtin_ia32_vpermi2vard256_mask ((__v8si) __A,
             (__v8si) __I
                       ,
             (__v8si) __B,
             (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_permutex2var_epi32 (__mmask8 __U, __m256i __A,
     __m256i __I, __m256i __B)
{
  return (__m256i) __builtin_ia32_vpermt2vard256_maskz ((__v8si) __I
                 ,
       (__v8si) __A,
       (__v8si) __B,
       (__mmask8)
       __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_permutex2var_pd (__m128d __A, __m128i __I, __m128d __B)
{
  return (__m128d) __builtin_ia32_vpermt2varpd128_mask ((__v2di) __I
                 ,
       (__v2df) __A,
       (__v2df) __B,
       (__mmask8) -1);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_permutex2var_pd (__m128d __A, __mmask8 __U, __m128i __I,
     __m128d __B)
{
  return (__m128d) __builtin_ia32_vpermt2varpd128_mask ((__v2di) __I
                 ,
       (__v2df) __A,
       (__v2df) __B,
       (__mmask8)
       __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask2_permutex2var_pd (__m128d __A, __m128i __I, __mmask8 __U,
      __m128d __B)
{
  return (__m128d) __builtin_ia32_vpermi2varpd128_mask ((__v2df) __A,
       (__v2di) __I
                 ,
       (__v2df) __B,
       (__mmask8)
       __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_permutex2var_pd (__mmask8 __U, __m128d __A, __m128i __I,
      __m128d __B)
{
  return (__m128d) __builtin_ia32_vpermt2varpd128_maskz ((__v2di) __I
                  ,
        (__v2df) __A,
        (__v2df) __B,
        (__mmask8)
        __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_permutex2var_ps (__m128 __A, __m128i __I, __m128 __B)
{
  return (__m128) __builtin_ia32_vpermt2varps128_mask ((__v4si) __I
                       ,
             (__v4sf) __A,
             (__v4sf) __B,
             (__mmask8) -1);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_permutex2var_ps (__m128 __A, __mmask8 __U, __m128i __I,
     __m128 __B)
{
  return (__m128) __builtin_ia32_vpermt2varps128_mask ((__v4si) __I
                       ,
             (__v4sf) __A,
             (__v4sf) __B,
             (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask2_permutex2var_ps (__m128 __A, __m128i __I, __mmask8 __U,
      __m128 __B)
{
  return (__m128) __builtin_ia32_vpermi2varps128_mask ((__v4sf) __A,
             (__v4si) __I
                       ,
             (__v4sf) __B,
             (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_permutex2var_ps (__mmask8 __U, __m128 __A, __m128i __I,
      __m128 __B)
{
  return (__m128) __builtin_ia32_vpermt2varps128_maskz ((__v4si) __I
                 ,
       (__v4sf) __A,
       (__v4sf) __B,
       (__mmask8)
       __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_srav_epi64 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_psravq128_mask ((__v2di) __X,
        (__v2di) __Y,
        (__v2di)
        _mm_setzero_si128 (),
        (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_srav_epi64 (__m128i __W, __mmask8 __U, __m128i __X,
       __m128i __Y)
{
  return (__m128i) __builtin_ia32_psravq128_mask ((__v2di) __X,
        (__v2di) __Y,
        (__v2di) __W,
        (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_srav_epi64 (__mmask8 __U, __m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_psravq128_mask ((__v2di) __X,
        (__v2di) __Y,
        (__v2di)
        _mm_setzero_si128 (),
        (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_sllv_epi32 (__m256i __W, __mmask8 __U, __m256i __X,
   __m256i __Y)
{
  return (__m256i) __builtin_ia32_psllv8si_mask ((__v8si) __X,
       (__v8si) __Y,
       (__v8si) __W,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_sllv_epi32 (__mmask8 __U, __m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_psllv8si_mask ((__v8si) __X,
       (__v8si) __Y,
       (__v8si)
       _mm256_setzero_si256 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_sllv_epi32 (__m128i __W, __mmask8 __U, __m128i __X,
       __m128i __Y)
{
  return (__m128i) __builtin_ia32_psllv4si_mask ((__v4si) __X,
       (__v4si) __Y,
       (__v4si) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_sllv_epi32 (__mmask8 __U, __m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_psllv4si_mask ((__v4si) __X,
       (__v4si) __Y,
       (__v4si)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_sllv_epi64 (__m256i __W, __mmask8 __U, __m256i __X,
   __m256i __Y)
{
  return (__m256i) __builtin_ia32_psllv4di_mask ((__v4di) __X,
       (__v4di) __Y,
       (__v4di) __W,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_sllv_epi64 (__mmask8 __U, __m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_psllv4di_mask ((__v4di) __X,
       (__v4di) __Y,
       (__v4di)
       _mm256_setzero_si256 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_sllv_epi64 (__m128i __W, __mmask8 __U, __m128i __X,
       __m128i __Y)
{
  return (__m128i) __builtin_ia32_psllv2di_mask ((__v2di) __X,
       (__v2di) __Y,
       (__v2di) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_sllv_epi64 (__mmask8 __U, __m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_psllv2di_mask ((__v2di) __X,
       (__v2di) __Y,
       (__v2di)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_srav_epi32 (__m256i __W, __mmask8 __U, __m256i __X,
   __m256i __Y)
{
  return (__m256i) __builtin_ia32_psrav8si_mask ((__v8si) __X,
       (__v8si) __Y,
       (__v8si) __W,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_srav_epi32 (__mmask8 __U, __m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_psrav8si_mask ((__v8si) __X,
       (__v8si) __Y,
       (__v8si)
       _mm256_setzero_si256 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_srav_epi32 (__m128i __W, __mmask8 __U, __m128i __X,
       __m128i __Y)
{
  return (__m128i) __builtin_ia32_psrav4si_mask ((__v4si) __X,
       (__v4si) __Y,
       (__v4si) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_srav_epi32 (__mmask8 __U, __m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_psrav4si_mask ((__v4si) __X,
       (__v4si) __Y,
       (__v4si)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_srlv_epi32 (__m256i __W, __mmask8 __U, __m256i __X,
   __m256i __Y)
{
  return (__m256i) __builtin_ia32_psrlv8si_mask ((__v8si) __X,
       (__v8si) __Y,
       (__v8si) __W,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_srlv_epi32 (__mmask8 __U, __m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_psrlv8si_mask ((__v8si) __X,
       (__v8si) __Y,
       (__v8si)
       _mm256_setzero_si256 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_srlv_epi32 (__m128i __W, __mmask8 __U, __m128i __X,
       __m128i __Y)
{
  return (__m128i) __builtin_ia32_psrlv4si_mask ((__v4si) __X,
       (__v4si) __Y,
       (__v4si) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_srlv_epi32 (__mmask8 __U, __m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_psrlv4si_mask ((__v4si) __X,
       (__v4si) __Y,
       (__v4si)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_srlv_epi64 (__m256i __W, __mmask8 __U, __m256i __X,
   __m256i __Y)
{
  return (__m256i) __builtin_ia32_psrlv4di_mask ((__v4di) __X,
       (__v4di) __Y,
       (__v4di) __W,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_srlv_epi64 (__mmask8 __U, __m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_psrlv4di_mask ((__v4di) __X,
       (__v4di) __Y,
       (__v4di)
       _mm256_setzero_si256 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_srlv_epi64 (__m128i __W, __mmask8 __U, __m128i __X,
       __m128i __Y)
{
  return (__m128i) __builtin_ia32_psrlv2di_mask ((__v2di) __X,
       (__v2di) __Y,
       (__v2di) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_srlv_epi64 (__mmask8 __U, __m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_psrlv2di_mask ((__v2di) __X,
       (__v2di) __Y,
       (__v2di)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_rolv_epi32 (__m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_prolvd256_mask ((__v8si) __A,
        (__v8si) __B,
        (__v8si)
        _mm256_setzero_si256 (),
        (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_rolv_epi32 (__m256i __W, __mmask8 __U, __m256i __A,
   __m256i __B)
{
  return (__m256i) __builtin_ia32_prolvd256_mask ((__v8si) __A,
        (__v8si) __B,
        (__v8si) __W,
        (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_rolv_epi32 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_prolvd256_mask ((__v8si) __A,
        (__v8si) __B,
        (__v8si)
        _mm256_setzero_si256 (),
        (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_rolv_epi32 (__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_prolvd128_mask ((__v4si) __A,
        (__v4si) __B,
        (__v4si)
        _mm_setzero_si128 (),
        (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_rolv_epi32 (__m128i __W, __mmask8 __U, __m128i __A,
       __m128i __B)
{
  return (__m128i) __builtin_ia32_prolvd128_mask ((__v4si) __A,
        (__v4si) __B,
        (__v4si) __W,
        (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_rolv_epi32 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_prolvd128_mask ((__v4si) __A,
        (__v4si) __B,
        (__v4si)
        _mm_setzero_si128 (),
        (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_rorv_epi32 (__m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_prorvd256_mask ((__v8si) __A,
        (__v8si) __B,
        (__v8si)
        _mm256_setzero_si256 (),
        (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_rorv_epi32 (__m256i __W, __mmask8 __U, __m256i __A,
   __m256i __B)
{
  return (__m256i) __builtin_ia32_prorvd256_mask ((__v8si) __A,
        (__v8si) __B,
        (__v8si) __W,
        (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_rorv_epi32 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_prorvd256_mask ((__v8si) __A,
        (__v8si) __B,
        (__v8si)
        _mm256_setzero_si256 (),
        (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_rorv_epi32 (__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_prorvd128_mask ((__v4si) __A,
        (__v4si) __B,
        (__v4si)
        _mm_setzero_si128 (),
        (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_rorv_epi32 (__m128i __W, __mmask8 __U, __m128i __A,
       __m128i __B)
{
  return (__m128i) __builtin_ia32_prorvd128_mask ((__v4si) __A,
        (__v4si) __B,
        (__v4si) __W,
        (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_rorv_epi32 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_prorvd128_mask ((__v4si) __A,
        (__v4si) __B,
        (__v4si)
        _mm_setzero_si128 (),
        (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_rolv_epi64 (__m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_prolvq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di)
        _mm256_setzero_si256 (),
        (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_rolv_epi64 (__m256i __W, __mmask8 __U, __m256i __A,
   __m256i __B)
{
  return (__m256i) __builtin_ia32_prolvq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di) __W,
        (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_rolv_epi64 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_prolvq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di)
        _mm256_setzero_si256 (),
        (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_rolv_epi64 (__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_prolvq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di)
        _mm_setzero_si128 (),
        (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_rolv_epi64 (__m128i __W, __mmask8 __U, __m128i __A,
       __m128i __B)
{
  return (__m128i) __builtin_ia32_prolvq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di) __W,
        (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_rolv_epi64 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_prolvq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di)
        _mm_setzero_si128 (),
        (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_rorv_epi64 (__m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_prorvq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di)
        _mm256_setzero_si256 (),
        (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_rorv_epi64 (__m256i __W, __mmask8 __U, __m256i __A,
   __m256i __B)
{
  return (__m256i) __builtin_ia32_prorvq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di) __W,
        (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_rorv_epi64 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_prorvq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di)
        _mm256_setzero_si256 (),
        (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_rorv_epi64 (__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_prorvq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di)
        _mm_setzero_si128 (),
        (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_rorv_epi64 (__m128i __W, __mmask8 __U, __m128i __A,
       __m128i __B)
{
  return (__m128i) __builtin_ia32_prorvq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di) __W,
        (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_rorv_epi64 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_prorvq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di)
        _mm_setzero_si128 (),
        (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_srav_epi64 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_psravq256_mask ((__v4di) __X,
        (__v4di) __Y,
        (__v4di)
        _mm256_setzero_si256 (),
        (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_srav_epi64 (__m256i __W, __mmask8 __U, __m256i __X,
   __m256i __Y)
{
  return (__m256i) __builtin_ia32_psravq256_mask ((__v4di) __X,
        (__v4di) __Y,
        (__v4di) __W,
        (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_srav_epi64 (__mmask8 __U, __m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_psravq256_mask ((__v4di) __X,
        (__v4di) __Y,
        (__v4di)
        _mm256_setzero_si256 (),
        (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_and_epi64 (__m256i __W, __mmask8 __U, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_pandq256_mask ((__v4di) __A,
       (__v4di) __B,
       (__v4di) __W, __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_and_epi64 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pandq256_mask ((__v4di) __A,
       (__v4di) __B,
       (__v4di)
       _mm256_setzero_pd (),
       __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_and_epi64 (__m128i __W, __mmask8 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_pandq128_mask ((__v2di) __A,
       (__v2di) __B,
       (__v2di) __W, __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_and_epi64 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pandq128_mask ((__v2di) __A,
       (__v2di) __B,
       (__v2di)
       _mm_setzero_pd (),
       __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_andnot_epi64 (__m256i __W, __mmask8 __U, __m256i __A,
     __m256i __B)
{
  return (__m256i) __builtin_ia32_pandnq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di) __W, __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_andnot_epi64 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pandnq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di)
        _mm256_setzero_pd (),
        __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_andnot_epi64 (__m128i __W, __mmask8 __U, __m128i __A,
         __m128i __B)
{
  return (__m128i) __builtin_ia32_pandnq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di) __W, __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_andnot_epi64 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pandnq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di)
        _mm_setzero_pd (),
        __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_or_epi64 (__m256i __W, __mmask8 __U, __m256i __A,
        __m256i __B)
{
  return (__m256i) __builtin_ia32_porq256_mask ((__v4di) __A,
      (__v4di) __B,
      (__v4di) __W,
      (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_or_epi64 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_porq256_mask ((__v4di) __A,
      (__v4di) __B,
      (__v4di)
      _mm256_setzero_si256 (),
      (__mmask8) __U);
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_or_epi64 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v4du)__A | (__v4du)__B);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_or_epi64 (__m128i __W, __mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_porq128_mask ((__v2di) __A,
      (__v2di) __B,
      (__v2di) __W,
      (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_or_epi64 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_porq128_mask ((__v2di) __A,
      (__v2di) __B,
      (__v2di)
      _mm_setzero_si128 (),
      (__mmask8) __U);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_or_epi64 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v2du)__A | (__v2du)__B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_xor_epi64 (__m256i __W, __mmask8 __U, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_pxorq256_mask ((__v4di) __A,
       (__v4di) __B,
       (__v4di) __W,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_xor_epi64 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pxorq256_mask ((__v4di) __A,
       (__v4di) __B,
       (__v4di)
       _mm256_setzero_si256 (),
       (__mmask8) __U);
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_xor_epi64 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v4du)__A ^ (__v4du)__B);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_xor_epi64 (__m128i __W, __mmask8 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_pxorq128_mask ((__v2di) __A,
       (__v2di) __B,
       (__v2di) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_xor_epi64 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pxorq128_mask ((__v2di) __A,
       (__v2di) __B,
       (__v2di)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_xor_epi64 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v2du)__A ^ (__v2du)__B);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_max_pd (__m256d __W, __mmask8 __U, __m256d __A,
      __m256d __B)
{
  return (__m256d) __builtin_ia32_maxpd256_mask ((__v4df) __A,
       (__v4df) __B,
       (__v4df) __W,
       (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_max_pd (__mmask8 __U, __m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_maxpd256_mask ((__v4df) __A,
       (__v4df) __B,
       (__v4df)
       _mm256_setzero_pd (),
       (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_max_ps (__m256 __W, __mmask8 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_maxps256_mask ((__v8sf) __A,
      (__v8sf) __B,
      (__v8sf) __W,
      (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_max_ps (__mmask8 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_maxps256_mask ((__v8sf) __A,
      (__v8sf) __B,
      (__v8sf)
      _mm256_setzero_ps (),
      (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_div_ps (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_divps_mask ((__v4sf) __A,
          (__v4sf) __B,
          (__v4sf) __W,
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_div_ps (__mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_divps_mask ((__v4sf) __A,
          (__v4sf) __B,
          (__v4sf)
          _mm_setzero_ps (),
          (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_div_pd (__m128d __W, __mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_divpd_mask ((__v2df) __A,
           (__v2df) __B,
           (__v2df) __W,
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_div_pd (__mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_divpd_mask ((__v2df) __A,
           (__v2df) __B,
           (__v2df)
           _mm_setzero_pd (),
           (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_min_pd (__m256d __W, __mmask8 __U, __m256d __A,
      __m256d __B)
{
  return (__m256d) __builtin_ia32_minpd256_mask ((__v4df) __A,
       (__v4df) __B,
       (__v4df) __W,
       (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_div_pd (__m256d __W, __mmask8 __U, __m256d __A,
      __m256d __B)
{
  return (__m256d) __builtin_ia32_divpd256_mask ((__v4df) __A,
       (__v4df) __B,
       (__v4df) __W,
       (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_min_pd (__mmask8 __U, __m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_minpd256_mask ((__v4df) __A,
       (__v4df) __B,
       (__v4df)
       _mm256_setzero_pd (),
       (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_min_ps (__m256 __W, __mmask8 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_minps256_mask ((__v8sf) __A,
      (__v8sf) __B,
      (__v8sf) __W,
      (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_div_pd (__mmask8 __U, __m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_divpd256_mask ((__v4df) __A,
       (__v4df) __B,
       (__v4df)
       _mm256_setzero_pd (),
       (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_div_ps (__m256 __W, __mmask8 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_divps256_mask ((__v8sf) __A,
      (__v8sf) __B,
      (__v8sf) __W,
      (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_min_ps (__mmask8 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_minps256_mask ((__v8sf) __A,
      (__v8sf) __B,
      (__v8sf)
      _mm256_setzero_ps (),
      (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_div_ps (__mmask8 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_divps256_mask ((__v8sf) __A,
      (__v8sf) __B,
      (__v8sf)
      _mm256_setzero_ps (),
      (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_min_ps (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_minps_mask ((__v4sf) __A,
          (__v4sf) __B,
          (__v4sf) __W,
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_mul_ps (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_mulps_mask ((__v4sf) __A,
          (__v4sf) __B,
          (__v4sf) __W,
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_min_ps (__mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_minps_mask ((__v4sf) __A,
          (__v4sf) __B,
          (__v4sf)
          _mm_setzero_ps (),
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_mul_ps (__mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_mulps_mask ((__v4sf) __A,
          (__v4sf) __B,
          (__v4sf)
          _mm_setzero_ps (),
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_max_ps (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_maxps_mask ((__v4sf) __A,
          (__v4sf) __B,
          (__v4sf) __W,
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_max_ps (__mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_maxps_mask ((__v4sf) __A,
          (__v4sf) __B,
          (__v4sf)
          _mm_setzero_ps (),
          (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_min_pd (__m128d __W, __mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_minpd_mask ((__v2df) __A,
           (__v2df) __B,
           (__v2df) __W,
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_min_pd (__mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_minpd_mask ((__v2df) __A,
           (__v2df) __B,
           (__v2df)
           _mm_setzero_pd (),
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_max_pd (__m128d __W, __mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_maxpd_mask ((__v2df) __A,
           (__v2df) __B,
           (__v2df) __W,
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_max_pd (__mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_maxpd_mask ((__v2df) __A,
           (__v2df) __B,
           (__v2df)
           _mm_setzero_pd (),
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_mul_pd (__m128d __W, __mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_mulpd_mask ((__v2df) __A,
           (__v2df) __B,
           (__v2df) __W,
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_mul_pd (__mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_mulpd_mask ((__v2df) __A,
           (__v2df) __B,
           (__v2df)
           _mm_setzero_pd (),
           (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_mul_ps (__m256 __W, __mmask8 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_mulps256_mask ((__v8sf) __A,
      (__v8sf) __B,
      (__v8sf) __W,
      (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_mul_ps (__mmask8 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_mulps256_mask ((__v8sf) __A,
      (__v8sf) __B,
      (__v8sf)
      _mm256_setzero_ps (),
      (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_mul_pd (__m256d __W, __mmask8 __U, __m256d __A,
      __m256d __B)
{
  return (__m256d) __builtin_ia32_mulpd256_mask ((__v4df) __A,
       (__v4df) __B,
       (__v4df) __W,
       (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_mul_pd (__mmask8 __U, __m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_mulpd256_mask ((__v4df) __A,
       (__v4df) __B,
       (__v4df)
       _mm256_setzero_pd (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_max_epi64 (__mmask8 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pmaxsq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di)
        _mm256_setzero_si256 (),
        __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_max_epi64 (__m256i __W, __mmask8 __M, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_pmaxsq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di) __W, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_min_epi64 (__m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pminsq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di)
        _mm256_setzero_si256 (),
        (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_min_epi64 (__m256i __W, __mmask8 __M, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_pminsq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di) __W, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_min_epi64 (__mmask8 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pminsq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di)
        _mm256_setzero_si256 (),
        __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_max_epu64 (__mmask8 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pmaxuq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di)
        _mm256_setzero_si256 (),
        __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_max_epi64 (__m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pmaxsq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di)
        _mm256_setzero_si256 (),
        (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_max_epu64 (__m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pmaxuq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di)
        _mm256_setzero_si256 (),
        (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_max_epu64 (__m256i __W, __mmask8 __M, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_pmaxuq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di) __W, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_min_epu64 (__m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pminuq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di)
        _mm256_setzero_si256 (),
        (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_min_epu64 (__m256i __W, __mmask8 __M, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_pminuq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di) __W, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_min_epu64 (__mmask8 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pminuq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di)
        _mm256_setzero_si256 (),
        __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_max_epi32 (__mmask8 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pmaxsd256_mask ((__v8si) __A,
        (__v8si) __B,
        (__v8si)
        _mm256_setzero_si256 (),
        __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_max_epi32 (__m256i __W, __mmask8 __M, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_pmaxsd256_mask ((__v8si) __A,
        (__v8si) __B,
        (__v8si) __W, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_min_epi32 (__mmask8 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pminsd256_mask ((__v8si) __A,
        (__v8si) __B,
        (__v8si)
        _mm256_setzero_si256 (),
        __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_min_epi32 (__m256i __W, __mmask8 __M, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_pminsd256_mask ((__v8si) __A,
        (__v8si) __B,
        (__v8si) __W, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_max_epu32 (__mmask8 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pmaxud256_mask ((__v8si) __A,
        (__v8si) __B,
        (__v8si)
        _mm256_setzero_si256 (),
        __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_max_epu32 (__m256i __W, __mmask8 __M, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_pmaxud256_mask ((__v8si) __A,
        (__v8si) __B,
        (__v8si) __W, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_min_epu32 (__mmask8 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pminud256_mask ((__v8si) __A,
        (__v8si) __B,
        (__v8si)
        _mm256_setzero_si256 (),
        __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_min_epu32 (__m256i __W, __mmask8 __M, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_pminud256_mask ((__v8si) __A,
        (__v8si) __B,
        (__v8si) __W, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_max_epi64 (__mmask8 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pmaxsq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_max_epi64 (__m128i __W, __mmask8 __M, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_pmaxsq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di) __W, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_min_epi64 (__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pminsq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di)
        _mm_setzero_si128 (),
        (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_min_epi64 (__m128i __W, __mmask8 __M, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_pminsq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di) __W, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_min_epi64 (__mmask8 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pminsq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_max_epu64 (__mmask8 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pmaxuq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_max_epi64 (__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pmaxsq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di)
        _mm_setzero_si128 (),
        (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_max_epu64 (__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pmaxuq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di)
        _mm_setzero_si128 (),
        (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_max_epu64 (__m128i __W, __mmask8 __M, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_pmaxuq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di) __W, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_min_epu64 (__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pminuq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di)
        _mm_setzero_si128 (),
        (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_min_epu64 (__m128i __W, __mmask8 __M, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_pminuq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di) __W, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_min_epu64 (__mmask8 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pminuq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_max_epi32 (__mmask8 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pmaxsd128_mask ((__v4si) __A,
        (__v4si) __B,
        (__v4si)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_max_epi32 (__m128i __W, __mmask8 __M, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_pmaxsd128_mask ((__v4si) __A,
        (__v4si) __B,
        (__v4si) __W, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_min_epi32 (__mmask8 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pminsd128_mask ((__v4si) __A,
        (__v4si) __B,
        (__v4si)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_min_epi32 (__m128i __W, __mmask8 __M, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_pminsd128_mask ((__v4si) __A,
        (__v4si) __B,
        (__v4si) __W, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_max_epu32 (__mmask8 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pmaxud128_mask ((__v4si) __A,
        (__v4si) __B,
        (__v4si)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_max_epu32 (__m128i __W, __mmask8 __M, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_pmaxud128_mask ((__v4si) __A,
        (__v4si) __B,
        (__v4si) __W, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_min_epu32 (__mmask8 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pminud128_mask ((__v4si) __A,
        (__v4si) __B,
        (__v4si)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_min_epu32 (__m128i __W, __mmask8 __M, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_pminud128_mask ((__v4si) __A,
        (__v4si) __B,
        (__v4si) __W, __M);
}
#pragma GCC push_options
#pragma GCC target("avx512vl,avx512cd")
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_broadcastmb_epi64 (__mmask8 __A)
{
  return (__m128i) __builtin_ia32_broadcastmb128 (__A);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_broadcastmb_epi64 (__mmask8 __A)
{
  return (__m256i) __builtin_ia32_broadcastmb256 (__A);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_broadcastmw_epi32 (__mmask16 __A)
{
  return (__m128i) __builtin_ia32_broadcastmw128 (__A);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_broadcastmw_epi32 (__mmask16 __A)
{
  return (__m256i) __builtin_ia32_broadcastmw256 (__A);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_lzcnt_epi32 (__m256i __A)
{
  return (__m256i) __builtin_ia32_vplzcntd_256_mask ((__v8si) __A,
           (__v8si)
           _mm256_setzero_si256 (),
           (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_lzcnt_epi32 (__m256i __W, __mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_vplzcntd_256_mask ((__v8si) __A,
           (__v8si) __W,
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_lzcnt_epi32 (__mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_vplzcntd_256_mask ((__v8si) __A,
           (__v8si)
           _mm256_setzero_si256 (),
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_lzcnt_epi64 (__m256i __A)
{
  return (__m256i) __builtin_ia32_vplzcntq_256_mask ((__v4di) __A,
           (__v4di)
           _mm256_setzero_si256 (),
           (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_lzcnt_epi64 (__m256i __W, __mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_vplzcntq_256_mask ((__v4di) __A,
           (__v4di) __W,
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_lzcnt_epi64 (__mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_vplzcntq_256_mask ((__v4di) __A,
           (__v4di)
           _mm256_setzero_si256 (),
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_conflict_epi64 (__m256i __A)
{
  return (__m256i) __builtin_ia32_vpconflictdi_256_mask ((__v4di) __A,
        (__v4di)
        _mm256_setzero_si256 (),
        (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_conflict_epi64 (__m256i __W, __mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_vpconflictdi_256_mask ((__v4di) __A,
        (__v4di) __W,
        (__mmask8)
        __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_conflict_epi64 (__mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_vpconflictdi_256_mask ((__v4di) __A,
        (__v4di)
        _mm256_setzero_si256 (),
        (__mmask8)
        __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_conflict_epi32 (__m256i __A)
{
  return (__m256i) __builtin_ia32_vpconflictsi_256_mask ((__v8si) __A,
        (__v8si)
        _mm256_setzero_si256 (),
        (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_conflict_epi32 (__m256i __W, __mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_vpconflictsi_256_mask ((__v8si) __A,
        (__v8si) __W,
        (__mmask8)
        __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_conflict_epi32 (__mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_vpconflictsi_256_mask ((__v8si) __A,
        (__v8si)
        _mm256_setzero_si256 (),
        (__mmask8)
        __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_lzcnt_epi32 (__m128i __A)
{
  return (__m128i) __builtin_ia32_vplzcntd_128_mask ((__v4si) __A,
           (__v4si)
           _mm_setzero_si128 (),
           (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_lzcnt_epi32 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_vplzcntd_128_mask ((__v4si) __A,
           (__v4si) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_lzcnt_epi32 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_vplzcntd_128_mask ((__v4si) __A,
           (__v4si)
           _mm_setzero_si128 (),
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_lzcnt_epi64 (__m128i __A)
{
  return (__m128i) __builtin_ia32_vplzcntq_128_mask ((__v2di) __A,
           (__v2di)
           _mm_setzero_si128 (),
           (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_lzcnt_epi64 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_vplzcntq_128_mask ((__v2di) __A,
           (__v2di) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_lzcnt_epi64 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_vplzcntq_128_mask ((__v2di) __A,
           (__v2di)
           _mm_setzero_si128 (),
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_conflict_epi64 (__m128i __A)
{
  return (__m128i) __builtin_ia32_vpconflictdi_128_mask ((__v2di) __A,
        (__v2di)
        _mm_setzero_si128 (),
        (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_conflict_epi64 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_vpconflictdi_128_mask ((__v2di) __A,
        (__v2di) __W,
        (__mmask8)
        __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_conflict_epi64 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_vpconflictdi_128_mask ((__v2di) __A,
        (__v2di)
        _mm_setzero_si128 (),
        (__mmask8)
        __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_conflict_epi32 (__m128i __A)
{
  return (__m128i) __builtin_ia32_vpconflictsi_128_mask ((__v4si) __A,
        (__v4si)
        _mm_setzero_si128 (),
        (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_conflict_epi32 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_vpconflictsi_128_mask ((__v4si) __A,
        (__v4si) __W,
        (__mmask8)
        __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_conflict_epi32 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_vpconflictsi_128_mask ((__v4si) __A,
        (__v4si)
        _mm_setzero_si128 (),
        (__mmask8)
        __U);
}
#pragma GCC pop_options
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_unpacklo_pd (__m256d __W, __mmask8 __U, __m256d __A,
    __m256d __B)
{
  return (__m256d) __builtin_ia32_unpcklpd256_mask ((__v4df) __A,
          (__v4df) __B,
          (__v4df) __W,
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_unpacklo_pd (__mmask8 __U, __m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_unpcklpd256_mask ((__v4df) __A,
          (__v4df) __B,
          (__v4df)
          _mm256_setzero_pd (),
          (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_unpacklo_pd (__m128d __W, __mmask8 __U, __m128d __A,
        __m128d __B)
{
  return (__m128d) __builtin_ia32_unpcklpd128_mask ((__v2df) __A,
          (__v2df) __B,
          (__v2df) __W,
          (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_unpacklo_pd (__mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_unpcklpd128_mask ((__v2df) __A,
          (__v2df) __B,
          (__v2df)
          _mm_setzero_pd (),
          (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_unpacklo_ps (__m256 __W, __mmask8 __U, __m256 __A,
    __m256 __B)
{
  return (__m256) __builtin_ia32_unpcklps256_mask ((__v8sf) __A,
         (__v8sf) __B,
         (__v8sf) __W,
         (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_unpackhi_pd (__m256d __W, __mmask8 __U, __m256d __A,
    __m256d __B)
{
  return (__m256d) __builtin_ia32_unpckhpd256_mask ((__v4df) __A,
          (__v4df) __B,
          (__v4df) __W,
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_unpackhi_pd (__mmask8 __U, __m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_unpckhpd256_mask ((__v4df) __A,
          (__v4df) __B,
          (__v4df)
          _mm256_setzero_pd (),
          (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_unpackhi_pd (__m128d __W, __mmask8 __U, __m128d __A,
        __m128d __B)
{
  return (__m128d) __builtin_ia32_unpckhpd128_mask ((__v2df) __A,
          (__v2df) __B,
          (__v2df) __W,
          (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_unpackhi_pd (__mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_unpckhpd128_mask ((__v2df) __A,
          (__v2df) __B,
          (__v2df)
          _mm_setzero_pd (),
          (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_unpackhi_ps (__m256 __W, __mmask8 __U, __m256 __A,
    __m256 __B)
{
  return (__m256) __builtin_ia32_unpckhps256_mask ((__v8sf) __A,
         (__v8sf) __B,
         (__v8sf) __W,
         (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_unpackhi_ps (__mmask8 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_unpckhps256_mask ((__v8sf) __A,
         (__v8sf) __B,
         (__v8sf)
         _mm256_setzero_ps (),
         (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_unpackhi_ps (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_unpckhps128_mask ((__v4sf) __A,
         (__v4sf) __B,
         (__v4sf) __W,
         (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_unpackhi_ps (__mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_unpckhps128_mask ((__v4sf) __A,
         (__v4sf) __B,
         (__v4sf)
         _mm_setzero_ps (),
         (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtph_ps (__m128 __W, __mmask8 __U, __m128i __A)
{
  return (__m128) __builtin_ia32_vcvtph2ps_mask ((__v8hi) __A,
       (__v4sf) __W,
       (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtph_ps (__mmask8 __U, __m128i __A)
{
  return (__m128) __builtin_ia32_vcvtph2ps_mask ((__v8hi) __A,
       (__v4sf)
       _mm_setzero_ps (),
       (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_unpacklo_ps (__mmask8 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_unpcklps256_mask ((__v8sf) __A,
         (__v8sf) __B,
         (__v8sf)
         _mm256_setzero_ps (),
         (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtph_ps (__m256 __W, __mmask8 __U, __m128i __A)
{
  return (__m256) __builtin_ia32_vcvtph2ps256_mask ((__v8hi) __A,
          (__v8sf) __W,
          (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtph_ps (__mmask8 __U, __m128i __A)
{
  return (__m256) __builtin_ia32_vcvtph2ps256_mask ((__v8hi) __A,
          (__v8sf)
          _mm256_setzero_ps (),
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_unpacklo_ps (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_unpcklps128_mask ((__v4sf) __A,
         (__v4sf) __B,
         (__v4sf) __W,
         (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_unpacklo_ps (__mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_unpcklps128_mask ((__v4sf) __A,
         (__v4sf) __B,
         (__v4sf)
         _mm_setzero_ps (),
         (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_sra_epi32 (__m256i __W, __mmask8 __U, __m256i __A,
         __m128i __B)
{
  return (__m256i) __builtin_ia32_psrad256_mask ((__v8si) __A,
       (__v4si) __B,
       (__v8si) __W,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_sra_epi32 (__mmask8 __U, __m256i __A, __m128i __B)
{
  return (__m256i) __builtin_ia32_psrad256_mask ((__v8si) __A,
       (__v4si) __B,
       (__v8si)
       _mm256_setzero_si256 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_sra_epi32 (__m128i __W, __mmask8 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_psrad128_mask ((__v4si) __A,
       (__v4si) __B,
       (__v4si) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_sra_epi32 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psrad128_mask ((__v4si) __A,
       (__v4si) __B,
       (__v4si)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sra_epi64 (__m256i __A, __m128i __B)
{
  return (__m256i) __builtin_ia32_psraq256_mask ((__v4di) __A,
       (__v2di) __B,
       (__v4di)
       _mm256_setzero_si256 (),
       (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_sra_epi64 (__m256i __W, __mmask8 __U, __m256i __A,
         __m128i __B)
{
  return (__m256i) __builtin_ia32_psraq256_mask ((__v4di) __A,
       (__v2di) __B,
       (__v4di) __W,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_sra_epi64 (__mmask8 __U, __m256i __A, __m128i __B)
{
  return (__m256i) __builtin_ia32_psraq256_mask ((__v4di) __A,
       (__v2di) __B,
       (__v4di)
       _mm256_setzero_si256 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_sra_epi64 (__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psraq128_mask ((__v2di) __A,
       (__v2di) __B,
       (__v2di)
       _mm_setzero_si128 (),
       (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_sra_epi64 (__m128i __W, __mmask8 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_psraq128_mask ((__v2di) __A,
       (__v2di) __B,
       (__v2di) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_sra_epi64 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psraq128_mask ((__v2di) __A,
       (__v2di) __B,
       (__v2di)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_sll_epi32 (__m128i __W, __mmask8 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_pslld128_mask ((__v4si) __A,
       (__v4si) __B,
       (__v4si) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_sll_epi32 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pslld128_mask ((__v4si) __A,
       (__v4si) __B,
       (__v4si)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_sll_epi64 (__m128i __W, __mmask8 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_psllq128_mask ((__v2di) __A,
       (__v2di) __B,
       (__v2di) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_sll_epi64 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psllq128_mask ((__v2di) __A,
       (__v2di) __B,
       (__v2di)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_sll_epi32 (__m256i __W, __mmask8 __U, __m256i __A,
         __m128i __B)
{
  return (__m256i) __builtin_ia32_pslld256_mask ((__v8si) __A,
       (__v4si) __B,
       (__v8si) __W,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_sll_epi32 (__mmask8 __U, __m256i __A, __m128i __B)
{
  return (__m256i) __builtin_ia32_pslld256_mask ((__v8si) __A,
       (__v4si) __B,
       (__v8si)
       _mm256_setzero_si256 (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_sll_epi64 (__m256i __W, __mmask8 __U, __m256i __A,
         __m128i __B)
{
  return (__m256i) __builtin_ia32_psllq256_mask ((__v4di) __A,
       (__v2di) __B,
       (__v4di) __W,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_sll_epi64 (__mmask8 __U, __m256i __A, __m128i __B)
{
  return (__m256i) __builtin_ia32_psllq256_mask ((__v4di) __A,
       (__v2di) __B,
       (__v4di)
       _mm256_setzero_si256 (),
       (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_permutexvar_ps (__m256 __W, __mmask8 __U, __m256i __X,
       __m256 __Y)
{
  return (__m256) __builtin_ia32_permvarsf256_mask ((__v8sf) __Y,
          (__v8si) __X,
          (__v8sf) __W,
          (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_permutexvar_ps (__mmask8 __U, __m256i __X, __m256 __Y)
{
  return (__m256) __builtin_ia32_permvarsf256_mask ((__v8sf) __Y,
          (__v8si) __X,
          (__v8sf)
          _mm256_setzero_ps (),
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_permutexvar_pd (__m256i __X, __m256d __Y)
{
  return (__m256d) __builtin_ia32_permvardf256_mask ((__v4df) __Y,
           (__v4di) __X,
           (__v4df)
           _mm256_setzero_pd (),
           (__mmask8) -1);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_permutexvar_pd (__m256d __W, __mmask8 __U, __m256i __X,
       __m256d __Y)
{
  return (__m256d) __builtin_ia32_permvardf256_mask ((__v4df) __Y,
           (__v4di) __X,
           (__v4df) __W,
           (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_permutexvar_pd (__mmask8 __U, __m256i __X, __m256d __Y)
{
  return (__m256d) __builtin_ia32_permvardf256_mask ((__v4df) __Y,
           (__v4di) __X,
           (__v4df)
           _mm256_setzero_pd (),
           (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_permutevar_pd (__m256d __W, __mmask8 __U, __m256d __A,
      __m256i __C)
{
  return (__m256d) __builtin_ia32_vpermilvarpd256_mask ((__v4df) __A,
       (__v4di) __C,
       (__v4df) __W,
       (__mmask8)
       __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_permutevar_pd (__mmask8 __U, __m256d __A, __m256i __C)
{
  return (__m256d) __builtin_ia32_vpermilvarpd256_mask ((__v4df) __A,
       (__v4di) __C,
       (__v4df)
       _mm256_setzero_pd (),
       (__mmask8)
       __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_permutevar_ps (__m256 __W, __mmask8 __U, __m256 __A,
      __m256i __C)
{
  return (__m256) __builtin_ia32_vpermilvarps256_mask ((__v8sf) __A,
             (__v8si) __C,
             (__v8sf) __W,
             (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_permutevar_ps (__mmask8 __U, __m256 __A, __m256i __C)
{
  return (__m256) __builtin_ia32_vpermilvarps256_mask ((__v8sf) __A,
             (__v8si) __C,
             (__v8sf)
             _mm256_setzero_ps (),
             (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_permutevar_pd (__m128d __W, __mmask8 __U, __m128d __A,
   __m128i __C)
{
  return (__m128d) __builtin_ia32_vpermilvarpd_mask ((__v2df) __A,
           (__v2di) __C,
           (__v2df) __W,
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_permutevar_pd (__mmask8 __U, __m128d __A, __m128i __C)
{
  return (__m128d) __builtin_ia32_vpermilvarpd_mask ((__v2df) __A,
           (__v2di) __C,
           (__v2df)
           _mm_setzero_pd (),
           (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_permutevar_ps (__m128 __W, __mmask8 __U, __m128 __A,
   __m128i __C)
{
  return (__m128) __builtin_ia32_vpermilvarps_mask ((__v4sf) __A,
          (__v4si) __C,
          (__v4sf) __W,
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_permutevar_ps (__mmask8 __U, __m128 __A, __m128i __C)
{
  return (__m128) __builtin_ia32_vpermilvarps_mask ((__v4sf) __A,
          (__v4si) __C,
          (__v4sf)
          _mm_setzero_ps (),
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_mullo_epi32 (__mmask8 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pmulld256_mask ((__v8si) __A,
        (__v8si) __B,
        (__v8si)
        _mm256_setzero_si256 (),
        __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_permutexvar_epi64 (__mmask8 __M, __m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_permvardi256_mask ((__v4di) __Y,
           (__v4di) __X,
           (__v4di)
           _mm256_setzero_si256 (),
           __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_mullo_epi32 (__m256i __W, __mmask8 __M, __m256i __A,
    __m256i __B)
{
  return (__m256i) __builtin_ia32_pmulld256_mask ((__v8si) __A,
        (__v8si) __B,
        (__v8si) __W, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_mullo_epi32 (__mmask8 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pmulld128_mask ((__v4si) __A,
        (__v4si) __B,
        (__v4si)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_mullo_epi32 (__m128i __W, __mmask8 __M, __m128i __A,
        __m128i __B)
{
  return (__m128i) __builtin_ia32_pmulld128_mask ((__v4si) __A,
        (__v4si) __B,
        (__v4si) __W, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_mul_epi32 (__m256i __W, __mmask8 __M, __m256i __X,
         __m256i __Y)
{
  return (__m256i) __builtin_ia32_pmuldq256_mask ((__v8si) __X,
        (__v8si) __Y,
        (__v4di) __W, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_mul_epi32 (__mmask8 __M, __m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_pmuldq256_mask ((__v8si) __X,
        (__v8si) __Y,
        (__v4di)
        _mm256_setzero_si256 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_mul_epi32 (__m128i __W, __mmask8 __M, __m128i __X,
      __m128i __Y)
{
  return (__m128i) __builtin_ia32_pmuldq128_mask ((__v4si) __X,
        (__v4si) __Y,
        (__v2di) __W, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_mul_epi32 (__mmask8 __M, __m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_pmuldq128_mask ((__v4si) __X,
        (__v4si) __Y,
        (__v2di)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_permutexvar_epi64 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_permvardi256_mask ((__v4di) __Y,
           (__v4di) __X,
           (__v4di)
           _mm256_setzero_si256 (),
           (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_permutexvar_epi64 (__m256i __W, __mmask8 __M, __m256i __X,
          __m256i __Y)
{
  return (__m256i) __builtin_ia32_permvardi256_mask ((__v4di) __Y,
           (__v4di) __X,
           (__v4di) __W,
           __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_mul_epu32 (__m256i __W, __mmask8 __M, __m256i __X,
         __m256i __Y)
{
  return (__m256i) __builtin_ia32_pmuludq256_mask ((__v8si) __X,
         (__v8si) __Y,
         (__v4di) __W, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_permutexvar_epi32 (__mmask8 __M, __m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_permvarsi256_mask ((__v8si) __Y,
           (__v8si) __X,
           (__v8si)
           _mm256_setzero_si256 (),
           __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_mul_epu32 (__mmask8 __M, __m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_pmuludq256_mask ((__v8si) __X,
         (__v8si) __Y,
         (__v4di)
         _mm256_setzero_si256 (),
         __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_mul_epu32 (__m128i __W, __mmask8 __M, __m128i __X,
      __m128i __Y)
{
  return (__m128i) __builtin_ia32_pmuludq128_mask ((__v4si) __X,
         (__v4si) __Y,
         (__v2di) __W, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_mul_epu32 (__mmask8 __M, __m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_pmuludq128_mask ((__v4si) __X,
         (__v4si) __Y,
         (__v2di)
         _mm_setzero_si128 (),
         __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_permutexvar_epi32 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_permvarsi256_mask ((__v8si) __Y,
           (__v8si) __X,
           (__v8si)
           _mm256_setzero_si256 (),
           (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_permutexvar_epi32 (__m256i __W, __mmask8 __M, __m256i __X,
          __m256i __Y)
{
  return (__m256i) __builtin_ia32_permvarsi256_mask ((__v8si) __Y,
           (__v8si) __X,
           (__v8si) __W,
           __M);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpneq_epu32_mask (__mmask8 __M, __m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpd256_mask ((__v8si) __X,
        (__v8si) __Y, 4,
        (__mmask8) __M);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpneq_epu32_mask (__m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpd256_mask ((__v8si) __X,
        (__v8si) __Y, 4,
        (__mmask8) -1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmplt_epu32_mask (__mmask8 __M, __m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpd256_mask ((__v8si) __X,
        (__v8si) __Y, 1,
        (__mmask8) __M);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmplt_epu32_mask (__m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpd256_mask ((__v8si) __X,
        (__v8si) __Y, 1,
        (__mmask8) -1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpge_epu32_mask (__mmask8 __M, __m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpd256_mask ((__v8si) __X,
        (__v8si) __Y, 5,
        (__mmask8) __M);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpge_epu32_mask (__m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpd256_mask ((__v8si) __X,
        (__v8si) __Y, 5,
        (__mmask8) -1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmple_epu32_mask (__mmask8 __M, __m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpd256_mask ((__v8si) __X,
        (__v8si) __Y, 2,
        (__mmask8) __M);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmple_epu32_mask (__m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpd256_mask ((__v8si) __X,
        (__v8si) __Y, 2,
        (__mmask8) -1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpneq_epu64_mask (__mmask8 __M, __m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpq256_mask ((__v4di) __X,
        (__v4di) __Y, 4,
        (__mmask8) __M);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpneq_epu64_mask (__m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpq256_mask ((__v4di) __X,
        (__v4di) __Y, 4,
        (__mmask8) -1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmplt_epu64_mask (__mmask8 __M, __m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpq256_mask ((__v4di) __X,
        (__v4di) __Y, 1,
        (__mmask8) __M);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmplt_epu64_mask (__m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpq256_mask ((__v4di) __X,
        (__v4di) __Y, 1,
        (__mmask8) -1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpge_epu64_mask (__mmask8 __M, __m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpq256_mask ((__v4di) __X,
        (__v4di) __Y, 5,
        (__mmask8) __M);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpge_epu64_mask (__m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpq256_mask ((__v4di) __X,
        (__v4di) __Y, 5,
        (__mmask8) -1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmple_epu64_mask (__mmask8 __M, __m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpq256_mask ((__v4di) __X,
        (__v4di) __Y, 2,
        (__mmask8) __M);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmple_epu64_mask (__m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpq256_mask ((__v4di) __X,
        (__v4di) __Y, 2,
        (__mmask8) -1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpneq_epi32_mask (__mmask8 __M, __m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_cmpd256_mask ((__v8si) __X,
       (__v8si) __Y, 4,
       (__mmask8) __M);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpneq_epi32_mask (__m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_cmpd256_mask ((__v8si) __X,
       (__v8si) __Y, 4,
       (__mmask8) -1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmplt_epi32_mask (__mmask8 __M, __m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_cmpd256_mask ((__v8si) __X,
       (__v8si) __Y, 1,
       (__mmask8) __M);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmplt_epi32_mask (__m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_cmpd256_mask ((__v8si) __X,
       (__v8si) __Y, 1,
       (__mmask8) -1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpge_epi32_mask (__mmask8 __M, __m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_cmpd256_mask ((__v8si) __X,
       (__v8si) __Y, 5,
       (__mmask8) __M);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpge_epi32_mask (__m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_cmpd256_mask ((__v8si) __X,
       (__v8si) __Y, 5,
       (__mmask8) -1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmple_epi32_mask (__mmask8 __M, __m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_cmpd256_mask ((__v8si) __X,
       (__v8si) __Y, 2,
       (__mmask8) __M);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmple_epi32_mask (__m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_cmpd256_mask ((__v8si) __X,
       (__v8si) __Y, 2,
       (__mmask8) -1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpneq_epi64_mask (__mmask8 __M, __m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_cmpq256_mask ((__v4di) __X,
       (__v4di) __Y, 4,
       (__mmask8) __M);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpneq_epi64_mask (__m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_cmpq256_mask ((__v4di) __X,
       (__v4di) __Y, 4,
       (__mmask8) -1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmplt_epi64_mask (__mmask8 __M, __m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_cmpq256_mask ((__v4di) __X,
       (__v4di) __Y, 1,
       (__mmask8) __M);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmplt_epi64_mask (__m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_cmpq256_mask ((__v4di) __X,
       (__v4di) __Y, 1,
       (__mmask8) -1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpge_epi64_mask (__mmask8 __M, __m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_cmpq256_mask ((__v4di) __X,
       (__v4di) __Y, 5,
       (__mmask8) __M);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpge_epi64_mask (__m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_cmpq256_mask ((__v4di) __X,
       (__v4di) __Y, 5,
       (__mmask8) -1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmple_epi64_mask (__mmask8 __M, __m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_cmpq256_mask ((__v4di) __X,
       (__v4di) __Y, 2,
       (__mmask8) __M);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmple_epi64_mask (__m256i __X, __m256i __Y)
{
  return (__mmask8) __builtin_ia32_cmpq256_mask ((__v4di) __X,
       (__v4di) __Y, 2,
       (__mmask8) -1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpneq_epu32_mask (__mmask8 __M, __m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpd128_mask ((__v4si) __X,
        (__v4si) __Y, 4,
        (__mmask8) __M);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpneq_epu32_mask (__m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpd128_mask ((__v4si) __X,
        (__v4si) __Y, 4,
        (__mmask8) -1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmplt_epu32_mask (__mmask8 __M, __m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpd128_mask ((__v4si) __X,
        (__v4si) __Y, 1,
        (__mmask8) __M);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmplt_epu32_mask (__m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpd128_mask ((__v4si) __X,
        (__v4si) __Y, 1,
        (__mmask8) -1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpge_epu32_mask (__mmask8 __M, __m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpd128_mask ((__v4si) __X,
        (__v4si) __Y, 5,
        (__mmask8) __M);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpge_epu32_mask (__m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpd128_mask ((__v4si) __X,
        (__v4si) __Y, 5,
        (__mmask8) -1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmple_epu32_mask (__mmask8 __M, __m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpd128_mask ((__v4si) __X,
        (__v4si) __Y, 2,
        (__mmask8) __M);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmple_epu32_mask (__m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpd128_mask ((__v4si) __X,
        (__v4si) __Y, 2,
        (__mmask8) -1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpneq_epu64_mask (__mmask8 __M, __m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpq128_mask ((__v2di) __X,
        (__v2di) __Y, 4,
        (__mmask8) __M);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpneq_epu64_mask (__m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpq128_mask ((__v2di) __X,
        (__v2di) __Y, 4,
        (__mmask8) -1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmplt_epu64_mask (__mmask8 __M, __m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpq128_mask ((__v2di) __X,
        (__v2di) __Y, 1,
        (__mmask8) __M);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmplt_epu64_mask (__m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpq128_mask ((__v2di) __X,
        (__v2di) __Y, 1,
        (__mmask8) -1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpge_epu64_mask (__mmask8 __M, __m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpq128_mask ((__v2di) __X,
        (__v2di) __Y, 5,
        (__mmask8) __M);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpge_epu64_mask (__m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpq128_mask ((__v2di) __X,
        (__v2di) __Y, 5,
        (__mmask8) -1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmple_epu64_mask (__mmask8 __M, __m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpq128_mask ((__v2di) __X,
        (__v2di) __Y, 2,
        (__mmask8) __M);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmple_epu64_mask (__m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpq128_mask ((__v2di) __X,
        (__v2di) __Y, 2,
        (__mmask8) -1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpneq_epi32_mask (__mmask8 __M, __m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_cmpd128_mask ((__v4si) __X,
       (__v4si) __Y, 4,
       (__mmask8) __M);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpneq_epi32_mask (__m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_cmpd128_mask ((__v4si) __X,
       (__v4si) __Y, 4,
       (__mmask8) -1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmplt_epi32_mask (__mmask8 __M, __m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_cmpd128_mask ((__v4si) __X,
       (__v4si) __Y, 1,
       (__mmask8) __M);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmplt_epi32_mask (__m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_cmpd128_mask ((__v4si) __X,
       (__v4si) __Y, 1,
       (__mmask8) -1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpge_epi32_mask (__mmask8 __M, __m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_cmpd128_mask ((__v4si) __X,
       (__v4si) __Y, 5,
       (__mmask8) __M);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpge_epi32_mask (__m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_cmpd128_mask ((__v4si) __X,
       (__v4si) __Y, 5,
       (__mmask8) -1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmple_epi32_mask (__mmask8 __M, __m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_cmpd128_mask ((__v4si) __X,
       (__v4si) __Y, 2,
       (__mmask8) __M);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmple_epi32_mask (__m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_cmpd128_mask ((__v4si) __X,
       (__v4si) __Y, 2,
       (__mmask8) -1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpneq_epi64_mask (__mmask8 __M, __m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_cmpq128_mask ((__v2di) __X,
       (__v2di) __Y, 4,
       (__mmask8) __M);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpneq_epi64_mask (__m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_cmpq128_mask ((__v2di) __X,
       (__v2di) __Y, 4,
       (__mmask8) -1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmplt_epi64_mask (__mmask8 __M, __m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_cmpq128_mask ((__v2di) __X,
       (__v2di) __Y, 1,
       (__mmask8) __M);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmplt_epi64_mask (__m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_cmpq128_mask ((__v2di) __X,
       (__v2di) __Y, 1,
       (__mmask8) -1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpge_epi64_mask (__mmask8 __M, __m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_cmpq128_mask ((__v2di) __X,
       (__v2di) __Y, 5,
       (__mmask8) __M);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpge_epi64_mask (__m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_cmpq128_mask ((__v2di) __X,
       (__v2di) __Y, 5,
       (__mmask8) -1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmple_epi64_mask (__mmask8 __M, __m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_cmpq128_mask ((__v2di) __X,
       (__v2di) __Y, 2,
       (__mmask8) __M);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmple_epi64_mask (__m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_cmpq128_mask ((__v2di) __X,
       (__v2di) __Y, 2,
       (__mmask8) -1);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx512bw")
typedef short __v32hi __attribute__ ((__vector_size__ (64)));
typedef short __v32hi_u __attribute__ ((__vector_size__ (64), __may_alias__, __aligned__ (1)));
typedef char __v64qi __attribute__ ((__vector_size__ (64)));
typedef char __v64qi_u __attribute__ ((__vector_size__ (64), __may_alias__, __aligned__ (1)));
typedef unsigned long long __mmask64;
extern __inline unsigned char
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_ktest_mask32_u8 (__mmask32 __A, __mmask32 __B, unsigned char *__CF)
{
  *__CF = (unsigned char) __builtin_ia32_ktestcsi (__A, __B);
  return (unsigned char) __builtin_ia32_ktestzsi (__A, __B);
}
extern __inline unsigned char
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_ktest_mask64_u8 (__mmask64 __A, __mmask64 __B, unsigned char *__CF)
{
  *__CF = (unsigned char) __builtin_ia32_ktestcdi (__A, __B);
  return (unsigned char) __builtin_ia32_ktestzdi (__A, __B);
}
extern __inline unsigned char
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_ktestz_mask32_u8 (__mmask32 __A, __mmask32 __B)
{
  return (unsigned char) __builtin_ia32_ktestzsi (__A, __B);
}
extern __inline unsigned char
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_ktestz_mask64_u8 (__mmask64 __A, __mmask64 __B)
{
  return (unsigned char) __builtin_ia32_ktestzdi (__A, __B);
}
extern __inline unsigned char
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_ktestc_mask32_u8 (__mmask32 __A, __mmask32 __B)
{
  return (unsigned char) __builtin_ia32_ktestcsi (__A, __B);
}
extern __inline unsigned char
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_ktestc_mask64_u8 (__mmask64 __A, __mmask64 __B)
{
  return (unsigned char) __builtin_ia32_ktestcdi (__A, __B);
}
extern __inline unsigned char
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_kortest_mask32_u8 (__mmask32 __A, __mmask32 __B, unsigned char *__CF)
{
  *__CF = (unsigned char) __builtin_ia32_kortestcsi (__A, __B);
  return (unsigned char) __builtin_ia32_kortestzsi (__A, __B);
}
extern __inline unsigned char
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_kortest_mask64_u8 (__mmask64 __A, __mmask64 __B, unsigned char *__CF)
{
  *__CF = (unsigned char) __builtin_ia32_kortestcdi (__A, __B);
  return (unsigned char) __builtin_ia32_kortestzdi (__A, __B);
}
extern __inline unsigned char
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_kortestz_mask32_u8 (__mmask32 __A, __mmask32 __B)
{
  return (unsigned char) __builtin_ia32_kortestzsi (__A, __B);
}
extern __inline unsigned char
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_kortestz_mask64_u8 (__mmask64 __A, __mmask64 __B)
{
  return (unsigned char) __builtin_ia32_kortestzdi (__A, __B);
}
extern __inline unsigned char
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_kortestc_mask32_u8 (__mmask32 __A, __mmask32 __B)
{
  return (unsigned char) __builtin_ia32_kortestcsi (__A, __B);
}
extern __inline unsigned char
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_kortestc_mask64_u8 (__mmask64 __A, __mmask64 __B)
{
  return (unsigned char) __builtin_ia32_kortestcdi (__A, __B);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_kadd_mask32 (__mmask32 __A, __mmask32 __B)
{
  return (__mmask32) __builtin_ia32_kaddsi ((__mmask32) __A, (__mmask32) __B);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_kadd_mask64 (__mmask64 __A, __mmask64 __B)
{
  return (__mmask64) __builtin_ia32_kadddi ((__mmask64) __A, (__mmask64) __B);
}
extern __inline unsigned int
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_cvtmask32_u32 (__mmask32 __A)
{
  return (unsigned int) __builtin_ia32_kmovd ((__mmask32) __A);
}
extern __inline unsigned long long
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_cvtmask64_u64 (__mmask64 __A)
{
  return (unsigned long long) __builtin_ia32_kmovq ((__mmask64) __A);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_cvtu32_mask32 (unsigned int __A)
{
  return (__mmask32) __builtin_ia32_kmovd ((__mmask32) __A);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_cvtu64_mask64 (unsigned long long __A)
{
  return (__mmask64) __builtin_ia32_kmovq ((__mmask64) __A);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_load_mask32 (__mmask32 *__A)
{
  return (__mmask32) __builtin_ia32_kmovd (*__A);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_load_mask64 (__mmask64 *__A)
{
  return (__mmask64) __builtin_ia32_kmovq (*(__mmask64 *) __A);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_store_mask32 (__mmask32 *__A, __mmask32 __B)
{
  *(__mmask32 *) __A = __builtin_ia32_kmovd (__B);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_store_mask64 (__mmask64 *__A, __mmask64 __B)
{
  *(__mmask64 *) __A = __builtin_ia32_kmovq (__B);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_knot_mask32 (__mmask32 __A)
{
  return (__mmask32) __builtin_ia32_knotsi ((__mmask32) __A);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_knot_mask64 (__mmask64 __A)
{
  return (__mmask64) __builtin_ia32_knotdi ((__mmask64) __A);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_kor_mask32 (__mmask32 __A, __mmask32 __B)
{
  return (__mmask32) __builtin_ia32_korsi ((__mmask32) __A, (__mmask32) __B);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_kor_mask64 (__mmask64 __A, __mmask64 __B)
{
  return (__mmask64) __builtin_ia32_kordi ((__mmask64) __A, (__mmask64) __B);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_kxnor_mask32 (__mmask32 __A, __mmask32 __B)
{
  return (__mmask32) __builtin_ia32_kxnorsi ((__mmask32) __A, (__mmask32) __B);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_kxnor_mask64 (__mmask64 __A, __mmask64 __B)
{
  return (__mmask64) __builtin_ia32_kxnordi ((__mmask64) __A, (__mmask64) __B);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_kxor_mask32 (__mmask32 __A, __mmask32 __B)
{
  return (__mmask32) __builtin_ia32_kxorsi ((__mmask32) __A, (__mmask32) __B);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_kxor_mask64 (__mmask64 __A, __mmask64 __B)
{
  return (__mmask64) __builtin_ia32_kxordi ((__mmask64) __A, (__mmask64) __B);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_kand_mask32 (__mmask32 __A, __mmask32 __B)
{
  return (__mmask32) __builtin_ia32_kandsi ((__mmask32) __A, (__mmask32) __B);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_kand_mask64 (__mmask64 __A, __mmask64 __B)
{
  return (__mmask64) __builtin_ia32_kanddi ((__mmask64) __A, (__mmask64) __B);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_kandn_mask32 (__mmask32 __A, __mmask32 __B)
{
  return (__mmask32) __builtin_ia32_kandnsi ((__mmask32) __A, (__mmask32) __B);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_kandn_mask64 (__mmask64 __A, __mmask64 __B)
{
  return (__mmask64) __builtin_ia32_kandndi ((__mmask64) __A, (__mmask64) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_mov_epi16 (__m512i __W, __mmask32 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_movdquhi512_mask ((__v32hi) __A,
          (__v32hi) __W,
          (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_mov_epi16 (__mmask32 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_movdquhi512_mask ((__v32hi) __A,
          (__v32hi)
          _mm512_setzero_si512 (),
          (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_loadu_epi16 (void const *__P)
{
  return (__m512i) (*(__v32hi_u *) __P);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_loadu_epi16 (__m512i __W, __mmask32 __U, void const *__P)
{
  return (__m512i) __builtin_ia32_loaddquhi512_mask ((const short *) __P,
           (__v32hi) __W,
           (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_loadu_epi16 (__mmask32 __U, void const *__P)
{
  return (__m512i) __builtin_ia32_loaddquhi512_mask ((const short *) __P,
           (__v32hi)
           _mm512_setzero_si512 (),
           (__mmask32) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_storeu_epi16 (void *__P, __m512i __A)
{
  *(__v32hi_u *) __P = (__v32hi_u) __A;
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_storeu_epi16 (void *__P, __mmask32 __U, __m512i __A)
{
  __builtin_ia32_storedquhi512_mask ((short *) __P,
         (__v32hi) __A,
         (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_mov_epi8 (__m512i __W, __mmask64 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_movdquqi512_mask ((__v64qi) __A,
          (__v64qi) __W,
          (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_mov_epi8 (__mmask64 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_movdquqi512_mask ((__v64qi) __A,
          (__v64qi)
          _mm512_setzero_si512 (),
          (__mmask64) __U);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_kunpackw (__mmask32 __A, __mmask32 __B)
{
  return (__mmask32) __builtin_ia32_kunpcksi ((__mmask32) __A,
           (__mmask32) __B);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_kunpackw_mask32 (__mmask16 __A, __mmask16 __B)
{
  return (__mmask32) __builtin_ia32_kunpcksi ((__mmask32) __A,
           (__mmask32) __B);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_kunpackd (__mmask64 __A, __mmask64 __B)
{
  return (__mmask64) __builtin_ia32_kunpckdi ((__mmask64) __A,
           (__mmask64) __B);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_kunpackd_mask64 (__mmask32 __A, __mmask32 __B)
{
  return (__mmask64) __builtin_ia32_kunpckdi ((__mmask64) __A,
           (__mmask64) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_loadu_epi8 (void const *__P)
{
  return (__m512i) (*(__v64qi_u *) __P);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_loadu_epi8 (__m512i __W, __mmask64 __U, void const *__P)
{
  return (__m512i) __builtin_ia32_loaddquqi512_mask ((const char *) __P,
           (__v64qi) __W,
           (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_loadu_epi8 (__mmask64 __U, void const *__P)
{
  return (__m512i) __builtin_ia32_loaddquqi512_mask ((const char *) __P,
           (__v64qi)
           _mm512_setzero_si512 (),
           (__mmask64) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_storeu_epi8 (void *__P, __m512i __A)
{
  *(__v64qi_u *) __P = (__v64qi_u) __A;
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_storeu_epi8 (void *__P, __mmask64 __U, __m512i __A)
{
  __builtin_ia32_storedquqi512_mask ((char *) __P,
         (__v64qi) __A,
         (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_sad_epu8 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psadbw512 ((__v64qi) __A,
          (__v64qi) __B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepi16_epi8 (__m512i __A)
{
  return (__m256i) __builtin_ia32_pmovwb512_mask ((__v32hi) __A,
        (__v32qi) _mm256_undefined_si256(),
        (__mmask32) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi16_storeu_epi8 (void * __P, __mmask32 __M, __m512i __A)
{
  __builtin_ia32_pmovwb512mem_mask ((__v32qi *) __P, (__v32hi) __A, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi16_epi8 (__m256i __O, __mmask32 __M, __m512i __A)
{
  return (__m256i) __builtin_ia32_pmovwb512_mask ((__v32hi) __A,
        (__v32qi) __O, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepi16_epi8 (__mmask32 __M, __m512i __A)
{
  return (__m256i) __builtin_ia32_pmovwb512_mask ((__v32hi) __A,
        (__v32qi)
        _mm256_setzero_si256 (),
        __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtsepi16_epi8 (__m512i __A)
{
  return (__m256i) __builtin_ia32_pmovswb512_mask ((__v32hi) __A,
         (__v32qi)_mm256_undefined_si256(),
         (__mmask32) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtsepi16_storeu_epi8 (void * __P, __mmask32 __M, __m512i __A)
{
  __builtin_ia32_pmovswb512mem_mask ((__v32qi *) __P, (__v32hi) __A, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtsepi16_epi8 (__m256i __O, __mmask32 __M, __m512i __A)
{
  return (__m256i) __builtin_ia32_pmovswb512_mask ((__v32hi) __A,
         (__v32qi)__O,
         __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtsepi16_epi8 (__mmask32 __M, __m512i __A)
{
  return (__m256i) __builtin_ia32_pmovswb512_mask ((__v32hi) __A,
         (__v32qi)
         _mm256_setzero_si256 (),
         __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtusepi16_epi8 (__m512i __A)
{
  return (__m256i) __builtin_ia32_pmovuswb512_mask ((__v32hi) __A,
          (__v32qi)_mm256_undefined_si256(),
          (__mmask32) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtusepi16_epi8 (__m256i __O, __mmask32 __M, __m512i __A)
{
  return (__m256i) __builtin_ia32_pmovuswb512_mask ((__v32hi) __A,
          (__v32qi) __O,
          __M);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtusepi16_storeu_epi8 (void * __P, __mmask32 __M, __m512i __A)
{
  __builtin_ia32_pmovuswb512mem_mask ((__v32qi *) __P, (__v32hi) __A, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtusepi16_epi8 (__mmask32 __M, __m512i __A)
{
  return (__m256i) __builtin_ia32_pmovuswb512_mask ((__v32hi) __A,
          (__v32qi)
          _mm256_setzero_si256 (),
          __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_broadcastb_epi8 (__m128i __A)
{
  return (__m512i) __builtin_ia32_pbroadcastb512_mask ((__v16qi) __A,
             (__v64qi)_mm512_undefined_epi32(),
             (__mmask64) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_broadcastb_epi8 (__m512i __O, __mmask64 __M, __m128i __A)
{
  return (__m512i) __builtin_ia32_pbroadcastb512_mask ((__v16qi) __A,
             (__v64qi) __O,
             __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_broadcastb_epi8 (__mmask64 __M, __m128i __A)
{
  return (__m512i) __builtin_ia32_pbroadcastb512_mask ((__v16qi) __A,
             (__v64qi)
             _mm512_setzero_si512 (),
             __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_set1_epi8 (__m512i __O, __mmask64 __M, char __A)
{
  return (__m512i) __builtin_ia32_pbroadcastb512_gpr_mask (__A,
          (__v64qi) __O,
          __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_set1_epi8 (__mmask64 __M, char __A)
{
  return (__m512i)
  __builtin_ia32_pbroadcastb512_gpr_mask (__A,
       (__v64qi)
       _mm512_setzero_si512 (),
       __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_broadcastw_epi16 (__m128i __A)
{
  return (__m512i) __builtin_ia32_pbroadcastw512_mask ((__v8hi) __A,
             (__v32hi)_mm512_undefined_epi32(),
             (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_broadcastw_epi16 (__m512i __O, __mmask32 __M, __m128i __A)
{
  return (__m512i) __builtin_ia32_pbroadcastw512_mask ((__v8hi) __A,
             (__v32hi) __O,
             __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_broadcastw_epi16 (__mmask32 __M, __m128i __A)
{
  return (__m512i) __builtin_ia32_pbroadcastw512_mask ((__v8hi) __A,
             (__v32hi)
             _mm512_setzero_si512 (),
             __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_set1_epi16 (__m512i __O, __mmask32 __M, short __A)
{
  return (__m512i) __builtin_ia32_pbroadcastw512_gpr_mask (__A,
          (__v32hi) __O,
          __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_set1_epi16 (__mmask32 __M, short __A)
{
  return (__m512i)
  __builtin_ia32_pbroadcastw512_gpr_mask (__A,
       (__v32hi)
       _mm512_setzero_si512 (),
       __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mulhrs_epi16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmulhrsw512_mask ((__v32hi) __A,
          (__v32hi) __B,
          (__v32hi)
          _mm512_setzero_si512 (),
          (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_mulhrs_epi16 (__m512i __W, __mmask32 __U, __m512i __A,
     __m512i __B)
{
  return (__m512i) __builtin_ia32_pmulhrsw512_mask ((__v32hi) __A,
          (__v32hi) __B,
          (__v32hi) __W,
          (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_mulhrs_epi16 (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmulhrsw512_mask ((__v32hi) __A,
          (__v32hi) __B,
          (__v32hi)
          _mm512_setzero_si512 (),
          (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mulhi_epi16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmulhw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_si512 (),
        (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_mulhi_epi16 (__m512i __W, __mmask32 __U, __m512i __A,
    __m512i __B)
{
  return (__m512i) __builtin_ia32_pmulhw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi) __W,
        (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_mulhi_epi16 (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmulhw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_si512 (),
        (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mulhi_epu16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmulhuw512_mask ((__v32hi) __A,
         (__v32hi) __B,
         (__v32hi)
         _mm512_setzero_si512 (),
         (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_mulhi_epu16 (__m512i __W, __mmask32 __U, __m512i __A,
    __m512i __B)
{
  return (__m512i) __builtin_ia32_pmulhuw512_mask ((__v32hi) __A,
         (__v32hi) __B,
         (__v32hi) __W,
         (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_mulhi_epu16 (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmulhuw512_mask ((__v32hi) __A,
         (__v32hi) __B,
         (__v32hi)
         _mm512_setzero_si512 (),
         (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mullo_epi16 (__m512i __A, __m512i __B)
{
  return (__m512i) ((__v32hu) __A * (__v32hu) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_mullo_epi16 (__m512i __W, __mmask32 __U, __m512i __A,
    __m512i __B)
{
  return (__m512i) __builtin_ia32_pmullw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi) __W,
        (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_mullo_epi16 (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmullw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_si512 (),
        (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepi8_epi16 (__m256i __A)
{
  return (__m512i) __builtin_ia32_pmovsxbw512_mask ((__v32qi) __A,
          (__v32hi)
          _mm512_setzero_si512 (),
          (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi8_epi16 (__m512i __W, __mmask32 __U, __m256i __A)
{
  return (__m512i) __builtin_ia32_pmovsxbw512_mask ((__v32qi) __A,
          (__v32hi) __W,
          (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepi8_epi16 (__mmask32 __U, __m256i __A)
{
  return (__m512i) __builtin_ia32_pmovsxbw512_mask ((__v32qi) __A,
          (__v32hi)
          _mm512_setzero_si512 (),
          (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepu8_epi16 (__m256i __A)
{
  return (__m512i) __builtin_ia32_pmovzxbw512_mask ((__v32qi) __A,
          (__v32hi)
          _mm512_setzero_si512 (),
          (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepu8_epi16 (__m512i __W, __mmask32 __U, __m256i __A)
{
  return (__m512i) __builtin_ia32_pmovzxbw512_mask ((__v32qi) __A,
          (__v32hi) __W,
          (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepu8_epi16 (__mmask32 __U, __m256i __A)
{
  return (__m512i) __builtin_ia32_pmovzxbw512_mask ((__v32qi) __A,
          (__v32hi)
          _mm512_setzero_si512 (),
          (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_permutexvar_epi16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_permvarhi512_mask ((__v32hi) __B,
           (__v32hi) __A,
           (__v32hi)
           _mm512_setzero_si512 (),
           (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_permutexvar_epi16 (__mmask32 __M, __m512i __A,
    __m512i __B)
{
  return (__m512i) __builtin_ia32_permvarhi512_mask ((__v32hi) __B,
           (__v32hi) __A,
           (__v32hi)
           _mm512_setzero_si512 (),
           (__mmask32) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_permutexvar_epi16 (__m512i __W, __mmask32 __M, __m512i __A,
          __m512i __B)
{
  return (__m512i) __builtin_ia32_permvarhi512_mask ((__v32hi) __B,
           (__v32hi) __A,
           (__v32hi) __W,
           (__mmask32) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_permutex2var_epi16 (__m512i __A, __m512i __I, __m512i __B)
{
  return (__m512i) __builtin_ia32_vpermt2varhi512_mask ((__v32hi) __I
                 ,
       (__v32hi) __A,
       (__v32hi) __B,
       (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_permutex2var_epi16 (__m512i __A, __mmask32 __U,
    __m512i __I, __m512i __B)
{
  return (__m512i) __builtin_ia32_vpermt2varhi512_mask ((__v32hi) __I
                 ,
       (__v32hi) __A,
       (__v32hi) __B,
       (__mmask32)
       __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask2_permutex2var_epi16 (__m512i __A, __m512i __I,
     __mmask32 __U, __m512i __B)
{
  return (__m512i) __builtin_ia32_vpermi2varhi512_mask ((__v32hi) __A,
       (__v32hi) __I
                 ,
       (__v32hi) __B,
       (__mmask32)
       __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_permutex2var_epi16 (__mmask32 __U, __m512i __A,
     __m512i __I, __m512i __B)
{
  return (__m512i) __builtin_ia32_vpermt2varhi512_maskz ((__v32hi) __I
                  ,
        (__v32hi) __A,
        (__v32hi) __B,
        (__mmask32)
        __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_avg_epu8 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pavgb512_mask ((__v64qi) __A,
       (__v64qi) __B,
       (__v64qi)
       _mm512_setzero_si512 (),
       (__mmask64) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_avg_epu8 (__m512i __W, __mmask64 __U, __m512i __A,
        __m512i __B)
{
  return (__m512i) __builtin_ia32_pavgb512_mask ((__v64qi) __A,
       (__v64qi) __B,
       (__v64qi) __W,
       (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_avg_epu8 (__mmask64 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pavgb512_mask ((__v64qi) __A,
       (__v64qi) __B,
       (__v64qi)
       _mm512_setzero_si512 (),
       (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_add_epi8 (__m512i __A, __m512i __B)
{
  return (__m512i) ((__v64qu) __A + (__v64qu) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_add_epi8 (__m512i __W, __mmask64 __U, __m512i __A,
        __m512i __B)
{
  return (__m512i) __builtin_ia32_paddb512_mask ((__v64qi) __A,
       (__v64qi) __B,
       (__v64qi) __W,
       (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_add_epi8 (__mmask64 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_paddb512_mask ((__v64qi) __A,
       (__v64qi) __B,
       (__v64qi)
       _mm512_setzero_si512 (),
       (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_sub_epi8 (__m512i __A, __m512i __B)
{
  return (__m512i) ((__v64qu) __A - (__v64qu) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_sub_epi8 (__m512i __W, __mmask64 __U, __m512i __A,
        __m512i __B)
{
  return (__m512i) __builtin_ia32_psubb512_mask ((__v64qi) __A,
       (__v64qi) __B,
       (__v64qi) __W,
       (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_sub_epi8 (__mmask64 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psubb512_mask ((__v64qi) __A,
       (__v64qi) __B,
       (__v64qi)
       _mm512_setzero_si512 (),
       (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_avg_epu16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pavgw512_mask ((__v32hi) __A,
       (__v32hi) __B,
       (__v32hi)
       _mm512_setzero_si512 (),
       (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_avg_epu16 (__m512i __W, __mmask32 __U, __m512i __A,
         __m512i __B)
{
  return (__m512i) __builtin_ia32_pavgw512_mask ((__v32hi) __A,
       (__v32hi) __B,
       (__v32hi) __W,
       (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_avg_epu16 (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pavgw512_mask ((__v32hi) __A,
       (__v32hi) __B,
       (__v32hi)
       _mm512_setzero_si512 (),
       (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_subs_epi8 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psubsb512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi)
        _mm512_setzero_si512 (),
        (__mmask64) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_subs_epi8 (__m512i __W, __mmask64 __U, __m512i __A,
         __m512i __B)
{
  return (__m512i) __builtin_ia32_psubsb512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi) __W,
        (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_subs_epi8 (__mmask64 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psubsb512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi)
        _mm512_setzero_si512 (),
        (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_subs_epu8 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psubusb512_mask ((__v64qi) __A,
         (__v64qi) __B,
         (__v64qi)
         _mm512_setzero_si512 (),
         (__mmask64) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_subs_epu8 (__m512i __W, __mmask64 __U, __m512i __A,
         __m512i __B)
{
  return (__m512i) __builtin_ia32_psubusb512_mask ((__v64qi) __A,
         (__v64qi) __B,
         (__v64qi) __W,
         (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_subs_epu8 (__mmask64 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psubusb512_mask ((__v64qi) __A,
         (__v64qi) __B,
         (__v64qi)
         _mm512_setzero_si512 (),
         (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_adds_epi8 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_paddsb512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi)
        _mm512_setzero_si512 (),
        (__mmask64) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_adds_epi8 (__m512i __W, __mmask64 __U, __m512i __A,
         __m512i __B)
{
  return (__m512i) __builtin_ia32_paddsb512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi) __W,
        (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_adds_epi8 (__mmask64 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_paddsb512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi)
        _mm512_setzero_si512 (),
        (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_adds_epu8 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_paddusb512_mask ((__v64qi) __A,
         (__v64qi) __B,
         (__v64qi)
         _mm512_setzero_si512 (),
         (__mmask64) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_adds_epu8 (__m512i __W, __mmask64 __U, __m512i __A,
         __m512i __B)
{
  return (__m512i) __builtin_ia32_paddusb512_mask ((__v64qi) __A,
         (__v64qi) __B,
         (__v64qi) __W,
         (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_adds_epu8 (__mmask64 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_paddusb512_mask ((__v64qi) __A,
         (__v64qi) __B,
         (__v64qi)
         _mm512_setzero_si512 (),
         (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_sub_epi16 (__m512i __A, __m512i __B)
{
  return (__m512i) ((__v32hu) __A - (__v32hu) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_sub_epi16 (__m512i __W, __mmask32 __U, __m512i __A,
         __m512i __B)
{
  return (__m512i) __builtin_ia32_psubw512_mask ((__v32hi) __A,
       (__v32hi) __B,
       (__v32hi) __W,
       (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_sub_epi16 (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psubw512_mask ((__v32hi) __A,
       (__v32hi) __B,
       (__v32hi)
       _mm512_setzero_si512 (),
       (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_subs_epi16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psubsw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_si512 (),
        (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_subs_epi16 (__m512i __W, __mmask32 __U, __m512i __A,
   __m512i __B)
{
  return (__m512i) __builtin_ia32_psubsw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi) __W,
        (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_subs_epi16 (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psubsw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_si512 (),
        (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_subs_epu16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psubusw512_mask ((__v32hi) __A,
         (__v32hi) __B,
         (__v32hi)
         _mm512_setzero_si512 (),
         (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_subs_epu16 (__m512i __W, __mmask32 __U, __m512i __A,
   __m512i __B)
{
  return (__m512i) __builtin_ia32_psubusw512_mask ((__v32hi) __A,
         (__v32hi) __B,
         (__v32hi) __W,
         (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_subs_epu16 (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psubusw512_mask ((__v32hi) __A,
         (__v32hi) __B,
         (__v32hi)
         _mm512_setzero_si512 (),
         (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_add_epi16 (__m512i __A, __m512i __B)
{
  return (__m512i) ((__v32hu) __A + (__v32hu) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_add_epi16 (__m512i __W, __mmask32 __U, __m512i __A,
         __m512i __B)
{
  return (__m512i) __builtin_ia32_paddw512_mask ((__v32hi) __A,
       (__v32hi) __B,
       (__v32hi) __W,
       (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_add_epi16 (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_paddw512_mask ((__v32hi) __A,
       (__v32hi) __B,
       (__v32hi)
       _mm512_setzero_si512 (),
       (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_adds_epi16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_paddsw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_si512 (),
        (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_adds_epi16 (__m512i __W, __mmask32 __U, __m512i __A,
   __m512i __B)
{
  return (__m512i) __builtin_ia32_paddsw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi) __W,
        (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_adds_epi16 (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_paddsw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_si512 (),
        (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_adds_epu16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_paddusw512_mask ((__v32hi) __A,
         (__v32hi) __B,
         (__v32hi)
         _mm512_setzero_si512 (),
         (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_adds_epu16 (__m512i __W, __mmask32 __U, __m512i __A,
   __m512i __B)
{
  return (__m512i) __builtin_ia32_paddusw512_mask ((__v32hi) __A,
         (__v32hi) __B,
         (__v32hi) __W,
         (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_adds_epu16 (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_paddusw512_mask ((__v32hi) __A,
         (__v32hi) __B,
         (__v32hi)
         _mm512_setzero_si512 (),
         (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_srl_epi16 (__m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psrlw512_mask ((__v32hi) __A,
       (__v8hi) __B,
       (__v32hi)
       _mm512_setzero_si512 (),
       (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_srl_epi16 (__m512i __W, __mmask32 __U, __m512i __A,
         __m128i __B)
{
  return (__m512i) __builtin_ia32_psrlw512_mask ((__v32hi) __A,
       (__v8hi) __B,
       (__v32hi) __W,
       (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_srl_epi16 (__mmask32 __U, __m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psrlw512_mask ((__v32hi) __A,
       (__v8hi) __B,
       (__v32hi)
       _mm512_setzero_si512 (),
       (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_packs_epi16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_packsswb512_mask ((__v32hi) __A,
          (__v32hi) __B,
          (__v64qi)
          _mm512_setzero_si512 (),
          (__mmask64) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_sll_epi16 (__m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psllw512_mask ((__v32hi) __A,
       (__v8hi) __B,
       (__v32hi)
       _mm512_setzero_si512 (),
       (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_sll_epi16 (__m512i __W, __mmask32 __U, __m512i __A,
         __m128i __B)
{
  return (__m512i) __builtin_ia32_psllw512_mask ((__v32hi) __A,
       (__v8hi) __B,
       (__v32hi) __W,
       (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_sll_epi16 (__mmask32 __U, __m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psllw512_mask ((__v32hi) __A,
       (__v8hi) __B,
       (__v32hi)
       _mm512_setzero_si512 (),
       (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maddubs_epi16 (__m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_pmaddubsw512_mask ((__v64qi) __X,
           (__v64qi) __Y,
           (__v32hi)
           _mm512_setzero_si512 (),
           (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_maddubs_epi16 (__m512i __W, __mmask32 __U, __m512i __X,
      __m512i __Y)
{
  return (__m512i) __builtin_ia32_pmaddubsw512_mask ((__v64qi) __X,
           (__v64qi) __Y,
           (__v32hi) __W,
           (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_maddubs_epi16 (__mmask32 __U, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_pmaddubsw512_mask ((__v64qi) __X,
           (__v64qi) __Y,
           (__v32hi)
           _mm512_setzero_si512 (),
           (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_madd_epi16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaddwd512_mask ((__v32hi) __A,
         (__v32hi) __B,
         (__v16si)
         _mm512_setzero_si512 (),
         (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_madd_epi16 (__m512i __W, __mmask16 __U, __m512i __A,
   __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaddwd512_mask ((__v32hi) __A,
         (__v32hi) __B,
         (__v16si) __W,
         (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_madd_epi16 (__mmask16 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaddwd512_mask ((__v32hi) __A,
         (__v32hi) __B,
         (__v16si)
         _mm512_setzero_si512 (),
         (__mmask16) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_unpackhi_epi8 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_punpckhbw512_mask ((__v64qi) __A,
           (__v64qi) __B,
           (__v64qi)
           _mm512_setzero_si512 (),
           (__mmask64) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_unpackhi_epi8 (__m512i __W, __mmask64 __U, __m512i __A,
      __m512i __B)
{
  return (__m512i) __builtin_ia32_punpckhbw512_mask ((__v64qi) __A,
           (__v64qi) __B,
           (__v64qi) __W,
           (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_unpackhi_epi8 (__mmask64 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_punpckhbw512_mask ((__v64qi) __A,
           (__v64qi) __B,
           (__v64qi)
           _mm512_setzero_si512 (),
           (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_unpackhi_epi16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_punpckhwd512_mask ((__v32hi) __A,
           (__v32hi) __B,
           (__v32hi)
           _mm512_setzero_si512 (),
           (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_unpackhi_epi16 (__m512i __W, __mmask32 __U, __m512i __A,
       __m512i __B)
{
  return (__m512i) __builtin_ia32_punpckhwd512_mask ((__v32hi) __A,
           (__v32hi) __B,
           (__v32hi) __W,
           (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_unpackhi_epi16 (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_punpckhwd512_mask ((__v32hi) __A,
           (__v32hi) __B,
           (__v32hi)
           _mm512_setzero_si512 (),
           (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_unpacklo_epi8 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_punpcklbw512_mask ((__v64qi) __A,
           (__v64qi) __B,
           (__v64qi)
           _mm512_setzero_si512 (),
           (__mmask64) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_unpacklo_epi8 (__m512i __W, __mmask64 __U, __m512i __A,
      __m512i __B)
{
  return (__m512i) __builtin_ia32_punpcklbw512_mask ((__v64qi) __A,
           (__v64qi) __B,
           (__v64qi) __W,
           (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_unpacklo_epi8 (__mmask64 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_punpcklbw512_mask ((__v64qi) __A,
           (__v64qi) __B,
           (__v64qi)
           _mm512_setzero_si512 (),
           (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_unpacklo_epi16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_punpcklwd512_mask ((__v32hi) __A,
           (__v32hi) __B,
           (__v32hi)
           _mm512_setzero_si512 (),
           (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_unpacklo_epi16 (__m512i __W, __mmask32 __U, __m512i __A,
       __m512i __B)
{
  return (__m512i) __builtin_ia32_punpcklwd512_mask ((__v32hi) __A,
           (__v32hi) __B,
           (__v32hi) __W,
           (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_unpacklo_epi16 (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_punpcklwd512_mask ((__v32hi) __A,
           (__v32hi) __B,
           (__v32hi)
           _mm512_setzero_si512 (),
           (__mmask32) __U);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpeq_epu8_mask (__m512i __A, __m512i __B)
{
  return (__mmask64) __builtin_ia32_ucmpb512_mask ((__v64qi) __A,
          (__v64qi) __B, 0,
          (__mmask64) -1);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpeq_epi8_mask (__m512i __A, __m512i __B)
{
  return (__mmask64) __builtin_ia32_pcmpeqb512_mask ((__v64qi) __A,
           (__v64qi) __B,
           (__mmask64) -1);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpeq_epu8_mask (__mmask64 __U, __m512i __A, __m512i __B)
{
  return (__mmask64) __builtin_ia32_ucmpb512_mask ((__v64qi) __A,
          (__v64qi) __B, 0,
          __U);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpeq_epi8_mask (__mmask64 __U, __m512i __A, __m512i __B)
{
  return (__mmask64) __builtin_ia32_pcmpeqb512_mask ((__v64qi) __A,
           (__v64qi) __B,
           __U);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpeq_epu16_mask (__m512i __A, __m512i __B)
{
  return (__mmask32) __builtin_ia32_ucmpw512_mask ((__v32hi) __A,
          (__v32hi) __B, 0,
          (__mmask32) -1);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpeq_epi16_mask (__m512i __A, __m512i __B)
{
  return (__mmask32) __builtin_ia32_pcmpeqw512_mask ((__v32hi) __A,
           (__v32hi) __B,
           (__mmask32) -1);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpeq_epu16_mask (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__mmask32) __builtin_ia32_ucmpw512_mask ((__v32hi) __A,
          (__v32hi) __B, 0,
          __U);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpeq_epi16_mask (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__mmask32) __builtin_ia32_pcmpeqw512_mask ((__v32hi) __A,
           (__v32hi) __B,
           __U);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpgt_epu8_mask (__m512i __A, __m512i __B)
{
  return (__mmask64) __builtin_ia32_ucmpb512_mask ((__v64qi) __A,
          (__v64qi) __B, 6,
          (__mmask64) -1);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpgt_epi8_mask (__m512i __A, __m512i __B)
{
  return (__mmask64) __builtin_ia32_pcmpgtb512_mask ((__v64qi) __A,
           (__v64qi) __B,
           (__mmask64) -1);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpgt_epu8_mask (__mmask64 __U, __m512i __A, __m512i __B)
{
  return (__mmask64) __builtin_ia32_ucmpb512_mask ((__v64qi) __A,
          (__v64qi) __B, 6,
          __U);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpgt_epi8_mask (__mmask64 __U, __m512i __A, __m512i __B)
{
  return (__mmask64) __builtin_ia32_pcmpgtb512_mask ((__v64qi) __A,
           (__v64qi) __B,
           __U);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpgt_epu16_mask (__m512i __A, __m512i __B)
{
  return (__mmask32) __builtin_ia32_ucmpw512_mask ((__v32hi) __A,
          (__v32hi) __B, 6,
          (__mmask32) -1);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpgt_epi16_mask (__m512i __A, __m512i __B)
{
  return (__mmask32) __builtin_ia32_pcmpgtw512_mask ((__v32hi) __A,
           (__v32hi) __B,
           (__mmask32) -1);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpgt_epu16_mask (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__mmask32) __builtin_ia32_ucmpw512_mask ((__v32hi) __A,
          (__v32hi) __B, 6,
          __U);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpgt_epi16_mask (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__mmask32) __builtin_ia32_pcmpgtw512_mask ((__v32hi) __A,
           (__v32hi) __B,
           __U);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_movepi8_mask (__m512i __A)
{
  return (__mmask64) __builtin_ia32_cvtb2mask512 ((__v64qi) __A);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_movepi16_mask (__m512i __A)
{
  return (__mmask32) __builtin_ia32_cvtw2mask512 ((__v32hi) __A);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_movm_epi8 (__mmask64 __A)
{
  return (__m512i) __builtin_ia32_cvtmask2b512 (__A);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_movm_epi16 (__mmask32 __A)
{
  return (__m512i) __builtin_ia32_cvtmask2w512 (__A);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_test_epi8_mask (__m512i __A, __m512i __B)
{
  return (__mmask64) __builtin_ia32_ptestmb512 ((__v64qi) __A,
      (__v64qi) __B,
      (__mmask64) -1);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_test_epi8_mask (__mmask64 __U, __m512i __A, __m512i __B)
{
  return (__mmask64) __builtin_ia32_ptestmb512 ((__v64qi) __A,
      (__v64qi) __B, __U);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_test_epi16_mask (__m512i __A, __m512i __B)
{
  return (__mmask32) __builtin_ia32_ptestmw512 ((__v32hi) __A,
      (__v32hi) __B,
      (__mmask32) -1);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_test_epi16_mask (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__mmask32) __builtin_ia32_ptestmw512 ((__v32hi) __A,
      (__v32hi) __B, __U);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_testn_epi8_mask (__m512i __A, __m512i __B)
{
  return (__mmask64) __builtin_ia32_ptestnmb512 ((__v64qi) __A,
       (__v64qi) __B,
       (__mmask64) -1);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_testn_epi8_mask (__mmask64 __U, __m512i __A, __m512i __B)
{
  return (__mmask64) __builtin_ia32_ptestnmb512 ((__v64qi) __A,
       (__v64qi) __B, __U);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_testn_epi16_mask (__m512i __A, __m512i __B)
{
  return (__mmask32) __builtin_ia32_ptestnmw512 ((__v32hi) __A,
       (__v32hi) __B,
       (__mmask32) -1);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_testn_epi16_mask (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__mmask32) __builtin_ia32_ptestnmw512 ((__v32hi) __A,
       (__v32hi) __B, __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_shuffle_epi8 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pshufb512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi)
        _mm512_setzero_si512 (),
        (__mmask64) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_shuffle_epi8 (__m512i __W, __mmask64 __U, __m512i __A,
     __m512i __B)
{
  return (__m512i) __builtin_ia32_pshufb512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi) __W,
        (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_shuffle_epi8 (__mmask64 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pshufb512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi)
        _mm512_setzero_si512 (),
        (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_min_epu16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pminuw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_si512 (),
        (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_min_epu16 (__mmask32 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pminuw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_si512 (),
        (__mmask32) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_min_epu16 (__m512i __W, __mmask32 __M, __m512i __A,
         __m512i __B)
{
  return (__m512i) __builtin_ia32_pminuw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi) __W,
        (__mmask32) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_min_epi16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pminsw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_si512 (),
        (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_min_epi16 (__mmask32 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pminsw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_si512 (),
        (__mmask32) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_min_epi16 (__m512i __W, __mmask32 __M, __m512i __A,
         __m512i __B)
{
  return (__m512i) __builtin_ia32_pminsw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi) __W,
        (__mmask32) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_max_epu8 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxub512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi)
        _mm512_setzero_si512 (),
        (__mmask64) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_max_epu8 (__mmask64 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxub512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi)
        _mm512_setzero_si512 (),
        (__mmask64) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_max_epu8 (__m512i __W, __mmask64 __M, __m512i __A,
        __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxub512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi) __W,
        (__mmask64) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_max_epi8 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxsb512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi)
        _mm512_setzero_si512 (),
        (__mmask64) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_max_epi8 (__mmask64 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxsb512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi)
        _mm512_setzero_si512 (),
        (__mmask64) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_max_epi8 (__m512i __W, __mmask64 __M, __m512i __A,
        __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxsb512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi) __W,
        (__mmask64) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_min_epu8 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pminub512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi)
        _mm512_setzero_si512 (),
        (__mmask64) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_min_epu8 (__mmask64 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pminub512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi)
        _mm512_setzero_si512 (),
        (__mmask64) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_min_epu8 (__m512i __W, __mmask64 __M, __m512i __A,
        __m512i __B)
{
  return (__m512i) __builtin_ia32_pminub512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi) __W,
        (__mmask64) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_min_epi8 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pminsb512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi)
        _mm512_setzero_si512 (),
        (__mmask64) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_min_epi8 (__mmask64 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pminsb512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi)
        _mm512_setzero_si512 (),
        (__mmask64) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_min_epi8 (__m512i __W, __mmask64 __M, __m512i __A,
        __m512i __B)
{
  return (__m512i) __builtin_ia32_pminsb512_mask ((__v64qi) __A,
        (__v64qi) __B,
        (__v64qi) __W,
        (__mmask64) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_max_epi16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxsw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_si512 (),
        (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_max_epi16 (__mmask32 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxsw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_si512 (),
        (__mmask32) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_max_epi16 (__m512i __W, __mmask32 __M, __m512i __A,
         __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxsw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi) __W,
        (__mmask32) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_max_epu16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxuw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_si512 (),
        (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_max_epu16 (__mmask32 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxuw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_si512 (),
        (__mmask32) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_max_epu16 (__m512i __W, __mmask32 __M, __m512i __A,
         __m512i __B)
{
  return (__m512i) __builtin_ia32_pmaxuw512_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi) __W,
        (__mmask32) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_sra_epi16 (__m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psraw512_mask ((__v32hi) __A,
       (__v8hi) __B,
       (__v32hi)
       _mm512_setzero_si512 (),
       (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_sra_epi16 (__m512i __W, __mmask32 __U, __m512i __A,
         __m128i __B)
{
  return (__m512i) __builtin_ia32_psraw512_mask ((__v32hi) __A,
       (__v8hi) __B,
       (__v32hi) __W,
       (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_sra_epi16 (__mmask32 __U, __m512i __A, __m128i __B)
{
  return (__m512i) __builtin_ia32_psraw512_mask ((__v32hi) __A,
       (__v8hi) __B,
       (__v32hi)
       _mm512_setzero_si512 (),
       (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_srav_epi16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psrav32hi_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_si512 (),
        (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_srav_epi16 (__m512i __W, __mmask32 __U, __m512i __A,
   __m512i __B)
{
  return (__m512i) __builtin_ia32_psrav32hi_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi) __W,
        (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_srav_epi16 (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psrav32hi_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_si512 (),
        (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_srlv_epi16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psrlv32hi_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_si512 (),
        (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_srlv_epi16 (__m512i __W, __mmask32 __U, __m512i __A,
   __m512i __B)
{
  return (__m512i) __builtin_ia32_psrlv32hi_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi) __W,
        (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_srlv_epi16 (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psrlv32hi_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_si512 (),
        (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_sllv_epi16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psllv32hi_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_si512 (),
        (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_sllv_epi16 (__m512i __W, __mmask32 __U, __m512i __A,
   __m512i __B)
{
  return (__m512i) __builtin_ia32_psllv32hi_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi) __W,
        (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_sllv_epi16 (__mmask32 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_psllv32hi_mask ((__v32hi) __A,
        (__v32hi) __B,
        (__v32hi)
        _mm512_setzero_si512 (),
        (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_packs_epi16 (__m512i __W, __mmask64 __M, __m512i __A,
    __m512i __B)
{
  return (__m512i) __builtin_ia32_packsswb512_mask ((__v32hi) __A,
          (__v32hi) __B,
          (__v64qi) __W,
          (__mmask64) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_packs_epi16 (__mmask64 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_packsswb512_mask ((__v32hi) __A,
          (__v32hi) __B,
          (__v64qi)
          _mm512_setzero_si512 (),
          __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_packus_epi16 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_packuswb512_mask ((__v32hi) __A,
          (__v32hi) __B,
          (__v64qi)
          _mm512_setzero_si512 (),
          (__mmask64) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_packus_epi16 (__m512i __W, __mmask64 __M, __m512i __A,
     __m512i __B)
{
  return (__m512i) __builtin_ia32_packuswb512_mask ((__v32hi) __A,
          (__v32hi) __B,
          (__v64qi) __W,
          (__mmask64) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_packus_epi16 (__mmask64 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_packuswb512_mask ((__v32hi) __A,
          (__v32hi) __B,
          (__v64qi)
          _mm512_setzero_si512 (),
          (__mmask64) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_abs_epi8 (__m512i __A)
{
  return (__m512i) __builtin_ia32_pabsb512_mask ((__v64qi) __A,
       (__v64qi)
       _mm512_setzero_si512 (),
       (__mmask64) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_abs_epi8 (__m512i __W, __mmask64 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_pabsb512_mask ((__v64qi) __A,
       (__v64qi) __W,
       (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_abs_epi8 (__mmask64 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_pabsb512_mask ((__v64qi) __A,
       (__v64qi)
       _mm512_setzero_si512 (),
       (__mmask64) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_abs_epi16 (__m512i __A)
{
  return (__m512i) __builtin_ia32_pabsw512_mask ((__v32hi) __A,
       (__v32hi)
       _mm512_setzero_si512 (),
       (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_abs_epi16 (__m512i __W, __mmask32 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_pabsw512_mask ((__v32hi) __A,
       (__v32hi) __W,
       (__mmask32) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_abs_epi16 (__mmask32 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_pabsw512_mask ((__v32hi) __A,
       (__v32hi)
       _mm512_setzero_si512 (),
       (__mmask32) __U);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpneq_epu8_mask (__mmask64 __M, __m512i __X, __m512i __Y)
{
  return (__mmask64) __builtin_ia32_ucmpb512_mask ((__v64qi) __X,
         (__v64qi) __Y, 4,
         (__mmask64) __M);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmplt_epu8_mask (__mmask64 __M, __m512i __X, __m512i __Y)
{
  return (__mmask64) __builtin_ia32_ucmpb512_mask ((__v64qi) __X,
         (__v64qi) __Y, 1,
         (__mmask64) __M);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpge_epu8_mask (__mmask64 __M, __m512i __X, __m512i __Y)
{
  return (__mmask64) __builtin_ia32_ucmpb512_mask ((__v64qi) __X,
         (__v64qi) __Y, 5,
         (__mmask64) __M);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmple_epu8_mask (__mmask64 __M, __m512i __X, __m512i __Y)
{
  return (__mmask64) __builtin_ia32_ucmpb512_mask ((__v64qi) __X,
         (__v64qi) __Y, 2,
         (__mmask64) __M);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpneq_epu16_mask (__mmask32 __M, __m512i __X, __m512i __Y)
{
  return (__mmask32) __builtin_ia32_ucmpw512_mask ((__v32hi) __X,
         (__v32hi) __Y, 4,
         (__mmask32) __M);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmplt_epu16_mask (__mmask32 __M, __m512i __X, __m512i __Y)
{
  return (__mmask32) __builtin_ia32_ucmpw512_mask ((__v32hi) __X,
         (__v32hi) __Y, 1,
         (__mmask32) __M);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpge_epu16_mask (__mmask32 __M, __m512i __X, __m512i __Y)
{
  return (__mmask32) __builtin_ia32_ucmpw512_mask ((__v32hi) __X,
         (__v32hi) __Y, 5,
         (__mmask32) __M);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmple_epu16_mask (__mmask32 __M, __m512i __X, __m512i __Y)
{
  return (__mmask32) __builtin_ia32_ucmpw512_mask ((__v32hi) __X,
         (__v32hi) __Y, 2,
         (__mmask32) __M);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpneq_epi8_mask (__mmask64 __M, __m512i __X, __m512i __Y)
{
  return (__mmask64) __builtin_ia32_cmpb512_mask ((__v64qi) __X,
        (__v64qi) __Y, 4,
        (__mmask64) __M);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmplt_epi8_mask (__mmask64 __M, __m512i __X, __m512i __Y)
{
  return (__mmask64) __builtin_ia32_cmpb512_mask ((__v64qi) __X,
        (__v64qi) __Y, 1,
        (__mmask64) __M);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpge_epi8_mask (__mmask64 __M, __m512i __X, __m512i __Y)
{
  return (__mmask64) __builtin_ia32_cmpb512_mask ((__v64qi) __X,
        (__v64qi) __Y, 5,
        (__mmask64) __M);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmple_epi8_mask (__mmask64 __M, __m512i __X, __m512i __Y)
{
  return (__mmask64) __builtin_ia32_cmpb512_mask ((__v64qi) __X,
        (__v64qi) __Y, 2,
        (__mmask64) __M);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpneq_epi16_mask (__mmask32 __M, __m512i __X, __m512i __Y)
{
  return (__mmask32) __builtin_ia32_cmpw512_mask ((__v32hi) __X,
        (__v32hi) __Y, 4,
        (__mmask32) __M);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmplt_epi16_mask (__mmask32 __M, __m512i __X, __m512i __Y)
{
  return (__mmask32) __builtin_ia32_cmpw512_mask ((__v32hi) __X,
        (__v32hi) __Y, 1,
        (__mmask32) __M);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmpge_epi16_mask (__mmask32 __M, __m512i __X, __m512i __Y)
{
  return (__mmask32) __builtin_ia32_cmpw512_mask ((__v32hi) __X,
        (__v32hi) __Y, 5,
        (__mmask32) __M);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cmple_epi16_mask (__mmask32 __M, __m512i __X, __m512i __Y)
{
  return (__mmask32) __builtin_ia32_cmpw512_mask ((__v32hi) __X,
        (__v32hi) __Y, 2,
        (__mmask32) __M);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpneq_epu8_mask (__m512i __X, __m512i __Y)
{
  return (__mmask64) __builtin_ia32_ucmpb512_mask ((__v64qi) __X,
         (__v64qi) __Y, 4,
         (__mmask64) -1);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmplt_epu8_mask (__m512i __X, __m512i __Y)
{
  return (__mmask64) __builtin_ia32_ucmpb512_mask ((__v64qi) __X,
         (__v64qi) __Y, 1,
         (__mmask64) -1);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpge_epu8_mask (__m512i __X, __m512i __Y)
{
  return (__mmask64) __builtin_ia32_ucmpb512_mask ((__v64qi) __X,
         (__v64qi) __Y, 5,
         (__mmask64) -1);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmple_epu8_mask (__m512i __X, __m512i __Y)
{
  return (__mmask64) __builtin_ia32_ucmpb512_mask ((__v64qi) __X,
         (__v64qi) __Y, 2,
         (__mmask64) -1);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpneq_epu16_mask (__m512i __X, __m512i __Y)
{
  return (__mmask32) __builtin_ia32_ucmpw512_mask ((__v32hi) __X,
         (__v32hi) __Y, 4,
         (__mmask32) -1);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmplt_epu16_mask (__m512i __X, __m512i __Y)
{
  return (__mmask32) __builtin_ia32_ucmpw512_mask ((__v32hi) __X,
         (__v32hi) __Y, 1,
         (__mmask32) -1);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpge_epu16_mask (__m512i __X, __m512i __Y)
{
  return (__mmask32) __builtin_ia32_ucmpw512_mask ((__v32hi) __X,
         (__v32hi) __Y, 5,
         (__mmask32) -1);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmple_epu16_mask (__m512i __X, __m512i __Y)
{
  return (__mmask32) __builtin_ia32_ucmpw512_mask ((__v32hi) __X,
         (__v32hi) __Y, 2,
         (__mmask32) -1);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpneq_epi8_mask (__m512i __X, __m512i __Y)
{
  return (__mmask64) __builtin_ia32_cmpb512_mask ((__v64qi) __X,
        (__v64qi) __Y, 4,
        (__mmask64) -1);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmplt_epi8_mask (__m512i __X, __m512i __Y)
{
  return (__mmask64) __builtin_ia32_cmpb512_mask ((__v64qi) __X,
        (__v64qi) __Y, 1,
        (__mmask64) -1);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpge_epi8_mask (__m512i __X, __m512i __Y)
{
  return (__mmask64) __builtin_ia32_cmpb512_mask ((__v64qi) __X,
        (__v64qi) __Y, 5,
        (__mmask64) -1);
}
extern __inline __mmask64
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmple_epi8_mask (__m512i __X, __m512i __Y)
{
  return (__mmask64) __builtin_ia32_cmpb512_mask ((__v64qi) __X,
        (__v64qi) __Y, 2,
        (__mmask64) -1);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpneq_epi16_mask (__m512i __X, __m512i __Y)
{
  return (__mmask32) __builtin_ia32_cmpw512_mask ((__v32hi) __X,
        (__v32hi) __Y, 4,
        (__mmask32) -1);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmplt_epi16_mask (__m512i __X, __m512i __Y)
{
  return (__mmask32) __builtin_ia32_cmpw512_mask ((__v32hi) __X,
        (__v32hi) __Y, 1,
        (__mmask32) -1);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmpge_epi16_mask (__m512i __X, __m512i __Y)
{
  return (__mmask32) __builtin_ia32_cmpw512_mask ((__v32hi) __X,
        (__v32hi) __Y, 5,
        (__mmask32) -1);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cmple_epi16_mask (__m512i __X, __m512i __Y)
{
  return (__mmask32) __builtin_ia32_cmpw512_mask ((__v32hi) __X,
        (__v32hi) __Y, 2,
        (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_packs_epi32 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_packssdw512_mask ((__v16si) __A,
          (__v16si) __B,
          (__v32hi)
          _mm512_setzero_si512 (),
          (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_packs_epi32 (__mmask32 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_packssdw512_mask ((__v16si) __A,
          (__v16si) __B,
          (__v32hi)
          _mm512_setzero_si512 (),
          __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_packs_epi32 (__m512i __W, __mmask32 __M, __m512i __A,
    __m512i __B)
{
  return (__m512i) __builtin_ia32_packssdw512_mask ((__v16si) __A,
          (__v16si) __B,
          (__v32hi) __W,
          __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_packus_epi32 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_packusdw512_mask ((__v16si) __A,
          (__v16si) __B,
          (__v32hi)
          _mm512_setzero_si512 (),
          (__mmask32) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_packus_epi32 (__mmask32 __M, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_packusdw512_mask ((__v16si) __A,
          (__v16si) __B,
          (__v32hi)
          _mm512_setzero_si512 (),
          __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_packus_epi32 (__m512i __W, __mmask32 __M, __m512i __A,
     __m512i __B)
{
  return (__m512i) __builtin_ia32_packusdw512_mask ((__v16si) __A,
          (__v16si) __B,
          (__v32hi) __W,
          __M);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx512dq")
extern __inline unsigned char
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_ktest_mask8_u8 (__mmask8 __A, __mmask8 __B, unsigned char *__CF)
{
  *__CF = (unsigned char) __builtin_ia32_ktestcqi (__A, __B);
  return (unsigned char) __builtin_ia32_ktestzqi (__A, __B);
}
extern __inline unsigned char
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_ktestz_mask8_u8 (__mmask8 __A, __mmask8 __B)
{
  return (unsigned char) __builtin_ia32_ktestzqi (__A, __B);
}
extern __inline unsigned char
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_ktestc_mask8_u8 (__mmask8 __A, __mmask8 __B)
{
  return (unsigned char) __builtin_ia32_ktestcqi (__A, __B);
}
extern __inline unsigned char
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_ktest_mask16_u8 (__mmask16 __A, __mmask16 __B, unsigned char *__CF)
{
  *__CF = (unsigned char) __builtin_ia32_ktestchi (__A, __B);
  return (unsigned char) __builtin_ia32_ktestzhi (__A, __B);
}
extern __inline unsigned char
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_ktestz_mask16_u8 (__mmask16 __A, __mmask16 __B)
{
  return (unsigned char) __builtin_ia32_ktestzhi (__A, __B);
}
extern __inline unsigned char
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_ktestc_mask16_u8 (__mmask16 __A, __mmask16 __B)
{
  return (unsigned char) __builtin_ia32_ktestchi (__A, __B);
}
extern __inline unsigned char
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_kortest_mask8_u8 (__mmask8 __A, __mmask8 __B, unsigned char *__CF)
{
  *__CF = (unsigned char) __builtin_ia32_kortestcqi (__A, __B);
  return (unsigned char) __builtin_ia32_kortestzqi (__A, __B);
}
extern __inline unsigned char
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_kortestz_mask8_u8 (__mmask8 __A, __mmask8 __B)
{
  return (unsigned char) __builtin_ia32_kortestzqi (__A, __B);
}
extern __inline unsigned char
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_kortestc_mask8_u8 (__mmask8 __A, __mmask8 __B)
{
  return (unsigned char) __builtin_ia32_kortestcqi (__A, __B);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_kadd_mask8 (__mmask8 __A, __mmask8 __B)
{
  return (__mmask8) __builtin_ia32_kaddqi ((__mmask8) __A, (__mmask8) __B);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_kadd_mask16 (__mmask16 __A, __mmask16 __B)
{
  return (__mmask16) __builtin_ia32_kaddhi ((__mmask16) __A, (__mmask16) __B);
}
extern __inline unsigned int
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_cvtmask8_u32 (__mmask8 __A)
{
  return (unsigned int) __builtin_ia32_kmovb ((__mmask8 ) __A);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_cvtu32_mask8 (unsigned int __A)
{
  return (__mmask8) __builtin_ia32_kmovb ((__mmask8) __A);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_load_mask8 (__mmask8 *__A)
{
  return (__mmask8) __builtin_ia32_kmovb (*(__mmask8 *) __A);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_store_mask8 (__mmask8 *__A, __mmask8 __B)
{
  *(__mmask8 *) __A = __builtin_ia32_kmovb (__B);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_knot_mask8 (__mmask8 __A)
{
  return (__mmask8) __builtin_ia32_knotqi ((__mmask8) __A);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_kor_mask8 (__mmask8 __A, __mmask8 __B)
{
  return (__mmask8) __builtin_ia32_korqi ((__mmask8) __A, (__mmask8) __B);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_kxnor_mask8 (__mmask8 __A, __mmask8 __B)
{
  return (__mmask8) __builtin_ia32_kxnorqi ((__mmask8) __A, (__mmask8) __B);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_kxor_mask8 (__mmask8 __A, __mmask8 __B)
{
  return (__mmask8) __builtin_ia32_kxorqi ((__mmask8) __A, (__mmask8) __B);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_kand_mask8 (__mmask8 __A, __mmask8 __B)
{
  return (__mmask8) __builtin_ia32_kandqi ((__mmask8) __A, (__mmask8) __B);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_kandn_mask8 (__mmask8 __A, __mmask8 __B)
{
  return (__mmask8) __builtin_ia32_kandnqi ((__mmask8) __A, (__mmask8) __B);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_broadcast_f64x2 (__m128d __A)
{
  return (__m512d)
  __builtin_ia32_broadcastf64x2_512_mask ((__v2df) __A,
       _mm512_undefined_pd (),
       (__mmask8) -1);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_broadcast_f64x2 (__m512d __O, __mmask8 __M, __m128d __A)
{
  return (__m512d) __builtin_ia32_broadcastf64x2_512_mask ((__v2df)
          __A,
          (__v8df)
          __O, __M);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_broadcast_f64x2 (__mmask8 __M, __m128d __A)
{
  return (__m512d) __builtin_ia32_broadcastf64x2_512_mask ((__v2df)
          __A,
          (__v8df)
          _mm512_setzero_ps (),
          __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_broadcast_i64x2 (__m128i __A)
{
  return (__m512i)
  __builtin_ia32_broadcasti64x2_512_mask ((__v2di) __A,
       _mm512_undefined_epi32 (),
       (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_broadcast_i64x2 (__m512i __O, __mmask8 __M, __m128i __A)
{
  return (__m512i) __builtin_ia32_broadcasti64x2_512_mask ((__v2di)
          __A,
          (__v8di)
          __O, __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_broadcast_i64x2 (__mmask8 __M, __m128i __A)
{
  return (__m512i) __builtin_ia32_broadcasti64x2_512_mask ((__v2di)
          __A,
          (__v8di)
          _mm512_setzero_si512 (),
          __M);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_broadcast_f32x2 (__m128 __A)
{
  return (__m512)
  __builtin_ia32_broadcastf32x2_512_mask ((__v4sf) __A,
       (__v16sf)_mm512_undefined_ps (),
       (__mmask16) -1);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_broadcast_f32x2 (__m512 __O, __mmask16 __M, __m128 __A)
{
  return (__m512) __builtin_ia32_broadcastf32x2_512_mask ((__v4sf) __A,
         (__v16sf)
         __O, __M);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_broadcast_f32x2 (__mmask16 __M, __m128 __A)
{
  return (__m512) __builtin_ia32_broadcastf32x2_512_mask ((__v4sf) __A,
         (__v16sf)
         _mm512_setzero_ps (),
         __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_broadcast_i32x2 (__m128i __A)
{
  return (__m512i)
  __builtin_ia32_broadcasti32x2_512_mask ((__v4si) __A,
       (__v16si)
       _mm512_undefined_epi32 (),
       (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_broadcast_i32x2 (__m512i __O, __mmask16 __M, __m128i __A)
{
  return (__m512i) __builtin_ia32_broadcasti32x2_512_mask ((__v4si)
          __A,
          (__v16si)
          __O, __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_broadcast_i32x2 (__mmask16 __M, __m128i __A)
{
  return (__m512i) __builtin_ia32_broadcasti32x2_512_mask ((__v4si)
          __A,
          (__v16si)
          _mm512_setzero_si512 (),
          __M);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_broadcast_f32x8 (__m256 __A)
{
  return (__m512)
  __builtin_ia32_broadcastf32x8_512_mask ((__v8sf) __A,
       _mm512_undefined_ps (),
       (__mmask16) -1);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_broadcast_f32x8 (__m512 __O, __mmask16 __M, __m256 __A)
{
  return (__m512) __builtin_ia32_broadcastf32x8_512_mask ((__v8sf) __A,
         (__v16sf)__O,
         __M);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_broadcast_f32x8 (__mmask16 __M, __m256 __A)
{
  return (__m512) __builtin_ia32_broadcastf32x8_512_mask ((__v8sf) __A,
         (__v16sf)
         _mm512_setzero_ps (),
         __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_broadcast_i32x8 (__m256i __A)
{
  return (__m512i)
  __builtin_ia32_broadcasti32x8_512_mask ((__v8si) __A,
       (__v16si)
       _mm512_undefined_epi32 (),
       (__mmask16) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_broadcast_i32x8 (__m512i __O, __mmask16 __M, __m256i __A)
{
  return (__m512i) __builtin_ia32_broadcasti32x8_512_mask ((__v8si)
          __A,
          (__v16si)__O,
          __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_broadcast_i32x8 (__mmask16 __M, __m256i __A)
{
  return (__m512i) __builtin_ia32_broadcasti32x8_512_mask ((__v8si)
          __A,
          (__v16si)
          _mm512_setzero_si512 (),
          __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mullo_epi64 (__m512i __A, __m512i __B)
{
  return (__m512i) ((__v8du) __A * (__v8du) __B);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_mullo_epi64 (__m512i __W, __mmask8 __U, __m512i __A,
    __m512i __B)
{
  return (__m512i) __builtin_ia32_pmullq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di) __W,
        (__mmask8) __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_mullo_epi64 (__mmask8 __U, __m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_pmullq512_mask ((__v8di) __A,
        (__v8di) __B,
        (__v8di)
        _mm512_setzero_si512 (),
        (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_xor_pd (__m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_xorpd512_mask ((__v8df) __A,
       (__v8df) __B,
       (__v8df)
       _mm512_setzero_pd (),
       (__mmask8) -1);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_xor_pd (__m512d __W, __mmask8 __U, __m512d __A,
      __m512d __B)
{
  return (__m512d) __builtin_ia32_xorpd512_mask ((__v8df) __A,
       (__v8df) __B,
       (__v8df) __W,
       (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_xor_pd (__mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_xorpd512_mask ((__v8df) __A,
       (__v8df) __B,
       (__v8df)
       _mm512_setzero_pd (),
       (__mmask8) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_xor_ps (__m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_xorps512_mask ((__v16sf) __A,
      (__v16sf) __B,
      (__v16sf)
      _mm512_setzero_ps (),
      (__mmask16) -1);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_xor_ps (__m512 __W, __mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_xorps512_mask ((__v16sf) __A,
      (__v16sf) __B,
      (__v16sf) __W,
      (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_xor_ps (__mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_xorps512_mask ((__v16sf) __A,
      (__v16sf) __B,
      (__v16sf)
      _mm512_setzero_ps (),
      (__mmask16) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_or_pd (__m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_orpd512_mask ((__v8df) __A,
      (__v8df) __B,
      (__v8df)
      _mm512_setzero_pd (),
      (__mmask8) -1);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_or_pd (__m512d __W, __mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_orpd512_mask ((__v8df) __A,
      (__v8df) __B,
      (__v8df) __W,
      (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_or_pd (__mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_orpd512_mask ((__v8df) __A,
      (__v8df) __B,
      (__v8df)
      _mm512_setzero_pd (),
      (__mmask8) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_or_ps (__m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_orps512_mask ((__v16sf) __A,
            (__v16sf) __B,
            (__v16sf)
            _mm512_setzero_ps (),
            (__mmask16) -1);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_or_ps (__m512 __W, __mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_orps512_mask ((__v16sf) __A,
            (__v16sf) __B,
            (__v16sf) __W,
            (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_or_ps (__mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_orps512_mask ((__v16sf) __A,
            (__v16sf) __B,
            (__v16sf)
            _mm512_setzero_ps (),
            (__mmask16) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_and_pd (__m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_andpd512_mask ((__v8df) __A,
       (__v8df) __B,
       (__v8df)
       _mm512_setzero_pd (),
       (__mmask8) -1);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_and_pd (__m512d __W, __mmask8 __U, __m512d __A,
      __m512d __B)
{
  return (__m512d) __builtin_ia32_andpd512_mask ((__v8df) __A,
       (__v8df) __B,
       (__v8df) __W,
       (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_and_pd (__mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_andpd512_mask ((__v8df) __A,
       (__v8df) __B,
       (__v8df)
       _mm512_setzero_pd (),
       (__mmask8) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_and_ps (__m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_andps512_mask ((__v16sf) __A,
      (__v16sf) __B,
      (__v16sf)
      _mm512_setzero_ps (),
      (__mmask16) -1);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_and_ps (__m512 __W, __mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_andps512_mask ((__v16sf) __A,
      (__v16sf) __B,
      (__v16sf) __W,
      (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_and_ps (__mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_andps512_mask ((__v16sf) __A,
      (__v16sf) __B,
      (__v16sf)
      _mm512_setzero_ps (),
      (__mmask16) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_andnot_pd (__m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_andnpd512_mask ((__v8df) __A,
        (__v8df) __B,
        (__v8df)
        _mm512_setzero_pd (),
        (__mmask8) -1);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_andnot_pd (__m512d __W, __mmask8 __U, __m512d __A,
         __m512d __B)
{
  return (__m512d) __builtin_ia32_andnpd512_mask ((__v8df) __A,
        (__v8df) __B,
        (__v8df) __W,
        (__mmask8) __U);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_andnot_pd (__mmask8 __U, __m512d __A, __m512d __B)
{
  return (__m512d) __builtin_ia32_andnpd512_mask ((__v8df) __A,
        (__v8df) __B,
        (__v8df)
        _mm512_setzero_pd (),
        (__mmask8) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_andnot_ps (__m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_andnps512_mask ((__v16sf) __A,
       (__v16sf) __B,
       (__v16sf)
       _mm512_setzero_ps (),
       (__mmask16) -1);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_andnot_ps (__m512 __W, __mmask16 __U, __m512 __A,
         __m512 __B)
{
  return (__m512) __builtin_ia32_andnps512_mask ((__v16sf) __A,
       (__v16sf) __B,
       (__v16sf) __W,
       (__mmask16) __U);
}
extern __inline __m512
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_andnot_ps (__mmask16 __U, __m512 __A, __m512 __B)
{
  return (__m512) __builtin_ia32_andnps512_mask ((__v16sf) __A,
       (__v16sf) __B,
       (__v16sf)
       _mm512_setzero_ps (),
       (__mmask16) __U);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_movepi32_mask (__m512i __A)
{
  return (__mmask16) __builtin_ia32_cvtd2mask512 ((__v16si) __A);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_movepi64_mask (__m512i __A)
{
  return (__mmask8) __builtin_ia32_cvtq2mask512 ((__v8di) __A);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_movm_epi32 (__mmask16 __A)
{
  return (__m512i) __builtin_ia32_cvtmask2d512 (__A);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_movm_epi64 (__mmask8 __A)
{
  return (__m512i) __builtin_ia32_cvtmask2q512 (__A);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvttpd_epi64 (__m512d __A)
{
  return (__m512i) __builtin_ia32_cvttpd2qq512_mask ((__v8df) __A,
           (__v8di)
           _mm512_setzero_si512 (),
           (__mmask8) -1,
           0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvttpd_epi64 (__m512i __W, __mmask8 __U, __m512d __A)
{
  return (__m512i) __builtin_ia32_cvttpd2qq512_mask ((__v8df) __A,
           (__v8di) __W,
           (__mmask8) __U,
           0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvttpd_epi64 (__mmask8 __U, __m512d __A)
{
  return (__m512i) __builtin_ia32_cvttpd2qq512_mask ((__v8df) __A,
           (__v8di)
           _mm512_setzero_si512 (),
           (__mmask8) __U,
           0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvttpd_epu64 (__m512d __A)
{
  return (__m512i) __builtin_ia32_cvttpd2uqq512_mask ((__v8df) __A,
            (__v8di)
            _mm512_setzero_si512 (),
            (__mmask8) -1,
            0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvttpd_epu64 (__m512i __W, __mmask8 __U, __m512d __A)
{
  return (__m512i) __builtin_ia32_cvttpd2uqq512_mask ((__v8df) __A,
            (__v8di) __W,
            (__mmask8) __U,
            0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvttpd_epu64 (__mmask8 __U, __m512d __A)
{
  return (__m512i) __builtin_ia32_cvttpd2uqq512_mask ((__v8df) __A,
            (__v8di)
            _mm512_setzero_si512 (),
            (__mmask8) __U,
            0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvttps_epi64 (__m256 __A)
{
  return (__m512i) __builtin_ia32_cvttps2qq512_mask ((__v8sf) __A,
           (__v8di)
           _mm512_setzero_si512 (),
           (__mmask8) -1,
           0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvttps_epi64 (__m512i __W, __mmask8 __U, __m256 __A)
{
  return (__m512i) __builtin_ia32_cvttps2qq512_mask ((__v8sf) __A,
           (__v8di) __W,
           (__mmask8) __U,
           0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvttps_epi64 (__mmask8 __U, __m256 __A)
{
  return (__m512i) __builtin_ia32_cvttps2qq512_mask ((__v8sf) __A,
           (__v8di)
           _mm512_setzero_si512 (),
           (__mmask8) __U,
           0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvttps_epu64 (__m256 __A)
{
  return (__m512i) __builtin_ia32_cvttps2uqq512_mask ((__v8sf) __A,
            (__v8di)
            _mm512_setzero_si512 (),
            (__mmask8) -1,
            0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvttps_epu64 (__m512i __W, __mmask8 __U, __m256 __A)
{
  return (__m512i) __builtin_ia32_cvttps2uqq512_mask ((__v8sf) __A,
            (__v8di) __W,
            (__mmask8) __U,
            0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvttps_epu64 (__mmask8 __U, __m256 __A)
{
  return (__m512i) __builtin_ia32_cvttps2uqq512_mask ((__v8sf) __A,
            (__v8di)
            _mm512_setzero_si512 (),
            (__mmask8) __U,
            0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtpd_epi64 (__m512d __A)
{
  return (__m512i) __builtin_ia32_cvtpd2qq512_mask ((__v8df) __A,
          (__v8di)
          _mm512_setzero_si512 (),
          (__mmask8) -1,
          0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtpd_epi64 (__m512i __W, __mmask8 __U, __m512d __A)
{
  return (__m512i) __builtin_ia32_cvtpd2qq512_mask ((__v8df) __A,
          (__v8di) __W,
          (__mmask8) __U,
          0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtpd_epi64 (__mmask8 __U, __m512d __A)
{
  return (__m512i) __builtin_ia32_cvtpd2qq512_mask ((__v8df) __A,
          (__v8di)
          _mm512_setzero_si512 (),
          (__mmask8) __U,
          0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtpd_epu64 (__m512d __A)
{
  return (__m512i) __builtin_ia32_cvtpd2uqq512_mask ((__v8df) __A,
           (__v8di)
           _mm512_setzero_si512 (),
           (__mmask8) -1,
           0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtpd_epu64 (__m512i __W, __mmask8 __U, __m512d __A)
{
  return (__m512i) __builtin_ia32_cvtpd2uqq512_mask ((__v8df) __A,
           (__v8di) __W,
           (__mmask8) __U,
           0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtpd_epu64 (__mmask8 __U, __m512d __A)
{
  return (__m512i) __builtin_ia32_cvtpd2uqq512_mask ((__v8df) __A,
           (__v8di)
           _mm512_setzero_si512 (),
           (__mmask8) __U,
           0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtps_epi64 (__m256 __A)
{
  return (__m512i) __builtin_ia32_cvtps2qq512_mask ((__v8sf) __A,
          (__v8di)
          _mm512_setzero_si512 (),
          (__mmask8) -1,
          0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtps_epi64 (__m512i __W, __mmask8 __U, __m256 __A)
{
  return (__m512i) __builtin_ia32_cvtps2qq512_mask ((__v8sf) __A,
          (__v8di) __W,
          (__mmask8) __U,
          0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtps_epi64 (__mmask8 __U, __m256 __A)
{
  return (__m512i) __builtin_ia32_cvtps2qq512_mask ((__v8sf) __A,
          (__v8di)
          _mm512_setzero_si512 (),
          (__mmask8) __U,
          0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtps_epu64 (__m256 __A)
{
  return (__m512i) __builtin_ia32_cvtps2uqq512_mask ((__v8sf) __A,
           (__v8di)
           _mm512_setzero_si512 (),
           (__mmask8) -1,
           0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtps_epu64 (__m512i __W, __mmask8 __U, __m256 __A)
{
  return (__m512i) __builtin_ia32_cvtps2uqq512_mask ((__v8sf) __A,
           (__v8di) __W,
           (__mmask8) __U,
           0x04);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtps_epu64 (__mmask8 __U, __m256 __A)
{
  return (__m512i) __builtin_ia32_cvtps2uqq512_mask ((__v8sf) __A,
           (__v8di)
           _mm512_setzero_si512 (),
           (__mmask8) __U,
           0x04);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepi64_ps (__m512i __A)
{
  return (__m256) __builtin_ia32_cvtqq2ps512_mask ((__v8di) __A,
         (__v8sf)
         _mm256_setzero_ps (),
         (__mmask8) -1,
         0x04);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi64_ps (__m256 __W, __mmask8 __U, __m512i __A)
{
  return (__m256) __builtin_ia32_cvtqq2ps512_mask ((__v8di) __A,
         (__v8sf) __W,
         (__mmask8) __U,
         0x04);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepi64_ps (__mmask8 __U, __m512i __A)
{
  return (__m256) __builtin_ia32_cvtqq2ps512_mask ((__v8di) __A,
         (__v8sf)
         _mm256_setzero_ps (),
         (__mmask8) __U,
         0x04);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepu64_ps (__m512i __A)
{
  return (__m256) __builtin_ia32_cvtuqq2ps512_mask ((__v8di) __A,
          (__v8sf)
          _mm256_setzero_ps (),
          (__mmask8) -1,
          0x04);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepu64_ps (__m256 __W, __mmask8 __U, __m512i __A)
{
  return (__m256) __builtin_ia32_cvtuqq2ps512_mask ((__v8di) __A,
          (__v8sf) __W,
          (__mmask8) __U,
          0x04);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepu64_ps (__mmask8 __U, __m512i __A)
{
  return (__m256) __builtin_ia32_cvtuqq2ps512_mask ((__v8di) __A,
          (__v8sf)
          _mm256_setzero_ps (),
          (__mmask8) __U,
          0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepi64_pd (__m512i __A)
{
  return (__m512d) __builtin_ia32_cvtqq2pd512_mask ((__v8di) __A,
          (__v8df)
          _mm512_setzero_pd (),
          (__mmask8) -1,
          0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepi64_pd (__m512d __W, __mmask8 __U, __m512i __A)
{
  return (__m512d) __builtin_ia32_cvtqq2pd512_mask ((__v8di) __A,
          (__v8df) __W,
          (__mmask8) __U,
          0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepi64_pd (__mmask8 __U, __m512i __A)
{
  return (__m512d) __builtin_ia32_cvtqq2pd512_mask ((__v8di) __A,
          (__v8df)
          _mm512_setzero_pd (),
          (__mmask8) __U,
          0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtepu64_pd (__m512i __A)
{
  return (__m512d) __builtin_ia32_cvtuqq2pd512_mask ((__v8di) __A,
           (__v8df)
           _mm512_setzero_pd (),
           (__mmask8) -1,
           0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtepu64_pd (__m512d __W, __mmask8 __U, __m512i __A)
{
  return (__m512d) __builtin_ia32_cvtuqq2pd512_mask ((__v8di) __A,
           (__v8df) __W,
           (__mmask8) __U,
           0x04);
}
extern __inline __m512d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtepu64_pd (__mmask8 __U, __m512i __A)
{
  return (__m512d) __builtin_ia32_cvtuqq2pd512_mask ((__v8di) __A,
           (__v8df)
           _mm512_setzero_pd (),
           (__mmask8) __U,
           0x04);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx512vl,avx512bw")
typedef short __v16hi_u __attribute__ ((__vector_size__ (32), __may_alias__, __aligned__ (1)));
typedef short __v8hi_u __attribute__ ((__vector_size__ (16), __may_alias__, __aligned__ (1)));
typedef char __v32qi_u __attribute__ ((__vector_size__ (32), __may_alias__, __aligned__ (1)));
typedef char __v16qi_u __attribute__ ((__vector_size__ (16), __may_alias__, __aligned__ (1)));
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_mov_epi8 (__m256i __W, __mmask32 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_movdquqi256_mask ((__v32qi) __A,
          (__v32qi) __W,
          (__mmask32) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_mov_epi8 (__mmask32 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_movdquqi256_mask ((__v32qi) __A,
          (__v32qi)
          _mm256_setzero_si256 (),
          (__mmask32) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_mov_epi8 (__m128i __W, __mmask16 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_movdquqi128_mask ((__v16qi) __A,
          (__v16qi) __W,
          (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_mov_epi8 (__mmask16 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_movdquqi128_mask ((__v16qi) __A,
          (__v16qi)
          _mm_setzero_si128 (),
          (__mmask16) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_storeu_epi8 (void *__P, __m256i __A)
{
  *(__v32qi_u *) __P = (__v32qi_u) __A;
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_storeu_epi8 (void *__P, __mmask32 __U, __m256i __A)
{
  __builtin_ia32_storedquqi256_mask ((char *) __P,
         (__v32qi) __A,
         (__mmask32) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_storeu_epi8 (void *__P, __m128i __A)
{
  *(__v16qi_u *) __P = (__v16qi_u) __A;
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_storeu_epi8 (void *__P, __mmask16 __U, __m128i __A)
{
  __builtin_ia32_storedquqi128_mask ((char *) __P,
         (__v16qi) __A,
         (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_loadu_epi16 (void const *__P)
{
  return (__m256i) (*(__v16hi_u *) __P);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_loadu_epi16 (__m256i __W, __mmask16 __U, void const *__P)
{
  return (__m256i) __builtin_ia32_loaddquhi256_mask ((const short *) __P,
           (__v16hi) __W,
           (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_loadu_epi16 (__mmask16 __U, void const *__P)
{
  return (__m256i) __builtin_ia32_loaddquhi256_mask ((const short *) __P,
           (__v16hi)
           _mm256_setzero_si256 (),
           (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_loadu_epi16 (void const *__P)
{
  return (__m128i) (*(__v8hi_u *) __P);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_loadu_epi16 (__m128i __W, __mmask8 __U, void const *__P)
{
  return (__m128i) __builtin_ia32_loaddquhi128_mask ((const short *) __P,
           (__v8hi) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_loadu_epi16 (__mmask8 __U, void const *__P)
{
  return (__m128i) __builtin_ia32_loaddquhi128_mask ((const short *) __P,
           (__v8hi)
           _mm_setzero_si128 (),
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_mov_epi16 (__m256i __W, __mmask16 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_movdquhi256_mask ((__v16hi) __A,
          (__v16hi) __W,
          (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_mov_epi16 (__mmask16 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_movdquhi256_mask ((__v16hi) __A,
          (__v16hi)
          _mm256_setzero_si256 (),
          (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_mov_epi16 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_movdquhi128_mask ((__v8hi) __A,
          (__v8hi) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_mov_epi16 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_movdquhi128_mask ((__v8hi) __A,
          (__v8hi)
          _mm_setzero_si128 (),
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_loadu_epi8 (void const *__P)
{
  return (__m256i) (*(__v32qi_u *) __P);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_loadu_epi8 (__m256i __W, __mmask32 __U, void const *__P)
{
  return (__m256i) __builtin_ia32_loaddquqi256_mask ((const char *) __P,
           (__v32qi) __W,
           (__mmask32) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_loadu_epi8 (__mmask32 __U, void const *__P)
{
  return (__m256i) __builtin_ia32_loaddquqi256_mask ((const char *) __P,
           (__v32qi)
           _mm256_setzero_si256 (),
           (__mmask32) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_loadu_epi8 (void const *__P)
{
  return (__m128i) (*(__v16qi_u *) __P);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_loadu_epi8 (__m128i __W, __mmask16 __U, void const *__P)
{
  return (__m128i) __builtin_ia32_loaddquqi128_mask ((const char *) __P,
           (__v16qi) __W,
           (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_loadu_epi8 (__mmask16 __U, void const *__P)
{
  return (__m128i) __builtin_ia32_loaddquqi128_mask ((const char *) __P,
           (__v16qi)
           _mm_setzero_si128 (),
           (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepi16_epi8 (__m256i __A)
{
  return (__m128i) __builtin_ia32_pmovwb256_mask ((__v16hi) __A,
        (__v16qi)_mm_undefined_si128(),
        (__mmask16) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi16_storeu_epi8 (void * __P, __mmask16 __M,__m256i __A)
{
  __builtin_ia32_pmovwb256mem_mask ((__v16qi *) __P , (__v16hi) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi16_epi8 (__m128i __O, __mmask16 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovwb256_mask ((__v16hi) __A,
        (__v16qi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepi16_epi8 (__mmask16 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovwb256_mask ((__v16hi) __A,
        (__v16qi)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtsepi16_epi8 (__m128i __A)
{
  return (__m128i) __builtin_ia32_pmovswb128_mask ((__v8hi) __A,
         (__v16qi)_mm_undefined_si128(),
         (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtsepi16_storeu_epi8 (void * __P, __mmask8 __M,__m128i __A)
{
  __builtin_ia32_pmovswb128mem_mask ((unsigned long long *) __P , (__v8hi) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtsepi16_epi8 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovswb128_mask ((__v8hi) __A,
         (__v16qi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtsepi16_epi8 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovswb128_mask ((__v8hi) __A,
         (__v16qi)
         _mm_setzero_si128 (),
         __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtsepi16_epi8 (__m256i __A)
{
  return (__m128i) __builtin_ia32_pmovswb256_mask ((__v16hi) __A,
         (__v16qi)_mm_undefined_si128(),
         (__mmask16) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtsepi16_storeu_epi8 (void * __P, __mmask16 __M,__m256i __A)
{
  __builtin_ia32_pmovswb256mem_mask ((__v16qi *) __P , (__v16hi) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtsepi16_epi8 (__m128i __O, __mmask16 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovswb256_mask ((__v16hi) __A,
         (__v16qi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtsepi16_epi8 (__mmask16 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovswb256_mask ((__v16hi) __A,
         (__v16qi)
         _mm_setzero_si128 (),
         __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtusepi16_epi8 (__m128i __A)
{
  return (__m128i) __builtin_ia32_pmovuswb128_mask ((__v8hi) __A,
          (__v16qi)_mm_undefined_si128(),
          (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtusepi16_storeu_epi8 (void * __P, __mmask8 __M,__m128i __A)
{
  __builtin_ia32_pmovuswb128mem_mask ((unsigned long long *) __P , (__v8hi) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtusepi16_epi8 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovuswb128_mask ((__v8hi) __A,
          (__v16qi) __O,
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtusepi16_epi8 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovuswb128_mask ((__v8hi) __A,
          (__v16qi)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtusepi16_epi8 (__m256i __A)
{
  return (__m128i) __builtin_ia32_pmovuswb256_mask ((__v16hi) __A,
          (__v16qi)_mm_undefined_si128(),
          (__mmask16) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtusepi16_storeu_epi8 (void * __P, __mmask16 __M,__m256i __A)
{
  __builtin_ia32_pmovuswb256mem_mask ((__v16qi *) __P , (__v16hi) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtusepi16_epi8 (__m128i __O, __mmask16 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovuswb256_mask ((__v16hi) __A,
          (__v16qi) __O,
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtusepi16_epi8 (__mmask16 __M, __m256i __A)
{
  return (__m128i) __builtin_ia32_pmovuswb256_mask ((__v16hi) __A,
          (__v16qi)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_broadcastb_epi8 (__m256i __O, __mmask32 __M, __m128i __A)
{
  return (__m256i) __builtin_ia32_pbroadcastb256_mask ((__v16qi) __A,
             (__v32qi) __O,
             __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_broadcastb_epi8 (__mmask32 __M, __m128i __A)
{
  return (__m256i) __builtin_ia32_pbroadcastb256_mask ((__v16qi) __A,
             (__v32qi)
             _mm256_setzero_si256 (),
             __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_set1_epi8 (__m256i __O, __mmask32 __M, char __A)
{
  return (__m256i) __builtin_ia32_pbroadcastb256_gpr_mask (__A,
          (__v32qi) __O,
          __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_set1_epi8 (__mmask32 __M, char __A)
{
  return (__m256i) __builtin_ia32_pbroadcastb256_gpr_mask (__A,
          (__v32qi)
          _mm256_setzero_si256 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_broadcastb_epi8 (__m128i __O, __mmask16 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pbroadcastb128_mask ((__v16qi) __A,
             (__v16qi) __O,
             __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_broadcastb_epi8 (__mmask16 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pbroadcastb128_mask ((__v16qi) __A,
             (__v16qi)
             _mm_setzero_si128 (),
             __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_set1_epi8 (__m128i __O, __mmask16 __M, char __A)
{
  return (__m128i) __builtin_ia32_pbroadcastb128_gpr_mask (__A,
          (__v16qi) __O,
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_set1_epi8 (__mmask16 __M, char __A)
{
  return (__m128i) __builtin_ia32_pbroadcastb128_gpr_mask (__A,
          (__v16qi)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_broadcastw_epi16 (__m256i __O, __mmask16 __M, __m128i __A)
{
  return (__m256i) __builtin_ia32_pbroadcastw256_mask ((__v8hi) __A,
             (__v16hi) __O,
             __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_broadcastw_epi16 (__mmask16 __M, __m128i __A)
{
  return (__m256i) __builtin_ia32_pbroadcastw256_mask ((__v8hi) __A,
             (__v16hi)
             _mm256_setzero_si256 (),
             __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_set1_epi16 (__m256i __O, __mmask16 __M, short __A)
{
  return (__m256i) __builtin_ia32_pbroadcastw256_gpr_mask (__A,
          (__v16hi) __O,
          __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_set1_epi16 (__mmask16 __M, short __A)
{
  return (__m256i) __builtin_ia32_pbroadcastw256_gpr_mask (__A,
          (__v16hi)
          _mm256_setzero_si256 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_broadcastw_epi16 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pbroadcastw128_mask ((__v8hi) __A,
             (__v8hi) __O,
             __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_broadcastw_epi16 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pbroadcastw128_mask ((__v8hi) __A,
             (__v8hi)
             _mm_setzero_si128 (),
             __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_set1_epi16 (__m128i __O, __mmask8 __M, short __A)
{
  return (__m128i) __builtin_ia32_pbroadcastw128_gpr_mask (__A,
          (__v8hi) __O,
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_set1_epi16 (__mmask8 __M, short __A)
{
  return (__m128i) __builtin_ia32_pbroadcastw128_gpr_mask (__A,
          (__v8hi)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_permutexvar_epi16 (__m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_permvarhi256_mask ((__v16hi) __B,
           (__v16hi) __A,
           (__v16hi)
           _mm256_setzero_si256 (),
           (__mmask16) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_permutexvar_epi16 (__mmask16 __M, __m256i __A,
    __m256i __B)
{
  return (__m256i) __builtin_ia32_permvarhi256_mask ((__v16hi) __B,
           (__v16hi) __A,
           (__v16hi)
           _mm256_setzero_si256 (),
           (__mmask16) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_permutexvar_epi16 (__m256i __W, __mmask16 __M, __m256i __A,
          __m256i __B)
{
  return (__m256i) __builtin_ia32_permvarhi256_mask ((__v16hi) __B,
           (__v16hi) __A,
           (__v16hi) __W,
           (__mmask16) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_permutexvar_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_permvarhi128_mask ((__v8hi) __B,
           (__v8hi) __A,
           (__v8hi)
           _mm_setzero_si128 (),
           (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_permutexvar_epi16 (__mmask8 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_permvarhi128_mask ((__v8hi) __B,
           (__v8hi) __A,
           (__v8hi)
           _mm_setzero_si128 (),
           (__mmask8) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_permutexvar_epi16 (__m128i __W, __mmask8 __M, __m128i __A,
       __m128i __B)
{
  return (__m128i) __builtin_ia32_permvarhi128_mask ((__v8hi) __B,
           (__v8hi) __A,
           (__v8hi) __W,
           (__mmask8) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_permutex2var_epi16 (__m256i __A, __m256i __I, __m256i __B)
{
  return (__m256i) __builtin_ia32_vpermt2varhi256_mask ((__v16hi) __I
                 ,
       (__v16hi) __A,
       (__v16hi) __B,
       (__mmask16) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_permutex2var_epi16 (__m256i __A, __mmask16 __U,
    __m256i __I, __m256i __B)
{
  return (__m256i) __builtin_ia32_vpermt2varhi256_mask ((__v16hi) __I
                 ,
       (__v16hi) __A,
       (__v16hi) __B,
       (__mmask16)
       __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask2_permutex2var_epi16 (__m256i __A, __m256i __I,
     __mmask16 __U, __m256i __B)
{
  return (__m256i) __builtin_ia32_vpermi2varhi256_mask ((__v16hi) __A,
       (__v16hi) __I
                 ,
       (__v16hi) __B,
       (__mmask16)
       __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_permutex2var_epi16 (__mmask16 __U, __m256i __A,
     __m256i __I, __m256i __B)
{
  return (__m256i) __builtin_ia32_vpermt2varhi256_maskz ((__v16hi) __I
                  ,
        (__v16hi) __A,
        (__v16hi) __B,
        (__mmask16)
        __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_permutex2var_epi16 (__m128i __A, __m128i __I, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpermt2varhi128_mask ((__v8hi) __I
                 ,
       (__v8hi) __A,
       (__v8hi) __B,
       (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_permutex2var_epi16 (__m128i __A, __mmask8 __U, __m128i __I,
        __m128i __B)
{
  return (__m128i) __builtin_ia32_vpermt2varhi128_mask ((__v8hi) __I
                 ,
       (__v8hi) __A,
       (__v8hi) __B,
       (__mmask8)
       __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask2_permutex2var_epi16 (__m128i __A, __m128i __I, __mmask8 __U,
         __m128i __B)
{
  return (__m128i) __builtin_ia32_vpermi2varhi128_mask ((__v8hi) __A,
       (__v8hi) __I
                 ,
       (__v8hi) __B,
       (__mmask8)
       __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_permutex2var_epi16 (__mmask8 __U, __m128i __A, __m128i __I,
         __m128i __B)
{
  return (__m128i) __builtin_ia32_vpermt2varhi128_maskz ((__v8hi) __I
                  ,
        (__v8hi) __A,
        (__v8hi) __B,
        (__mmask8)
        __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_maddubs_epi16 (__m256i __W, __mmask16 __U, __m256i __X,
      __m256i __Y)
{
  return (__m256i) __builtin_ia32_pmaddubsw256_mask ((__v32qi) __X,
           (__v32qi) __Y,
           (__v16hi) __W,
           (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_maddubs_epi16 (__mmask16 __U, __m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_pmaddubsw256_mask ((__v32qi) __X,
           (__v32qi) __Y,
           (__v16hi)
           _mm256_setzero_si256 (),
           (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_maddubs_epi16 (__m128i __W, __mmask8 __U, __m128i __X,
   __m128i __Y)
{
  return (__m128i) __builtin_ia32_pmaddubsw128_mask ((__v16qi) __X,
           (__v16qi) __Y,
           (__v8hi) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_maddubs_epi16 (__mmask8 __U, __m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_pmaddubsw128_mask ((__v16qi) __X,
           (__v16qi) __Y,
           (__v8hi)
           _mm_setzero_si128 (),
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_madd_epi16 (__m256i __W, __mmask8 __U, __m256i __A,
   __m256i __B)
{
  return (__m256i) __builtin_ia32_pmaddwd256_mask ((__v16hi) __A,
         (__v16hi) __B,
         (__v8si) __W,
         (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_madd_epi16 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pmaddwd256_mask ((__v16hi) __A,
         (__v16hi) __B,
         (__v8si)
         _mm256_setzero_si256 (),
         (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_madd_epi16 (__m128i __W, __mmask8 __U, __m128i __A,
       __m128i __B)
{
  return (__m128i) __builtin_ia32_pmaddwd128_mask ((__v8hi) __A,
         (__v8hi) __B,
         (__v4si) __W,
         (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_madd_epi16 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pmaddwd128_mask ((__v8hi) __A,
         (__v8hi) __B,
         (__v4si)
         _mm_setzero_si128 (),
         (__mmask8) __U);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_movepi8_mask (__m128i __A)
{
  return (__mmask16) __builtin_ia32_cvtb2mask128 ((__v16qi) __A);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_movepi8_mask (__m256i __A)
{
  return (__mmask32) __builtin_ia32_cvtb2mask256 ((__v32qi) __A);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_movepi16_mask (__m128i __A)
{
  return (__mmask8) __builtin_ia32_cvtw2mask128 ((__v8hi) __A);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_movepi16_mask (__m256i __A)
{
  return (__mmask16) __builtin_ia32_cvtw2mask256 ((__v16hi) __A);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_movm_epi8 (__mmask16 __A)
{
  return (__m128i) __builtin_ia32_cvtmask2b128 (__A);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_movm_epi8 (__mmask32 __A)
{
  return (__m256i) __builtin_ia32_cvtmask2b256 (__A);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_movm_epi16 (__mmask8 __A)
{
  return (__m128i) __builtin_ia32_cvtmask2w128 (__A);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_movm_epi16 (__mmask16 __A)
{
  return (__m256i) __builtin_ia32_cvtmask2w256 (__A);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_test_epi8_mask (__m128i __A, __m128i __B)
{
  return (__mmask16) __builtin_ia32_ptestmb128 ((__v16qi) __A,
      (__v16qi) __B,
      (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_test_epi8_mask (__mmask16 __U, __m128i __A, __m128i __B)
{
  return (__mmask16) __builtin_ia32_ptestmb128 ((__v16qi) __A,
      (__v16qi) __B, __U);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_test_epi8_mask (__m256i __A, __m256i __B)
{
  return (__mmask32) __builtin_ia32_ptestmb256 ((__v32qi) __A,
      (__v32qi) __B,
      (__mmask32) -1);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_test_epi8_mask (__mmask32 __U, __m256i __A, __m256i __B)
{
  return (__mmask32) __builtin_ia32_ptestmb256 ((__v32qi) __A,
      (__v32qi) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_test_epi16_mask (__m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ptestmw128 ((__v8hi) __A,
            (__v8hi) __B,
            (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_test_epi16_mask (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ptestmw128 ((__v8hi) __A,
            (__v8hi) __B, __U);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_test_epi16_mask (__m256i __A, __m256i __B)
{
  return (__mmask16) __builtin_ia32_ptestmw256 ((__v16hi) __A,
      (__v16hi) __B,
      (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_test_epi16_mask (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__mmask16) __builtin_ia32_ptestmw256 ((__v16hi) __A,
      (__v16hi) __B, __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_min_epu16 (__mmask16 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pminuw256_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi)
        _mm256_setzero_si256 (),
        (__mmask16) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_min_epu16 (__m256i __W, __mmask16 __M, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_pminuw256_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi) __W,
        (__mmask16) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_min_epu16 (__mmask8 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pminuw128_mask ((__v8hi) __A,
        (__v8hi) __B,
        (__v8hi)
        _mm_setzero_si128 (),
        (__mmask8) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_min_epu16 (__m128i __W, __mmask8 __M, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_pminuw128_mask ((__v8hi) __A,
        (__v8hi) __B,
        (__v8hi) __W,
        (__mmask8) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_min_epi16 (__mmask16 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pminsw256_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi)
        _mm256_setzero_si256 (),
        (__mmask16) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_min_epi16 (__m256i __W, __mmask16 __M, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_pminsw256_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi) __W,
        (__mmask16) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_max_epu8 (__mmask32 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pmaxub256_mask ((__v32qi) __A,
        (__v32qi) __B,
        (__v32qi)
        _mm256_setzero_si256 (),
        (__mmask32) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_max_epu8 (__m256i __W, __mmask32 __M, __m256i __A,
        __m256i __B)
{
  return (__m256i) __builtin_ia32_pmaxub256_mask ((__v32qi) __A,
        (__v32qi) __B,
        (__v32qi) __W,
        (__mmask32) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_max_epu8 (__mmask16 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pmaxub128_mask ((__v16qi) __A,
        (__v16qi) __B,
        (__v16qi)
        _mm_setzero_si128 (),
        (__mmask16) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_max_epu8 (__m128i __W, __mmask16 __M, __m128i __A,
     __m128i __B)
{
  return (__m128i) __builtin_ia32_pmaxub128_mask ((__v16qi) __A,
        (__v16qi) __B,
        (__v16qi) __W,
        (__mmask16) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_max_epi8 (__mmask32 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pmaxsb256_mask ((__v32qi) __A,
        (__v32qi) __B,
        (__v32qi)
        _mm256_setzero_si256 (),
        (__mmask32) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_max_epi8 (__m256i __W, __mmask32 __M, __m256i __A,
        __m256i __B)
{
  return (__m256i) __builtin_ia32_pmaxsb256_mask ((__v32qi) __A,
        (__v32qi) __B,
        (__v32qi) __W,
        (__mmask32) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_max_epi8 (__mmask16 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pmaxsb128_mask ((__v16qi) __A,
        (__v16qi) __B,
        (__v16qi)
        _mm_setzero_si128 (),
        (__mmask16) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_max_epi8 (__m128i __W, __mmask16 __M, __m128i __A,
     __m128i __B)
{
  return (__m128i) __builtin_ia32_pmaxsb128_mask ((__v16qi) __A,
        (__v16qi) __B,
        (__v16qi) __W,
        (__mmask16) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_min_epu8 (__mmask32 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pminub256_mask ((__v32qi) __A,
        (__v32qi) __B,
        (__v32qi)
        _mm256_setzero_si256 (),
        (__mmask32) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_min_epu8 (__m256i __W, __mmask32 __M, __m256i __A,
        __m256i __B)
{
  return (__m256i) __builtin_ia32_pminub256_mask ((__v32qi) __A,
        (__v32qi) __B,
        (__v32qi) __W,
        (__mmask32) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_min_epu8 (__mmask16 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pminub128_mask ((__v16qi) __A,
        (__v16qi) __B,
        (__v16qi)
        _mm_setzero_si128 (),
        (__mmask16) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_min_epu8 (__m128i __W, __mmask16 __M, __m128i __A,
     __m128i __B)
{
  return (__m128i) __builtin_ia32_pminub128_mask ((__v16qi) __A,
        (__v16qi) __B,
        (__v16qi) __W,
        (__mmask16) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_min_epi8 (__mmask32 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pminsb256_mask ((__v32qi) __A,
        (__v32qi) __B,
        (__v32qi)
        _mm256_setzero_si256 (),
        (__mmask32) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_min_epi8 (__m256i __W, __mmask32 __M, __m256i __A,
        __m256i __B)
{
  return (__m256i) __builtin_ia32_pminsb256_mask ((__v32qi) __A,
        (__v32qi) __B,
        (__v32qi) __W,
        (__mmask32) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_min_epi8 (__mmask16 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pminsb128_mask ((__v16qi) __A,
        (__v16qi) __B,
        (__v16qi)
        _mm_setzero_si128 (),
        (__mmask16) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_min_epi8 (__m128i __W, __mmask16 __M, __m128i __A,
     __m128i __B)
{
  return (__m128i) __builtin_ia32_pminsb128_mask ((__v16qi) __A,
        (__v16qi) __B,
        (__v16qi) __W,
        (__mmask16) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_max_epi16 (__mmask16 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pmaxsw256_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi)
        _mm256_setzero_si256 (),
        (__mmask16) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_max_epi16 (__m256i __W, __mmask16 __M, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_pmaxsw256_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi) __W,
        (__mmask16) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_max_epi16 (__mmask8 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pmaxsw128_mask ((__v8hi) __A,
        (__v8hi) __B,
        (__v8hi)
        _mm_setzero_si128 (),
        (__mmask8) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_max_epi16 (__m128i __W, __mmask8 __M, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_pmaxsw128_mask ((__v8hi) __A,
        (__v8hi) __B,
        (__v8hi) __W,
        (__mmask8) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_max_epu16 (__mmask16 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pmaxuw256_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi)
        _mm256_setzero_si256 (),
        (__mmask16) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_max_epu16 (__m256i __W, __mmask16 __M, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_pmaxuw256_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi) __W,
        (__mmask16) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_max_epu16 (__mmask8 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pmaxuw128_mask ((__v8hi) __A,
        (__v8hi) __B,
        (__v8hi)
        _mm_setzero_si128 (),
        (__mmask8) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_max_epu16 (__m128i __W, __mmask8 __M, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_pmaxuw128_mask ((__v8hi) __A,
        (__v8hi) __B,
        (__v8hi) __W,
        (__mmask8) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_min_epi16 (__mmask8 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pminsw128_mask ((__v8hi) __A,
        (__v8hi) __B,
        (__v8hi)
        _mm_setzero_si128 (),
        (__mmask8) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_min_epi16 (__m128i __W, __mmask8 __M, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_pminsw128_mask ((__v8hi) __A,
        (__v8hi) __B,
        (__v8hi) __W,
        (__mmask8) __M);
}
extern __inline __mmask32
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpneq_epi8_mask (__m256i __X, __m256i __Y)
{
  return (__mmask32) __builtin_ia32_cmpb256_mask ((__v32qi) __X,
        (__v32qi) __Y, 4,
        (__mmask32) -1);
}
extern __inline __mmask32
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmplt_epi8_mask (__m256i __X, __m256i __Y)
{
  return (__mmask32) __builtin_ia32_cmpb256_mask ((__v32qi) __X,
        (__v32qi) __Y, 1,
        (__mmask32) -1);
}
extern __inline __mmask32
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpge_epi8_mask (__m256i __X, __m256i __Y)
{
  return (__mmask32) __builtin_ia32_cmpb256_mask ((__v32qi) __X,
        (__v32qi) __Y, 5,
        (__mmask32) -1);
}
extern __inline __mmask32
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmple_epi8_mask (__m256i __X, __m256i __Y)
{
  return (__mmask32) __builtin_ia32_cmpb256_mask ((__v32qi) __X,
        (__v32qi) __Y, 2,
        (__mmask32) -1);
}
extern __inline __mmask16
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpneq_epi16_mask (__m256i __X, __m256i __Y)
{
  return (__mmask16) __builtin_ia32_cmpw256_mask ((__v16hi) __X,
        (__v16hi) __Y, 4,
        (__mmask16) -1);
}
extern __inline __mmask16
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmplt_epi16_mask (__m256i __X, __m256i __Y)
{
  return (__mmask16) __builtin_ia32_cmpw256_mask ((__v16hi) __X,
        (__v16hi) __Y, 1,
        (__mmask16) -1);
}
extern __inline __mmask16
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpge_epi16_mask (__m256i __X, __m256i __Y)
{
  return (__mmask16) __builtin_ia32_cmpw256_mask ((__v16hi) __X,
        (__v16hi) __Y, 5,
        (__mmask16) -1);
}
extern __inline __mmask16
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmple_epi16_mask (__m256i __X, __m256i __Y)
{
  return (__mmask16) __builtin_ia32_cmpw256_mask ((__v16hi) __X,
        (__v16hi) __Y, 2,
        (__mmask16) -1);
}
extern __inline __mmask16
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpneq_epu8_mask (__m128i __X, __m128i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpb128_mask ((__v16qi) __X,
         (__v16qi) __Y, 4,
         (__mmask16) -1);
}
extern __inline __mmask16
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmplt_epu8_mask (__m128i __X, __m128i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpb128_mask ((__v16qi) __X,
         (__v16qi) __Y, 1,
         (__mmask16) -1);
}
extern __inline __mmask16
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpge_epu8_mask (__m128i __X, __m128i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpb128_mask ((__v16qi) __X,
         (__v16qi) __Y, 5,
         (__mmask16) -1);
}
extern __inline __mmask16
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmple_epu8_mask (__m128i __X, __m128i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpb128_mask ((__v16qi) __X,
         (__v16qi) __Y, 2,
         (__mmask16) -1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpneq_epu16_mask (__m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpw128_mask ((__v8hi) __X,
        (__v8hi) __Y, 4,
        (__mmask8) -1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmplt_epu16_mask (__m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpw128_mask ((__v8hi) __X,
        (__v8hi) __Y, 1,
        (__mmask8) -1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpge_epu16_mask (__m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpw128_mask ((__v8hi) __X,
        (__v8hi) __Y, 5,
        (__mmask8) -1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmple_epu16_mask (__m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpw128_mask ((__v8hi) __X,
        (__v8hi) __Y, 2,
        (__mmask8) -1);
}
extern __inline __mmask16
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpneq_epi8_mask (__m128i __X, __m128i __Y)
{
  return (__mmask16) __builtin_ia32_cmpb128_mask ((__v16qi) __X,
        (__v16qi) __Y, 4,
        (__mmask16) -1);
}
extern __inline __mmask16
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmplt_epi8_mask (__m128i __X, __m128i __Y)
{
  return (__mmask16) __builtin_ia32_cmpb128_mask ((__v16qi) __X,
        (__v16qi) __Y, 1,
        (__mmask16) -1);
}
extern __inline __mmask16
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpge_epi8_mask (__m128i __X, __m128i __Y)
{
  return (__mmask16) __builtin_ia32_cmpb128_mask ((__v16qi) __X,
        (__v16qi) __Y, 5,
        (__mmask16) -1);
}
extern __inline __mmask16
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmple_epi8_mask (__m128i __X, __m128i __Y)
{
  return (__mmask16) __builtin_ia32_cmpb128_mask ((__v16qi) __X,
        (__v16qi) __Y, 2,
        (__mmask16) -1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpneq_epi16_mask (__m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_cmpw128_mask ((__v8hi) __X,
       (__v8hi) __Y, 4,
       (__mmask8) -1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmplt_epi16_mask (__m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_cmpw128_mask ((__v8hi) __X,
       (__v8hi) __Y, 1,
       (__mmask8) -1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpge_epi16_mask (__m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_cmpw128_mask ((__v8hi) __X,
       (__v8hi) __Y, 5,
       (__mmask8) -1);
}
extern __inline __mmask8
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmple_epi16_mask (__m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_cmpw128_mask ((__v8hi) __X,
       (__v8hi) __Y, 2,
       (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_mulhrs_epi16 (__m256i __W, __mmask16 __U, __m256i __X,
     __m256i __Y)
{
  return (__m256i) __builtin_ia32_pmulhrsw256_mask ((__v16hi) __X,
          (__v16hi) __Y,
          (__v16hi) __W,
          (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_mulhrs_epi16 (__mmask16 __U, __m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_pmulhrsw256_mask ((__v16hi) __X,
          (__v16hi) __Y,
          (__v16hi)
          _mm256_setzero_si256 (),
          (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_mulhi_epu16 (__m256i __W, __mmask16 __U, __m256i __A,
    __m256i __B)
{
  return (__m256i) __builtin_ia32_pmulhuw256_mask ((__v16hi) __A,
         (__v16hi) __B,
         (__v16hi) __W,
         (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_mulhi_epu16 (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pmulhuw256_mask ((__v16hi) __A,
         (__v16hi) __B,
         (__v16hi)
         _mm256_setzero_si256 (),
         (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_mulhi_epi16 (__m256i __W, __mmask16 __U, __m256i __A,
    __m256i __B)
{
  return (__m256i) __builtin_ia32_pmulhw256_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi) __W,
        (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_mulhi_epi16 (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pmulhw256_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi)
        _mm256_setzero_si256 (),
        (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_mulhi_epi16 (__m128i __W, __mmask8 __U, __m128i __A,
        __m128i __B)
{
  return (__m128i) __builtin_ia32_pmulhw128_mask ((__v8hi) __A,
        (__v8hi) __B,
        (__v8hi) __W,
        (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_mulhi_epi16 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pmulhw128_mask ((__v8hi) __A,
        (__v8hi) __B,
        (__v8hi)
        _mm_setzero_si128 (),
        (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_mulhi_epu16 (__m128i __W, __mmask8 __U, __m128i __A,
        __m128i __B)
{
  return (__m128i) __builtin_ia32_pmulhuw128_mask ((__v8hi) __A,
         (__v8hi) __B,
         (__v8hi) __W,
         (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_mulhi_epu16 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pmulhuw128_mask ((__v8hi) __A,
         (__v8hi) __B,
         (__v8hi)
         _mm_setzero_si128 (),
         (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_mulhrs_epi16 (__m128i __W, __mmask8 __U, __m128i __X,
         __m128i __Y)
{
  return (__m128i) __builtin_ia32_pmulhrsw128_mask ((__v8hi) __X,
          (__v8hi) __Y,
          (__v8hi) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_mulhrs_epi16 (__mmask8 __U, __m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_pmulhrsw128_mask ((__v8hi) __X,
          (__v8hi) __Y,
          (__v8hi)
          _mm_setzero_si128 (),
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_mullo_epi16 (__m256i __W, __mmask16 __U, __m256i __A,
    __m256i __B)
{
  return (__m256i) __builtin_ia32_pmullw256_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi) __W,
        (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_mullo_epi16 (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pmullw256_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi)
        _mm256_setzero_si256 (),
        (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_mullo_epi16 (__m128i __W, __mmask8 __U, __m128i __A,
        __m128i __B)
{
  return (__m128i) __builtin_ia32_pmullw128_mask ((__v8hi) __A,
        (__v8hi) __B,
        (__v8hi) __W,
        (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_mullo_epi16 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pmullw128_mask ((__v8hi) __A,
        (__v8hi) __B,
        (__v8hi)
        _mm_setzero_si128 (),
        (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi8_epi16 (__m256i __W, __mmask16 __U, __m128i __A)
{
  return (__m256i) __builtin_ia32_pmovsxbw256_mask ((__v16qi) __A,
          (__v16hi) __W,
          (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepi8_epi16 (__mmask16 __U, __m128i __A)
{
  return (__m256i) __builtin_ia32_pmovsxbw256_mask ((__v16qi) __A,
          (__v16hi)
          _mm256_setzero_si256 (),
          (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi8_epi16 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsxbw128_mask ((__v16qi) __A,
          (__v8hi) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepi8_epi16 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovsxbw128_mask ((__v16qi) __A,
          (__v8hi)
          _mm_setzero_si128 (),
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepu8_epi16 (__m256i __W, __mmask16 __U, __m128i __A)
{
  return (__m256i) __builtin_ia32_pmovzxbw256_mask ((__v16qi) __A,
          (__v16hi) __W,
          (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepu8_epi16 (__mmask16 __U, __m128i __A)
{
  return (__m256i) __builtin_ia32_pmovzxbw256_mask ((__v16qi) __A,
          (__v16hi)
          _mm256_setzero_si256 (),
          (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepu8_epi16 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovzxbw128_mask ((__v16qi) __A,
          (__v8hi) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepu8_epi16 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovzxbw128_mask ((__v16qi) __A,
          (__v8hi)
          _mm_setzero_si128 (),
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_avg_epu8 (__m256i __W, __mmask32 __U, __m256i __A,
        __m256i __B)
{
  return (__m256i) __builtin_ia32_pavgb256_mask ((__v32qi) __A,
       (__v32qi) __B,
       (__v32qi) __W,
       (__mmask32) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_avg_epu8 (__mmask32 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pavgb256_mask ((__v32qi) __A,
       (__v32qi) __B,
       (__v32qi)
       _mm256_setzero_si256 (),
       (__mmask32) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_avg_epu8 (__m128i __W, __mmask16 __U, __m128i __A,
     __m128i __B)
{
  return (__m128i) __builtin_ia32_pavgb128_mask ((__v16qi) __A,
       (__v16qi) __B,
       (__v16qi) __W,
       (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_avg_epu8 (__mmask16 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pavgb128_mask ((__v16qi) __A,
       (__v16qi) __B,
       (__v16qi)
       _mm_setzero_si128 (),
       (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_avg_epu16 (__m256i __W, __mmask16 __U, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_pavgw256_mask ((__v16hi) __A,
       (__v16hi) __B,
       (__v16hi) __W,
       (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_avg_epu16 (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pavgw256_mask ((__v16hi) __A,
       (__v16hi) __B,
       (__v16hi)
       _mm256_setzero_si256 (),
       (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_avg_epu16 (__m128i __W, __mmask8 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_pavgw128_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_avg_epu16 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pavgw128_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_add_epi8 (__m256i __W, __mmask32 __U, __m256i __A,
        __m256i __B)
{
  return (__m256i) __builtin_ia32_paddb256_mask ((__v32qi) __A,
       (__v32qi) __B,
       (__v32qi) __W,
       (__mmask32) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_add_epi8 (__mmask32 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_paddb256_mask ((__v32qi) __A,
       (__v32qi) __B,
       (__v32qi)
       _mm256_setzero_si256 (),
       (__mmask32) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_add_epi16 (__m256i __W, __mmask16 __U, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_paddw256_mask ((__v16hi) __A,
       (__v16hi) __B,
       (__v16hi) __W,
       (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_add_epi16 (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_paddw256_mask ((__v16hi) __A,
       (__v16hi) __B,
       (__v16hi)
       _mm256_setzero_si256 (),
       (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_adds_epi8 (__m256i __W, __mmask32 __U, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_paddsb256_mask ((__v32qi) __A,
        (__v32qi) __B,
        (__v32qi) __W,
        (__mmask32) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_adds_epi8 (__mmask32 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_paddsb256_mask ((__v32qi) __A,
        (__v32qi) __B,
        (__v32qi)
        _mm256_setzero_si256 (),
        (__mmask32) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_adds_epi16 (__m256i __W, __mmask16 __U, __m256i __A,
   __m256i __B)
{
  return (__m256i) __builtin_ia32_paddsw256_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi) __W,
        (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_adds_epi16 (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_paddsw256_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi)
        _mm256_setzero_si256 (),
        (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_adds_epu8 (__m256i __W, __mmask32 __U, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_paddusb256_mask ((__v32qi) __A,
         (__v32qi) __B,
         (__v32qi) __W,
         (__mmask32) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_adds_epu8 (__mmask32 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_paddusb256_mask ((__v32qi) __A,
         (__v32qi) __B,
         (__v32qi)
         _mm256_setzero_si256 (),
         (__mmask32) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_adds_epu16 (__m256i __W, __mmask16 __U, __m256i __A,
   __m256i __B)
{
  return (__m256i) __builtin_ia32_paddusw256_mask ((__v16hi) __A,
         (__v16hi) __B,
         (__v16hi) __W,
         (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_adds_epu16 (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_paddusw256_mask ((__v16hi) __A,
         (__v16hi) __B,
         (__v16hi)
         _mm256_setzero_si256 (),
         (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_sub_epi8 (__m256i __W, __mmask32 __U, __m256i __A,
        __m256i __B)
{
  return (__m256i) __builtin_ia32_psubb256_mask ((__v32qi) __A,
       (__v32qi) __B,
       (__v32qi) __W,
       (__mmask32) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_sub_epi8 (__mmask32 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_psubb256_mask ((__v32qi) __A,
       (__v32qi) __B,
       (__v32qi)
       _mm256_setzero_si256 (),
       (__mmask32) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_sub_epi16 (__m256i __W, __mmask16 __U, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_psubw256_mask ((__v16hi) __A,
       (__v16hi) __B,
       (__v16hi) __W,
       (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_sub_epi16 (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_psubw256_mask ((__v16hi) __A,
       (__v16hi) __B,
       (__v16hi)
       _mm256_setzero_si256 (),
       (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_subs_epi8 (__m256i __W, __mmask32 __U, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_psubsb256_mask ((__v32qi) __A,
        (__v32qi) __B,
        (__v32qi) __W,
        (__mmask32) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_subs_epi8 (__mmask32 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_psubsb256_mask ((__v32qi) __A,
        (__v32qi) __B,
        (__v32qi)
        _mm256_setzero_si256 (),
        (__mmask32) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_subs_epi16 (__m256i __W, __mmask16 __U, __m256i __A,
   __m256i __B)
{
  return (__m256i) __builtin_ia32_psubsw256_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi) __W,
        (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_subs_epi16 (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_psubsw256_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi)
        _mm256_setzero_si256 (),
        (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_subs_epu8 (__m256i __W, __mmask32 __U, __m256i __A,
         __m256i __B)
{
  return (__m256i) __builtin_ia32_psubusb256_mask ((__v32qi) __A,
         (__v32qi) __B,
         (__v32qi) __W,
         (__mmask32) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_subs_epu8 (__mmask32 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_psubusb256_mask ((__v32qi) __A,
         (__v32qi) __B,
         (__v32qi)
         _mm256_setzero_si256 (),
         (__mmask32) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_subs_epu16 (__m256i __W, __mmask16 __U, __m256i __A,
   __m256i __B)
{
  return (__m256i) __builtin_ia32_psubusw256_mask ((__v16hi) __A,
         (__v16hi) __B,
         (__v16hi) __W,
         (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_subs_epu16 (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_psubusw256_mask ((__v16hi) __A,
         (__v16hi) __B,
         (__v16hi)
         _mm256_setzero_si256 (),
         (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_add_epi8 (__m128i __W, __mmask16 __U, __m128i __A,
     __m128i __B)
{
  return (__m128i) __builtin_ia32_paddb128_mask ((__v16qi) __A,
       (__v16qi) __B,
       (__v16qi) __W,
       (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_add_epi8 (__mmask16 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_paddb128_mask ((__v16qi) __A,
       (__v16qi) __B,
       (__v16qi)
       _mm_setzero_si128 (),
       (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_add_epi16 (__m128i __W, __mmask8 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_paddw128_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_add_epi16 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_paddw128_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_unpackhi_epi8 (__m256i __W, __mmask32 __U, __m256i __A,
      __m256i __B)
{
  return (__m256i) __builtin_ia32_punpckhbw256_mask ((__v32qi) __A,
           (__v32qi) __B,
           (__v32qi) __W,
           (__mmask32) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_unpackhi_epi8 (__mmask32 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_punpckhbw256_mask ((__v32qi) __A,
           (__v32qi) __B,
           (__v32qi)
           _mm256_setzero_si256 (),
           (__mmask32) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_unpackhi_epi8 (__m128i __W, __mmask16 __U, __m128i __A,
   __m128i __B)
{
  return (__m128i) __builtin_ia32_punpckhbw128_mask ((__v16qi) __A,
           (__v16qi) __B,
           (__v16qi) __W,
           (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_unpackhi_epi8 (__mmask16 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_punpckhbw128_mask ((__v16qi) __A,
           (__v16qi) __B,
           (__v16qi)
           _mm_setzero_si128 (),
           (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_unpackhi_epi16 (__m256i __W, __mmask16 __U, __m256i __A,
       __m256i __B)
{
  return (__m256i) __builtin_ia32_punpckhwd256_mask ((__v16hi) __A,
           (__v16hi) __B,
           (__v16hi) __W,
           (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_unpackhi_epi16 (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_punpckhwd256_mask ((__v16hi) __A,
           (__v16hi) __B,
           (__v16hi)
           _mm256_setzero_si256 (),
           (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_unpackhi_epi16 (__m128i __W, __mmask8 __U, __m128i __A,
    __m128i __B)
{
  return (__m128i) __builtin_ia32_punpckhwd128_mask ((__v8hi) __A,
           (__v8hi) __B,
           (__v8hi) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_unpackhi_epi16 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_punpckhwd128_mask ((__v8hi) __A,
           (__v8hi) __B,
           (__v8hi)
           _mm_setzero_si128 (),
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_unpacklo_epi8 (__m256i __W, __mmask32 __U, __m256i __A,
      __m256i __B)
{
  return (__m256i) __builtin_ia32_punpcklbw256_mask ((__v32qi) __A,
           (__v32qi) __B,
           (__v32qi) __W,
           (__mmask32) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_unpacklo_epi8 (__mmask32 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_punpcklbw256_mask ((__v32qi) __A,
           (__v32qi) __B,
           (__v32qi)
           _mm256_setzero_si256 (),
           (__mmask32) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_unpacklo_epi8 (__m128i __W, __mmask16 __U, __m128i __A,
   __m128i __B)
{
  return (__m128i) __builtin_ia32_punpcklbw128_mask ((__v16qi) __A,
           (__v16qi) __B,
           (__v16qi) __W,
           (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_unpacklo_epi8 (__mmask16 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_punpcklbw128_mask ((__v16qi) __A,
           (__v16qi) __B,
           (__v16qi)
           _mm_setzero_si128 (),
           (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_unpacklo_epi16 (__m256i __W, __mmask16 __U, __m256i __A,
       __m256i __B)
{
  return (__m256i) __builtin_ia32_punpcklwd256_mask ((__v16hi) __A,
           (__v16hi) __B,
           (__v16hi) __W,
           (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_unpacklo_epi16 (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_punpcklwd256_mask ((__v16hi) __A,
           (__v16hi) __B,
           (__v16hi)
           _mm256_setzero_si256 (),
           (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_unpacklo_epi16 (__m128i __W, __mmask8 __U, __m128i __A,
    __m128i __B)
{
  return (__m128i) __builtin_ia32_punpcklwd128_mask ((__v8hi) __A,
           (__v8hi) __B,
           (__v8hi) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_unpacklo_epi16 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_punpcklwd128_mask ((__v8hi) __A,
           (__v8hi) __B,
           (__v8hi)
           _mm_setzero_si128 (),
           (__mmask8) __U);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpeq_epi8_mask (__m128i __A, __m128i __B)
{
  return (__mmask16) __builtin_ia32_pcmpeqb128_mask ((__v16qi) __A,
           (__v16qi) __B,
           (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpeq_epu8_mask (__m128i __A, __m128i __B)
{
  return (__mmask16) __builtin_ia32_ucmpb128_mask ((__v16qi) __A,
          (__v16qi) __B, 0,
          (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpeq_epu8_mask (__mmask16 __U, __m128i __A, __m128i __B)
{
  return (__mmask16) __builtin_ia32_ucmpb128_mask ((__v16qi) __A,
          (__v16qi) __B, 0,
          __U);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpeq_epi8_mask (__mmask16 __U, __m128i __A, __m128i __B)
{
  return (__mmask16) __builtin_ia32_pcmpeqb128_mask ((__v16qi) __A,
           (__v16qi) __B,
           __U);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpeq_epu8_mask (__m256i __A, __m256i __B)
{
  return (__mmask32) __builtin_ia32_ucmpb256_mask ((__v32qi) __A,
          (__v32qi) __B, 0,
          (__mmask32) -1);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpeq_epi8_mask (__m256i __A, __m256i __B)
{
  return (__mmask32) __builtin_ia32_pcmpeqb256_mask ((__v32qi) __A,
           (__v32qi) __B,
           (__mmask32) -1);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpeq_epu8_mask (__mmask32 __U, __m256i __A, __m256i __B)
{
  return (__mmask32) __builtin_ia32_ucmpb256_mask ((__v32qi) __A,
          (__v32qi) __B, 0,
          __U);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpeq_epi8_mask (__mmask32 __U, __m256i __A, __m256i __B)
{
  return (__mmask32) __builtin_ia32_pcmpeqb256_mask ((__v32qi) __A,
           (__v32qi) __B,
           __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpeq_epu16_mask (__m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ucmpw128_mask ((__v8hi) __A,
         (__v8hi) __B, 0,
         (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpeq_epi16_mask (__m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_pcmpeqw128_mask ((__v8hi) __A,
          (__v8hi) __B,
          (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpeq_epu16_mask (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ucmpw128_mask ((__v8hi) __A,
         (__v8hi) __B, 0, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpeq_epi16_mask (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_pcmpeqw128_mask ((__v8hi) __A,
          (__v8hi) __B, __U);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpeq_epu16_mask (__m256i __A, __m256i __B)
{
  return (__mmask16) __builtin_ia32_ucmpw256_mask ((__v16hi) __A,
          (__v16hi) __B, 0,
          (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpeq_epi16_mask (__m256i __A, __m256i __B)
{
  return (__mmask16) __builtin_ia32_pcmpeqw256_mask ((__v16hi) __A,
           (__v16hi) __B,
           (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpeq_epu16_mask (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__mmask16) __builtin_ia32_ucmpw256_mask ((__v16hi) __A,
          (__v16hi) __B, 0,
          __U);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpeq_epi16_mask (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__mmask16) __builtin_ia32_pcmpeqw256_mask ((__v16hi) __A,
           (__v16hi) __B,
           __U);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpgt_epu8_mask (__m128i __A, __m128i __B)
{
  return (__mmask16) __builtin_ia32_ucmpb128_mask ((__v16qi) __A,
          (__v16qi) __B, 6,
          (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpgt_epi8_mask (__m128i __A, __m128i __B)
{
  return (__mmask16) __builtin_ia32_pcmpgtb128_mask ((__v16qi) __A,
           (__v16qi) __B,
           (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpgt_epu8_mask (__mmask16 __U, __m128i __A, __m128i __B)
{
  return (__mmask16) __builtin_ia32_ucmpb128_mask ((__v16qi) __A,
          (__v16qi) __B, 6,
          __U);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpgt_epi8_mask (__mmask16 __U, __m128i __A, __m128i __B)
{
  return (__mmask16) __builtin_ia32_pcmpgtb128_mask ((__v16qi) __A,
           (__v16qi) __B,
           __U);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpgt_epu8_mask (__m256i __A, __m256i __B)
{
  return (__mmask32) __builtin_ia32_ucmpb256_mask ((__v32qi) __A,
          (__v32qi) __B, 6,
          (__mmask32) -1);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpgt_epi8_mask (__m256i __A, __m256i __B)
{
  return (__mmask32) __builtin_ia32_pcmpgtb256_mask ((__v32qi) __A,
           (__v32qi) __B,
           (__mmask32) -1);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpgt_epu8_mask (__mmask32 __U, __m256i __A, __m256i __B)
{
  return (__mmask32) __builtin_ia32_ucmpb256_mask ((__v32qi) __A,
          (__v32qi) __B, 6,
          __U);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpgt_epi8_mask (__mmask32 __U, __m256i __A, __m256i __B)
{
  return (__mmask32) __builtin_ia32_pcmpgtb256_mask ((__v32qi) __A,
           (__v32qi) __B,
           __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpgt_epu16_mask (__m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ucmpw128_mask ((__v8hi) __A,
         (__v8hi) __B, 6,
         (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmpgt_epi16_mask (__m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_pcmpgtw128_mask ((__v8hi) __A,
          (__v8hi) __B,
          (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpgt_epu16_mask (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ucmpw128_mask ((__v8hi) __A,
         (__v8hi) __B, 6, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpgt_epi16_mask (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_pcmpgtw128_mask ((__v8hi) __A,
          (__v8hi) __B, __U);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpgt_epu16_mask (__m256i __A, __m256i __B)
{
  return (__mmask16) __builtin_ia32_ucmpw256_mask ((__v16hi) __A,
          (__v16hi) __B, 6,
          (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpgt_epi16_mask (__m256i __A, __m256i __B)
{
  return (__mmask16) __builtin_ia32_pcmpgtw256_mask ((__v16hi) __A,
           (__v16hi) __B,
           (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpgt_epu16_mask (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__mmask16) __builtin_ia32_ucmpw256_mask ((__v16hi) __A,
          (__v16hi) __B, 6,
          __U);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpgt_epi16_mask (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__mmask16) __builtin_ia32_pcmpgtw256_mask ((__v16hi) __A,
           (__v16hi) __B,
           __U);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_testn_epi8_mask (__m128i __A, __m128i __B)
{
  return (__mmask16) __builtin_ia32_ptestnmb128 ((__v16qi) __A,
       (__v16qi) __B,
       (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_testn_epi8_mask (__mmask16 __U, __m128i __A, __m128i __B)
{
  return (__mmask16) __builtin_ia32_ptestnmb128 ((__v16qi) __A,
       (__v16qi) __B, __U);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_testn_epi8_mask (__m256i __A, __m256i __B)
{
  return (__mmask32) __builtin_ia32_ptestnmb256 ((__v32qi) __A,
       (__v32qi) __B,
       (__mmask32) -1);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_testn_epi8_mask (__mmask32 __U, __m256i __A, __m256i __B)
{
  return (__mmask32) __builtin_ia32_ptestnmb256 ((__v32qi) __A,
       (__v32qi) __B, __U);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_testn_epi16_mask (__m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ptestnmw128 ((__v8hi) __A,
      (__v8hi) __B,
      (__mmask8) -1);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_testn_epi16_mask (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__mmask8) __builtin_ia32_ptestnmw128 ((__v8hi) __A,
      (__v8hi) __B, __U);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_testn_epi16_mask (__m256i __A, __m256i __B)
{
  return (__mmask16) __builtin_ia32_ptestnmw256 ((__v16hi) __A,
       (__v16hi) __B,
       (__mmask16) -1);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_testn_epi16_mask (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__mmask16) __builtin_ia32_ptestnmw256 ((__v16hi) __A,
       (__v16hi) __B, __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_shuffle_epi8 (__m256i __W, __mmask32 __U, __m256i __A,
     __m256i __B)
{
  return (__m256i) __builtin_ia32_pshufb256_mask ((__v32qi) __A,
        (__v32qi) __B,
        (__v32qi) __W,
        (__mmask32) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_shuffle_epi8 (__mmask32 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pshufb256_mask ((__v32qi) __A,
        (__v32qi) __B,
        (__v32qi)
        _mm256_setzero_si256 (),
        (__mmask32) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_shuffle_epi8 (__m128i __W, __mmask16 __U, __m128i __A,
         __m128i __B)
{
  return (__m128i) __builtin_ia32_pshufb128_mask ((__v16qi) __A,
        (__v16qi) __B,
        (__v16qi) __W,
        (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_shuffle_epi8 (__mmask16 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pshufb128_mask ((__v16qi) __A,
        (__v16qi) __B,
        (__v16qi)
        _mm_setzero_si128 (),
        (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_packs_epi16 (__mmask32 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_packsswb256_mask ((__v16hi) __A,
          (__v16hi) __B,
          (__v32qi)
          _mm256_setzero_si256 (),
          __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_packs_epi16 (__m256i __W, __mmask32 __M, __m256i __A,
    __m256i __B)
{
  return (__m256i) __builtin_ia32_packsswb256_mask ((__v16hi) __A,
          (__v16hi) __B,
          (__v32qi) __W,
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_packs_epi16 (__mmask16 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_packsswb128_mask ((__v8hi) __A,
          (__v8hi) __B,
          (__v16qi)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_packs_epi16 (__m128i __W, __mmask16 __M, __m128i __A,
        __m128i __B)
{
  return (__m128i) __builtin_ia32_packsswb128_mask ((__v8hi) __A,
          (__v8hi) __B,
          (__v16qi) __W,
          __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_packus_epi16 (__mmask32 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_packuswb256_mask ((__v16hi) __A,
          (__v16hi) __B,
          (__v32qi)
          _mm256_setzero_si256 (),
          __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_packus_epi16 (__m256i __W, __mmask32 __M, __m256i __A,
     __m256i __B)
{
  return (__m256i) __builtin_ia32_packuswb256_mask ((__v16hi) __A,
          (__v16hi) __B,
          (__v32qi) __W,
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_packus_epi16 (__mmask16 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_packuswb128_mask ((__v8hi) __A,
          (__v8hi) __B,
          (__v16qi)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_packus_epi16 (__m128i __W, __mmask16 __M, __m128i __A,
         __m128i __B)
{
  return (__m128i) __builtin_ia32_packuswb128_mask ((__v8hi) __A,
          (__v8hi) __B,
          (__v16qi) __W,
          __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_abs_epi8 (__m256i __W, __mmask32 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_pabsb256_mask ((__v32qi) __A,
       (__v32qi) __W,
       (__mmask32) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_abs_epi8 (__mmask32 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_pabsb256_mask ((__v32qi) __A,
       (__v32qi)
       _mm256_setzero_si256 (),
       (__mmask32) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_abs_epi8 (__m128i __W, __mmask16 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pabsb128_mask ((__v16qi) __A,
       (__v16qi) __W,
       (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_abs_epi8 (__mmask16 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pabsb128_mask ((__v16qi) __A,
       (__v16qi)
       _mm_setzero_si128 (),
       (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_abs_epi16 (__m256i __W, __mmask16 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_pabsw256_mask ((__v16hi) __A,
       (__v16hi) __W,
       (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_abs_epi16 (__mmask16 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_pabsw256_mask ((__v16hi) __A,
       (__v16hi)
       _mm256_setzero_si256 (),
       (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_abs_epi16 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pabsw128_mask ((__v8hi) __A,
       (__v8hi) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_abs_epi16 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_pabsw128_mask ((__v8hi) __A,
       (__v8hi)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __mmask32
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpneq_epu8_mask (__m256i __X, __m256i __Y)
{
  return (__mmask32) __builtin_ia32_ucmpb256_mask ((__v32qi) __X,
         (__v32qi) __Y, 4,
         (__mmask32) -1);
}
extern __inline __mmask32
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmplt_epu8_mask (__m256i __X, __m256i __Y)
{
  return (__mmask32) __builtin_ia32_ucmpb256_mask ((__v32qi) __X,
         (__v32qi) __Y, 1,
         (__mmask32) -1);
}
extern __inline __mmask32
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpge_epu8_mask (__m256i __X, __m256i __Y)
{
  return (__mmask32) __builtin_ia32_ucmpb256_mask ((__v32qi) __X,
         (__v32qi) __Y, 5,
         (__mmask32) -1);
}
extern __inline __mmask32
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmple_epu8_mask (__m256i __X, __m256i __Y)
{
  return (__mmask32) __builtin_ia32_ucmpb256_mask ((__v32qi) __X,
         (__v32qi) __Y, 2,
         (__mmask32) -1);
}
extern __inline __mmask16
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpneq_epu16_mask (__m256i __X, __m256i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpw256_mask ((__v16hi) __X,
         (__v16hi) __Y, 4,
         (__mmask16) -1);
}
extern __inline __mmask16
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmplt_epu16_mask (__m256i __X, __m256i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpw256_mask ((__v16hi) __X,
         (__v16hi) __Y, 1,
         (__mmask16) -1);
}
extern __inline __mmask16
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmpge_epu16_mask (__m256i __X, __m256i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpw256_mask ((__v16hi) __X,
         (__v16hi) __Y, 5,
         (__mmask16) -1);
}
extern __inline __mmask16
  __attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmple_epu16_mask (__m256i __X, __m256i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpw256_mask ((__v16hi) __X,
         (__v16hi) __Y, 2,
         (__mmask16) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_storeu_epi16 (void *__P, __m256i __A)
{
  *(__v16hi_u *) __P = (__v16hi_u) __A;
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_storeu_epi16 (void *__P, __mmask16 __U, __m256i __A)
{
  __builtin_ia32_storedquhi256_mask ((short *) __P,
         (__v16hi) __A,
         (__mmask16) __U);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_storeu_epi16 (void *__P, __m128i __A)
{
  *(__v8hi_u *) __P = (__v8hi_u) __A;
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_storeu_epi16 (void *__P, __mmask8 __U, __m128i __A)
{
  __builtin_ia32_storedquhi128_mask ((short *) __P,
         (__v8hi) __A,
         (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_adds_epi16 (__m128i __W, __mmask8 __U, __m128i __A,
       __m128i __B)
{
  return (__m128i) __builtin_ia32_paddsw128_mask ((__v8hi) __A,
        (__v8hi) __B,
        (__v8hi) __W,
        (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_subs_epi8 (__m128i __W, __mmask16 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_psubsb128_mask ((__v16qi) __A,
        (__v16qi) __B,
        (__v16qi) __W,
        (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_subs_epi8 (__mmask16 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psubsb128_mask ((__v16qi) __A,
        (__v16qi) __B,
        (__v16qi)
        _mm_setzero_si128 (),
        (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_subs_epi16 (__m128i __W, __mmask8 __U, __m128i __A,
       __m128i __B)
{
  return (__m128i) __builtin_ia32_psubsw128_mask ((__v8hi) __A,
        (__v8hi) __B,
        (__v8hi) __W,
        (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_subs_epi16 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psubsw128_mask ((__v8hi) __A,
        (__v8hi) __B,
        (__v8hi)
        _mm_setzero_si128 (),
        (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_subs_epu8 (__m128i __W, __mmask16 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_psubusb128_mask ((__v16qi) __A,
         (__v16qi) __B,
         (__v16qi) __W,
         (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_subs_epu8 (__mmask16 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psubusb128_mask ((__v16qi) __A,
         (__v16qi) __B,
         (__v16qi)
         _mm_setzero_si128 (),
         (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_subs_epu16 (__m128i __W, __mmask8 __U, __m128i __A,
       __m128i __B)
{
  return (__m128i) __builtin_ia32_psubusw128_mask ((__v8hi) __A,
         (__v8hi) __B,
         (__v8hi) __W,
         (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_subs_epu16 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psubusw128_mask ((__v8hi) __A,
         (__v8hi) __B,
         (__v8hi)
         _mm_setzero_si128 (),
         (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_srl_epi16 (__m256i __W, __mmask16 __U, __m256i __A,
         __m128i __B)
{
  return (__m256i) __builtin_ia32_psrlw256_mask ((__v16hi) __A,
       (__v8hi) __B,
       (__v16hi) __W,
       (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_srl_epi16 (__mmask16 __U, __m256i __A, __m128i __B)
{
  return (__m256i) __builtin_ia32_psrlw256_mask ((__v16hi) __A,
       (__v8hi) __B,
       (__v16hi)
       _mm256_setzero_si256 (),
       (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_srl_epi16 (__m128i __W, __mmask8 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_psrlw128_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_srl_epi16 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psrlw128_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_sra_epi16 (__m256i __W, __mmask16 __U, __m256i __A,
         __m128i __B)
{
  return (__m256i) __builtin_ia32_psraw256_mask ((__v16hi) __A,
       (__v8hi) __B,
       (__v16hi) __W,
       (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_sra_epi16 (__mmask16 __U, __m256i __A, __m128i __B)
{
  return (__m256i) __builtin_ia32_psraw256_mask ((__v16hi) __A,
       (__v8hi) __B,
       (__v16hi)
       _mm256_setzero_si256 (),
       (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_sra_epi16 (__m128i __W, __mmask8 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_psraw128_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_sra_epi16 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psraw128_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_adds_epi16 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_paddsw128_mask ((__v8hi) __A,
        (__v8hi) __B,
        (__v8hi)
        _mm_setzero_si128 (),
        (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_adds_epu8 (__m128i __W, __mmask16 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_paddusb128_mask ((__v16qi) __A,
         (__v16qi) __B,
         (__v16qi) __W,
         (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_adds_epu8 (__mmask16 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_paddusb128_mask ((__v16qi) __A,
         (__v16qi) __B,
         (__v16qi)
         _mm_setzero_si128 (),
         (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_adds_epu16 (__m128i __W, __mmask8 __U, __m128i __A,
       __m128i __B)
{
  return (__m128i) __builtin_ia32_paddusw128_mask ((__v8hi) __A,
         (__v8hi) __B,
         (__v8hi) __W,
         (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_adds_epu16 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_paddusw128_mask ((__v8hi) __A,
         (__v8hi) __B,
         (__v8hi)
         _mm_setzero_si128 (),
         (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_sub_epi8 (__m128i __W, __mmask16 __U, __m128i __A,
     __m128i __B)
{
  return (__m128i) __builtin_ia32_psubb128_mask ((__v16qi) __A,
       (__v16qi) __B,
       (__v16qi) __W,
       (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_sub_epi8 (__mmask16 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psubb128_mask ((__v16qi) __A,
       (__v16qi) __B,
       (__v16qi)
       _mm_setzero_si128 (),
       (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_sub_epi16 (__m128i __W, __mmask8 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_psubw128_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_sub_epi16 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psubw128_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_adds_epi8 (__m128i __W, __mmask16 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_paddsb128_mask ((__v16qi) __A,
        (__v16qi) __B,
        (__v16qi) __W,
        (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_adds_epi8 (__mmask16 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_paddsb128_mask ((__v16qi) __A,
        (__v16qi) __B,
        (__v16qi)
        _mm_setzero_si128 (),
        (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepi16_epi8 (__m128i __A)
{
  return (__m128i) __builtin_ia32_pmovwb128_mask ((__v8hi) __A,
        (__v16qi)_mm_undefined_si128(),
        (__mmask8) -1);
}
extern __inline void
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi16_storeu_epi8 (void * __P, __mmask8 __M,__m128i __A)
{
  __builtin_ia32_pmovwb128mem_mask ((unsigned long long *) __P , (__v8hi) __A, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi16_epi8 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovwb128_mask ((__v8hi) __A,
        (__v16qi) __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepi16_epi8 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_pmovwb128_mask ((__v8hi) __A,
        (__v16qi)
        _mm_setzero_si128 (),
        __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_srav_epi16 (__m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_psrav16hi_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi)
        _mm256_setzero_si256 (),
        (__mmask16) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_srav_epi16 (__m256i __W, __mmask16 __U, __m256i __A,
   __m256i __B)
{
  return (__m256i) __builtin_ia32_psrav16hi_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi) __W,
        (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_srav_epi16 (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_psrav16hi_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi)
        _mm256_setzero_si256 (),
        (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_srav_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psrav8hi_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi)
       _mm_setzero_si128 (),
       (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_srav_epi16 (__m128i __W, __mmask8 __U, __m128i __A,
       __m128i __B)
{
  return (__m128i) __builtin_ia32_psrav8hi_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_srav_epi16 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psrav8hi_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_srlv_epi16 (__m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_psrlv16hi_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi)
        _mm256_setzero_si256 (),
        (__mmask16) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_srlv_epi16 (__m256i __W, __mmask16 __U, __m256i __A,
   __m256i __B)
{
  return (__m256i) __builtin_ia32_psrlv16hi_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi) __W,
        (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_srlv_epi16 (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_psrlv16hi_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi)
        _mm256_setzero_si256 (),
        (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_srlv_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psrlv8hi_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi)
       _mm_setzero_si128 (),
       (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_srlv_epi16 (__m128i __W, __mmask8 __U, __m128i __A,
       __m128i __B)
{
  return (__m128i) __builtin_ia32_psrlv8hi_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_srlv_epi16 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psrlv8hi_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_sllv_epi16 (__m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_psllv16hi_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi)
        _mm256_setzero_si256 (),
        (__mmask16) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_sllv_epi16 (__m256i __W, __mmask16 __U, __m256i __A,
   __m256i __B)
{
  return (__m256i) __builtin_ia32_psllv16hi_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi) __W,
        (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_sllv_epi16 (__mmask16 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_psllv16hi_mask ((__v16hi) __A,
        (__v16hi) __B,
        (__v16hi)
        _mm256_setzero_si256 (),
        (__mmask16) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_sllv_epi16 (__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psllv8hi_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi)
       _mm_setzero_si128 (),
       (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_sllv_epi16 (__m128i __W, __mmask8 __U, __m128i __A,
       __m128i __B)
{
  return (__m128i) __builtin_ia32_psllv8hi_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_sllv_epi16 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psllv8hi_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_sll_epi16 (__m128i __W, __mmask8 __U, __m128i __A,
      __m128i __B)
{
  return (__m128i) __builtin_ia32_psllw128_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_sll_epi16 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_psllw128_mask ((__v8hi) __A,
       (__v8hi) __B,
       (__v8hi)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_sll_epi16 (__m256i __W, __mmask16 __U, __m256i __A,
         __m128i __B)
{
  return (__m256i) __builtin_ia32_psllw256_mask ((__v16hi) __A,
       (__v8hi) __B,
       (__v16hi) __W,
       (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_sll_epi16 (__mmask16 __U, __m256i __A, __m128i __B)
{
  return (__m256i) __builtin_ia32_psllw256_mask ((__v16hi) __A,
       (__v8hi) __B,
       (__v16hi)
       _mm256_setzero_si256 (),
       (__mmask16) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_packus_epi32 (__mmask16 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_packusdw256_mask ((__v8si) __A,
          (__v8si) __B,
          (__v16hi)
          _mm256_setzero_si256 (),
          __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_packus_epi32 (__m256i __W, __mmask16 __M, __m256i __A,
     __m256i __B)
{
  return (__m256i) __builtin_ia32_packusdw256_mask ((__v8si) __A,
          (__v8si) __B,
          (__v16hi) __W,
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_packus_epi32 (__mmask8 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_packusdw128_mask ((__v4si) __A,
          (__v4si) __B,
          (__v8hi)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_packus_epi32 (__m128i __W, __mmask8 __M, __m128i __A,
         __m128i __B)
{
  return (__m128i) __builtin_ia32_packusdw128_mask ((__v4si) __A,
          (__v4si) __B,
          (__v8hi) __W, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_packs_epi32 (__mmask16 __M, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_packssdw256_mask ((__v8si) __A,
          (__v8si) __B,
          (__v16hi)
          _mm256_setzero_si256 (),
          __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_packs_epi32 (__m256i __W, __mmask16 __M, __m256i __A,
    __m256i __B)
{
  return (__m256i) __builtin_ia32_packssdw256_mask ((__v8si) __A,
          (__v8si) __B,
          (__v16hi) __W,
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_packs_epi32 (__mmask8 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_packssdw128_mask ((__v4si) __A,
          (__v4si) __B,
          (__v8hi)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_packs_epi32 (__m128i __W, __mmask8 __M, __m128i __A,
        __m128i __B)
{
  return (__m128i) __builtin_ia32_packssdw128_mask ((__v4si) __A,
          (__v4si) __B,
          (__v8hi) __W, __M);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpneq_epu8_mask (__mmask16 __M, __m128i __X, __m128i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpb128_mask ((__v16qi) __X,
         (__v16qi) __Y, 4,
         (__mmask16) __M);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmplt_epu8_mask (__mmask16 __M, __m128i __X, __m128i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpb128_mask ((__v16qi) __X,
         (__v16qi) __Y, 1,
         (__mmask16) __M);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpge_epu8_mask (__mmask16 __M, __m128i __X, __m128i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpb128_mask ((__v16qi) __X,
         (__v16qi) __Y, 5,
         (__mmask16) __M);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmple_epu8_mask (__mmask16 __M, __m128i __X, __m128i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpb128_mask ((__v16qi) __X,
         (__v16qi) __Y, 2,
         (__mmask16) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpneq_epu16_mask (__mmask8 __M, __m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpw128_mask ((__v8hi) __X,
        (__v8hi) __Y, 4,
        (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmplt_epu16_mask (__mmask8 __M, __m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpw128_mask ((__v8hi) __X,
        (__v8hi) __Y, 1,
        (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpge_epu16_mask (__mmask8 __M, __m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpw128_mask ((__v8hi) __X,
        (__v8hi) __Y, 5,
        (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmple_epu16_mask (__mmask8 __M, __m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_ucmpw128_mask ((__v8hi) __X,
        (__v8hi) __Y, 2,
        (__mmask8) __M);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpneq_epi8_mask (__mmask16 __M, __m128i __X, __m128i __Y)
{
  return (__mmask16) __builtin_ia32_cmpb128_mask ((__v16qi) __X,
        (__v16qi) __Y, 4,
        (__mmask16) __M);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmplt_epi8_mask (__mmask16 __M, __m128i __X, __m128i __Y)
{
  return (__mmask16) __builtin_ia32_cmpb128_mask ((__v16qi) __X,
        (__v16qi) __Y, 1,
        (__mmask16) __M);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpge_epi8_mask (__mmask16 __M, __m128i __X, __m128i __Y)
{
  return (__mmask16) __builtin_ia32_cmpb128_mask ((__v16qi) __X,
        (__v16qi) __Y, 5,
        (__mmask16) __M);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmple_epi8_mask (__mmask16 __M, __m128i __X, __m128i __Y)
{
  return (__mmask16) __builtin_ia32_cmpb128_mask ((__v16qi) __X,
        (__v16qi) __Y, 2,
        (__mmask16) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpneq_epi16_mask (__mmask8 __M, __m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_cmpw128_mask ((__v8hi) __X,
       (__v8hi) __Y, 4,
       (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmplt_epi16_mask (__mmask8 __M, __m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_cmpw128_mask ((__v8hi) __X,
       (__v8hi) __Y, 1,
       (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmpge_epi16_mask (__mmask8 __M, __m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_cmpw128_mask ((__v8hi) __X,
       (__v8hi) __Y, 5,
       (__mmask8) __M);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cmple_epi16_mask (__mmask8 __M, __m128i __X, __m128i __Y)
{
  return (__mmask8) __builtin_ia32_cmpw128_mask ((__v8hi) __X,
       (__v8hi) __Y, 2,
       (__mmask8) __M);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpneq_epu8_mask (__mmask32 __M, __m256i __X, __m256i __Y)
{
  return (__mmask32) __builtin_ia32_ucmpb256_mask ((__v32qi) __X,
         (__v32qi) __Y, 4,
         (__mmask32) __M);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmplt_epu8_mask (__mmask32 __M, __m256i __X, __m256i __Y)
{
  return (__mmask32) __builtin_ia32_ucmpb256_mask ((__v32qi) __X,
         (__v32qi) __Y, 1,
         (__mmask32) __M);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpge_epu8_mask (__mmask32 __M, __m256i __X, __m256i __Y)
{
  return (__mmask32) __builtin_ia32_ucmpb256_mask ((__v32qi) __X,
         (__v32qi) __Y, 5,
         (__mmask32) __M);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmple_epu8_mask (__mmask32 __M, __m256i __X, __m256i __Y)
{
  return (__mmask32) __builtin_ia32_ucmpb256_mask ((__v32qi) __X,
         (__v32qi) __Y, 2,
         (__mmask32) __M);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpneq_epu16_mask (__mmask16 __M, __m256i __X, __m256i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpw256_mask ((__v16hi) __X,
         (__v16hi) __Y, 4,
         (__mmask16) __M);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmplt_epu16_mask (__mmask16 __M, __m256i __X, __m256i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpw256_mask ((__v16hi) __X,
         (__v16hi) __Y, 1,
         (__mmask16) __M);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpge_epu16_mask (__mmask16 __M, __m256i __X, __m256i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpw256_mask ((__v16hi) __X,
         (__v16hi) __Y, 5,
         (__mmask16) __M);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmple_epu16_mask (__mmask16 __M, __m256i __X, __m256i __Y)
{
  return (__mmask16) __builtin_ia32_ucmpw256_mask ((__v16hi) __X,
         (__v16hi) __Y, 2,
         (__mmask16) __M);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpneq_epi8_mask (__mmask32 __M, __m256i __X, __m256i __Y)
{
  return (__mmask32) __builtin_ia32_cmpb256_mask ((__v32qi) __X,
        (__v32qi) __Y, 4,
        (__mmask32) __M);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmplt_epi8_mask (__mmask32 __M, __m256i __X, __m256i __Y)
{
  return (__mmask32) __builtin_ia32_cmpb256_mask ((__v32qi) __X,
        (__v32qi) __Y, 1,
        (__mmask32) __M);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpge_epi8_mask (__mmask32 __M, __m256i __X, __m256i __Y)
{
  return (__mmask32) __builtin_ia32_cmpb256_mask ((__v32qi) __X,
        (__v32qi) __Y, 5,
        (__mmask32) __M);
}
extern __inline __mmask32
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmple_epi8_mask (__mmask32 __M, __m256i __X, __m256i __Y)
{
  return (__mmask32) __builtin_ia32_cmpb256_mask ((__v32qi) __X,
        (__v32qi) __Y, 2,
        (__mmask32) __M);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpneq_epi16_mask (__mmask16 __M, __m256i __X, __m256i __Y)
{
  return (__mmask16) __builtin_ia32_cmpw256_mask ((__v16hi) __X,
        (__v16hi) __Y, 4,
        (__mmask16) __M);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmplt_epi16_mask (__mmask16 __M, __m256i __X, __m256i __Y)
{
  return (__mmask16) __builtin_ia32_cmpw256_mask ((__v16hi) __X,
        (__v16hi) __Y, 1,
        (__mmask16) __M);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmpge_epi16_mask (__mmask16 __M, __m256i __X, __m256i __Y)
{
  return (__mmask16) __builtin_ia32_cmpw256_mask ((__v16hi) __X,
        (__v16hi) __Y, 5,
        (__mmask16) __M);
}
extern __inline __mmask16
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cmple_epi16_mask (__mmask16 __M, __m256i __X, __m256i __Y)
{
  return (__mmask16) __builtin_ia32_cmpw256_mask ((__v16hi) __X,
        (__v16hi) __Y, 2,
        (__mmask16) __M);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx512vl,avx512dq")
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvttpd_epi64 (__m256d __A)
{
  return (__m256i) __builtin_ia32_cvttpd2qq256_mask ((__v4df) __A,
           (__v4di)
           _mm256_setzero_si256 (),
           (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvttpd_epi64 (__m256i __W, __mmask8 __U, __m256d __A)
{
  return (__m256i) __builtin_ia32_cvttpd2qq256_mask ((__v4df) __A,
           (__v4di) __W,
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvttpd_epi64 (__mmask8 __U, __m256d __A)
{
  return (__m256i) __builtin_ia32_cvttpd2qq256_mask ((__v4df) __A,
           (__v4di)
           _mm256_setzero_si256 (),
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttpd_epi64 (__m128d __A)
{
  return (__m128i) __builtin_ia32_cvttpd2qq128_mask ((__v2df) __A,
           (__v2di)
           _mm_setzero_si128 (),
           (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvttpd_epi64 (__m128i __W, __mmask8 __U, __m128d __A)
{
  return (__m128i) __builtin_ia32_cvttpd2qq128_mask ((__v2df) __A,
           (__v2di) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvttpd_epi64 (__mmask8 __U, __m128d __A)
{
  return (__m128i) __builtin_ia32_cvttpd2qq128_mask ((__v2df) __A,
           (__v2di)
           _mm_setzero_si128 (),
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvttpd_epu64 (__m256d __A)
{
  return (__m256i) __builtin_ia32_cvttpd2uqq256_mask ((__v4df) __A,
            (__v4di)
            _mm256_setzero_si256 (),
            (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvttpd_epu64 (__m256i __W, __mmask8 __U, __m256d __A)
{
  return (__m256i) __builtin_ia32_cvttpd2uqq256_mask ((__v4df) __A,
            (__v4di) __W,
            (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvttpd_epu64 (__mmask8 __U, __m256d __A)
{
  return (__m256i) __builtin_ia32_cvttpd2uqq256_mask ((__v4df) __A,
            (__v4di)
            _mm256_setzero_si256 (),
            (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttpd_epu64 (__m128d __A)
{
  return (__m128i) __builtin_ia32_cvttpd2uqq128_mask ((__v2df) __A,
            (__v2di)
            _mm_setzero_si128 (),
            (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvttpd_epu64 (__m128i __W, __mmask8 __U, __m128d __A)
{
  return (__m128i) __builtin_ia32_cvttpd2uqq128_mask ((__v2df) __A,
            (__v2di) __W,
            (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvttpd_epu64 (__mmask8 __U, __m128d __A)
{
  return (__m128i) __builtin_ia32_cvttpd2uqq128_mask ((__v2df) __A,
            (__v2di)
            _mm_setzero_si128 (),
            (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtpd_epi64 (__m256d __A)
{
  return (__m256i) __builtin_ia32_cvtpd2qq256_mask ((__v4df) __A,
          (__v4di)
          _mm256_setzero_si256 (),
          (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtpd_epi64 (__m256i __W, __mmask8 __U, __m256d __A)
{
  return (__m256i) __builtin_ia32_cvtpd2qq256_mask ((__v4df) __A,
          (__v4di) __W,
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtpd_epi64 (__mmask8 __U, __m256d __A)
{
  return (__m256i) __builtin_ia32_cvtpd2qq256_mask ((__v4df) __A,
          (__v4di)
          _mm256_setzero_si256 (),
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtpd_epi64 (__m128d __A)
{
  return (__m128i) __builtin_ia32_cvtpd2qq128_mask ((__v2df) __A,
          (__v2di)
          _mm_setzero_si128 (),
          (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtpd_epi64 (__m128i __W, __mmask8 __U, __m128d __A)
{
  return (__m128i) __builtin_ia32_cvtpd2qq128_mask ((__v2df) __A,
          (__v2di) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtpd_epi64 (__mmask8 __U, __m128d __A)
{
  return (__m128i) __builtin_ia32_cvtpd2qq128_mask ((__v2df) __A,
          (__v2di)
          _mm_setzero_si128 (),
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtpd_epu64 (__m256d __A)
{
  return (__m256i) __builtin_ia32_cvtpd2uqq256_mask ((__v4df) __A,
           (__v4di)
           _mm256_setzero_si256 (),
           (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtpd_epu64 (__m256i __W, __mmask8 __U, __m256d __A)
{
  return (__m256i) __builtin_ia32_cvtpd2uqq256_mask ((__v4df) __A,
           (__v4di) __W,
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtpd_epu64 (__mmask8 __U, __m256d __A)
{
  return (__m256i) __builtin_ia32_cvtpd2uqq256_mask ((__v4df) __A,
           (__v4di)
           _mm256_setzero_si256 (),
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtpd_epu64 (__m128d __A)
{
  return (__m128i) __builtin_ia32_cvtpd2uqq128_mask ((__v2df) __A,
           (__v2di)
           _mm_setzero_si128 (),
           (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtpd_epu64 (__m128i __W, __mmask8 __U, __m128d __A)
{
  return (__m128i) __builtin_ia32_cvtpd2uqq128_mask ((__v2df) __A,
           (__v2di) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtpd_epu64 (__mmask8 __U, __m128d __A)
{
  return (__m128i) __builtin_ia32_cvtpd2uqq128_mask ((__v2df) __A,
           (__v2di)
           _mm_setzero_si128 (),
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvttps_epi64 (__m128 __A)
{
  return (__m256i) __builtin_ia32_cvttps2qq256_mask ((__v4sf) __A,
           (__v4di)
           _mm256_setzero_si256 (),
           (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvttps_epi64 (__m256i __W, __mmask8 __U, __m128 __A)
{
  return (__m256i) __builtin_ia32_cvttps2qq256_mask ((__v4sf) __A,
           (__v4di) __W,
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvttps_epi64 (__mmask8 __U, __m128 __A)
{
  return (__m256i) __builtin_ia32_cvttps2qq256_mask ((__v4sf) __A,
           (__v4di)
           _mm256_setzero_si256 (),
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttps_epi64 (__m128 __A)
{
  return (__m128i) __builtin_ia32_cvttps2qq128_mask ((__v4sf) __A,
           (__v2di)
           _mm_setzero_si128 (),
           (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvttps_epi64 (__m128i __W, __mmask8 __U, __m128 __A)
{
  return (__m128i) __builtin_ia32_cvttps2qq128_mask ((__v4sf) __A,
           (__v2di) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvttps_epi64 (__mmask8 __U, __m128 __A)
{
  return (__m128i) __builtin_ia32_cvttps2qq128_mask ((__v4sf) __A,
           (__v2di)
           _mm_setzero_si128 (),
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvttps_epu64 (__m128 __A)
{
  return (__m256i) __builtin_ia32_cvttps2uqq256_mask ((__v4sf) __A,
            (__v4di)
            _mm256_setzero_si256 (),
            (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvttps_epu64 (__m256i __W, __mmask8 __U, __m128 __A)
{
  return (__m256i) __builtin_ia32_cvttps2uqq256_mask ((__v4sf) __A,
            (__v4di) __W,
            (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvttps_epu64 (__mmask8 __U, __m128 __A)
{
  return (__m256i) __builtin_ia32_cvttps2uqq256_mask ((__v4sf) __A,
            (__v4di)
            _mm256_setzero_si256 (),
            (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvttps_epu64 (__m128 __A)
{
  return (__m128i) __builtin_ia32_cvttps2uqq128_mask ((__v4sf) __A,
            (__v2di)
            _mm_setzero_si128 (),
            (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvttps_epu64 (__m128i __W, __mmask8 __U, __m128 __A)
{
  return (__m128i) __builtin_ia32_cvttps2uqq128_mask ((__v4sf) __A,
            (__v2di) __W,
            (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvttps_epu64 (__mmask8 __U, __m128 __A)
{
  return (__m128i) __builtin_ia32_cvttps2uqq128_mask ((__v4sf) __A,
            (__v2di)
            _mm_setzero_si128 (),
            (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_broadcast_f64x2 (__m128d __A)
{
  return (__m256d) __builtin_ia32_broadcastf64x2_256_mask ((__v2df)
          __A,
                 (__v4df)_mm256_undefined_pd(),
          (__mmask8) -1);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_broadcast_f64x2 (__m256d __O, __mmask8 __M, __m128d __A)
{
  return (__m256d) __builtin_ia32_broadcastf64x2_256_mask ((__v2df)
          __A,
          (__v4df)
          __O, __M);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_broadcast_f64x2 (__mmask8 __M, __m128d __A)
{
  return (__m256d) __builtin_ia32_broadcastf64x2_256_mask ((__v2df)
          __A,
          (__v4df)
          _mm256_setzero_ps (),
          __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_broadcast_i64x2 (__m128i __A)
{
  return (__m256i) __builtin_ia32_broadcasti64x2_256_mask ((__v2di)
          __A,
                 (__v4di)_mm256_undefined_si256(),
          (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_broadcast_i64x2 (__m256i __O, __mmask8 __M, __m128i __A)
{
  return (__m256i) __builtin_ia32_broadcasti64x2_256_mask ((__v2di)
          __A,
          (__v4di)
          __O, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_broadcast_i64x2 (__mmask8 __M, __m128i __A)
{
  return (__m256i) __builtin_ia32_broadcasti64x2_256_mask ((__v2di)
          __A,
          (__v4di)
          _mm256_setzero_si256 (),
          __M);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_broadcast_f32x2 (__m128 __A)
{
  return (__m256) __builtin_ia32_broadcastf32x2_256_mask ((__v4sf) __A,
                (__v8sf)_mm256_undefined_ps(),
         (__mmask8) -1);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_broadcast_f32x2 (__m256 __O, __mmask8 __M, __m128 __A)
{
  return (__m256) __builtin_ia32_broadcastf32x2_256_mask ((__v4sf) __A,
         (__v8sf) __O,
         __M);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_broadcast_f32x2 (__mmask8 __M, __m128 __A)
{
  return (__m256) __builtin_ia32_broadcastf32x2_256_mask ((__v4sf) __A,
         (__v8sf)
         _mm256_setzero_ps (),
         __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_broadcast_i32x2 (__m128i __A)
{
  return (__m256i) __builtin_ia32_broadcasti32x2_256_mask ((__v4si)
          __A,
                (__v8si)_mm256_undefined_si256(),
          (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_broadcast_i32x2 (__m256i __O, __mmask8 __M, __m128i __A)
{
  return (__m256i) __builtin_ia32_broadcasti32x2_256_mask ((__v4si)
          __A,
          (__v8si)
          __O, __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_broadcast_i32x2 (__mmask8 __M, __m128i __A)
{
  return (__m256i) __builtin_ia32_broadcasti32x2_256_mask ((__v4si)
          __A,
          (__v8si)
          _mm256_setzero_si256 (),
          __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_broadcast_i32x2 (__m128i __A)
{
  return (__m128i) __builtin_ia32_broadcasti32x2_128_mask ((__v4si)
          __A,
                (__v4si)_mm_undefined_si128(),
          (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_broadcast_i32x2 (__m128i __O, __mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_broadcasti32x2_128_mask ((__v4si)
          __A,
          (__v4si)
          __O, __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_broadcast_i32x2 (__mmask8 __M, __m128i __A)
{
  return (__m128i) __builtin_ia32_broadcasti32x2_128_mask ((__v4si)
          __A,
          (__v4si)
          _mm_setzero_si128 (),
          __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mullo_epi64 (__m256i __A, __m256i __B)
{
  return (__m256i) ((__v4du) __A * (__v4du) __B);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_mullo_epi64 (__m256i __W, __mmask8 __U, __m256i __A,
    __m256i __B)
{
  return (__m256i) __builtin_ia32_pmullq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di) __W,
        (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_mullo_epi64 (__mmask8 __U, __m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_pmullq256_mask ((__v4di) __A,
        (__v4di) __B,
        (__v4di)
        _mm256_setzero_si256 (),
        (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mullo_epi64 (__m128i __A, __m128i __B)
{
  return (__m128i) ((__v2du) __A * (__v2du) __B);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_mullo_epi64 (__m128i __W, __mmask8 __U, __m128i __A,
        __m128i __B)
{
  return (__m128i) __builtin_ia32_pmullq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di) __W,
        (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_mullo_epi64 (__mmask8 __U, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_pmullq128_mask ((__v2di) __A,
        (__v2di) __B,
        (__v2di)
        _mm_setzero_si128 (),
        (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_andnot_pd (__m256d __W, __mmask8 __U, __m256d __A,
         __m256d __B)
{
  return (__m256d) __builtin_ia32_andnpd256_mask ((__v4df) __A,
        (__v4df) __B,
        (__v4df) __W,
        (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_andnot_pd (__mmask8 __U, __m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_andnpd256_mask ((__v4df) __A,
        (__v4df) __B,
        (__v4df)
        _mm256_setzero_pd (),
        (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_andnot_pd (__m128d __W, __mmask8 __U, __m128d __A,
      __m128d __B)
{
  return (__m128d) __builtin_ia32_andnpd128_mask ((__v2df) __A,
        (__v2df) __B,
        (__v2df) __W,
        (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_andnot_pd (__mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_andnpd128_mask ((__v2df) __A,
        (__v2df) __B,
        (__v2df)
        _mm_setzero_pd (),
        (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_andnot_ps (__m256 __W, __mmask8 __U, __m256 __A,
         __m256 __B)
{
  return (__m256) __builtin_ia32_andnps256_mask ((__v8sf) __A,
       (__v8sf) __B,
       (__v8sf) __W,
       (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_andnot_ps (__mmask8 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_andnps256_mask ((__v8sf) __A,
       (__v8sf) __B,
       (__v8sf)
       _mm256_setzero_ps (),
       (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_andnot_ps (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_andnps128_mask ((__v4sf) __A,
       (__v4sf) __B,
       (__v4sf) __W,
       (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_andnot_ps (__mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_andnps128_mask ((__v4sf) __A,
       (__v4sf) __B,
       (__v4sf)
       _mm_setzero_ps (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtps_epi64 (__m128 __A)
{
  return (__m256i) __builtin_ia32_cvtps2qq256_mask ((__v4sf) __A,
          (__v4di)
          _mm256_setzero_si256 (),
          (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtps_epi64 (__m256i __W, __mmask8 __U, __m128 __A)
{
  return (__m256i) __builtin_ia32_cvtps2qq256_mask ((__v4sf) __A,
          (__v4di) __W,
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtps_epi64 (__mmask8 __U, __m128 __A)
{
  return (__m256i) __builtin_ia32_cvtps2qq256_mask ((__v4sf) __A,
          (__v4di)
          _mm256_setzero_si256 (),
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtps_epi64 (__m128 __A)
{
  return (__m128i) __builtin_ia32_cvtps2qq128_mask ((__v4sf) __A,
          (__v2di)
          _mm_setzero_si128 (),
          (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtps_epi64 (__m128i __W, __mmask8 __U, __m128 __A)
{
  return (__m128i) __builtin_ia32_cvtps2qq128_mask ((__v4sf) __A,
          (__v2di) __W,
          (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtps_epi64 (__mmask8 __U, __m128 __A)
{
  return (__m128i) __builtin_ia32_cvtps2qq128_mask ((__v4sf) __A,
          (__v2di)
          _mm_setzero_si128 (),
          (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtps_epu64 (__m128 __A)
{
  return (__m256i) __builtin_ia32_cvtps2uqq256_mask ((__v4sf) __A,
           (__v4di)
           _mm256_setzero_si256 (),
           (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtps_epu64 (__m256i __W, __mmask8 __U, __m128 __A)
{
  return (__m256i) __builtin_ia32_cvtps2uqq256_mask ((__v4sf) __A,
           (__v4di) __W,
           (__mmask8) __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtps_epu64 (__mmask8 __U, __m128 __A)
{
  return (__m256i) __builtin_ia32_cvtps2uqq256_mask ((__v4sf) __A,
           (__v4di)
           _mm256_setzero_si256 (),
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtps_epu64 (__m128 __A)
{
  return (__m128i) __builtin_ia32_cvtps2uqq128_mask ((__v4sf) __A,
           (__v2di)
           _mm_setzero_si128 (),
           (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtps_epu64 (__m128i __W, __mmask8 __U, __m128 __A)
{
  return (__m128i) __builtin_ia32_cvtps2uqq128_mask ((__v4sf) __A,
           (__v2di) __W,
           (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtps_epu64 (__mmask8 __U, __m128 __A)
{
  return (__m128i) __builtin_ia32_cvtps2uqq128_mask ((__v4sf) __A,
           (__v2di)
           _mm_setzero_si128 (),
           (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepi64_ps (__m256i __A)
{
  return (__m128) __builtin_ia32_cvtqq2ps256_mask ((__v4di) __A,
         (__v4sf)
         _mm_setzero_ps (),
         (__mmask8) -1);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi64_ps (__m128 __W, __mmask8 __U, __m256i __A)
{
  return (__m128) __builtin_ia32_cvtqq2ps256_mask ((__v4di) __A,
         (__v4sf) __W,
         (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepi64_ps (__mmask8 __U, __m256i __A)
{
  return (__m128) __builtin_ia32_cvtqq2ps256_mask ((__v4di) __A,
         (__v4sf)
         _mm_setzero_ps (),
         (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepi64_ps (__m128i __A)
{
  return (__m128) __builtin_ia32_cvtqq2ps128_mask ((__v2di) __A,
         (__v4sf)
         _mm_setzero_ps (),
         (__mmask8) -1);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi64_ps (__m128 __W, __mmask8 __U, __m128i __A)
{
  return (__m128) __builtin_ia32_cvtqq2ps128_mask ((__v2di) __A,
         (__v4sf) __W,
         (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepi64_ps (__mmask8 __U, __m128i __A)
{
  return (__m128) __builtin_ia32_cvtqq2ps128_mask ((__v2di) __A,
         (__v4sf)
         _mm_setzero_ps (),
         (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepu64_ps (__m256i __A)
{
  return (__m128) __builtin_ia32_cvtuqq2ps256_mask ((__v4di) __A,
          (__v4sf)
          _mm_setzero_ps (),
          (__mmask8) -1);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepu64_ps (__m128 __W, __mmask8 __U, __m256i __A)
{
  return (__m128) __builtin_ia32_cvtuqq2ps256_mask ((__v4di) __A,
          (__v4sf) __W,
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepu64_ps (__mmask8 __U, __m256i __A)
{
  return (__m128) __builtin_ia32_cvtuqq2ps256_mask ((__v4di) __A,
          (__v4sf)
          _mm_setzero_ps (),
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepu64_ps (__m128i __A)
{
  return (__m128) __builtin_ia32_cvtuqq2ps128_mask ((__v2di) __A,
          (__v4sf)
          _mm_setzero_ps (),
          (__mmask8) -1);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepu64_ps (__m128 __W, __mmask8 __U, __m128i __A)
{
  return (__m128) __builtin_ia32_cvtuqq2ps128_mask ((__v2di) __A,
          (__v4sf) __W,
          (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepu64_ps (__mmask8 __U, __m128i __A)
{
  return (__m128) __builtin_ia32_cvtuqq2ps128_mask ((__v2di) __A,
          (__v4sf)
          _mm_setzero_ps (),
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepi64_pd (__m256i __A)
{
  return (__m256d) __builtin_ia32_cvtqq2pd256_mask ((__v4di) __A,
          (__v4df)
          _mm256_setzero_pd (),
          (__mmask8) -1);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepi64_pd (__m256d __W, __mmask8 __U, __m256i __A)
{
  return (__m256d) __builtin_ia32_cvtqq2pd256_mask ((__v4di) __A,
          (__v4df) __W,
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepi64_pd (__mmask8 __U, __m256i __A)
{
  return (__m256d) __builtin_ia32_cvtqq2pd256_mask ((__v4di) __A,
          (__v4df)
          _mm256_setzero_pd (),
          (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepi64_pd (__m128i __A)
{
  return (__m128d) __builtin_ia32_cvtqq2pd128_mask ((__v2di) __A,
          (__v2df)
          _mm_setzero_pd (),
          (__mmask8) -1);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepi64_pd (__m128d __W, __mmask8 __U, __m128i __A)
{
  return (__m128d) __builtin_ia32_cvtqq2pd128_mask ((__v2di) __A,
          (__v2df) __W,
          (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepi64_pd (__mmask8 __U, __m128i __A)
{
  return (__m128d) __builtin_ia32_cvtqq2pd128_mask ((__v2di) __A,
          (__v2df)
          _mm_setzero_pd (),
          (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtepu64_pd (__m256i __A)
{
  return (__m256d) __builtin_ia32_cvtuqq2pd256_mask ((__v4di) __A,
           (__v4df)
           _mm256_setzero_pd (),
           (__mmask8) -1);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtepu64_pd (__m256d __W, __mmask8 __U, __m256i __A)
{
  return (__m256d) __builtin_ia32_cvtuqq2pd256_mask ((__v4di) __A,
           (__v4df) __W,
           (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtepu64_pd (__mmask8 __U, __m256i __A)
{
  return (__m256d) __builtin_ia32_cvtuqq2pd256_mask ((__v4di) __A,
           (__v4df)
           _mm256_setzero_pd (),
           (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_and_pd (__m256d __W, __mmask8 __U, __m256d __A,
      __m256d __B)
{
  return (__m256d) __builtin_ia32_andpd256_mask ((__v4df) __A,
       (__v4df) __B,
       (__v4df) __W,
       (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_and_pd (__mmask8 __U, __m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_andpd256_mask ((__v4df) __A,
       (__v4df) __B,
       (__v4df)
       _mm256_setzero_pd (),
       (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_and_pd (__m128d __W, __mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_andpd128_mask ((__v2df) __A,
       (__v2df) __B,
       (__v2df) __W,
       (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_and_pd (__mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_andpd128_mask ((__v2df) __A,
       (__v2df) __B,
       (__v2df)
       _mm_setzero_pd (),
       (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_and_ps (__m256 __W, __mmask8 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_andps256_mask ((__v8sf) __A,
      (__v8sf) __B,
      (__v8sf) __W,
      (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_and_ps (__mmask8 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_andps256_mask ((__v8sf) __A,
      (__v8sf) __B,
      (__v8sf)
      _mm256_setzero_ps (),
      (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_and_ps (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_andps128_mask ((__v4sf) __A,
      (__v4sf) __B,
      (__v4sf) __W,
      (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_and_ps (__mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_andps128_mask ((__v4sf) __A,
      (__v4sf) __B,
      (__v4sf)
      _mm_setzero_ps (),
      (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtepu64_pd (__m128i __A)
{
  return (__m128d) __builtin_ia32_cvtuqq2pd128_mask ((__v2di) __A,
           (__v2df)
           _mm_setzero_pd (),
           (__mmask8) -1);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtepu64_pd (__m128d __W, __mmask8 __U, __m128i __A)
{
  return (__m128d) __builtin_ia32_cvtuqq2pd128_mask ((__v2di) __A,
           (__v2df) __W,
           (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtepu64_pd (__mmask8 __U, __m128i __A)
{
  return (__m128d) __builtin_ia32_cvtuqq2pd128_mask ((__v2di) __A,
           (__v2df)
           _mm_setzero_pd (),
           (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_xor_pd (__m256d __W, __mmask8 __U, __m256d __A,
      __m256d __B)
{
  return (__m256d) __builtin_ia32_xorpd256_mask ((__v4df) __A,
       (__v4df) __B,
       (__v4df) __W,
       (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_xor_pd (__mmask8 __U, __m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_xorpd256_mask ((__v4df) __A,
       (__v4df) __B,
       (__v4df)
       _mm256_setzero_pd (),
       (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_xor_pd (__m128d __W, __mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_xorpd128_mask ((__v2df) __A,
       (__v2df) __B,
       (__v2df) __W,
       (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_xor_pd (__mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_xorpd128_mask ((__v2df) __A,
       (__v2df) __B,
       (__v2df)
       _mm_setzero_pd (),
       (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_xor_ps (__m256 __W, __mmask8 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_xorps256_mask ((__v8sf) __A,
      (__v8sf) __B,
      (__v8sf) __W,
      (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_xor_ps (__mmask8 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_xorps256_mask ((__v8sf) __A,
      (__v8sf) __B,
      (__v8sf)
      _mm256_setzero_ps (),
      (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_xor_ps (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_xorps128_mask ((__v4sf) __A,
      (__v4sf) __B,
      (__v4sf) __W,
      (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_xor_ps (__mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_xorps128_mask ((__v4sf) __A,
      (__v4sf) __B,
      (__v4sf)
      _mm_setzero_ps (),
      (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_or_pd (__m256d __W, __mmask8 __U, __m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_orpd256_mask ((__v4df) __A,
      (__v4df) __B,
      (__v4df) __W,
      (__mmask8) __U);
}
extern __inline __m256d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_or_pd (__mmask8 __U, __m256d __A, __m256d __B)
{
  return (__m256d) __builtin_ia32_orpd256_mask ((__v4df) __A,
      (__v4df) __B,
      (__v4df)
      _mm256_setzero_pd (),
      (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_or_pd (__m128d __W, __mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_orpd128_mask ((__v2df) __A,
      (__v2df) __B,
      (__v2df) __W,
      (__mmask8) __U);
}
extern __inline __m128d
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_or_pd (__mmask8 __U, __m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_orpd128_mask ((__v2df) __A,
      (__v2df) __B,
      (__v2df)
      _mm_setzero_pd (),
      (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_or_ps (__m256 __W, __mmask8 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_orps256_mask ((__v8sf) __A,
            (__v8sf) __B,
            (__v8sf) __W,
            (__mmask8) __U);
}
extern __inline __m256
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_or_ps (__mmask8 __U, __m256 __A, __m256 __B)
{
  return (__m256) __builtin_ia32_orps256_mask ((__v8sf) __A,
            (__v8sf) __B,
            (__v8sf)
            _mm256_setzero_ps (),
            (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_or_ps (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_orps128_mask ((__v4sf) __A,
            (__v4sf) __B,
            (__v4sf) __W,
            (__mmask8) __U);
}
extern __inline __m128
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_or_ps (__mmask8 __U, __m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_orps128_mask ((__v4sf) __A,
            (__v4sf) __B,
            (__v4sf)
            _mm_setzero_ps (),
            (__mmask8) __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_movm_epi32 (__mmask8 __A)
{
  return (__m128i) __builtin_ia32_cvtmask2d128 (__A);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_movm_epi32 (__mmask8 __A)
{
  return (__m256i) __builtin_ia32_cvtmask2d256 (__A);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_movm_epi64 (__mmask8 __A)
{
  return (__m128i) __builtin_ia32_cvtmask2q128 (__A);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_movm_epi64 (__mmask8 __A)
{
  return (__m256i) __builtin_ia32_cvtmask2q256 (__A);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_movepi32_mask (__m128i __A)
{
  return (__mmask8) __builtin_ia32_cvtd2mask128 ((__v4si) __A);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_movepi32_mask (__m256i __A)
{
  return (__mmask8) __builtin_ia32_cvtd2mask256 ((__v8si) __A);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_movepi64_mask (__m128i __A)
{
  return (__mmask8) __builtin_ia32_cvtq2mask128 ((__v2di) __A);
}
extern __inline __mmask8
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_movepi64_mask (__m256i __A)
{
  return (__mmask8) __builtin_ia32_cvtq2mask256 ((__v4di) __A);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx512ifma")
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_madd52lo_epu64 (__m512i __X, __m512i __Y, __m512i __Z)
{
  return (__m512i) __builtin_ia32_vpmadd52luq512_mask ((__v8di) __X,
             (__v8di) __Y,
             (__v8di) __Z,
             (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_madd52hi_epu64 (__m512i __X, __m512i __Y, __m512i __Z)
{
  return (__m512i) __builtin_ia32_vpmadd52huq512_mask ((__v8di) __X,
             (__v8di) __Y,
             (__v8di) __Z,
             (__mmask8) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_madd52lo_epu64 (__m512i __W, __mmask8 __M, __m512i __X,
       __m512i __Y)
{
  return (__m512i) __builtin_ia32_vpmadd52luq512_mask ((__v8di) __W,
             (__v8di) __X,
             (__v8di) __Y,
             (__mmask8) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_madd52hi_epu64 (__m512i __W, __mmask8 __M, __m512i __X,
       __m512i __Y)
{
  return (__m512i) __builtin_ia32_vpmadd52huq512_mask ((__v8di) __W,
             (__v8di) __X,
             (__v8di) __Y,
             (__mmask8) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_madd52lo_epu64 (__mmask8 __M, __m512i __X, __m512i __Y, __m512i __Z)
{
  return (__m512i) __builtin_ia32_vpmadd52luq512_maskz ((__v8di) __X,
       (__v8di) __Y,
       (__v8di) __Z,
       (__mmask8) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_madd52hi_epu64 (__mmask8 __M, __m512i __X, __m512i __Y, __m512i __Z)
{
  return (__m512i) __builtin_ia32_vpmadd52huq512_maskz ((__v8di) __X,
       (__v8di) __Y,
       (__v8di) __Z,
       (__mmask8) __M);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx512ifma,avx512vl")
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_madd52lo_epu64 (__m128i __X, __m128i __Y, __m128i __Z)
{
  return (__m128i) __builtin_ia32_vpmadd52luq128_mask ((__v2di) __X,
             (__v2di) __Y,
             (__v2di) __Z,
             (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_madd52hi_epu64 (__m128i __X, __m128i __Y, __m128i __Z)
{
  return (__m128i) __builtin_ia32_vpmadd52huq128_mask ((__v2di) __X,
             (__v2di) __Y,
             (__v2di) __Z,
             (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_madd52lo_epu64 (__m256i __X, __m256i __Y, __m256i __Z)
{
  return (__m256i) __builtin_ia32_vpmadd52luq256_mask ((__v4di) __X,
             (__v4di) __Y,
             (__v4di) __Z,
             (__mmask8) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_madd52hi_epu64 (__m256i __X, __m256i __Y, __m256i __Z)
{
  return (__m256i) __builtin_ia32_vpmadd52huq256_mask ((__v4di) __X,
             (__v4di) __Y,
             (__v4di) __Z,
             (__mmask8) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_madd52lo_epu64 (__m128i __W, __mmask8 __M, __m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_vpmadd52luq128_mask ((__v2di) __W,
             (__v2di) __X,
             (__v2di) __Y,
             (__mmask8) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_madd52hi_epu64 (__m128i __W, __mmask8 __M, __m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_vpmadd52huq128_mask ((__v2di) __W,
             (__v2di) __X,
             (__v2di) __Y,
             (__mmask8) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_madd52lo_epu64 (__m256i __W, __mmask8 __M, __m256i __X,
       __m256i __Y)
{
  return (__m256i) __builtin_ia32_vpmadd52luq256_mask ((__v4di) __W,
             (__v4di) __X,
             (__v4di) __Y,
             (__mmask8) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_madd52hi_epu64 (__m256i __W, __mmask8 __M, __m256i __X,
       __m256i __Y)
{
  return (__m256i) __builtin_ia32_vpmadd52huq256_mask ((__v4di) __W,
             (__v4di) __X,
             (__v4di) __Y,
             (__mmask8) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_madd52lo_epu64 (__mmask8 __M, __m128i __X, __m128i __Y, __m128i __Z)
{
  return (__m128i) __builtin_ia32_vpmadd52luq128_maskz ((__v2di) __X,
       (__v2di) __Y,
       (__v2di) __Z,
       (__mmask8) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_madd52hi_epu64 (__mmask8 __M, __m128i __X, __m128i __Y, __m128i __Z)
{
  return (__m128i) __builtin_ia32_vpmadd52huq128_maskz ((__v2di) __X,
       (__v2di) __Y,
       (__v2di) __Z,
       (__mmask8) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_madd52lo_epu64 (__mmask8 __M, __m256i __X, __m256i __Y, __m256i __Z)
{
  return (__m256i) __builtin_ia32_vpmadd52luq256_maskz ((__v4di) __X,
       (__v4di) __Y,
       (__v4di) __Z,
       (__mmask8) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_madd52hi_epu64 (__mmask8 __M, __m256i __X, __m256i __Y, __m256i __Z)
{
  return (__m256i) __builtin_ia32_vpmadd52huq256_maskz ((__v4di) __X,
       (__v4di) __Y,
       (__v4di) __Z,
       (__mmask8) __M);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx512vbmi")
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_multishift_epi64_epi8 (__m512i __W, __mmask64 __M, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_vpmultishiftqb512_mask ((__v64qi) __X,
         (__v64qi) __Y,
         (__v64qi) __W,
         (__mmask64) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_multishift_epi64_epi8 (__mmask64 __M, __m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_vpmultishiftqb512_mask ((__v64qi) __X,
         (__v64qi) __Y,
         (__v64qi)
         _mm512_setzero_si512 (),
         (__mmask64) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_multishift_epi64_epi8 (__m512i __X, __m512i __Y)
{
  return (__m512i) __builtin_ia32_vpmultishiftqb512_mask ((__v64qi) __X,
         (__v64qi) __Y,
         (__v64qi)
         _mm512_undefined_epi32 (),
         (__mmask64) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_permutexvar_epi8 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_permvarqi512_mask ((__v64qi) __B,
           (__v64qi) __A,
           (__v64qi)
           _mm512_undefined_epi32 (),
           (__mmask64) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_permutexvar_epi8 (__mmask64 __M, __m512i __A,
    __m512i __B)
{
  return (__m512i) __builtin_ia32_permvarqi512_mask ((__v64qi) __B,
           (__v64qi) __A,
           (__v64qi)
           _mm512_setzero_si512(),
           (__mmask64) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_permutexvar_epi8 (__m512i __W, __mmask64 __M, __m512i __A,
          __m512i __B)
{
  return (__m512i) __builtin_ia32_permvarqi512_mask ((__v64qi) __B,
           (__v64qi) __A,
           (__v64qi) __W,
           (__mmask64) __M);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_permutex2var_epi8 (__m512i __A, __m512i __I, __m512i __B)
{
  return (__m512i) __builtin_ia32_vpermt2varqi512_mask ((__v64qi) __I
                 ,
       (__v64qi) __A,
       (__v64qi) __B,
       (__mmask64) -1);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_permutex2var_epi8 (__m512i __A, __mmask64 __U,
    __m512i __I, __m512i __B)
{
  return (__m512i) __builtin_ia32_vpermt2varqi512_mask ((__v64qi) __I
                 ,
       (__v64qi) __A,
       (__v64qi) __B,
       (__mmask64)
       __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask2_permutex2var_epi8 (__m512i __A, __m512i __I,
     __mmask64 __U, __m512i __B)
{
  return (__m512i) __builtin_ia32_vpermi2varqi512_mask ((__v64qi) __A,
       (__v64qi) __I
                 ,
       (__v64qi) __B,
       (__mmask64)
       __U);
}
extern __inline __m512i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_permutex2var_epi8 (__mmask64 __U, __m512i __A,
     __m512i __I, __m512i __B)
{
  return (__m512i) __builtin_ia32_vpermt2varqi512_maskz ((__v64qi) __I
                  ,
        (__v64qi) __A,
        (__v64qi) __B,
        (__mmask64)
        __U);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx512vbmi,avx512vl")
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_multishift_epi64_epi8 (__m256i __W, __mmask32 __M, __m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_vpmultishiftqb256_mask ((__v32qi) __X,
         (__v32qi) __Y,
         (__v32qi) __W,
         (__mmask32) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_multishift_epi64_epi8 (__mmask32 __M, __m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_vpmultishiftqb256_mask ((__v32qi) __X,
         (__v32qi) __Y,
         (__v32qi)
         _mm256_setzero_si256 (),
         (__mmask32) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_multishift_epi64_epi8 (__m256i __X, __m256i __Y)
{
  return (__m256i) __builtin_ia32_vpmultishiftqb256_mask ((__v32qi) __X,
         (__v32qi) __Y,
         (__v32qi)
         _mm256_undefined_si256 (),
         (__mmask32) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_multishift_epi64_epi8 (__m128i __W, __mmask16 __M, __m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_vpmultishiftqb128_mask ((__v16qi) __X,
         (__v16qi) __Y,
         (__v16qi) __W,
         (__mmask16) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_multishift_epi64_epi8 (__mmask16 __M, __m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_vpmultishiftqb128_mask ((__v16qi) __X,
         (__v16qi) __Y,
         (__v16qi)
         _mm_setzero_si128 (),
         (__mmask16) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_multishift_epi64_epi8 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_vpmultishiftqb128_mask ((__v16qi) __X,
         (__v16qi) __Y,
         (__v16qi)
         _mm_undefined_si128 (),
         (__mmask16) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_permutexvar_epi8 (__m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_permvarqi256_mask ((__v32qi) __B,
           (__v32qi) __A,
           (__v32qi)
           _mm256_undefined_si256 (),
           (__mmask32) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_permutexvar_epi8 (__mmask32 __M, __m256i __A,
    __m256i __B)
{
  return (__m256i) __builtin_ia32_permvarqi256_mask ((__v32qi) __B,
           (__v32qi) __A,
           (__v32qi)
           _mm256_setzero_si256 (),
           (__mmask32) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_permutexvar_epi8 (__m256i __W, __mmask32 __M, __m256i __A,
          __m256i __B)
{
  return (__m256i) __builtin_ia32_permvarqi256_mask ((__v32qi) __B,
           (__v32qi) __A,
           (__v32qi) __W,
           (__mmask32) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_permutexvar_epi8 (__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_permvarqi128_mask ((__v16qi) __B,
           (__v16qi) __A,
           (__v16qi)
           _mm_undefined_si128 (),
           (__mmask16) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_permutexvar_epi8 (__mmask16 __M, __m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_permvarqi128_mask ((__v16qi) __B,
           (__v16qi) __A,
           (__v16qi)
           _mm_setzero_si128 (),
           (__mmask16) __M);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_permutexvar_epi8 (__m128i __W, __mmask16 __M, __m128i __A,
       __m128i __B)
{
  return (__m128i) __builtin_ia32_permvarqi128_mask ((__v16qi) __B,
           (__v16qi) __A,
           (__v16qi) __W,
           (__mmask16) __M);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_permutex2var_epi8 (__m256i __A, __m256i __I, __m256i __B)
{
  return (__m256i) __builtin_ia32_vpermt2varqi256_mask ((__v32qi) __I
                 ,
       (__v32qi) __A,
       (__v32qi) __B,
       (__mmask32) -1);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_permutex2var_epi8 (__m256i __A, __mmask32 __U,
    __m256i __I, __m256i __B)
{
  return (__m256i) __builtin_ia32_vpermt2varqi256_mask ((__v32qi) __I
                 ,
       (__v32qi) __A,
       (__v32qi) __B,
       (__mmask32)
       __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask2_permutex2var_epi8 (__m256i __A, __m256i __I,
     __mmask32 __U, __m256i __B)
{
  return (__m256i) __builtin_ia32_vpermi2varqi256_mask ((__v32qi) __A,
       (__v32qi) __I
                 ,
       (__v32qi) __B,
       (__mmask32)
       __U);
}
extern __inline __m256i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_permutex2var_epi8 (__mmask32 __U, __m256i __A,
     __m256i __I, __m256i __B)
{
  return (__m256i) __builtin_ia32_vpermt2varqi256_maskz ((__v32qi) __I
                  ,
        (__v32qi) __A,
        (__v32qi) __B,
        (__mmask32)
        __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_permutex2var_epi8 (__m128i __A, __m128i __I, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpermt2varqi128_mask ((__v16qi) __I
                 ,
       (__v16qi) __A,
       (__v16qi) __B,
       (__mmask16) -1);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_permutex2var_epi8 (__m128i __A, __mmask16 __U, __m128i __I,
        __m128i __B)
{
  return (__m128i) __builtin_ia32_vpermt2varqi128_mask ((__v16qi) __I
                 ,
       (__v16qi) __A,
       (__v16qi) __B,
       (__mmask16)
       __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask2_permutex2var_epi8 (__m128i __A, __m128i __I, __mmask16 __U,
         __m128i __B)
{
  return (__m128i) __builtin_ia32_vpermi2varqi128_mask ((__v16qi) __A,
       (__v16qi) __I
                 ,
       (__v16qi) __B,
       (__mmask16)
       __U);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_permutex2var_epi8 (__mmask16 __U, __m128i __A, __m128i __I,
         __m128i __B)
{
  return (__m128i) __builtin_ia32_vpermt2varqi128_maskz ((__v16qi) __I
                  ,
        (__v16qi) __A,
        (__v16qi) __B,
        (__mmask16)
        __U);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx5124fmaps")
extern __inline __m512
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_4fmadd_ps (__m512 __A, __m512 __B, __m512 __C,
    __m512 __D, __m512 __E, __m128 *__F)
{
  return (__m512) __builtin_ia32_4fmaddps ((__v16sf) __B,
        (__v16sf) __C,
        (__v16sf) __D,
        (__v16sf) __E,
        (__v16sf) __A,
        (const __v4sf *) __F);
}
extern __inline __m512
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_4fmadd_ps (__m512 __A, __mmask16 __U, __m512 __B,
         __m512 __C, __m512 __D, __m512 __E, __m128 *__F)
{
  return (__m512) __builtin_ia32_4fmaddps_mask ((__v16sf) __B,
      (__v16sf) __C,
      (__v16sf) __D,
      (__v16sf) __E,
      (__v16sf) __A,
      (const __v4sf *) __F,
      (__v16sf) __A,
      (__mmask16) __U);
}
extern __inline __m512
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_4fmadd_ps (__mmask16 __U,
   __m512 __A, __m512 __B, __m512 __C,
   __m512 __D, __m512 __E, __m128 *__F)
{
  return (__m512) __builtin_ia32_4fmaddps_mask ((__v16sf) __B,
      (__v16sf) __C,
      (__v16sf) __D,
      (__v16sf) __E,
      (__v16sf) __A,
      (const __v4sf *) __F,
      (__v16sf) _mm512_setzero_ps (),
      (__mmask16) __U);
}
extern __inline __m128
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_4fmadd_ss (__m128 __A, __m128 __B, __m128 __C,
        __m128 __D, __m128 __E, __m128 *__F)
{
  return (__m128) __builtin_ia32_4fmaddss ((__v4sf) __B,
        (__v4sf) __C,
        (__v4sf) __D,
        (__v4sf) __E,
        (__v4sf) __A,
        (const __v4sf *) __F);
}
extern __inline __m128
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_4fmadd_ss (__m128 __A, __mmask8 __U, __m128 __B, __m128 __C,
      __m128 __D, __m128 __E, __m128 *__F)
{
  return (__m128) __builtin_ia32_4fmaddss_mask ((__v4sf) __B,
      (__v4sf) __C,
      (__v4sf) __D,
      (__v4sf) __E,
      (__v4sf) __A,
      (const __v4sf *) __F,
      (__v4sf) __A,
      (__mmask8) __U);
}
extern __inline __m128
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_4fmadd_ss (__mmask8 __U, __m128 __A, __m128 __B, __m128 __C,
       __m128 __D, __m128 __E, __m128 *__F)
{
  return (__m128) __builtin_ia32_4fmaddss_mask ((__v4sf) __B,
      (__v4sf) __C,
      (__v4sf) __D,
      (__v4sf) __E,
      (__v4sf) __A,
      (const __v4sf *) __F,
      (__v4sf) _mm_setzero_ps (),
      (__mmask8) __U);
}
extern __inline __m512
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_4fnmadd_ps (__m512 __A, __m512 __B, __m512 __C,
     __m512 __D, __m512 __E, __m128 *__F)
{
  return (__m512) __builtin_ia32_4fnmaddps ((__v16sf) __B,
         (__v16sf) __C,
         (__v16sf) __D,
         (__v16sf) __E,
         (__v16sf) __A,
         (const __v4sf *) __F);
}
extern __inline __m512
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_4fnmadd_ps (__m512 __A, __mmask16 __U, __m512 __B,
   __m512 __C, __m512 __D, __m512 __E, __m128 *__F)
{
  return (__m512) __builtin_ia32_4fnmaddps_mask ((__v16sf) __B,
       (__v16sf) __C,
       (__v16sf) __D,
       (__v16sf) __E,
       (__v16sf) __A,
       (const __v4sf *) __F,
       (__v16sf) __A,
       (__mmask16) __U);
}
extern __inline __m512
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_4fnmadd_ps (__mmask16 __U,
    __m512 __A, __m512 __B, __m512 __C,
    __m512 __D, __m512 __E, __m128 *__F)
{
  return (__m512) __builtin_ia32_4fnmaddps_mask ((__v16sf) __B,
       (__v16sf) __C,
       (__v16sf) __D,
       (__v16sf) __E,
       (__v16sf) __A,
       (const __v4sf *) __F,
       (__v16sf) _mm512_setzero_ps (),
       (__mmask16) __U);
}
extern __inline __m128
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_4fnmadd_ss (__m128 __A, __m128 __B, __m128 __C,
  __m128 __D, __m128 __E, __m128 *__F)
{
  return (__m128) __builtin_ia32_4fnmaddss ((__v4sf) __B,
         (__v4sf) __C,
         (__v4sf) __D,
         (__v4sf) __E,
         (__v4sf) __A,
         (const __v4sf *) __F);
}
extern __inline __m128
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_4fnmadd_ss (__m128 __A, __mmask8 __U, __m128 __B, __m128 __C,
       __m128 __D, __m128 __E, __m128 *__F)
{
  return (__m128) __builtin_ia32_4fnmaddss_mask ((__v4sf) __B,
       (__v4sf) __C,
       (__v4sf) __D,
       (__v4sf) __E,
       (__v4sf) __A,
       (const __v4sf *) __F,
       (__v4sf) __A,
       (__mmask8) __U);
}
extern __inline __m128
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_4fnmadd_ss (__mmask8 __U, __m128 __A, __m128 __B, __m128 __C,
        __m128 __D, __m128 __E, __m128 *__F)
{
  return (__m128) __builtin_ia32_4fnmaddss_mask ((__v4sf) __B,
       (__v4sf) __C,
       (__v4sf) __D,
       (__v4sf) __E,
       (__v4sf) __A,
       (const __v4sf *) __F,
       (__v4sf) _mm_setzero_ps (),
       (__mmask8) __U);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx5124vnniw")
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_4dpwssd_epi32 (__m512i __A, __m512i __B, __m512i __C,
        __m512i __D, __m512i __E, __m128i *__F)
{
  return (__m512i) __builtin_ia32_vp4dpwssd ((__v16si) __B,
          (__v16si) __C,
          (__v16si) __D,
          (__v16si) __E,
          (__v16si) __A,
          (const __v4si *) __F);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_4dpwssd_epi32 (__m512i __A, __mmask16 __U, __m512i __B,
      __m512i __C, __m512i __D, __m512i __E,
      __m128i *__F)
{
  return (__m512i) __builtin_ia32_vp4dpwssd_mask ((__v16si) __B,
        (__v16si) __C,
        (__v16si) __D,
        (__v16si) __E,
        (__v16si) __A,
        (const __v4si *) __F,
        (__v16si) __A,
        (__mmask16) __U);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_4dpwssd_epi32 (__mmask16 __U, __m512i __A, __m512i __B,
       __m512i __C, __m512i __D, __m512i __E,
       __m128i *__F)
{
  return (__m512i) __builtin_ia32_vp4dpwssd_mask ((__v16si) __B,
        (__v16si) __C,
        (__v16si) __D,
        (__v16si) __E,
        (__v16si) __A,
        (const __v4si *) __F,
        (__v16si) _mm512_setzero_ps (),
        (__mmask16) __U);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_4dpwssds_epi32 (__m512i __A, __m512i __B, __m512i __C,
         __m512i __D, __m512i __E, __m128i *__F)
{
  return (__m512i) __builtin_ia32_vp4dpwssds ((__v16si) __B,
           (__v16si) __C,
           (__v16si) __D,
           (__v16si) __E,
           (__v16si) __A,
           (const __v4si *) __F);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_4dpwssds_epi32 (__m512i __A, __mmask16 __U, __m512i __B,
       __m512i __C, __m512i __D, __m512i __E,
       __m128i *__F)
{
  return (__m512i) __builtin_ia32_vp4dpwssds_mask ((__v16si) __B,
         (__v16si) __C,
         (__v16si) __D,
         (__v16si) __E,
         (__v16si) __A,
         (const __v4si *) __F,
         (__v16si) __A,
         (__mmask16) __U);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_4dpwssds_epi32 (__mmask16 __U, __m512i __A, __m512i __B,
        __m512i __C, __m512i __D, __m512i __E,
        __m128i *__F)
{
  return (__m512i) __builtin_ia32_vp4dpwssds_mask ((__v16si) __B,
         (__v16si) __C,
         (__v16si) __D,
         (__v16si) __E,
         (__v16si) __A,
         (const __v4si *) __F,
         (__v16si) _mm512_setzero_ps (),
         (__mmask16) __U);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx512vpopcntdq")
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_popcnt_epi32 (__m512i __A)
{
  return (__m512i) __builtin_ia32_vpopcountd_v16si ((__v16si) __A);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_popcnt_epi32 (__m512i __W, __mmask16 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_vpopcountd_v16si_mask ((__v16si) __A,
        (__v16si) __W,
        (__mmask16) __U);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_popcnt_epi32 (__mmask16 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_vpopcountd_v16si_mask ((__v16si) __A,
        (__v16si)
        _mm512_setzero_si512 (),
        (__mmask16) __U);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_popcnt_epi64 (__m512i __A)
{
  return (__m512i) __builtin_ia32_vpopcountq_v8di ((__v8di) __A);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_popcnt_epi64 (__m512i __W, __mmask8 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_vpopcountq_v8di_mask ((__v8di) __A,
       (__v8di) __W,
       (__mmask8) __U);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_popcnt_epi64 (__mmask8 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_vpopcountq_v8di_mask ((__v8di) __A,
       (__v8di)
       _mm512_setzero_si512 (),
       (__mmask8) __U);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx512vbmi2")
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_shrdv_epi16 (__m512i __A, __m512i __B, __m512i __C)
{
  return (__m512i) __builtin_ia32_vpshrdv_v32hi ((__v32hi)__A, (__v32hi) __B,
        (__v32hi) __C);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_shrdv_epi32 (__m512i __A, __m512i __B, __m512i __C)
{
  return (__m512i) __builtin_ia32_vpshrdv_v16si ((__v16si)__A, (__v16si) __B,
        (__v16si) __C);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_shrdv_epi32 (__m512i __A, __mmask16 __B, __m512i __C, __m512i __D)
{
  return (__m512i)__builtin_ia32_vpshrdv_v16si_mask ((__v16si)__A,
    (__v16si) __C, (__v16si) __D, (__mmask16)__B);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_shrdv_epi32 (__mmask16 __A, __m512i __B, __m512i __C, __m512i __D)
{
  return (__m512i)__builtin_ia32_vpshrdv_v16si_maskz ((__v16si)__B,
    (__v16si) __C, (__v16si) __D, (__mmask16)__A);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_shrdv_epi64 (__m512i __A, __m512i __B, __m512i __C)
{
  return (__m512i) __builtin_ia32_vpshrdv_v8di ((__v8di)__A, (__v8di) __B,
        (__v8di) __C);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_shrdv_epi64 (__m512i __A, __mmask8 __B, __m512i __C, __m512i __D)
{
  return (__m512i)__builtin_ia32_vpshrdv_v8di_mask ((__v8di)__A, (__v8di) __C,
      (__v8di) __D, (__mmask8)__B);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_shrdv_epi64 (__mmask8 __A, __m512i __B, __m512i __C, __m512i __D)
{
  return (__m512i)__builtin_ia32_vpshrdv_v8di_maskz ((__v8di)__B, (__v8di) __C,
       (__v8di) __D, (__mmask8)__A);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_shldv_epi16 (__m512i __A, __m512i __B, __m512i __C)
{
  return (__m512i) __builtin_ia32_vpshldv_v32hi ((__v32hi)__A, (__v32hi) __B,
        (__v32hi) __C);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_shldv_epi32 (__m512i __A, __m512i __B, __m512i __C)
{
  return (__m512i) __builtin_ia32_vpshldv_v16si ((__v16si)__A, (__v16si) __B,
        (__v16si) __C);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_shldv_epi32 (__m512i __A, __mmask16 __B, __m512i __C, __m512i __D)
{
  return (__m512i)__builtin_ia32_vpshldv_v16si_mask ((__v16si)__A,
    (__v16si) __C, (__v16si) __D, (__mmask16)__B);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_shldv_epi32 (__mmask16 __A, __m512i __B, __m512i __C, __m512i __D)
{
  return (__m512i)__builtin_ia32_vpshldv_v16si_maskz ((__v16si)__B,
    (__v16si) __C, (__v16si) __D, (__mmask16)__A);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_shldv_epi64 (__m512i __A, __m512i __B, __m512i __C)
{
  return (__m512i) __builtin_ia32_vpshldv_v8di ((__v8di)__A, (__v8di) __B,
        (__v8di) __C);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_shldv_epi64 (__m512i __A, __mmask8 __B, __m512i __C, __m512i __D)
{
  return (__m512i)__builtin_ia32_vpshldv_v8di_mask ((__v8di)__A, (__v8di) __C,
      (__v8di) __D, (__mmask8)__B);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_shldv_epi64 (__mmask8 __A, __m512i __B, __m512i __C, __m512i __D)
{
  return (__m512i)__builtin_ia32_vpshldv_v8di_maskz ((__v8di)__B, (__v8di) __C,
      (__v8di) __D, (__mmask8)__A);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx512vbmi2,avx512bw")
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_compress_epi8 (__m512i __A, __mmask64 __B, __m512i __C)
{
  return (__m512i) __builtin_ia32_compressqi512_mask ((__v64qi)__C,
      (__v64qi)__A, (__mmask64)__B);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_compress_epi8 (__mmask64 __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_compressqi512_mask ((__v64qi)__B,
   (__v64qi)_mm512_setzero_si512 (), (__mmask64)__A);
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_compressstoreu_epi8 (void * __A, __mmask64 __B, __m512i __C)
{
  __builtin_ia32_compressstoreuqi512_mask ((__v64qi *) __A, (__v64qi) __C,
       (__mmask64) __B);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_compress_epi16 (__m512i __A, __mmask32 __B, __m512i __C)
{
  return (__m512i) __builtin_ia32_compresshi512_mask ((__v32hi)__C,
      (__v32hi)__A, (__mmask32)__B);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_compress_epi16 (__mmask32 __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_compresshi512_mask ((__v32hi)__B,
   (__v32hi)_mm512_setzero_si512 (), (__mmask32)__A);
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_compressstoreu_epi16 (void * __A, __mmask32 __B, __m512i __C)
{
  __builtin_ia32_compressstoreuhi512_mask ((__v32hi *) __A, (__v32hi) __C,
       (__mmask32) __B);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_expand_epi8 (__m512i __A, __mmask64 __B, __m512i __C)
{
  return (__m512i) __builtin_ia32_expandqi512_mask ((__v64qi) __C,
          (__v64qi) __A,
          (__mmask64) __B);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_expand_epi8 (__mmask64 __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_expandqi512_maskz ((__v64qi) __B,
   (__v64qi) _mm512_setzero_si512 (), (__mmask64) __A);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_expandloadu_epi8 (__m512i __A, __mmask64 __B, const void * __C)
{
  return (__m512i) __builtin_ia32_expandloadqi512_mask ((const __v64qi *) __C,
     (__v64qi) __A, (__mmask64) __B);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_expandloadu_epi8 (__mmask64 __A, const void * __B)
{
  return (__m512i) __builtin_ia32_expandloadqi512_maskz ((const __v64qi *) __B,
   (__v64qi) _mm512_setzero_si512 (), (__mmask64) __A);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_expand_epi16 (__m512i __A, __mmask32 __B, __m512i __C)
{
  return (__m512i) __builtin_ia32_expandhi512_mask ((__v32hi) __C,
          (__v32hi) __A,
          (__mmask32) __B);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_expand_epi16 (__mmask32 __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_expandhi512_maskz ((__v32hi) __B,
   (__v32hi) _mm512_setzero_si512 (), (__mmask32) __A);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_expandloadu_epi16 (__m512i __A, __mmask32 __B, const void * __C)
{
  return (__m512i) __builtin_ia32_expandloadhi512_mask ((const __v32hi *) __C,
     (__v32hi) __A, (__mmask32) __B);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_expandloadu_epi16 (__mmask32 __A, const void * __B)
{
  return (__m512i) __builtin_ia32_expandloadhi512_maskz ((const __v32hi *) __B,
   (__v32hi) _mm512_setzero_si512 (), (__mmask32) __A);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_shrdv_epi16 (__m512i __A, __mmask32 __B, __m512i __C, __m512i __D)
{
  return (__m512i)__builtin_ia32_vpshrdv_v32hi_mask ((__v32hi)__A,
    (__v32hi) __C, (__v32hi) __D, (__mmask32)__B);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_shrdv_epi16 (__mmask32 __A, __m512i __B, __m512i __C, __m512i __D)
{
  return (__m512i)__builtin_ia32_vpshrdv_v32hi_maskz ((__v32hi)__B,
    (__v32hi) __C, (__v32hi) __D, (__mmask32)__A);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_shldv_epi16 (__m512i __A, __mmask32 __B, __m512i __C, __m512i __D)
{
  return (__m512i)__builtin_ia32_vpshldv_v32hi_mask ((__v32hi)__A,
    (__v32hi) __C, (__v32hi) __D, (__mmask32)__B);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_shldv_epi16 (__mmask32 __A, __m512i __B, __m512i __C, __m512i __D)
{
  return (__m512i)__builtin_ia32_vpshldv_v32hi_maskz ((__v32hi)__B,
    (__v32hi) __C, (__v32hi) __D, (__mmask32)__A);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx512vbmi2,avx512vl")
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_compress_epi8 (__m128i __A, __mmask16 __B, __m128i __C)
{
  return (__m128i) __builtin_ia32_compressqi128_mask ((__v16qi)__C,
      (__v16qi)__A, (__mmask16)__B);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_compress_epi8 (__mmask16 __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_compressqi128_mask ((__v16qi) __B,
   (__v16qi) _mm_setzero_si128 (), (__mmask16) __A);
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_compressstoreu_epi16 (void * __A, __mmask16 __B, __m256i __C)
{
  __builtin_ia32_compressstoreuhi256_mask ((__v16hi *) __A, (__v16hi) __C,
       (__mmask16) __B);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_compress_epi16 (__m128i __A, __mmask8 __B, __m128i __C)
{
  return (__m128i) __builtin_ia32_compresshi128_mask ((__v8hi)__C, (__v8hi)__A,
        (__mmask8)__B);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_compress_epi16 (__mmask8 __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_compresshi128_mask ((__v8hi) __B,
    (__v8hi) _mm_setzero_si128 (), (__mmask8) __A);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_compress_epi16 (__m256i __A, __mmask16 __B, __m256i __C)
{
  return (__m256i) __builtin_ia32_compresshi256_mask ((__v16hi)__C,
      (__v16hi)__A, (__mmask16)__B);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_compress_epi16 (__mmask16 __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_compresshi256_mask ((__v16hi) __B,
   (__v16hi) _mm256_setzero_si256 (), (__mmask16) __A);
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_compressstoreu_epi8 (void * __A, __mmask16 __B, __m128i __C)
{
  __builtin_ia32_compressstoreuqi128_mask ((__v16qi *) __A, (__v16qi) __C,
       (__mmask16) __B);
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_compressstoreu_epi16 (void * __A, __mmask8 __B, __m128i __C)
{
  __builtin_ia32_compressstoreuhi128_mask ((__v8hi *) __A, (__v8hi) __C,
       (__mmask8) __B);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_expand_epi8 (__m128i __A, __mmask16 __B, __m128i __C)
{
  return (__m128i) __builtin_ia32_expandqi128_mask ((__v16qi) __C,
          (__v16qi) __A,
          (__mmask16) __B);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_expand_epi8 (__mmask16 __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_expandqi128_maskz ((__v16qi) __B,
   (__v16qi) _mm_setzero_si128 (), (__mmask16) __A);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_expandloadu_epi8 (__m128i __A, __mmask16 __B, const void * __C)
{
  return (__m128i) __builtin_ia32_expandloadqi128_mask ((const __v16qi *) __C,
     (__v16qi) __A, (__mmask16) __B);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_expandloadu_epi8 (__mmask16 __A, const void * __B)
{
  return (__m128i) __builtin_ia32_expandloadqi128_maskz ((const __v16qi *) __B,
   (__v16qi) _mm_setzero_si128 (), (__mmask16) __A);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_expand_epi16 (__m128i __A, __mmask8 __B, __m128i __C)
{
  return (__m128i) __builtin_ia32_expandhi128_mask ((__v8hi) __C,
          (__v8hi) __A,
          (__mmask8) __B);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_expand_epi16 (__mmask8 __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_expandhi128_maskz ((__v8hi) __B,
    (__v8hi) _mm_setzero_si128 (), (__mmask8) __A);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_expandloadu_epi16 (__m128i __A, __mmask8 __B, const void * __C)
{
  return (__m128i) __builtin_ia32_expandloadhi128_mask ((const __v8hi *) __C,
      (__v8hi) __A, (__mmask8) __B);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_expandloadu_epi16 (__mmask8 __A, const void * __B)
{
  return (__m128i) __builtin_ia32_expandloadhi128_maskz ((const __v8hi *) __B,
    (__v8hi) _mm_setzero_si128 (), (__mmask8) __A);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_expand_epi16 (__m256i __A, __mmask16 __B, __m256i __C)
{
  return (__m256i) __builtin_ia32_expandhi256_mask ((__v16hi) __C,
          (__v16hi) __A,
          (__mmask16) __B);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_expand_epi16 (__mmask16 __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_expandhi256_maskz ((__v16hi) __B,
   (__v16hi) _mm256_setzero_si256 (), (__mmask16) __A);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_expandloadu_epi16 (__m256i __A, __mmask16 __B, const void * __C)
{
  return (__m256i) __builtin_ia32_expandloadhi256_mask ((const __v16hi *) __C,
     (__v16hi) __A, (__mmask16) __B);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_expandloadu_epi16 (__mmask16 __A, const void * __B)
{
  return (__m256i) __builtin_ia32_expandloadhi256_maskz ((const __v16hi *) __B,
   (__v16hi) _mm256_setzero_si256 (), (__mmask16) __A);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_shrdv_epi16 (__m256i __A, __m256i __B, __m256i __C)
{
  return (__m256i) __builtin_ia32_vpshrdv_v16hi ((__v16hi)__A, (__v16hi) __B,
        (__v16hi) __C);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_shrdv_epi16 (__m256i __A, __mmask16 __B, __m256i __C, __m256i __D)
{
  return (__m256i)__builtin_ia32_vpshrdv_v16hi_mask ((__v16hi)__A,
    (__v16hi) __C, (__v16hi) __D, (__mmask16)__B);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_shrdv_epi16 (__mmask16 __A, __m256i __B, __m256i __C, __m256i __D)
{
  return (__m256i)__builtin_ia32_vpshrdv_v16hi_maskz ((__v16hi)__B,
    (__v16hi) __C, (__v16hi) __D, (__mmask16)__A);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_shrdv_epi32 (__m256i __A, __m256i __B, __m256i __C)
{
  return (__m256i) __builtin_ia32_vpshrdv_v8si ((__v8si)__A, (__v8si) __B,
        (__v8si) __C);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_shrdv_epi32 (__m256i __A, __mmask8 __B, __m256i __C, __m256i __D)
{
  return (__m256i)__builtin_ia32_vpshrdv_v8si_mask ((__v8si)__A, (__v8si) __C,
      (__v8si) __D, (__mmask8)__B);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_shrdv_epi32 (__mmask8 __A, __m256i __B, __m256i __C, __m256i __D)
{
  return (__m256i)__builtin_ia32_vpshrdv_v8si_maskz ((__v8si)__B, (__v8si) __C,
       (__v8si) __D, (__mmask8)__A);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_shrdv_epi64 (__m256i __A, __m256i __B, __m256i __C)
{
  return (__m256i) __builtin_ia32_vpshrdv_v4di ((__v4di)__A, (__v4di) __B,
        (__v4di) __C);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_shrdv_epi64 (__m256i __A, __mmask8 __B, __m256i __C, __m256i __D)
{
  return (__m256i)__builtin_ia32_vpshrdv_v4di_mask ((__v4di)__A, (__v4di) __C,
      (__v4di) __D, (__mmask8)__B);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_shrdv_epi64 (__mmask8 __A, __m256i __B, __m256i __C, __m256i __D)
{
  return (__m256i)__builtin_ia32_vpshrdv_v4di_maskz ((__v4di)__B, (__v4di) __C,
       (__v4di) __D, (__mmask8)__A);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_shrdv_epi16 (__m128i __A, __m128i __B, __m128i __C)
{
  return (__m128i) __builtin_ia32_vpshrdv_v8hi ((__v8hi)__A, (__v8hi) __B,
        (__v8hi) __C);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_shrdv_epi16 (__m128i __A, __mmask8 __B, __m128i __C, __m128i __D)
{
  return (__m128i)__builtin_ia32_vpshrdv_v8hi_mask ((__v8hi)__A, (__v8hi) __C,
      (__v8hi) __D, (__mmask8)__B);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_shrdv_epi16 (__mmask8 __A, __m128i __B, __m128i __C, __m128i __D)
{
  return (__m128i)__builtin_ia32_vpshrdv_v8hi_maskz ((__v8hi)__B, (__v8hi) __C,
       (__v8hi) __D, (__mmask8)__A);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_shrdv_epi32 (__m128i __A, __m128i __B, __m128i __C)
{
  return (__m128i) __builtin_ia32_vpshrdv_v4si ((__v4si)__A, (__v4si) __B,
        (__v4si) __C);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_shrdv_epi32 (__m128i __A, __mmask8 __B, __m128i __C, __m128i __D)
{
  return (__m128i)__builtin_ia32_vpshrdv_v4si_mask ((__v4si)__A, (__v4si) __C,
      (__v4si) __D, (__mmask8)__B);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_shrdv_epi32 (__mmask8 __A, __m128i __B, __m128i __C, __m128i __D)
{
  return (__m128i)__builtin_ia32_vpshrdv_v4si_maskz ((__v4si)__B, (__v4si) __C,
       (__v4si) __D, (__mmask8)__A);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_shrdv_epi64 (__m128i __A, __m128i __B, __m128i __C)
{
  return (__m128i) __builtin_ia32_vpshrdv_v2di ((__v2di)__A, (__v2di) __B,
        (__v2di) __C);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_shrdv_epi64 (__m128i __A, __mmask8 __B, __m128i __C, __m128i __D)
{
  return (__m128i)__builtin_ia32_vpshrdv_v2di_mask ((__v2di)__A, (__v2di) __C,
      (__v2di) __D, (__mmask8)__B);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_shrdv_epi64 (__mmask8 __A, __m128i __B, __m128i __C, __m128i __D)
{
  return (__m128i)__builtin_ia32_vpshrdv_v2di_maskz ((__v2di)__B, (__v2di) __C,
       (__v2di) __D, (__mmask8)__A);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_shldv_epi16 (__m256i __A, __m256i __B, __m256i __C)
{
  return (__m256i) __builtin_ia32_vpshldv_v16hi ((__v16hi)__A, (__v16hi) __B,
        (__v16hi) __C);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_shldv_epi16 (__m256i __A, __mmask16 __B, __m256i __C, __m256i __D)
{
  return (__m256i)__builtin_ia32_vpshldv_v16hi_mask ((__v16hi)__A,
    (__v16hi) __C, (__v16hi) __D, (__mmask16)__B);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_shldv_epi16 (__mmask16 __A, __m256i __B, __m256i __C, __m256i __D)
{
  return (__m256i)__builtin_ia32_vpshldv_v16hi_maskz ((__v16hi)__B,
    (__v16hi) __C, (__v16hi) __D, (__mmask16)__A);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_shldv_epi32 (__m256i __A, __m256i __B, __m256i __C)
{
  return (__m256i) __builtin_ia32_vpshldv_v8si ((__v8si)__A, (__v8si) __B,
        (__v8si) __C);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_shldv_epi32 (__m256i __A, __mmask8 __B, __m256i __C, __m256i __D)
{
  return (__m256i)__builtin_ia32_vpshldv_v8si_mask ((__v8si)__A, (__v8si) __C,
      (__v8si) __D, (__mmask8)__B) ;
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_shldv_epi32 (__mmask8 __A, __m256i __B, __m256i __C, __m256i __D)
{
  return (__m256i)__builtin_ia32_vpshldv_v8si_maskz ((__v8si)__B, (__v8si) __C,
      (__v8si) __D, (__mmask8)__A);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_shldv_epi64 (__m256i __A, __m256i __B, __m256i __C)
{
  return (__m256i) __builtin_ia32_vpshldv_v4di ((__v4di)__A, (__v4di) __B,
        (__v4di) __C);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_shldv_epi64 (__m256i __A, __mmask8 __B, __m256i __C, __m256i __D)
{
  return (__m256i)__builtin_ia32_vpshldv_v4di_mask ((__v4di)__A, (__v4di) __C,
      (__v4di) __D, (__mmask8)__B);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_shldv_epi64 (__mmask8 __A, __m256i __B, __m256i __C, __m256i __D)
{
  return (__m256i)__builtin_ia32_vpshldv_v4di_maskz ((__v4di)__B, (__v4di) __C,
       (__v4di) __D, (__mmask8)__A);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_shldv_epi16 (__m128i __A, __m128i __B, __m128i __C)
{
  return (__m128i) __builtin_ia32_vpshldv_v8hi ((__v8hi)__A, (__v8hi) __B,
        (__v8hi) __C);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_shldv_epi16 (__m128i __A, __mmask8 __B, __m128i __C, __m128i __D)
{
  return (__m128i)__builtin_ia32_vpshldv_v8hi_mask ((__v8hi)__A, (__v8hi) __C,
      (__v8hi) __D, (__mmask8)__B);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_shldv_epi16 (__mmask8 __A, __m128i __B, __m128i __C, __m128i __D)
{
  return (__m128i)__builtin_ia32_vpshldv_v8hi_maskz ((__v8hi)__B, (__v8hi) __C,
       (__v8hi) __D, (__mmask8)__A);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_shldv_epi32 (__m128i __A, __m128i __B, __m128i __C)
{
  return (__m128i) __builtin_ia32_vpshldv_v4si ((__v4si)__A, (__v4si) __B,
        (__v4si) __C);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_shldv_epi32 (__m128i __A, __mmask8 __B, __m128i __C, __m128i __D)
{
  return (__m128i)__builtin_ia32_vpshldv_v4si_mask ((__v4si)__A, (__v4si) __C,
      (__v4si) __D, (__mmask8)__B);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_shldv_epi32 (__mmask8 __A, __m128i __B, __m128i __C, __m128i __D)
{
  return (__m128i)__builtin_ia32_vpshldv_v4si_maskz ((__v4si)__B, (__v4si) __C,
       (__v4si) __D, (__mmask8)__A);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_shldv_epi64 (__m128i __A, __m128i __B, __m128i __C)
{
  return (__m128i) __builtin_ia32_vpshldv_v2di ((__v2di)__A, (__v2di) __B,
        (__v2di) __C);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_shldv_epi64 (__m128i __A, __mmask8 __B, __m128i __C, __m128i __D)
{
  return (__m128i)__builtin_ia32_vpshldv_v2di_mask ((__v2di)__A, (__v2di) __C,
      (__v2di) __D, (__mmask8)__B);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_shldv_epi64 (__mmask8 __A, __m128i __B, __m128i __C, __m128i __D)
{
  return (__m128i)__builtin_ia32_vpshldv_v2di_maskz ((__v2di)__B, (__v2di) __C,
      (__v2di) __D, (__mmask8)__A);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx512vbmi2,avx512vl,avx512bw")
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_compress_epi8 (__m256i __A, __mmask32 __B, __m256i __C)
{
  return (__m256i) __builtin_ia32_compressqi256_mask ((__v32qi)__C,
      (__v32qi)__A, (__mmask32)__B);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_compress_epi8 (__mmask32 __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_compressqi256_mask ((__v32qi) __B,
   (__v32qi) _mm256_setzero_si256 (), (__mmask32) __A);
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_compressstoreu_epi8 (void * __A, __mmask32 __B, __m256i __C)
{
  __builtin_ia32_compressstoreuqi256_mask ((__v32qi *) __A, (__v32qi) __C,
       (__mmask32) __B);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_expand_epi8 (__m256i __A, __mmask32 __B, __m256i __C)
{
  return (__m256i) __builtin_ia32_expandqi256_mask ((__v32qi) __C,
          (__v32qi) __A,
          (__mmask32) __B);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_expand_epi8 (__mmask32 __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_expandqi256_maskz ((__v32qi) __B,
   (__v32qi) _mm256_setzero_si256 (), (__mmask32) __A);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_expandloadu_epi8 (__m256i __A, __mmask32 __B, const void * __C)
{
  return (__m256i) __builtin_ia32_expandloadqi256_mask ((const __v32qi *) __C,
     (__v32qi) __A, (__mmask32) __B);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_expandloadu_epi8 (__mmask32 __A, const void * __B)
{
  return (__m256i) __builtin_ia32_expandloadqi256_maskz ((const __v32qi *) __B,
   (__v32qi) _mm256_setzero_si256 (), (__mmask32) __A);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx512vnni")
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_dpbusd_epi32 (__m512i __A, __m512i __B, __m512i __C)
{
  return (__m512i) __builtin_ia32_vpdpbusd_v16si ((__v16si)__A, (__v16si) __B,
        (__v16si) __C);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_dpbusd_epi32 (__m512i __A, __mmask16 __B, __m512i __C, __m512i __D)
{
  return (__m512i)__builtin_ia32_vpdpbusd_v16si_mask ((__v16si)__A,
    (__v16si) __C, (__v16si) __D, (__mmask16)__B);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_dpbusd_epi32 (__mmask16 __A, __m512i __B, __m512i __C,
       __m512i __D)
{
  return (__m512i)__builtin_ia32_vpdpbusd_v16si_maskz ((__v16si)__B,
    (__v16si) __C, (__v16si) __D, (__mmask16)__A);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_dpbusds_epi32 (__m512i __A, __m512i __B, __m512i __C)
{
  return (__m512i) __builtin_ia32_vpdpbusds_v16si ((__v16si)__A, (__v16si) __B,
        (__v16si) __C);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_dpbusds_epi32 (__m512i __A, __mmask16 __B, __m512i __C,
       __m512i __D)
{
  return (__m512i)__builtin_ia32_vpdpbusds_v16si_mask ((__v16si)__A,
    (__v16si) __C, (__v16si) __D, (__mmask16)__B);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_dpbusds_epi32 (__mmask16 __A, __m512i __B, __m512i __C,
       __m512i __D)
{
  return (__m512i)__builtin_ia32_vpdpbusds_v16si_maskz ((__v16si)__B,
    (__v16si) __C, (__v16si) __D, (__mmask16)__A);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_dpwssd_epi32 (__m512i __A, __m512i __B, __m512i __C)
{
  return (__m512i) __builtin_ia32_vpdpwssd_v16si ((__v16si)__A, (__v16si) __B,
        (__v16si) __C);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_dpwssd_epi32 (__m512i __A, __mmask16 __B, __m512i __C, __m512i __D)
{
  return (__m512i)__builtin_ia32_vpdpwssd_v16si_mask ((__v16si)__A,
    (__v16si) __C, (__v16si) __D, (__mmask16)__B);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_dpwssd_epi32 (__mmask16 __A, __m512i __B, __m512i __C,
       __m512i __D)
{
  return (__m512i)__builtin_ia32_vpdpwssd_v16si_maskz ((__v16si)__B,
    (__v16si) __C, (__v16si) __D, (__mmask16)__A);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_dpwssds_epi32 (__m512i __A, __m512i __B, __m512i __C)
{
  return (__m512i) __builtin_ia32_vpdpwssds_v16si ((__v16si)__A, (__v16si) __B,
        (__v16si) __C);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_dpwssds_epi32 (__m512i __A, __mmask16 __B, __m512i __C,
       __m512i __D)
{
  return (__m512i)__builtin_ia32_vpdpwssds_v16si_mask ((__v16si)__A,
    (__v16si) __C, (__v16si) __D, (__mmask16)__B);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_dpwssds_epi32 (__mmask16 __A, __m512i __B, __m512i __C,
       __m512i __D)
{
  return (__m512i)__builtin_ia32_vpdpwssds_v16si_maskz ((__v16si)__B,
    (__v16si) __C, (__v16si) __D, (__mmask16)__A);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx512vnni,avx512vl")
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_dpbusd_epi32 (__m256i __A, __mmask8 __B, __m256i __C, __m256i __D)
{
  return (__m256i)__builtin_ia32_vpdpbusd_v8si_mask ((__v8si)__A, (__v8si) __C,
      (__v8si) __D, (__mmask8)__B);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_dpbusd_epi32 (__mmask8 __A, __m256i __B, __m256i __C, __m256i __D)
{
  return (__m256i)__builtin_ia32_vpdpbusd_v8si_maskz ((__v8si)__B,
    (__v8si) __C, (__v8si) __D, (__mmask8)__A);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_dpbusd_epi32 (__m128i __A, __mmask8 __B, __m128i __C, __m128i __D)
{
  return (__m128i)__builtin_ia32_vpdpbusd_v4si_mask ((__v4si)__A, (__v4si) __C,
      (__v4si) __D, (__mmask8)__B);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_dpbusd_epi32 (__mmask8 __A, __m128i __B, __m128i __C, __m128i __D)
{
  return (__m128i)__builtin_ia32_vpdpbusd_v4si_maskz ((__v4si)__B,
    (__v4si) __C, (__v4si) __D, (__mmask8)__A);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_dpbusds_epi32 (__m256i __A, __mmask8 __B, __m256i __C, __m256i __D)
{
  return (__m256i)__builtin_ia32_vpdpbusds_v8si_mask ((__v8si)__A,
    (__v8si) __C, (__v8si) __D, (__mmask8)__B);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_dpbusds_epi32 (__mmask8 __A, __m256i __B, __m256i __C,
        __m256i __D)
{
  return (__m256i)__builtin_ia32_vpdpbusds_v8si_maskz ((__v8si)__B,
    (__v8si) __C, (__v8si) __D, (__mmask8)__A);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_dpbusds_epi32 (__m128i __A, __mmask8 __B, __m128i __C, __m128i __D)
{
  return (__m128i)__builtin_ia32_vpdpbusds_v4si_mask ((__v4si)__A,
    (__v4si) __C, (__v4si) __D, (__mmask8)__B);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_dpbusds_epi32 (__mmask8 __A, __m128i __B, __m128i __C, __m128i __D)
{
  return (__m128i)__builtin_ia32_vpdpbusds_v4si_maskz ((__v4si)__B,
    (__v4si) __C, (__v4si) __D, (__mmask8)__A);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_dpwssd_epi32 (__m256i __A, __mmask8 __B, __m256i __C, __m256i __D)
{
  return (__m256i)__builtin_ia32_vpdpwssd_v8si_mask ((__v8si)__A, (__v8si) __C,
      (__v8si) __D, (__mmask8)__B);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_dpwssd_epi32 (__mmask8 __A, __m256i __B, __m256i __C, __m256i __D)
{
  return (__m256i)__builtin_ia32_vpdpwssd_v8si_maskz ((__v8si)__B,
    (__v8si) __C, (__v8si) __D, (__mmask8)__A);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_dpwssd_epi32 (__m128i __A, __mmask8 __B, __m128i __C, __m128i __D)
{
  return (__m128i)__builtin_ia32_vpdpwssd_v4si_mask ((__v4si)__A, (__v4si) __C,
      (__v4si) __D, (__mmask8)__B);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_dpwssd_epi32 (__mmask8 __A, __m128i __B, __m128i __C, __m128i __D)
{
  return (__m128i)__builtin_ia32_vpdpwssd_v4si_maskz ((__v4si)__B,
    (__v4si) __C, (__v4si) __D, (__mmask8)__A);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_dpwssds_epi32 (__m256i __A, __mmask8 __B, __m256i __C, __m256i __D)
{
  return (__m256i)__builtin_ia32_vpdpwssds_v8si_mask ((__v8si)__A,
    (__v8si) __C, (__v8si) __D, (__mmask8)__B);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_dpwssds_epi32 (__mmask8 __A, __m256i __B, __m256i __C,
       __m256i __D)
{
  return (__m256i)__builtin_ia32_vpdpwssds_v8si_maskz ((__v8si)__B,
    (__v8si) __C, (__v8si) __D, (__mmask8)__A);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_dpwssds_epi32 (__m128i __A, __mmask8 __B, __m128i __C, __m128i __D)
{
  return (__m128i)__builtin_ia32_vpdpwssds_v4si_mask ((__v4si)__A,
    (__v4si) __C, (__v4si) __D, (__mmask8)__B);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_dpwssds_epi32 (__mmask8 __A, __m128i __B, __m128i __C, __m128i __D)
{
  return (__m128i)__builtin_ia32_vpdpwssds_v4si_maskz ((__v4si)__B,
    (__v4si) __C, (__v4si) __D, (__mmask8)__A);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx512vpopcntdq,avx512vl")
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_popcnt_epi32 (__m128i __A)
{
  return (__m128i) __builtin_ia32_vpopcountd_v4si ((__v4si) __A);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_popcnt_epi32 (__m128i __W, __mmask16 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_vpopcountd_v4si_mask ((__v4si) __A,
        (__v4si) __W,
        (__mmask16) __U);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_popcnt_epi32 (__mmask16 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_vpopcountd_v4si_mask ((__v4si) __A,
        (__v4si)
        _mm_setzero_si128 (),
        (__mmask16) __U);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_popcnt_epi32 (__m256i __A)
{
  return (__m256i) __builtin_ia32_vpopcountd_v8si ((__v8si) __A);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_popcnt_epi32 (__m256i __W, __mmask16 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_vpopcountd_v8si_mask ((__v8si) __A,
        (__v8si) __W,
        (__mmask16) __U);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_popcnt_epi32 (__mmask16 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_vpopcountd_v8si_mask ((__v8si) __A,
      (__v8si)
      _mm256_setzero_si256 (),
      (__mmask16) __U);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_popcnt_epi64 (__m128i __A)
{
  return (__m128i) __builtin_ia32_vpopcountq_v2di ((__v2di) __A);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_popcnt_epi64 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_vpopcountq_v2di_mask ((__v2di) __A,
       (__v2di) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_popcnt_epi64 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_vpopcountq_v2di_mask ((__v2di) __A,
       (__v2di)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_popcnt_epi64 (__m256i __A)
{
  return (__m256i) __builtin_ia32_vpopcountq_v4di ((__v4di) __A);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_popcnt_epi64 (__m256i __W, __mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_vpopcountq_v4di_mask ((__v4di) __A,
       (__v4di) __W,
       (__mmask8) __U);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_popcnt_epi64 (__mmask8 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_vpopcountq_v4di_mask ((__v4di) __A,
      (__v4di)
      _mm256_setzero_si256 (),
      (__mmask8) __U);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx512bitalg")
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_popcnt_epi8 (__m512i __A)
{
  return (__m512i) __builtin_ia32_vpopcountb_v64qi ((__v64qi) __A);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_popcnt_epi16 (__m512i __A)
{
  return (__m512i) __builtin_ia32_vpopcountw_v32hi ((__v32hi) __A);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx512bitalg,avx512bw")
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_popcnt_epi8 (__m512i __W, __mmask64 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_vpopcountb_v64qi_mask ((__v64qi) __A,
        (__v64qi) __W,
        (__mmask64) __U);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_popcnt_epi8 (__mmask64 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_vpopcountb_v64qi_mask ((__v64qi) __A,
      (__v64qi)
      _mm512_setzero_si512 (),
      (__mmask64) __U);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_popcnt_epi16 (__m512i __W, __mmask32 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_vpopcountw_v32hi_mask ((__v32hi) __A,
       (__v32hi) __W,
       (__mmask32) __U);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_popcnt_epi16 (__mmask32 __U, __m512i __A)
{
  return (__m512i) __builtin_ia32_vpopcountw_v32hi_mask ((__v32hi) __A,
      (__v32hi)
      _mm512_setzero_si512 (),
      (__mmask32) __U);
}
extern __inline __mmask64
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_bitshuffle_epi64_mask (__m512i __A, __m512i __B)
{
  return (__mmask64) __builtin_ia32_vpshufbitqmb512_mask ((__v64qi) __A,
       (__v64qi) __B,
       (__mmask64) -1);
}
extern __inline __mmask64
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_bitshuffle_epi64_mask (__mmask64 __M, __m512i __A, __m512i __B)
{
  return (__mmask64) __builtin_ia32_vpshufbitqmb512_mask ((__v64qi) __A,
       (__v64qi) __B,
       (__mmask64) __M);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx512bitalg,avx512vl,avx512bw")
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_popcnt_epi8 (__m256i __W, __mmask32 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_vpopcountb_v32qi_mask ((__v32qi) __A,
        (__v32qi) __W,
        (__mmask32) __U);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_popcnt_epi8 (__mmask32 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_vpopcountb_v32qi_mask ((__v32qi) __A,
      (__v32qi)
       _mm256_setzero_si256 (),
      (__mmask32) __U);
}
extern __inline __mmask32
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_bitshuffle_epi64_mask (__m256i __A, __m256i __B)
{
  return (__mmask32) __builtin_ia32_vpshufbitqmb256_mask ((__v32qi) __A,
       (__v32qi) __B,
       (__mmask32) -1);
}
extern __inline __mmask32
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_bitshuffle_epi64_mask (__mmask32 __M, __m256i __A, __m256i __B)
{
  return (__mmask32) __builtin_ia32_vpshufbitqmb256_mask ((__v32qi) __A,
       (__v32qi) __B,
       (__mmask32) __M);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx512bitalg,avx512vl")
extern __inline __mmask16
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_bitshuffle_epi64_mask (__m128i __A, __m128i __B)
{
  return (__mmask16) __builtin_ia32_vpshufbitqmb128_mask ((__v16qi) __A,
       (__v16qi) __B,
       (__mmask16) -1);
}
extern __inline __mmask16
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_bitshuffle_epi64_mask (__mmask16 __M, __m128i __A, __m128i __B)
{
  return (__mmask16) __builtin_ia32_vpshufbitqmb128_mask ((__v16qi) __A,
       (__v16qi) __B,
       (__mmask16) __M);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_popcnt_epi8 (__m256i __A)
{
  return (__m256i) __builtin_ia32_vpopcountb_v32qi ((__v32qi) __A);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_popcnt_epi16 (__m256i __A)
{
  return (__m256i) __builtin_ia32_vpopcountw_v16hi ((__v16hi) __A);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_popcnt_epi8 (__m128i __A)
{
  return (__m128i) __builtin_ia32_vpopcountb_v16qi ((__v16qi) __A);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_popcnt_epi16 (__m128i __A)
{
  return (__m128i) __builtin_ia32_vpopcountw_v8hi ((__v8hi) __A);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_popcnt_epi16 (__m256i __W, __mmask16 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_vpopcountw_v16hi_mask ((__v16hi) __A,
       (__v16hi) __W,
       (__mmask16) __U);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_popcnt_epi16 (__mmask16 __U, __m256i __A)
{
  return (__m256i) __builtin_ia32_vpopcountw_v16hi_mask ((__v16hi) __A,
      (__v16hi)
      _mm256_setzero_si256 (),
      (__mmask16) __U);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_popcnt_epi8 (__m128i __W, __mmask16 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_vpopcountb_v16qi_mask ((__v16qi) __A,
        (__v16qi) __W,
        (__mmask16) __U);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_popcnt_epi8 (__mmask16 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_vpopcountb_v16qi_mask ((__v16qi) __A,
        (__v16qi)
        _mm_setzero_si128 (),
        (__mmask16) __U);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_popcnt_epi16 (__m128i __W, __mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_vpopcountw_v8hi_mask ((__v8hi) __A,
       (__v8hi) __W,
       (__mmask8) __U);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_popcnt_epi16 (__mmask8 __U, __m128i __A)
{
  return (__m128i) __builtin_ia32_vpopcountw_v8hi_mask ((__v8hi) __A,
       (__v8hi)
       _mm_setzero_si128 (),
       (__mmask8) __U);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx512vp2intersect")
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_2intersect_epi32 (__m512i __A, __m512i __B, __mmask16 *__U,
    __mmask16 *__M)
{
  __builtin_ia32_2intersectd512 (__U, __M, (__v16si) __A, (__v16si) __B);
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_2intersect_epi64 (__m512i __A, __m512i __B, __mmask8 *__U,
    __mmask8 *__M)
{
  __builtin_ia32_2intersectq512 (__U, __M, (__v8di) __A, (__v8di) __B);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx512vp2intersect,avx512vl")
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_2intersect_epi32 (__m128i __A, __m128i __B, __mmask8 *__U, __mmask8 *__M)
{
  __builtin_ia32_2intersectd128 (__U, __M, (__v4si) __A, (__v4si) __B);
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_2intersect_epi32 (__m256i __A, __m256i __B, __mmask8 *__U,
    __mmask8 *__M)
{
  __builtin_ia32_2intersectd256 (__U, __M, (__v8si) __A, (__v8si) __B);
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_2intersect_epi64 (__m128i __A, __m128i __B, __mmask8 *__U, __mmask8 *__M)
{
  __builtin_ia32_2intersectq128 (__U, __M, (__v2di) __A, (__v2di) __B);
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_2intersect_epi64 (__m256i __A, __m256i __B, __mmask8 *__U,
    __mmask8 *__M)
{
  __builtin_ia32_2intersectq256 (__U, __M, (__v4di) __A, (__v4di) __B);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("sha")
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_sha1msg1_epu32 (__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_sha1msg1 ((__v4si) __A, (__v4si) __B);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_sha1msg2_epu32 (__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_sha1msg2 ((__v4si) __A, (__v4si) __B);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_sha1nexte_epu32 (__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_sha1nexte ((__v4si) __A, (__v4si) __B);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_sha256msg1_epu32 (__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_sha256msg1 ((__v4si) __A, (__v4si) __B);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_sha256msg2_epu32 (__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_sha256msg2 ((__v4si) __A, (__v4si) __B);
}
extern __inline __m128i
__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
_mm_sha256rnds2_epu32 (__m128i __A, __m128i __B, __m128i __C)
{
  return (__m128i) __builtin_ia32_sha256rnds2 ((__v4si) __A, (__v4si) __B,
            (__v4si) __C);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("fma")
extern __inline __m128d
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_fmadd_pd (__m128d __A, __m128d __B, __m128d __C)
{
  return (__m128d)__builtin_ia32_vfmaddpd ((__v2df)__A, (__v2df)__B,
                                           (__v2df)__C);
}
extern __inline __m256d
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_fmadd_pd (__m256d __A, __m256d __B, __m256d __C)
{
  return (__m256d)__builtin_ia32_vfmaddpd256 ((__v4df)__A, (__v4df)__B,
                                              (__v4df)__C);
}
extern __inline __m128
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_fmadd_ps (__m128 __A, __m128 __B, __m128 __C)
{
  return (__m128)__builtin_ia32_vfmaddps ((__v4sf)__A, (__v4sf)__B,
                                          (__v4sf)__C);
}
extern __inline __m256
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_fmadd_ps (__m256 __A, __m256 __B, __m256 __C)
{
  return (__m256)__builtin_ia32_vfmaddps256 ((__v8sf)__A, (__v8sf)__B,
                                             (__v8sf)__C);
}
extern __inline __m128d
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_fmadd_sd (__m128d __A, __m128d __B, __m128d __C)
{
  return (__m128d) __builtin_ia32_vfmaddsd3 ((__v2df)__A, (__v2df)__B,
                                             (__v2df)__C);
}
extern __inline __m128
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_fmadd_ss (__m128 __A, __m128 __B, __m128 __C)
{
  return (__m128) __builtin_ia32_vfmaddss3 ((__v4sf)__A, (__v4sf)__B,
                                            (__v4sf)__C);
}
extern __inline __m128d
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_fmsub_pd (__m128d __A, __m128d __B, __m128d __C)
{
  return (__m128d)__builtin_ia32_vfmsubpd ((__v2df)__A, (__v2df)__B,
                                           (__v2df)__C);
}
extern __inline __m256d
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_fmsub_pd (__m256d __A, __m256d __B, __m256d __C)
{
  return (__m256d)__builtin_ia32_vfmsubpd256 ((__v4df)__A, (__v4df)__B,
                                              (__v4df)__C);
}
extern __inline __m128
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_fmsub_ps (__m128 __A, __m128 __B, __m128 __C)
{
  return (__m128)__builtin_ia32_vfmsubps ((__v4sf)__A, (__v4sf)__B,
                                          (__v4sf)__C);
}
extern __inline __m256
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_fmsub_ps (__m256 __A, __m256 __B, __m256 __C)
{
  return (__m256)__builtin_ia32_vfmsubps256 ((__v8sf)__A, (__v8sf)__B,
                                             (__v8sf)__C);
}
extern __inline __m128d
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_fmsub_sd (__m128d __A, __m128d __B, __m128d __C)
{
  return (__m128d)__builtin_ia32_vfmsubsd3 ((__v2df)__A, (__v2df)__B,
                                            (__v2df)__C);
}
extern __inline __m128
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_fmsub_ss (__m128 __A, __m128 __B, __m128 __C)
{
  return (__m128)__builtin_ia32_vfmsubss3 ((__v4sf)__A, (__v4sf)__B,
                                           (__v4sf)__C);
}
extern __inline __m128d
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_fnmadd_pd (__m128d __A, __m128d __B, __m128d __C)
{
  return (__m128d)__builtin_ia32_vfnmaddpd ((__v2df)__A, (__v2df)__B,
         (__v2df)__C);
}
extern __inline __m256d
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_fnmadd_pd (__m256d __A, __m256d __B, __m256d __C)
{
  return (__m256d)__builtin_ia32_vfnmaddpd256 ((__v4df)__A, (__v4df)__B,
            (__v4df)__C);
}
extern __inline __m128
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_fnmadd_ps (__m128 __A, __m128 __B, __m128 __C)
{
  return (__m128)__builtin_ia32_vfnmaddps ((__v4sf)__A, (__v4sf)__B,
        (__v4sf)__C);
}
extern __inline __m256
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_fnmadd_ps (__m256 __A, __m256 __B, __m256 __C)
{
  return (__m256)__builtin_ia32_vfnmaddps256 ((__v8sf)__A, (__v8sf)__B,
           (__v8sf)__C);
}
extern __inline __m128d
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_fnmadd_sd (__m128d __A, __m128d __B, __m128d __C)
{
  return (__m128d)__builtin_ia32_vfnmaddsd3 ((__v2df)__A, (__v2df)__B,
          (__v2df)__C);
}
extern __inline __m128
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_fnmadd_ss (__m128 __A, __m128 __B, __m128 __C)
{
  return (__m128)__builtin_ia32_vfnmaddss3 ((__v4sf)__A, (__v4sf)__B,
         (__v4sf)__C);
}
extern __inline __m128d
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_fnmsub_pd (__m128d __A, __m128d __B, __m128d __C)
{
  return (__m128d)__builtin_ia32_vfnmsubpd ((__v2df)__A, (__v2df)__B,
         (__v2df)__C);
}
extern __inline __m256d
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_fnmsub_pd (__m256d __A, __m256d __B, __m256d __C)
{
  return (__m256d)__builtin_ia32_vfnmsubpd256 ((__v4df)__A, (__v4df)__B,
            (__v4df)__C);
}
extern __inline __m128
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_fnmsub_ps (__m128 __A, __m128 __B, __m128 __C)
{
  return (__m128)__builtin_ia32_vfnmsubps ((__v4sf)__A, (__v4sf)__B,
        (__v4sf)__C);
}
extern __inline __m256
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_fnmsub_ps (__m256 __A, __m256 __B, __m256 __C)
{
  return (__m256)__builtin_ia32_vfnmsubps256 ((__v8sf)__A, (__v8sf)__B,
           (__v8sf)__C);
}
extern __inline __m128d
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_fnmsub_sd (__m128d __A, __m128d __B, __m128d __C)
{
  return (__m128d)__builtin_ia32_vfnmsubsd3 ((__v2df)__A, (__v2df)__B,
          (__v2df)__C);
}
extern __inline __m128
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_fnmsub_ss (__m128 __A, __m128 __B, __m128 __C)
{
  return (__m128)__builtin_ia32_vfnmsubss3 ((__v4sf)__A, (__v4sf)__B,
         (__v4sf)__C);
}
extern __inline __m128d
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_fmaddsub_pd (__m128d __A, __m128d __B, __m128d __C)
{
  return (__m128d)__builtin_ia32_vfmaddsubpd ((__v2df)__A, (__v2df)__B,
                                              (__v2df)__C);
}
extern __inline __m256d
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_fmaddsub_pd (__m256d __A, __m256d __B, __m256d __C)
{
  return (__m256d)__builtin_ia32_vfmaddsubpd256 ((__v4df)__A,
                                                 (__v4df)__B,
                                                 (__v4df)__C);
}
extern __inline __m128
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_fmaddsub_ps (__m128 __A, __m128 __B, __m128 __C)
{
  return (__m128)__builtin_ia32_vfmaddsubps ((__v4sf)__A, (__v4sf)__B,
                                             (__v4sf)__C);
}
extern __inline __m256
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_fmaddsub_ps (__m256 __A, __m256 __B, __m256 __C)
{
  return (__m256)__builtin_ia32_vfmaddsubps256 ((__v8sf)__A,
                                                (__v8sf)__B,
                                                (__v8sf)__C);
}
extern __inline __m128d
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_fmsubadd_pd (__m128d __A, __m128d __B, __m128d __C)
{
  return (__m128d)__builtin_ia32_vfmaddsubpd ((__v2df)__A, (__v2df)__B,
                                              -(__v2df)__C);
}
extern __inline __m256d
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_fmsubadd_pd (__m256d __A, __m256d __B, __m256d __C)
{
  return (__m256d)__builtin_ia32_vfmaddsubpd256 ((__v4df)__A,
                                                 (__v4df)__B,
                                                 -(__v4df)__C);
}
extern __inline __m128
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_fmsubadd_ps (__m128 __A, __m128 __B, __m128 __C)
{
  return (__m128)__builtin_ia32_vfmaddsubps ((__v4sf)__A, (__v4sf)__B,
                                             -(__v4sf)__C);
}
extern __inline __m256
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_fmsubadd_ps (__m256 __A, __m256 __B, __m256 __C)
{
  return (__m256)__builtin_ia32_vfmaddsubps256 ((__v8sf)__A,
                                                (__v8sf)__B,
                                                -(__v8sf)__C);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("f16c")
extern __inline float __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_cvtsh_ss (unsigned short __S)
{
  __v8hi __H = __extension__ (__v8hi){ (short) __S, 0, 0, 0, 0, 0, 0, 0 };
  __v4sf __A = __builtin_ia32_vcvtph2ps (__H);
  return __builtin_ia32_vec_ext_v4sf (__A, 0);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtph_ps (__m128i __A)
{
  return (__m128) __builtin_ia32_vcvtph2ps ((__v8hi) __A);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtph_ps (__m128i __A)
{
  return (__m256) __builtin_ia32_vcvtph2ps256 ((__v8hi) __A);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("gfni,sse2")
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_gf2p8mul_epi8 (__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vgf2p8mulb_v16qi((__v16qi) __A,
         (__v16qi) __B);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("gfni,avx")
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_gf2p8mul_epi8 (__m256i __A, __m256i __B)
{
  return (__m256i) __builtin_ia32_vgf2p8mulb_v32qi ((__v32qi) __A,
          (__v32qi) __B);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("gfni,avx512vl")
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_gf2p8mul_epi8 (__m128i __A, __mmask16 __B, __m128i __C, __m128i __D)
{
  return (__m128i) __builtin_ia32_vgf2p8mulb_v16qi_mask ((__v16qi) __C,
        (__v16qi) __D,
        (__v16qi)__A, __B);
}
extern __inline __m128i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_gf2p8mul_epi8 (__mmask16 __A, __m128i __B, __m128i __C)
{
  return (__m128i) __builtin_ia32_vgf2p8mulb_v16qi_mask ((__v16qi) __B,
   (__v16qi) __C, (__v16qi) _mm_setzero_si128 (), __A);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("gfni,avx512vl,avx512bw")
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_gf2p8mul_epi8 (__m256i __A, __mmask32 __B, __m256i __C,
      __m256i __D)
{
  return (__m256i) __builtin_ia32_vgf2p8mulb_v32qi_mask ((__v32qi) __C,
        (__v32qi) __D,
        (__v32qi)__A, __B);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_gf2p8mul_epi8 (__mmask32 __A, __m256i __B, __m256i __C)
{
  return (__m256i) __builtin_ia32_vgf2p8mulb_v32qi_mask ((__v32qi) __B,
   (__v32qi) __C, (__v32qi) _mm256_setzero_si256 (), __A);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("gfni,avx512f,avx512bw")
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_gf2p8mul_epi8 (__m512i __A, __mmask64 __B, __m512i __C,
      __m512i __D)
{
  return (__m512i) __builtin_ia32_vgf2p8mulb_v64qi_mask ((__v64qi) __C,
     (__v64qi) __D, (__v64qi)__A, __B);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_gf2p8mul_epi8 (__mmask64 __A, __m512i __B, __m512i __C)
{
  return (__m512i) __builtin_ia32_vgf2p8mulb_v64qi_mask ((__v64qi) __B,
   (__v64qi) __C, (__v64qi) _mm512_setzero_si512 (), __A);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_gf2p8mul_epi8 (__m512i __A, __m512i __B)
{
  return (__m512i) __builtin_ia32_vgf2p8mulb_v64qi ((__v64qi) __A,
          (__v64qi) __B);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("vaes,avx")
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_aesdec_epi128 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_vaesdec_v32qi ((__v32qi) __A, (__v32qi) __B);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_aesdeclast_epi128 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_vaesdeclast_v32qi ((__v32qi) __A,
        (__v32qi) __B);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_aesenc_epi128 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_vaesenc_v32qi ((__v32qi) __A, (__v32qi) __B);
}
extern __inline __m256i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_aesenclast_epi128 (__m256i __A, __m256i __B)
{
  return (__m256i)__builtin_ia32_vaesenclast_v32qi ((__v32qi) __A,
        (__v32qi) __B);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("vaes,avx512f")
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_aesdec_epi128 (__m512i __A, __m512i __B)
{
  return (__m512i)__builtin_ia32_vaesdec_v64qi ((__v64qi) __A, (__v64qi) __B);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_aesdeclast_epi128 (__m512i __A, __m512i __B)
{
  return (__m512i)__builtin_ia32_vaesdeclast_v64qi ((__v64qi) __A,
          (__v64qi) __B);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_aesenc_epi128 (__m512i __A, __m512i __B)
{
  return (__m512i)__builtin_ia32_vaesenc_v64qi ((__v64qi) __A, (__v64qi) __B);
}
extern __inline __m512i
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_aesenclast_epi128 (__m512i __A, __m512i __B)
{
  return (__m512i)__builtin_ia32_vaesenclast_v64qi ((__v64qi) __A,
          (__v64qi) __B);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("vpclmulqdq,avx512f")
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("vpclmulqdq,avx")
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx512bf16,avx512vl")
typedef short __v16bh __attribute__ ((__vector_size__ (32)));
typedef short __v8bh __attribute__ ((__vector_size__ (16)));
typedef short __m256bh __attribute__ ((__vector_size__ (32), __may_alias__));
typedef short __m128bh __attribute__ ((__vector_size__ (16), __may_alias__));
extern __inline __m256bh
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtne2ps_pbh (__m256 __A, __m256 __B)
{
  return (__m256bh)__builtin_ia32_cvtne2ps2bf16_v16hi(__A, __B);
}
extern __inline __m256bh
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtne2ps_pbh (__m256bh __A, __mmask16 __B, __m256 __C, __m256 __D)
{
  return (__m256bh)__builtin_ia32_cvtne2ps2bf16_v16hi_mask(__C, __D, __A, __B);
}
extern __inline __m256bh
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtne2ps_pbh (__mmask16 __A, __m256 __B, __m256 __C)
{
  return (__m256bh)__builtin_ia32_cvtne2ps2bf16_v16hi_maskz(__B, __C, __A);
}
extern __inline __m128bh
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtne2ps_pbh (__m128 __A, __m128 __B)
{
  return (__m128bh)__builtin_ia32_cvtne2ps2bf16_v8hi(__A, __B);
}
extern __inline __m128bh
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtne2ps_pbh (__m128bh __A, __mmask8 __B, __m128 __C, __m128 __D)
{
  return (__m128bh)__builtin_ia32_cvtne2ps2bf16_v8hi_mask(__C, __D, __A, __B);
}
extern __inline __m128bh
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtne2ps_pbh (__mmask8 __A, __m128 __B, __m128 __C)
{
  return (__m128bh)__builtin_ia32_cvtne2ps2bf16_v8hi_maskz(__B, __C, __A);
}
extern __inline __m128bh
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cvtneps_pbh (__m256 __A)
{
  return (__m128bh)__builtin_ia32_cvtneps2bf16_v8sf(__A);
}
extern __inline __m128bh
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_cvtneps_pbh (__m128bh __A, __mmask8 __B, __m256 __C)
{
  return (__m128bh)__builtin_ia32_cvtneps2bf16_v8sf_mask(__C, __A, __B);
}
extern __inline __m128bh
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_cvtneps_pbh (__mmask8 __A, __m256 __B)
{
  return (__m128bh)__builtin_ia32_cvtneps2bf16_v8sf_maskz(__B, __A);
}
extern __inline __m128bh
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cvtneps_pbh (__m128 __A)
{
  return (__m128bh)__builtin_ia32_cvtneps2bf16_v4sf(__A);
}
extern __inline __m128bh
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_cvtneps_pbh (__m128bh __A, __mmask8 __B, __m128 __C)
{
  return (__m128bh)__builtin_ia32_cvtneps2bf16_v4sf_mask(__C, __A, __B);
}
extern __inline __m128bh
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_cvtneps_pbh (__mmask8 __A, __m128 __B)
{
  return (__m128bh)__builtin_ia32_cvtneps2bf16_v4sf_maskz(__B, __A);
}
extern __inline __m256
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_dpbf16_ps (__m256 __A, __m256bh __B, __m256bh __C)
{
  return (__m256)__builtin_ia32_dpbf16ps_v8sf(__A, __B, __C);
}
extern __inline __m256
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_mask_dpbf16_ps (__m256 __A, __mmask8 __B, __m256bh __C, __m256bh __D)
{
  return (__m256)__builtin_ia32_dpbf16ps_v8sf_mask(__A, __C, __D, __B);
}
extern __inline __m256
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maskz_dpbf16_ps (__mmask8 __A, __m256 __B, __m256bh __C, __m256bh __D)
{
  return (__m256)__builtin_ia32_dpbf16ps_v8sf_maskz(__B, __C, __D, __A);
}
extern __inline __m128
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_dpbf16_ps (__m128 __A, __m128bh __B, __m128bh __C)
{
  return (__m128)__builtin_ia32_dpbf16ps_v4sf(__A, __B, __C);
}
extern __inline __m128
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_mask_dpbf16_ps (__m128 __A, __mmask8 __B, __m128bh __C, __m128bh __D)
{
  return (__m128)__builtin_ia32_dpbf16ps_v4sf_mask(__A, __C, __D, __B);
}
extern __inline __m128
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maskz_dpbf16_ps (__mmask8 __A, __m128 __B, __m128bh __C, __m128bh __D)
{
  return (__m128)__builtin_ia32_dpbf16ps_v4sf_maskz(__B, __C, __D, __A);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("avx512bf16")
typedef short __v32bh __attribute__ ((__vector_size__ (64)));
typedef short __m512bh __attribute__ ((__vector_size__ (64), __may_alias__));
extern __inline __m512bh
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtne2ps_pbh (__m512 __A, __m512 __B)
{
  return (__m512bh)__builtin_ia32_cvtne2ps2bf16_v32hi(__A, __B);
}
extern __inline __m512bh
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtne2ps_pbh (__m512bh __A, __mmask32 __B, __m512 __C, __m512 __D)
{
  return (__m512bh)__builtin_ia32_cvtne2ps2bf16_v32hi_mask(__C, __D, __A, __B);
}
extern __inline __m512bh
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtne2ps_pbh (__mmask32 __A, __m512 __B, __m512 __C)
{
  return (__m512bh)__builtin_ia32_cvtne2ps2bf16_v32hi_maskz(__B, __C, __A);
}
extern __inline __m256bh
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_cvtneps_pbh (__m512 __A)
{
  return (__m256bh)__builtin_ia32_cvtneps2bf16_v16sf(__A);
}
extern __inline __m256bh
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_cvtneps_pbh (__m256bh __A, __mmask16 __B, __m512 __C)
{
  return (__m256bh)__builtin_ia32_cvtneps2bf16_v16sf_mask(__C, __A, __B);
}
extern __inline __m256bh
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_cvtneps_pbh (__mmask16 __A, __m512 __B)
{
  return (__m256bh)__builtin_ia32_cvtneps2bf16_v16sf_maskz(__B, __A);
}
extern __inline __m512
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_dpbf16_ps (__m512 __A, __m512bh __B, __m512bh __C)
{
  return (__m512)__builtin_ia32_dpbf16ps_v16sf(__A, __B, __C);
}
extern __inline __m512
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_mask_dpbf16_ps (__m512 __A, __mmask16 __B, __m512bh __C, __m512bh __D)
{
  return (__m512)__builtin_ia32_dpbf16ps_v16sf_mask(__A, __C, __D, __B);
}
extern __inline __m512
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm512_maskz_dpbf16_ps (__mmask16 __A, __m512 __B, __m512bh __C, __m512bh __D)
{
  return (__m512)__builtin_ia32_dpbf16ps_v16sf_maskz(__B, __C, __D, __A);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("amx-tile")
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_tile_loadconfig (const void *__config)
{
  __asm__ volatile ("ldtilecfg\t%X0" :: "m" (*((const void **)__config)));
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_tile_storeconfig (void *__config)
{
  __asm__ volatile ("sttilecfg\t%X0" : "=m" (*((void **)__config)));
}
extern __inline void
__attribute__((__gnu_inline__, __always_inline__, __artificial__))
_tile_release (void)
{
  __asm__ volatile ("tilerelease" ::);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("amx-int8")
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("amx-bf16")
#pragma GCC pop_options
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_prefetchw (void *__P)
{
  __builtin_prefetch (__P, 1, 3 );
}
#pragma GCC push_options
#pragma GCC target("kl")
extern __inline
void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_loadiwkey (unsigned int __I, __m128i __A, __m128i __B, __m128i __C)
{
  __builtin_ia32_loadiwkey ((__v2di) __B, (__v2di) __C, (__v2di) __A, __I);
}
extern __inline
unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_encodekey128_u32 (unsigned int __I, __m128i __A, void * __P)
{
  return __builtin_ia32_encodekey128_u32 (__I, (__v2di)__A, __P);
}
extern __inline
unsigned int __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_encodekey256_u32 (unsigned int __I, __m128i __A, __m128i __B, void * __P)
{
  return __builtin_ia32_encodekey256_u32 (__I, (__v2di)__A, (__v2di)__B, __P);
}
extern __inline
unsigned char __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_aesdec128kl_u8 (__m128i * __A, __m128i __B, const void * __P)
{
  return __builtin_ia32_aesdec128kl_u8 ((__v2di *) __A, (__v2di) __B, __P);
}
extern __inline
unsigned char __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_aesdec256kl_u8 (__m128i * __A, __m128i __B, const void * __P)
{
  return __builtin_ia32_aesdec256kl_u8 ((__v2di *) __A, (__v2di) __B, __P);
}
extern __inline
unsigned char __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_aesenc128kl_u8 (__m128i * __A, __m128i __B, const void * __P)
{
  return __builtin_ia32_aesenc128kl_u8 ((__v2di *) __A, (__v2di) __B, __P);
}
extern __inline
unsigned char __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_aesenc256kl_u8 (__m128i * __A, __m128i __B, const void * __P)
{
  return __builtin_ia32_aesenc256kl_u8 ((__v2di *) __A, (__v2di) __B, __P);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("widekl")
extern __inline
unsigned char __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_aesdecwide128kl_u8(__m128i __A[8], const __m128i __B[8], const void * __P)
{
  return __builtin_ia32_aesdecwide128kl_u8 ((__v2di *) __A, (__v2di *) __B, __P);
}
extern __inline
unsigned char __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_aesdecwide256kl_u8(__m128i __A[8], const __m128i __B[8], const void * __P)
{
  return __builtin_ia32_aesdecwide256kl_u8 ((__v2di *) __A, (__v2di *) __B, __P);
}
extern __inline
unsigned char __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_aesencwide128kl_u8(__m128i __A[8], const __m128i __B[8], const void * __P)
{
  return __builtin_ia32_aesencwide128kl_u8 ((__v2di *) __A, (__v2di *) __B, __P);
}
extern __inline
unsigned char __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_aesencwide256kl_u8(__m128i __A[8], const __m128i __B[8], const void * __P)
{
  return __builtin_ia32_aesencwide256kl_u8 ((__v2di *) __A, (__v2di *) __B, __P);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("sse,3dnow")
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_femms (void)
{
  __builtin_ia32_femms();
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pavgusb (__m64 __A, __m64 __B)
{
  return (__m64)__builtin_ia32_pavgusb ((__v8qi)__A, (__v8qi)__B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pf2id (__m64 __A)
{
  return (__m64)__builtin_ia32_pf2id ((__v2sf)__A);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pfacc (__m64 __A, __m64 __B)
{
  return (__m64)__builtin_ia32_pfacc ((__v2sf)__A, (__v2sf)__B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pfadd (__m64 __A, __m64 __B)
{
  return (__m64)__builtin_ia32_pfadd ((__v2sf)__A, (__v2sf)__B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pfcmpeq (__m64 __A, __m64 __B)
{
  return (__m64)__builtin_ia32_pfcmpeq ((__v2sf)__A, (__v2sf)__B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pfcmpge (__m64 __A, __m64 __B)
{
  return (__m64)__builtin_ia32_pfcmpge ((__v2sf)__A, (__v2sf)__B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pfcmpgt (__m64 __A, __m64 __B)
{
  return (__m64)__builtin_ia32_pfcmpgt ((__v2sf)__A, (__v2sf)__B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pfmax (__m64 __A, __m64 __B)
{
  return (__m64)__builtin_ia32_pfmax ((__v2sf)__A, (__v2sf)__B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pfmin (__m64 __A, __m64 __B)
{
  return (__m64)__builtin_ia32_pfmin ((__v2sf)__A, (__v2sf)__B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pfmul (__m64 __A, __m64 __B)
{
  return (__m64)__builtin_ia32_pfmul ((__v2sf)__A, (__v2sf)__B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pfrcp (__m64 __A)
{
  return (__m64)__builtin_ia32_pfrcp ((__v2sf)__A);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pfrcpit1 (__m64 __A, __m64 __B)
{
  return (__m64)__builtin_ia32_pfrcpit1 ((__v2sf)__A, (__v2sf)__B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pfrcpit2 (__m64 __A, __m64 __B)
{
  return (__m64)__builtin_ia32_pfrcpit2 ((__v2sf)__A, (__v2sf)__B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pfrsqrt (__m64 __A)
{
  return (__m64)__builtin_ia32_pfrsqrt ((__v2sf)__A);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pfrsqit1 (__m64 __A, __m64 __B)
{
  return (__m64)__builtin_ia32_pfrsqit1 ((__v2sf)__A, (__v2sf)__B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pfsub (__m64 __A, __m64 __B)
{
  return (__m64)__builtin_ia32_pfsub ((__v2sf)__A, (__v2sf)__B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pfsubr (__m64 __A, __m64 __B)
{
  return (__m64)__builtin_ia32_pfsubr ((__v2sf)__A, (__v2sf)__B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pi2fd (__m64 __A)
{
  return (__m64)__builtin_ia32_pi2fd ((__v2si)__A);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pmulhrw (__m64 __A, __m64 __B)
{
  return (__m64)__builtin_ia32_pmulhrw ((__v4hi)__A, (__v4hi)__B);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_prefetch (void *__P)
{
  __builtin_prefetch (__P, 0, 3 );
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_from_float (float __A)
{
  return __extension__ (__m64)(__v2sf){ __A, 0.0f };
}
extern __inline float __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_to_float (__m64 __A)
{
  union { __v2sf v; float a[2]; } __tmp;
  __tmp.v = (__v2sf)__A;
  return __tmp.a[0];
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("sse,3dnowa")
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pf2iw (__m64 __A)
{
  return (__m64)__builtin_ia32_pf2iw ((__v2sf)__A);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pfnacc (__m64 __A, __m64 __B)
{
  return (__m64)__builtin_ia32_pfnacc ((__v2sf)__A, (__v2sf)__B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pfpnacc (__m64 __A, __m64 __B)
{
  return (__m64)__builtin_ia32_pfpnacc ((__v2sf)__A, (__v2sf)__B);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pi2fw (__m64 __A)
{
  return (__m64)__builtin_ia32_pi2fw ((__v2si)__A);
}
extern __inline __m64 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_m_pswapd (__m64 __A)
{
  return (__m64)__builtin_ia32_pswapdsf ((__v2sf)__A);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("sse4a")
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_stream_sd (double * __P, __m128d __Y)
{
  __builtin_ia32_movntsd (__P, (__v2df) __Y);
}
extern __inline void __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_stream_ss (float * __P, __m128 __Y)
{
  __builtin_ia32_movntss (__P, (__v4sf) __Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_extract_si64 (__m128i __X, __m128i __Y)
{
  return (__m128i) __builtin_ia32_extrq ((__v2di) __X, (__v16qi) __Y);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_insert_si64 (__m128i __X,__m128i __Y)
{
  return (__m128i) __builtin_ia32_insertq ((__v2di)__X, (__v2di)__Y);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("fma4")
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_macc_ps (__m128 __A, __m128 __B, __m128 __C)
{
  return (__m128) __builtin_ia32_vfmaddps ((__v4sf)__A, (__v4sf)__B, (__v4sf)__C);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_macc_pd (__m128d __A, __m128d __B, __m128d __C)
{
  return (__m128d) __builtin_ia32_vfmaddpd ((__v2df)__A, (__v2df)__B, (__v2df)__C);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_macc_ss (__m128 __A, __m128 __B, __m128 __C)
{
  return (__m128) __builtin_ia32_vfmaddss ((__v4sf)__A, (__v4sf)__B, (__v4sf)__C);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_macc_sd (__m128d __A, __m128d __B, __m128d __C)
{
  return (__m128d) __builtin_ia32_vfmaddsd ((__v2df)__A, (__v2df)__B, (__v2df)__C);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_msub_ps (__m128 __A, __m128 __B, __m128 __C)
{
  return (__m128) __builtin_ia32_vfmaddps ((__v4sf)__A, (__v4sf)__B, -(__v4sf)__C);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_msub_pd (__m128d __A, __m128d __B, __m128d __C)
{
  return (__m128d) __builtin_ia32_vfmaddpd ((__v2df)__A, (__v2df)__B, -(__v2df)__C);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_msub_ss (__m128 __A, __m128 __B, __m128 __C)
{
  return (__m128) __builtin_ia32_vfmaddss ((__v4sf)__A, (__v4sf)__B, -(__v4sf)__C);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_msub_sd (__m128d __A, __m128d __B, __m128d __C)
{
  return (__m128d) __builtin_ia32_vfmaddsd ((__v2df)__A, (__v2df)__B, -(__v2df)__C);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_nmacc_ps (__m128 __A, __m128 __B, __m128 __C)
{
  return (__m128) __builtin_ia32_vfmaddps (-(__v4sf)__A, (__v4sf)__B, (__v4sf)__C);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_nmacc_pd (__m128d __A, __m128d __B, __m128d __C)
{
  return (__m128d) __builtin_ia32_vfmaddpd (-(__v2df)__A, (__v2df)__B, (__v2df)__C);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_nmacc_ss (__m128 __A, __m128 __B, __m128 __C)
{
  return (__m128) __builtin_ia32_vfmaddss (-(__v4sf)__A, (__v4sf)__B, (__v4sf)__C);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_nmacc_sd (__m128d __A, __m128d __B, __m128d __C)
{
  return (__m128d) __builtin_ia32_vfmaddsd (-(__v2df)__A, (__v2df)__B, (__v2df)__C);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_nmsub_ps (__m128 __A, __m128 __B, __m128 __C)
{
  return (__m128) __builtin_ia32_vfmaddps (-(__v4sf)__A, (__v4sf)__B, -(__v4sf)__C);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_nmsub_pd (__m128d __A, __m128d __B, __m128d __C)
{
  return (__m128d) __builtin_ia32_vfmaddpd (-(__v2df)__A, (__v2df)__B, -(__v2df)__C);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_nmsub_ss (__m128 __A, __m128 __B, __m128 __C)
{
  return (__m128) __builtin_ia32_vfmaddss (-(__v4sf)__A, (__v4sf)__B, -(__v4sf)__C);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_nmsub_sd (__m128d __A, __m128d __B, __m128d __C)
{
  return (__m128d) __builtin_ia32_vfmaddsd (-(__v2df)__A, (__v2df)__B, -(__v2df)__C);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maddsub_ps (__m128 __A, __m128 __B, __m128 __C)
{
  return (__m128) __builtin_ia32_vfmaddsubps ((__v4sf)__A, (__v4sf)__B, (__v4sf)__C);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maddsub_pd (__m128d __A, __m128d __B, __m128d __C)
{
  return (__m128d) __builtin_ia32_vfmaddsubpd ((__v2df)__A, (__v2df)__B, (__v2df)__C);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_msubadd_ps (__m128 __A, __m128 __B, __m128 __C)
{
  return (__m128) __builtin_ia32_vfmaddsubps ((__v4sf)__A, (__v4sf)__B, -(__v4sf)__C);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_msubadd_pd (__m128d __A, __m128d __B, __m128d __C)
{
  return (__m128d) __builtin_ia32_vfmaddsubpd ((__v2df)__A, (__v2df)__B, -(__v2df)__C);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_macc_ps (__m256 __A, __m256 __B, __m256 __C)
{
  return (__m256) __builtin_ia32_vfmaddps256 ((__v8sf)__A, (__v8sf)__B, (__v8sf)__C);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_macc_pd (__m256d __A, __m256d __B, __m256d __C)
{
  return (__m256d) __builtin_ia32_vfmaddpd256 ((__v4df)__A, (__v4df)__B, (__v4df)__C);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_msub_ps (__m256 __A, __m256 __B, __m256 __C)
{
  return (__m256) __builtin_ia32_vfmaddps256 ((__v8sf)__A, (__v8sf)__B, -(__v8sf)__C);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_msub_pd (__m256d __A, __m256d __B, __m256d __C)
{
  return (__m256d) __builtin_ia32_vfmaddpd256 ((__v4df)__A, (__v4df)__B, -(__v4df)__C);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_nmacc_ps (__m256 __A, __m256 __B, __m256 __C)
{
  return (__m256) __builtin_ia32_vfmaddps256 (-(__v8sf)__A, (__v8sf)__B, (__v8sf)__C);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_nmacc_pd (__m256d __A, __m256d __B, __m256d __C)
{
  return (__m256d) __builtin_ia32_vfmaddpd256 (-(__v4df)__A, (__v4df)__B, (__v4df)__C);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_nmsub_ps (__m256 __A, __m256 __B, __m256 __C)
{
  return (__m256) __builtin_ia32_vfmaddps256 (-(__v8sf)__A, (__v8sf)__B, -(__v8sf)__C);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_nmsub_pd (__m256d __A, __m256d __B, __m256d __C)
{
  return (__m256d) __builtin_ia32_vfmaddpd256 (-(__v4df)__A, (__v4df)__B, -(__v4df)__C);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maddsub_ps (__m256 __A, __m256 __B, __m256 __C)
{
  return (__m256) __builtin_ia32_vfmaddsubps256 ((__v8sf)__A, (__v8sf)__B, (__v8sf)__C);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_maddsub_pd (__m256d __A, __m256d __B, __m256d __C)
{
  return (__m256d) __builtin_ia32_vfmaddsubpd256 ((__v4df)__A, (__v4df)__B, (__v4df)__C);
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_msubadd_ps (__m256 __A, __m256 __B, __m256 __C)
{
  return (__m256) __builtin_ia32_vfmaddsubps256 ((__v8sf)__A, (__v8sf)__B, -(__v8sf)__C);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_msubadd_pd (__m256d __A, __m256d __B, __m256d __C)
{
  return (__m256d) __builtin_ia32_vfmaddsubpd256 ((__v4df)__A, (__v4df)__B, -(__v4df)__C);
}
#pragma GCC pop_options
#pragma GCC push_options
#pragma GCC target("xop")
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maccs_epi16(__m128i __A, __m128i __B, __m128i __C)
{
  return (__m128i) __builtin_ia32_vpmacssww ((__v8hi)__A,(__v8hi)__B, (__v8hi)__C);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_macc_epi16(__m128i __A, __m128i __B, __m128i __C)
{
  return (__m128i) __builtin_ia32_vpmacsww ((__v8hi)__A, (__v8hi)__B, (__v8hi)__C);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maccsd_epi16(__m128i __A, __m128i __B, __m128i __C)
{
  return (__m128i) __builtin_ia32_vpmacsswd ((__v8hi)__A, (__v8hi)__B, (__v4si)__C);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maccd_epi16(__m128i __A, __m128i __B, __m128i __C)
{
  return (__m128i) __builtin_ia32_vpmacswd ((__v8hi)__A, (__v8hi)__B, (__v4si)__C);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maccs_epi32(__m128i __A, __m128i __B, __m128i __C)
{
  return (__m128i) __builtin_ia32_vpmacssdd ((__v4si)__A, (__v4si)__B, (__v4si)__C);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_macc_epi32(__m128i __A, __m128i __B, __m128i __C)
{
  return (__m128i) __builtin_ia32_vpmacsdd ((__v4si)__A, (__v4si)__B, (__v4si)__C);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maccslo_epi32(__m128i __A, __m128i __B, __m128i __C)
{
  return (__m128i) __builtin_ia32_vpmacssdql ((__v4si)__A, (__v4si)__B, (__v2di)__C);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_macclo_epi32(__m128i __A, __m128i __B, __m128i __C)
{
  return (__m128i) __builtin_ia32_vpmacsdql ((__v4si)__A, (__v4si)__B, (__v2di)__C);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maccshi_epi32(__m128i __A, __m128i __B, __m128i __C)
{
  return (__m128i) __builtin_ia32_vpmacssdqh ((__v4si)__A, (__v4si)__B, (__v2di)__C);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_macchi_epi32(__m128i __A, __m128i __B, __m128i __C)
{
  return (__m128i) __builtin_ia32_vpmacsdqh ((__v4si)__A, (__v4si)__B, (__v2di)__C);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maddsd_epi16(__m128i __A, __m128i __B, __m128i __C)
{
  return (__m128i) __builtin_ia32_vpmadcsswd ((__v8hi)__A,(__v8hi)__B,(__v4si)__C);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_maddd_epi16(__m128i __A, __m128i __B, __m128i __C)
{
  return (__m128i) __builtin_ia32_vpmadcswd ((__v8hi)__A,(__v8hi)__B,(__v4si)__C);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_haddw_epi8(__m128i __A)
{
  return (__m128i) __builtin_ia32_vphaddbw ((__v16qi)__A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_haddd_epi8(__m128i __A)
{
  return (__m128i) __builtin_ia32_vphaddbd ((__v16qi)__A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_haddq_epi8(__m128i __A)
{
  return (__m128i) __builtin_ia32_vphaddbq ((__v16qi)__A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_haddd_epi16(__m128i __A)
{
  return (__m128i) __builtin_ia32_vphaddwd ((__v8hi)__A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_haddq_epi16(__m128i __A)
{
  return (__m128i) __builtin_ia32_vphaddwq ((__v8hi)__A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_haddq_epi32(__m128i __A)
{
  return (__m128i) __builtin_ia32_vphadddq ((__v4si)__A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_haddw_epu8(__m128i __A)
{
  return (__m128i) __builtin_ia32_vphaddubw ((__v16qi)__A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_haddd_epu8(__m128i __A)
{
  return (__m128i) __builtin_ia32_vphaddubd ((__v16qi)__A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_haddq_epu8(__m128i __A)
{
  return (__m128i) __builtin_ia32_vphaddubq ((__v16qi)__A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_haddd_epu16(__m128i __A)
{
  return (__m128i) __builtin_ia32_vphadduwd ((__v8hi)__A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_haddq_epu16(__m128i __A)
{
  return (__m128i) __builtin_ia32_vphadduwq ((__v8hi)__A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_haddq_epu32(__m128i __A)
{
  return (__m128i) __builtin_ia32_vphaddudq ((__v4si)__A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_hsubw_epi8(__m128i __A)
{
  return (__m128i) __builtin_ia32_vphsubbw ((__v16qi)__A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_hsubd_epi16(__m128i __A)
{
  return (__m128i) __builtin_ia32_vphsubwd ((__v8hi)__A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_hsubq_epi32(__m128i __A)
{
  return (__m128i) __builtin_ia32_vphsubdq ((__v4si)__A);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_cmov_si128(__m128i __A, __m128i __B, __m128i __C)
{
  return (__m128i) __builtin_ia32_vpcmov (__A, __B, __C);
}
extern __inline __m256i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_cmov_si256(__m256i __A, __m256i __B, __m256i __C)
{
  return (__m256i) __builtin_ia32_vpcmov256 (__A, __B, __C);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_perm_epi8(__m128i __A, __m128i __B, __m128i __C)
{
  return (__m128i) __builtin_ia32_vpperm ((__v16qi)__A, (__v16qi)__B, (__v16qi)__C);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_rot_epi8(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vprotb ((__v16qi)__A, (__v16qi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_rot_epi16(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vprotw ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_rot_epi32(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vprotd ((__v4si)__A, (__v4si)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_rot_epi64(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vprotq ((__v2di)__A, (__v2di)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_shl_epi8(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpshlb ((__v16qi)__A, (__v16qi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_shl_epi16(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpshlw ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_shl_epi32(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpshld ((__v4si)__A, (__v4si)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_shl_epi64(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpshlq ((__v2di)__A, (__v2di)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sha_epi8(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpshab ((__v16qi)__A, (__v16qi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sha_epi16(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpshaw ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sha_epi32(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpshad ((__v4si)__A, (__v4si)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_sha_epi64(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpshaq ((__v2di)__A, (__v2di)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comlt_epu8(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomltub ((__v16qi)__A, (__v16qi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comle_epu8(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomleub ((__v16qi)__A, (__v16qi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comgt_epu8(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomgtub ((__v16qi)__A, (__v16qi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comge_epu8(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomgeub ((__v16qi)__A, (__v16qi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comeq_epu8(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomequb ((__v16qi)__A, (__v16qi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comneq_epu8(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomnequb ((__v16qi)__A, (__v16qi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comfalse_epu8(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomfalseub ((__v16qi)__A, (__v16qi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comtrue_epu8(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomtrueub ((__v16qi)__A, (__v16qi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comlt_epu16(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomltuw ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comle_epu16(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomleuw ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comgt_epu16(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomgtuw ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comge_epu16(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomgeuw ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comeq_epu16(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomequw ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comneq_epu16(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomnequw ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comfalse_epu16(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomfalseuw ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comtrue_epu16(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomtrueuw ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comlt_epu32(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomltud ((__v4si)__A, (__v4si)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comle_epu32(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomleud ((__v4si)__A, (__v4si)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comgt_epu32(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomgtud ((__v4si)__A, (__v4si)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comge_epu32(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomgeud ((__v4si)__A, (__v4si)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comeq_epu32(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomequd ((__v4si)__A, (__v4si)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comneq_epu32(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomnequd ((__v4si)__A, (__v4si)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comfalse_epu32(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomfalseud ((__v4si)__A, (__v4si)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comtrue_epu32(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomtrueud ((__v4si)__A, (__v4si)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comlt_epu64(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomltuq ((__v2di)__A, (__v2di)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comle_epu64(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomleuq ((__v2di)__A, (__v2di)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comgt_epu64(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomgtuq ((__v2di)__A, (__v2di)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comge_epu64(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomgeuq ((__v2di)__A, (__v2di)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comeq_epu64(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomequq ((__v2di)__A, (__v2di)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comneq_epu64(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomnequq ((__v2di)__A, (__v2di)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comfalse_epu64(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomfalseuq ((__v2di)__A, (__v2di)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comtrue_epu64(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomtrueuq ((__v2di)__A, (__v2di)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comlt_epi8(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomltb ((__v16qi)__A, (__v16qi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comle_epi8(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomleb ((__v16qi)__A, (__v16qi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comgt_epi8(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomgtb ((__v16qi)__A, (__v16qi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comge_epi8(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomgeb ((__v16qi)__A, (__v16qi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comeq_epi8(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomeqb ((__v16qi)__A, (__v16qi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comneq_epi8(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomneqb ((__v16qi)__A, (__v16qi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comfalse_epi8(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomfalseb ((__v16qi)__A, (__v16qi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comtrue_epi8(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomtrueb ((__v16qi)__A, (__v16qi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comlt_epi16(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomltw ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comle_epi16(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomlew ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comgt_epi16(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomgtw ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comge_epi16(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomgew ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comeq_epi16(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomeqw ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comneq_epi16(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomneqw ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comfalse_epi16(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomfalsew ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comtrue_epi16(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomtruew ((__v8hi)__A, (__v8hi)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comlt_epi32(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomltd ((__v4si)__A, (__v4si)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comle_epi32(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomled ((__v4si)__A, (__v4si)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comgt_epi32(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomgtd ((__v4si)__A, (__v4si)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comge_epi32(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomged ((__v4si)__A, (__v4si)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comeq_epi32(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomeqd ((__v4si)__A, (__v4si)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comneq_epi32(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomneqd ((__v4si)__A, (__v4si)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comfalse_epi32(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomfalsed ((__v4si)__A, (__v4si)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comtrue_epi32(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomtrued ((__v4si)__A, (__v4si)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comlt_epi64(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomltq ((__v2di)__A, (__v2di)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comle_epi64(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomleq ((__v2di)__A, (__v2di)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comgt_epi64(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomgtq ((__v2di)__A, (__v2di)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comge_epi64(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomgeq ((__v2di)__A, (__v2di)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comeq_epi64(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomeqq ((__v2di)__A, (__v2di)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comneq_epi64(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomneqq ((__v2di)__A, (__v2di)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comfalse_epi64(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomfalseq ((__v2di)__A, (__v2di)__B);
}
extern __inline __m128i __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_comtrue_epi64(__m128i __A, __m128i __B)
{
  return (__m128i) __builtin_ia32_vpcomtrueq ((__v2di)__A, (__v2di)__B);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_frcz_ps (__m128 __A)
{
  return (__m128) __builtin_ia32_vfrczps ((__v4sf)__A);
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_frcz_pd (__m128d __A)
{
  return (__m128d) __builtin_ia32_vfrczpd ((__v2df)__A);
}
extern __inline __m128 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_frcz_ss (__m128 __A, __m128 __B)
{
  return (__m128) __builtin_ia32_movss ((__v4sf)__A,
     (__v4sf)
     __builtin_ia32_vfrczss ((__v4sf)__B));
}
extern __inline __m128d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm_frcz_sd (__m128d __A, __m128d __B)
{
  return (__m128d) __builtin_ia32_movsd ((__v2df)__A,
      (__v2df)
      __builtin_ia32_vfrczsd ((__v2df)__B));
}
extern __inline __m256 __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_frcz_ps (__m256 __A)
{
  return (__m256) __builtin_ia32_vfrczps256 ((__v8sf)__A);
}
extern __inline __m256d __attribute__((__gnu_inline__, __always_inline__, __artificial__))
_mm256_frcz_pd (__m256d __A)
{
  return (__m256d) __builtin_ia32_vfrczpd256 ((__v4df)__A);
}
#pragma GCC pop_options
static inline uint16_t ruby_swap16(uint16_t);
static inline uint32_t ruby_swap32(uint32_t);
static inline uint64_t ruby_swap64(uint64_t);
static inline unsigned nlz_int(unsigned x);
static inline unsigned nlz_long(unsigned long x);
static inline unsigned nlz_long_long(unsigned long long x);
static inline unsigned nlz_intptr(uintptr_t x);
static inline unsigned nlz_int32(uint32_t x);
static inline unsigned nlz_int64(uint64_t x);
static inline unsigned nlz_int128(unsigned __int128 x);
static inline unsigned rb_popcount32(uint32_t x);
static inline unsigned rb_popcount64(uint64_t x);
static inline unsigned rb_popcount_intptr(uintptr_t x);
static inline int ntz_int32(uint32_t x);
static inline int ntz_int64(uint64_t x);
static inline int ntz_intptr(uintptr_t x);
static inline VALUE RUBY_BIT_ROTL(VALUE, int);
static inline VALUE RUBY_BIT_ROTR(VALUE, int);
static inline uint16_t
ruby_swap16(uint16_t x)
{
    return __builtin_bswap16(x);
}
static inline uint32_t
ruby_swap32(uint32_t x)
{
    return __builtin_bswap32(x);
}
static inline uint64_t
ruby_swap64(uint64_t x)
{
    return __builtin_bswap64(x);
}
static inline unsigned int
nlz_int32(uint32_t x)
{
    __extension__ _Static_assert(sizeof(int) * 8 == 32, "sizeof_int" ": " "sizeof(int) * CHAR_BIT == 32");
    return x ? (unsigned int)__builtin_clz(x) : 32;
}
static inline unsigned int
nlz_int64(uint64_t x)
{
    if (x == 0) {
        return 64;
    }
    else if (sizeof(long) * 8 == 64) {
        return (unsigned int)__builtin_clzl((unsigned long)x);
    }
    else if (sizeof(long long) * 8 == 64) {
        return (unsigned int)__builtin_clzll((unsigned long long)x);
    }
    else {
        __builtin_unreachable();
    }
}
static inline unsigned int
nlz_int128(unsigned __int128 x)
{
    uint64_t y = (uint64_t)(x >> 64);
    if (x == 0) {
        return 128;
    }
    else if (y == 0) {
        return (unsigned int)nlz_int64(x) + 64;
    }
    else {
        return (unsigned int)nlz_int64(y);
    }
}
static inline unsigned int
nlz_int(unsigned int x)
{
    if (sizeof(unsigned int) * 8 == 32) {
        return nlz_int32((uint32_t)x);
    }
    else if (sizeof(unsigned int) * 8 == 64) {
        return nlz_int64((uint64_t)x);
    }
    else {
        __builtin_unreachable();
    }
}
static inline unsigned int
nlz_long(unsigned long x)
{
    if (sizeof(unsigned long) * 8 == 32) {
        return nlz_int32((uint32_t)x);
    }
    else if (sizeof(unsigned long) * 8 == 64) {
        return nlz_int64((uint64_t)x);
    }
    else {
        __builtin_unreachable();
    }
}
static inline unsigned int
nlz_long_long(unsigned long long x)
{
    if (sizeof(unsigned long long) * 8 == 64) {
        return nlz_int64((uint64_t)x);
    }
    else if (sizeof(unsigned long long) * 8 == 128) {
        return nlz_int128((unsigned __int128)x);
    }
    else {
        __builtin_unreachable();
    }
}
static inline unsigned int
nlz_intptr(uintptr_t x)
{
    if (sizeof(uintptr_t) == sizeof(unsigned int)) {
        return nlz_int((unsigned int)x);
    }
    if (sizeof(uintptr_t) == sizeof(unsigned long)) {
        return nlz_long((unsigned long)x);
    }
    if (sizeof(uintptr_t) == sizeof(unsigned long long)) {
        return nlz_long_long((unsigned long long)x);
    }
    else {
        __builtin_unreachable();
    }
}
static inline unsigned int
rb_popcount32(uint32_t x)
{
    __extension__ _Static_assert(sizeof(int) * 8 >= 32, "sizeof_int" ": " "sizeof(int) * CHAR_BIT >= 32");
    return (unsigned int)__builtin_popcount(x);
}
static inline unsigned int
rb_popcount64(uint64_t x)
{
    if (sizeof(long) * 8 == 64) {
        return (unsigned int)__builtin_popcountl((unsigned long)x);
    }
    else if (sizeof(long long) * 8 == 64) {
        return (unsigned int)__builtin_popcountll((unsigned long long)x);
    }
    else {
        __builtin_unreachable();
    }
}
static inline unsigned int
rb_popcount_intptr(uintptr_t x)
{
    if (sizeof(uintptr_t) * 8 == 64) {
        return rb_popcount64((uint64_t)x);
    }
    else if (sizeof(uintptr_t) * 8 == 32) {
        return rb_popcount32((uint32_t)x);
    }
    else {
        __builtin_unreachable();
    }
}
static inline int
ntz_int32(uint32_t x)
{
    __extension__ _Static_assert(sizeof(int) * 8 == 32, "sizeof_int" ": " "sizeof(int) * CHAR_BIT == 32");
    return x ? (unsigned)__builtin_ctz(x) : 32;
}
static inline int
ntz_int64(uint64_t x)
{
    if (x == 0) {
        return 64;
    }
    else if (sizeof(long) * 8 == 64) {
        return (unsigned)__builtin_ctzl((unsigned long)x);
    }
    else if (sizeof(long long) * 8 == 64) {
        return (unsigned)__builtin_ctzll((unsigned long long)x);
    }
    else {
        __builtin_unreachable();
    }
}
static inline int
ntz_intptr(uintptr_t x)
{
    if (sizeof(uintptr_t) * 8 == 64) {
        return ntz_int64((uint64_t)x);
    }
    else if (sizeof(uintptr_t) * 8 == 32) {
        return ntz_int32((uint32_t)x);
    }
    else {
        __builtin_unreachable();
    }
}
static inline VALUE
RUBY_BIT_ROTL(VALUE v, int n)
{
    return __rolq((v), (n));
}
static inline VALUE
RUBY_BIT_ROTR(VALUE v, int n)
{
    return __rorq((v), (n));
}
VALUE rb_int128t2big(__int128 n);
static inline long rb_overflowed_fix_to_int(long x);
static inline VALUE rb_fix_plus_fix(VALUE x, VALUE y);
static inline VALUE rb_fix_minus_fix(VALUE x, VALUE y);
static inline VALUE rb_fix_mul_fix(VALUE x, VALUE y);
static inline void rb_fix_divmod_fix(VALUE x, VALUE y, VALUE *divp, VALUE *modp);
static inline VALUE rb_fix_div_fix(VALUE x, VALUE y);
static inline VALUE rb_fix_mod_fix(VALUE x, VALUE y);
static inline _Bool FIXNUM_POSITIVE_P(VALUE num);
static inline _Bool FIXNUM_NEGATIVE_P(VALUE num);
static inline _Bool FIXNUM_ZERO_P(VALUE num);
static inline long
rb_overflowed_fix_to_int(long x)
{
    return (long)((unsigned long)(x >> 1) ^ (1LU << (8 * 8 - 1)));
}
static inline VALUE
rb_fix_plus_fix(VALUE x, VALUE y)
{
    long lz;
    if (__builtin_add_overflow((long)x, (long)y-1, &lz)) {
        return rb_int2big(rb_overflowed_fix_to_int(lz));
    }
    else {
        return (VALUE)lz;
    }
}
static inline VALUE
rb_fix_minus_fix(VALUE x, VALUE y)
{
    long lz;
    if (__builtin_sub_overflow((long)x, (long)y-1, &lz)) {
        return rb_int2big(rb_overflowed_fix_to_int(lz));
    }
    else {
        return (VALUE)lz;
    }
}
static inline VALUE
rb_fix_mul_fix(VALUE x, VALUE y)
{
    long lx = rb_fix2long(x);
    long ly = rb_fix2long(y);
    return (((((__int128)lx * (__int128)ly) < (0x7fffffffffffffffL / 2) + 1) && (((__int128)lx * (__int128)ly) >= ((-0x7fffffffffffffffL - 1L) / 2))) ? RB_INT2FIX((__int128)lx * (__int128)ly) : rb_int128t2big((__int128)lx * (__int128)ly));
}
static inline void
rb_fix_divmod_fix(VALUE a, VALUE b, VALUE *divp, VALUE *modp)
{
    long x = rb_fix2long(a);
    long y = rb_fix2long(b);
    long div, mod;
    if (x == ((-0x7fffffffffffffffL - 1L) / 2) && y == -1) {
        if (divp) *divp = rb_long2num_inline(-((-0x7fffffffffffffffL - 1L) / 2));
        if (modp) *modp = RB_INT2FIX(0);
        return;
    }
    div = x / y;
    mod = x % y;
    if (y > 0 ? mod < 0 : mod > 0) {
        mod += y;
        div -= 1;
    }
    if (divp) *divp = RB_INT2FIX(div);
    if (modp) *modp = RB_INT2FIX(mod);
}
static inline VALUE
rb_fix_div_fix(VALUE x, VALUE y)
{
    VALUE div;
    rb_fix_divmod_fix(x, y, &div, ((void *)0));
    return div;
}
static inline VALUE
rb_fix_mod_fix(VALUE x, VALUE y)
{
    VALUE mod;
    rb_fix_divmod_fix(x, y, ((void *)0), &mod);
    return mod;
}
static inline _Bool
FIXNUM_POSITIVE_P(VALUE num)
{
    return (long)num > (long)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0));
}
static inline _Bool
FIXNUM_NEGATIVE_P(VALUE num)
{
    return (long)num < 0;
}
static inline _Bool
FIXNUM_ZERO_P(VALUE num)
{
    return num == __builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0));
}
enum ruby_num_rounding_mode {
    RUBY_NUM_ROUND_HALF_UP,
    RUBY_NUM_ROUND_HALF_EVEN,
    RUBY_NUM_ROUND_HALF_DOWN,
    RUBY_NUM_ROUND_DEFAULT = RUBY_NUM_ROUND_HALF_UP,
};
typedef double rb_float_value_type;
struct RFloat {
    struct RBasic basic;
    rb_float_value_type float_value;
};
int rb_num_to_uint(VALUE val, unsigned int *ret);
VALUE ruby_num_interval_step_size(VALUE from, VALUE to, VALUE step, int excl);
double ruby_float_step_size(double beg, double end, double unit, int excl);
int ruby_float_step(VALUE from, VALUE to, VALUE step, int excl, int allow_endless);
int rb_num_negative_p(VALUE);
VALUE rb_int_succ(VALUE num);
VALUE rb_float_uminus(VALUE num);
VALUE rb_int_plus(VALUE x, VALUE y);
VALUE rb_float_plus(VALUE x, VALUE y);
VALUE rb_int_minus(VALUE x, VALUE y);
VALUE rb_float_minus(VALUE x, VALUE y);
VALUE rb_int_mul(VALUE x, VALUE y);
VALUE rb_float_mul(VALUE x, VALUE y);
VALUE rb_float_div(VALUE x, VALUE y);
VALUE rb_int_idiv(VALUE x, VALUE y);
VALUE rb_int_modulo(VALUE x, VALUE y);
VALUE rb_int2str(VALUE num, int base);
VALUE rb_fix_plus(VALUE x, VALUE y);
VALUE rb_int_gt(VALUE x, VALUE y);
VALUE rb_float_gt(VALUE x, VALUE y);
VALUE rb_int_ge(VALUE x, VALUE y);
enum ruby_num_rounding_mode rb_num_get_rounding_option(VALUE opts);
double rb_int_fdiv_double(VALUE x, VALUE y);
VALUE rb_int_pow(VALUE x, VALUE y);
VALUE rb_float_pow(VALUE x, VALUE y);
VALUE rb_int_cmp(VALUE x, VALUE y);
VALUE rb_int_equal(VALUE x, VALUE y);
VALUE rb_int_divmod(VALUE x, VALUE y);
VALUE rb_int_and(VALUE x, VALUE y);
VALUE rb_int_lshift(VALUE x, VALUE y);
VALUE rb_int_rshift(VALUE x, VALUE y);
VALUE rb_int_div(VALUE x, VALUE y);
int rb_int_positive_p(VALUE num);
int rb_int_negative_p(VALUE num);
VALUE rb_check_integer_type(VALUE);
VALUE rb_num_pow(VALUE x, VALUE y);
VALUE rb_float_ceil(VALUE num, int ndigits);
VALUE rb_float_floor(VALUE x, int ndigits);
VALUE rb_float_abs(VALUE flt);
static inline VALUE rb_num_compare_with_zero(VALUE num, ID mid);
static inline int rb_num_positive_int_p(VALUE num);
static inline int rb_num_negative_int_p(VALUE num);
static inline double rb_float_flonum_value(VALUE v);
static inline double rb_float_noflonum_value(VALUE v);
static inline double rb_float_value_inline(VALUE v);
static inline VALUE rb_float_new_inline(double d);
static inline _Bool INT_POSITIVE_P(VALUE num);
static inline _Bool INT_NEGATIVE_P(VALUE num);
static inline _Bool FLOAT_ZERO_P(VALUE num);

#pragma GCC visibility push(default)


#pragma GCC visibility pop

VALUE rb_flo_div_flo(VALUE x, VALUE y);
double ruby_float_mod(double x, double y);
VALUE rb_float_equal(VALUE x, VALUE y);
int rb_float_cmp(VALUE x, VALUE y);
VALUE rb_float_eql(VALUE x, VALUE y);
VALUE rb_fix_aref(VALUE fix, VALUE idx);
VALUE rb_int_zero_p(VALUE num);
VALUE rb_int_even_p(VALUE num);
VALUE rb_int_odd_p(VALUE num);
VALUE rb_int_abs(VALUE num);
VALUE rb_int_bit_length(VALUE num);
VALUE rb_int_uminus(VALUE num);
VALUE rb_int_comp(VALUE num);
static inline _Bool
INT_POSITIVE_P(VALUE num)
{
    if (RB_FIXNUM_P(num)) {
        return FIXNUM_POSITIVE_P(num);
    }
    else {
        return BIGNUM_POSITIVE_P(num);
    }
}
static inline _Bool
INT_NEGATIVE_P(VALUE num)
{
    if (RB_FIXNUM_P(num)) {
        return FIXNUM_NEGATIVE_P(num);
    }
    else {
        return BIGNUM_NEGATIVE_P(num);
    }
}
static inline _Bool
FLOAT_ZERO_P(VALUE num)
{
    return rb_float_value_inline(num) == 0.0;
}
static inline VALUE
rb_num_compare_with_zero(VALUE num, ID mid)
{
    VALUE zero = __builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0));
    VALUE r = rb_check_funcall(num, mid, 1, &zero);
    if (RB_UNDEF_P(r)) {
        rb_cmperr(num, zero);
    }
    return r;
}
static inline int
rb_num_positive_int_p(VALUE num)
{
    const ID mid = '>';
    if (RB_FIXNUM_P(num)) {
        if (rb_method_basic_definition_p(rb_cInteger, mid))
            return FIXNUM_POSITIVE_P(num);
    }
    else if (RB_TYPE_P(num, RUBY_T_BIGNUM)) {
        if (rb_method_basic_definition_p(rb_cInteger, mid))
            return BIGNUM_POSITIVE_P(num);
    }
    return RB_TEST(rb_num_compare_with_zero(num, mid));
}
static inline int
rb_num_negative_int_p(VALUE num)
{
    const ID mid = '<';
    if (RB_FIXNUM_P(num)) {
        if (rb_method_basic_definition_p(rb_cInteger, mid))
            return FIXNUM_NEGATIVE_P(num);
    }
    else if (RB_TYPE_P(num, RUBY_T_BIGNUM)) {
        if (rb_method_basic_definition_p(rb_cInteger, mid))
            return BIGNUM_NEGATIVE_P(num);
    }
    return RB_TEST(rb_num_compare_with_zero(num, mid));
}
static inline double
rb_float_flonum_value(VALUE v)
{
    if (v != (VALUE)0x8000000000000002) {
        union {
            double d;
            VALUE v;
        } t;
        VALUE b63 = (v >> 63);
        t.v = RUBY_BIT_ROTR((2 - b63) | (v & ~(VALUE)0x03), 3);
        return t.d;
    }
    return 0.0;
}
static inline double
rb_float_noflonum_value(VALUE v)
{
    return ((struct RFloat *)(v))->float_value;
}
static inline double
rb_float_value_inline(VALUE v)
{
    if (RB_FLONUM_P(v)) {
        return rb_float_flonum_value(v);
    }
    return rb_float_noflonum_value(v);
}
static inline VALUE
rb_float_new_inline(double d)
{
    union {
        double d;
        VALUE v;
    } t;
    int bits;
    t.d = d;
    bits = (int)((VALUE)(t.v >> 60) & 0x7);
    if (t.v != 0x3000000000000000 &&
        !((bits-3) & ~0x01)) {
        return (RUBY_BIT_ROTL(t.v, 3) & ~(VALUE)0x01) | 0x02;
    }
    else if (t.v == (VALUE)0) {
        return 0x8000000000000002;
    }
    return rb_float_new_in_heap(d);
}
size_t rb_obj_embedded_size(uint32_t numiv);
VALUE rb_class_allocate_instance(VALUE klass);
VALUE rb_class_search_ancestor(VALUE klass, VALUE super);
__attribute__((__noreturn__)) void rb_undefined_alloc(VALUE klass);
double rb_num_to_dbl(VALUE val);
VALUE rb_obj_dig(int argc, VALUE *argv, VALUE self, VALUE notfound);
VALUE rb_obj_clone_setup(VALUE obj, VALUE clone, VALUE kwfreeze);
VALUE rb_obj_dup_setup(VALUE obj, VALUE dup);
VALUE rb_immutable_obj_clone(int, VALUE *, VALUE);
VALUE rb_check_convert_type_with_id(VALUE,int,const char*,ID);
int rb_bool_expected(VALUE, const char *, int raise);
static inline void RBASIC_CLEAR_CLASS(VALUE obj);
static inline void RBASIC_SET_CLASS_RAW(VALUE obj, VALUE klass);
static inline void RBASIC_SET_CLASS(VALUE obj, VALUE klass);

#pragma GCC visibility push(default)

int rb_opts_exception_p(VALUE opts, int default_value);

#pragma GCC visibility pop

__attribute__((__const__)) VALUE rb_obj_equal(VALUE obj1, VALUE obj2);
__attribute__((__const__)) VALUE rb_obj_not(VALUE obj);
VALUE rb_obj_not_equal(VALUE obj1, VALUE obj2);
void rb_obj_copy_ivar(VALUE dest, VALUE obj);
VALUE rb_false(VALUE obj);
VALUE rb_convert_type_with_id(VALUE v, int t, const char* nam, ID mid);
VALUE rb_obj_size(VALUE self, VALUE args, VALUE obj);
VALUE rb_get_freeze_opt(int argc, VALUE *argv);
static inline void
RBASIC_SET_CLASS_RAW(VALUE obj, VALUE klass)
{
    const VALUE *ptr = &((struct RBasic *)(obj))->klass;
    *(VALUE *)ptr = klass;
}
static inline void
RBASIC_CLEAR_CLASS(VALUE obj)
{
    RBASIC_SET_CLASS_RAW(obj, 0);
}
static inline void
RBASIC_SET_CLASS(VALUE obj, VALUE klass)
{
    VALUE oldv = RBASIC_CLASS(obj);
    RBASIC_SET_CLASS_RAW(obj, klass);
    (rb_obj_written((VALUE)(obj), (VALUE)(oldv), (VALUE)(klass), "internal/object.h", 61));
}
struct RRational {
    struct RBasic basic;
    VALUE num;
    VALUE den;
};
VALUE rb_rational_canonicalize(VALUE x);
VALUE rb_rational_uminus(VALUE self);
VALUE rb_rational_plus(VALUE self, VALUE other);
VALUE rb_rational_minus(VALUE self, VALUE other);
VALUE rb_rational_mul(VALUE self, VALUE other);
VALUE rb_rational_div(VALUE self, VALUE other);
VALUE rb_lcm(VALUE x, VALUE y);
VALUE rb_rational_reciprocal(VALUE x);
VALUE rb_cstr_to_rat(const char *, int);
VALUE rb_rational_hash(VALUE self);
VALUE rb_rational_abs(VALUE self);
VALUE rb_rational_cmp(VALUE self, VALUE other);
VALUE rb_rational_pow(VALUE self, VALUE other);
VALUE rb_rational_floor(VALUE self, int ndigits);
VALUE rb_numeric_quo(VALUE x, VALUE y);
VALUE rb_flo_round_by_rational(int argc, VALUE *argv, VALUE num);
VALUE rb_float_numerator(VALUE x);
VALUE rb_float_denominator(VALUE x);
static inline void RATIONAL_SET_NUM(VALUE r, VALUE n);
static inline void RATIONAL_SET_DEN(VALUE r, VALUE d);

#pragma GCC visibility push(default)

VALUE rb_gcd(VALUE x, VALUE y);
VALUE rb_gcd_normal(VALUE self, VALUE other);
VALUE rb_gcd_gmp(VALUE x, VALUE y);

#pragma GCC visibility pop

static inline void
RATIONAL_SET_NUM(VALUE r, VALUE n)
{
    ((void) (0));
    (rb_obj_write((VALUE)(r), (VALUE *)(&((struct RRational *)(r))->num), (VALUE)(n), "internal/rational.h", 60));
}
static inline void
RATIONAL_SET_DEN(VALUE r, VALUE d)
{
    ((void) (0));
    ((void) (0));
    (rb_obj_write((VALUE)(r), (VALUE *)(&((struct RRational *)(r))->den), (VALUE)(d), "internal/rational.h", 68));
}
VALUE rb_reg_compile(VALUE str, int options, const char *sourcefile, int sourceline);
VALUE rb_reg_check_preprocess(VALUE);
long rb_reg_search0(VALUE, VALUE, long, int, int);
VALUE rb_reg_match_p(VALUE re, VALUE str, long pos);
_Bool rb_reg_start_with_p(VALUE re, VALUE str);
VALUE rb_reg_hash(VALUE re);
VALUE rb_reg_equal(VALUE re1, VALUE re2);
void rb_backref_set_string(VALUE string, long pos, long len);
void rb_match_unbusy(VALUE);
int rb_match_count(VALUE match);
VALUE rb_reg_new_ary(VALUE ary, int options);
VALUE rb_reg_last_defined(VALUE match);
typedef enum {
    RB_DEFAULT_PARSER_PARSE_Y,
    RB_DEFAULT_PARSER_PRISM,
} ruby_default_parser_enum;
ruby_default_parser_enum rb_ruby_default_parser(void);
void rb_ruby_default_parser_set(ruby_default_parser_enum parser);
struct rb_iseq_struct;
typedef struct rb_strterm_literal_struct {
    long nest;
    int func;
    int paren;
    int term;
} rb_strterm_literal_t;
typedef struct rb_strterm_heredoc_struct {
    rb_parser_string_t *lastline;
    long offset;
    int sourceline;
    unsigned length;
    uint8_t quote;
    uint8_t func;
} rb_strterm_heredoc_t;
typedef struct rb_strterm_struct {
    _Bool heredoc;
    union {
        rb_strterm_literal_t literal;
        rb_strterm_heredoc_t heredoc;
    } u;
} rb_strterm_t;
void rb_ruby_parser_mark(void *ptr);
size_t rb_ruby_parser_memsize(const void *ptr);
void rb_ruby_parser_set_options(rb_parser_t *p, int print, int loop, int chomp, int split);
rb_parser_t *rb_ruby_parser_set_context(rb_parser_t *p, const struct rb_iseq_struct *base, int main);
void rb_ruby_parser_set_script_lines(rb_parser_t *p);
void rb_ruby_parser_error_tolerant(rb_parser_t *p);
void rb_ruby_parser_keep_tokens(rb_parser_t *p);
typedef rb_parser_string_t*(rb_parser_lex_gets_func)(struct parser_params*, rb_parser_input_data, int);
rb_ast_t *rb_parser_compile(rb_parser_t *p, rb_parser_lex_gets_func *gets, VALUE fname, rb_parser_input_data input, int line);

#pragma GCC visibility push(default)

rb_encoding *rb_ruby_parser_encoding(rb_parser_t *p);
int rb_ruby_parser_end_seen_p(rb_parser_t *p);
int rb_ruby_parser_set_yydebug(rb_parser_t *p, int flag);
rb_parser_string_t *rb_str_to_parser_string(rb_parser_t *p, VALUE str);
void rb_parser_string_free(rb_parser_t *p, rb_parser_string_t *str);
int rb_parser_dvar_defined_ref(struct parser_params*, ID, ID**);
ID rb_parser_internal_id(struct parser_params*);
int rb_parser_reg_fragment_check(struct parser_params*, rb_parser_string_t*, int);
int rb_reg_named_capture_assign_iter_impl(struct parser_params *p, const char *s, long len, rb_encoding *enc, NODE **succ_block, const rb_code_location_t *loc);
int rb_parser_local_defined(struct parser_params *p, ID id, const struct rb_iseq_struct *iseq);

#pragma GCC visibility pop

rb_parser_t *rb_ruby_parser_allocate(void);
rb_parser_t *rb_ruby_parser_new(void);
struct lex_pointer_string {
    VALUE str;
    long ptr;
};

#pragma GCC visibility push(default)

VALUE rb_parser_set_context(VALUE, const struct rb_iseq_struct *, int);
VALUE rb_parser_new(void);
VALUE rb_parser_compile_string_path(VALUE vparser, VALUE fname, VALUE src, int line);
VALUE rb_str_new_parser_string(rb_parser_string_t *str);
VALUE rb_str_new_mutable_parser_string(rb_parser_string_t *str);
rb_parser_string_t *rb_parser_lex_get_str(struct parser_params *p, struct lex_pointer_string *ptr_str);
VALUE rb_node_str_string_val(const NODE *);
VALUE rb_node_sym_string_val(const NODE *);
VALUE rb_node_dstr_string_val(const NODE *);
VALUE rb_node_regx_string_val(const NODE *);
VALUE rb_node_dregx_string_val(const NODE *);
VALUE rb_node_line_lineno_val(const NODE *);
VALUE rb_node_file_path_val(const NODE *);
VALUE rb_node_encoding_val(const NODE *);
VALUE rb_node_integer_literal_val(const NODE *);
VALUE rb_node_float_literal_val(const NODE *);
VALUE rb_node_rational_literal_val(const NODE *);
VALUE rb_node_imaginary_literal_val(const NODE *);

#pragma GCC visibility pop

VALUE rb_parser_end_seen_p(VALUE);
VALUE rb_parser_encoding(VALUE);
VALUE rb_parser_set_yydebug(VALUE, VALUE);
VALUE rb_parser_build_script_lines_from(rb_parser_ary_t *script_lines);
void rb_parser_set_options(VALUE, int, int, int, int);
VALUE rb_parser_load_file(VALUE parser, VALUE name);
void rb_parser_set_script_lines(VALUE vparser);
void rb_parser_error_tolerant(VALUE vparser);
void rb_parser_keep_tokens(VALUE vparser);
VALUE rb_parser_compile_string(VALUE, const char*, VALUE, int);
VALUE rb_parser_compile_file_path(VALUE vparser, VALUE fname, VALUE input, int line);
VALUE rb_parser_compile_generic(VALUE vparser, rb_parser_lex_gets_func *lex_gets, VALUE fname, VALUE input, int line);
VALUE rb_parser_compile_array(VALUE vparser, VALUE fname, VALUE array, int start);
enum lex_state_bits {
    EXPR_BEG_bit,
    EXPR_END_bit,
    EXPR_ENDARG_bit,
    EXPR_ENDFN_bit,
    EXPR_ARG_bit,
    EXPR_CMDARG_bit,
    EXPR_MID_bit,
    EXPR_FNAME_bit,
    EXPR_DOT_bit,
    EXPR_CLASS_bit,
    EXPR_LABEL_bit,
    EXPR_LABELED_bit,
    EXPR_FITEM_bit,
    EXPR_MAX_STATE
};
enum lex_state_e {
    EXPR_BEG = (1 << EXPR_BEG_bit),
    EXPR_END = (1 << EXPR_END_bit),
    EXPR_ENDARG = (1 << EXPR_ENDARG_bit),
    EXPR_ENDFN = (1 << EXPR_ENDFN_bit),
    EXPR_ARG = (1 << EXPR_ARG_bit),
    EXPR_CMDARG = (1 << EXPR_CMDARG_bit),
    EXPR_MID = (1 << EXPR_MID_bit),
    EXPR_FNAME = (1 << EXPR_FNAME_bit),
    EXPR_DOT = (1 << EXPR_DOT_bit),
    EXPR_CLASS = (1 << EXPR_CLASS_bit),
    EXPR_LABEL = (1 << EXPR_LABEL_bit),
    EXPR_LABELED = (1 << EXPR_LABELED_bit),
    EXPR_FITEM = (1 << EXPR_FITEM_bit),
    EXPR_VALUE = EXPR_BEG,
    EXPR_BEG_ANY = (EXPR_BEG | EXPR_MID | EXPR_CLASS),
    EXPR_ARG_ANY = (EXPR_ARG | EXPR_CMDARG),
    EXPR_END_ANY = (EXPR_END | EXPR_ENDARG | EXPR_ENDFN),
    EXPR_NONE = 0
};
VALUE rb_ruby_ast_new(const NODE *const root);
rb_ast_t *rb_ruby_ast_data_get(VALUE ast_value);
VALUE rb_to_symbol_type(VALUE obj);
VALUE rb_sym_intern(const char *ptr, long len, rb_encoding *enc);
VALUE rb_sym_intern_ascii(const char *ptr, long len);
VALUE rb_sym_intern_ascii_cstr(const char *ptr);
int rb_is_const_name(VALUE name);
int rb_is_class_name(VALUE name);
int rb_is_instance_name(VALUE name);
int rb_is_local_name(VALUE name);
__attribute__((__pure__)) int rb_is_const_sym(VALUE sym);
__attribute__((__pure__)) int rb_is_attrset_sym(VALUE sym);
ID rb_make_internal_id(void);
ID rb_make_temporary_id(size_t n);
void rb_gc_free_dsymbol(VALUE);
int rb_static_id_valid_p(ID id);
void rb_free_static_symid_str(void);
struct rb_thread_struct;
VALUE rb_obj_is_mutex(VALUE obj);
VALUE rb_suppress_tracing(VALUE (*func)(VALUE), VALUE arg);
void rb_thread_execute_interrupts(VALUE th);
VALUE rb_get_coverages(void);
int rb_get_coverage_mode(void);
VALUE rb_default_coverage(int);
VALUE rb_thread_shield_new(void);
_Bool rb_thread_shield_owned(VALUE self);
VALUE rb_thread_shield_wait(VALUE self);
VALUE rb_thread_shield_release(VALUE self);
VALUE rb_thread_shield_destroy(VALUE self);
int rb_thread_to_be_killed(VALUE thread);
void rb_thread_acquire_fork_lock(void);
void rb_thread_release_fork_lock(void);
void rb_thread_reset_fork_lock(void);
void rb_mutex_allow_trap(VALUE self, int val);
VALUE rb_uninterruptible(VALUE (*b_proc)(VALUE), VALUE data);
VALUE rb_mutex_owned_p(VALUE self);
VALUE rb_exec_recursive_outer_mid(VALUE (*f)(VALUE g, VALUE h, int r), VALUE g, VALUE h, ID mid);
void ruby_mn_threads_params(void);
int rb_thread_wait_for_single_fd(int fd, int events, struct timeval * timeout);
struct rb_io_close_wait_list {
    struct ccan_list_head pending_fd_users;
    VALUE closing_thread;
    VALUE closing_fiber;
    VALUE wakeup_mutex;
};
int rb_notify_fd_close(int fd, struct rb_io_close_wait_list *busy);
void rb_notify_fd_close_wait(struct rb_io_close_wait_list *busy);
void rb_ec_check_ints(struct rb_execution_context_struct *ec);

#pragma GCC visibility push(default)

void *rb_thread_prevent_fork(void *(*func)(void *), void *data);
VALUE rb_thread_io_blocking_region(rb_blocking_function_t *func, void *data1, int fd);
VALUE rb_thread_io_blocking_call(rb_blocking_function_t *func, void *data1, int fd, int events);
int ruby_thread_has_gvl_p(void);

#pragma GCC visibility pop

int rb_threadptr_execute_interrupts(struct rb_thread_struct *th, int blocking_timing);
_Bool rb_thread_mn_schedulable(VALUE thread);
typedef VALUE (rb_interrupt_exec_func_t)(void *data);
enum rb_interrupt_exec_flag {
    rb_interrupt_exec_flag_none = 0x00,
    rb_interrupt_exec_flag_value_data = 0x01,
};
struct rb_ractor_struct;
void rb_threadptr_interrupt_exec(struct rb_thread_struct *target_th,
                                 rb_interrupt_exec_func_t *func, void *data, enum rb_interrupt_exec_flag flags);
void rb_ractor_interrupt_exec(struct rb_ractor_struct *target_r,
                              rb_interrupt_exec_func_t *func, void *data, enum rb_interrupt_exec_flag flags);
void rb_threadptr_interrupt_exec_task_mark(struct rb_thread_struct *th);
typedef enum {
    CONST_DEPRECATED = 0x100,
    CONST_VISIBILITY_MASK = 0xff,
    CONST_PUBLIC = 0x00,
    CONST_PRIVATE,
    CONST_VISIBILITY_MAX
} rb_const_flag_t;
typedef struct rb_const_entry_struct {
    rb_const_flag_t flag;
    int line;
    VALUE value;
    VALUE file;
} rb_const_entry_t;
VALUE rb_mod_private_constant(int argc, const VALUE *argv, VALUE obj);
VALUE rb_mod_public_constant(int argc, const VALUE *argv, VALUE obj);
VALUE rb_mod_deprecate_constant(int argc, const VALUE *argv, VALUE obj);
void rb_free_const_table(struct rb_id_table *tbl);
VALUE rb_const_source_location(VALUE, ID);
int rb_autoloading_value(VALUE mod, ID id, VALUE *value, rb_const_flag_t *flag);
rb_const_entry_t *rb_const_lookup(VALUE klass, ID id);
VALUE rb_public_const_get_at(VALUE klass, ID id);
VALUE rb_public_const_get_from(VALUE klass, ID id);
int rb_public_const_defined_from(VALUE klass, ID id);
VALUE rb_const_source_location_at(VALUE, ID);
typedef uint32_t attr_index_t;
typedef uint32_t shape_id_t;
typedef uint32_t redblack_id_t;
typedef struct redblack_node redblack_node_t;
struct rb_shape {
    struct rb_id_table * edges;
    ID edge_name;
    attr_index_t next_iv_index;
    uint32_t capacity;
    uint8_t type;
    uint8_t heap_index;
    shape_id_t parent_id;
    redblack_node_t * ancestor_index;
};
typedef struct rb_shape rb_shape_t;
struct redblack_node {
    ID key;
    rb_shape_t * value;
    redblack_id_t l;
    redblack_id_t r;
};
enum shape_type {
    SHAPE_ROOT,
    SHAPE_IVAR,
    SHAPE_FROZEN,
    SHAPE_T_OBJECT,
    SHAPE_OBJ_TOO_COMPLEX,
};
typedef struct {
    rb_shape_t *shape_list;
    rb_shape_t *root_shape;
    shape_id_t next_shape_id;
    redblack_node_t *shape_cache;
    unsigned int cache_size;
} rb_shape_tree_t;
extern rb_shape_tree_t *rb_shape_tree_ptr;
static inline rb_shape_tree_t *
rb_current_shape_tree(void)
{
    return rb_shape_tree_ptr;
}
static inline shape_id_t
get_shape_id_from_flags(VALUE obj)
{
    ((void)0);
    return (shape_id_t)((((uintptr_t)1 << 32) - 1) & ((((struct RBasic *)(obj))->flags) >> ((8 * 8) - 32)));
}
static inline void
set_shape_id_in_flags(VALUE obj, shape_id_t shape_id)
{
    ((struct RBasic *)(obj))->flags &= (((VALUE)-1) >> 32);
    ((struct RBasic *)(obj))->flags |= ((VALUE)(shape_id) << ((8 * 8) - 32));
}
static inline shape_id_t
RBASIC_SHAPE_ID(VALUE obj)
{
    return get_shape_id_from_flags(obj);
}
static inline void
RBASIC_SET_SHAPE_ID(VALUE obj, shape_id_t shape_id)
{
    set_shape_id_in_flags(obj, shape_id);
}
static inline shape_id_t
ROBJECT_SHAPE_ID(VALUE obj)
{
    ((void)0);
    return get_shape_id_from_flags(obj);
}
static inline void
ROBJECT_SET_SHAPE_ID(VALUE obj, shape_id_t shape_id)
{
    ((void)0);
    set_shape_id_in_flags(obj, shape_id);
}
static inline shape_id_t
RCLASS_SHAPE_ID(VALUE obj)
{
    ((void)0);
    return get_shape_id_from_flags(obj);
}
static inline void
RCLASS_SET_SHAPE_ID(VALUE obj, shape_id_t shape_id)
{
    ((void)0);
    set_shape_id_in_flags(obj, shape_id);
}
rb_shape_t * rb_shape_get_root_shape(void);
int32_t rb_shape_id_offset(void);
rb_shape_t * rb_shape_get_parent(rb_shape_t * shape);
__attribute__ ((__visibility__("default"))) extern rb_shape_t *rb_shape_get_shape_by_id(shape_id_t shape_id);
__attribute__ ((__visibility__("default"))) extern shape_id_t rb_shape_get_shape_id(VALUE obj);
rb_shape_t * rb_shape_get_next_iv_shape(rb_shape_t * shape, ID id);
_Bool rb_shape_get_iv_index(rb_shape_t * shape, ID id, attr_index_t * value);
_Bool rb_shape_get_iv_index_with_hint(shape_id_t shape_id, ID id, attr_index_t * value, shape_id_t *shape_id_hint);
__attribute__ ((__visibility__("default"))) extern _Bool rb_shape_obj_too_complex(VALUE obj);
void rb_shape_set_shape(VALUE obj, rb_shape_t* shape);
rb_shape_t* rb_shape_get_shape(VALUE obj);
int rb_shape_frozen_shape_p(rb_shape_t* shape);
rb_shape_t* rb_shape_transition_shape_frozen(VALUE obj);
_Bool rb_shape_transition_shape_remove_ivar(VALUE obj, ID id, rb_shape_t *shape, VALUE * removed);
rb_shape_t* rb_shape_get_next(rb_shape_t* shape, VALUE obj, ID id);
rb_shape_t* rb_shape_get_next_no_warnings(rb_shape_t* shape, VALUE obj, ID id);
rb_shape_t * rb_shape_rebuild_shape(rb_shape_t * initial_shape, rb_shape_t * dest_shape);
static inline uint32_t
ROBJECT_IV_CAPACITY(VALUE obj)
{
    ((void)0);
    ((void)0);
    return rb_shape_get_shape_by_id(ROBJECT_SHAPE_ID(obj))->capacity;
}
static inline st_table *
ROBJECT_IV_HASH(VALUE obj)
{
    ((void)0);
    ((void)0);
    return (st_table *)((struct RObject *)(obj))->as.heap.ivptr;
}
static inline void
ROBJECT_SET_IV_HASH(VALUE obj, const st_table *tbl)
{
    ((void)0);
    ((void)0);
    ((struct RObject *)(obj))->as.heap.ivptr = (VALUE *)tbl;
}
size_t rb_id_table_size(const struct rb_id_table *tbl);
static inline uint32_t
ROBJECT_IV_COUNT(VALUE obj)
{
    if (rb_shape_obj_too_complex(obj)) {
        return (uint32_t)rb_st_table_size(ROBJECT_IV_HASH(obj));
    }
    else {
        ((void)0);
        ((void)0);
        return rb_shape_get_shape_by_id(ROBJECT_SHAPE_ID(obj))->next_iv_index;
    }
}
static inline uint32_t
RBASIC_IV_COUNT(VALUE obj)
{
    return rb_shape_get_shape_by_id(rb_shape_get_shape_id(obj))->next_iv_index;
}
rb_shape_t *rb_shape_traverse_from_new_root(rb_shape_t *initial_shape, rb_shape_t *orig_shape);
_Bool rb_shape_set_shape_id(VALUE obj, shape_id_t shape_id);
VALUE rb_obj_debug_shape(VALUE self, VALUE obj);

#pragma GCC visibility push(default)

typedef void each_shape_callback(rb_shape_t * shape, void *data);
void rb_shape_each_shape(each_shape_callback callback, void *data);
size_t rb_shape_memsize(rb_shape_t *shape);
size_t rb_shape_edges_count(rb_shape_t *shape);
size_t rb_shape_depth(rb_shape_t *shape);
shape_id_t rb_shape_id(rb_shape_t * shape);

#pragma GCC visibility pop

void rb_gc_mark_global_tbl(void);
void rb_gc_update_global_tbl(void);
size_t rb_generic_ivar_memsize(VALUE);
VALUE rb_search_class_path(VALUE);
VALUE rb_attr_delete(VALUE, ID);
void rb_autoload_str(VALUE mod, ID id, VALUE file);
VALUE rb_autoload_at_p(VALUE, ID, int);
__attribute__((__noreturn__)) VALUE rb_mod_const_missing(VALUE,VALUE);
rb_gvar_getter_t *rb_gvar_getter_function_of(ID);
rb_gvar_setter_t *rb_gvar_setter_function_of(ID);
void rb_gvar_readonly_setter(VALUE v, ID id, VALUE *_);
void rb_gvar_ractor_local(const char *name);
VALUE rb_mod_set_temporary_name(VALUE, VALUE);
struct gen_ivtbl;
int rb_gen_ivtbl_get(VALUE obj, ID id, struct gen_ivtbl **ivtbl);
void rb_obj_copy_ivs_to_hash_table(VALUE obj, st_table *table);
void rb_obj_convert_to_too_complex(VALUE obj, st_table *table);
void rb_evict_ivars_to_hash(VALUE obj);

#pragma GCC visibility push(default)

void rb_mark_generic_ivar(VALUE obj);
void rb_ref_update_generic_ivar(VALUE);
void rb_mv_generic_ivar(VALUE src, VALUE dst);
VALUE rb_const_missing(VALUE klass, VALUE name);
int rb_class_ivar_set(VALUE klass, ID vid, VALUE value);
void rb_iv_tbl_copy(VALUE dst, VALUE src);

#pragma GCC visibility pop

VALUE rb_ivar_lookup(VALUE obj, ID id, VALUE undef);
VALUE rb_gvar_get(ID);
VALUE rb_gvar_set(ID, VALUE);
VALUE rb_gvar_defined(ID);
void rb_const_warn_if_deprecated(const rb_const_entry_t *, VALUE, ID);
void rb_ensure_iv_list_size(VALUE obj, uint32_t len, uint32_t newsize);
attr_index_t rb_obj_ivar_set(VALUE obj, ID id, VALUE val);
typedef struct {
    const uint8_t *start;
    size_t size;
    size_t capacity;
    size_t *offsets;
} pm_newline_list_t;
typedef struct {
    int32_t line;
    uint32_t column;
} pm_line_column_t;
_Bool pm_newline_list_init(pm_newline_list_t *list, const uint8_t *start, size_t capacity);
void
pm_newline_list_clear(pm_newline_list_t *list);
_Bool pm_newline_list_append(pm_newline_list_t *list, const uint8_t *cursor);
int32_t pm_newline_list_line(const pm_newline_list_t *list, const uint8_t *cursor, int32_t start_line);
pm_line_column_t pm_newline_list_line_column(const pm_newline_list_t *list, const uint8_t *cursor, int32_t start_line);
void pm_newline_list_free(pm_newline_list_t *list);
size_t pm_strspn_whitespace(const uint8_t *string, ptrdiff_t length);
size_t pm_strspn_whitespace_newlines(const uint8_t *string, ptrdiff_t length, pm_newline_list_t *newline_list);
size_t pm_strspn_inline_whitespace(const uint8_t *string, ptrdiff_t length);
size_t pm_strspn_decimal_digit(const uint8_t *string, ptrdiff_t length);
size_t pm_strspn_hexadecimal_digit(const uint8_t *string, ptrdiff_t length);
size_t pm_strspn_octal_number(const uint8_t *string, ptrdiff_t length, const uint8_t **invalid);
size_t pm_strspn_decimal_number(const uint8_t *string, ptrdiff_t length, const uint8_t **invalid);
size_t pm_strspn_hexadecimal_number(const uint8_t *string, ptrdiff_t length, const uint8_t **invalid);
size_t pm_strspn_regexp_option(const uint8_t *string, ptrdiff_t length);
size_t pm_strspn_binary_number(const uint8_t *string, ptrdiff_t length, const uint8_t **invalid);
_Bool pm_char_is_whitespace(const uint8_t b);
_Bool pm_char_is_inline_whitespace(const uint8_t b);
_Bool pm_char_is_binary_digit(const uint8_t b);
_Bool pm_char_is_octal_digit(const uint8_t b);
_Bool pm_char_is_decimal_digit(const uint8_t b);
_Bool pm_char_is_hexadecimal_digit(const uint8_t b);
typedef struct {
    size_t length;
    size_t capacity;
    char *value;
} pm_buffer_t;
 size_t pm_buffer_sizeof(void);
_Bool pm_buffer_init_capacity(pm_buffer_t *buffer, size_t capacity);
 _Bool pm_buffer_init(pm_buffer_t *buffer);
 char * pm_buffer_value(const pm_buffer_t *buffer);
 size_t pm_buffer_length(const pm_buffer_t *buffer);
void pm_buffer_append_zeroes(pm_buffer_t *buffer, size_t length);
void pm_buffer_append_format(pm_buffer_t *buffer, const char *format, ...) __attribute__((format(printf, 2, 3)));
void pm_buffer_append_string(pm_buffer_t *buffer, const char *value, size_t length);
void pm_buffer_append_bytes(pm_buffer_t *buffer, const uint8_t *value, size_t length);
void pm_buffer_append_byte(pm_buffer_t *buffer, uint8_t value);
void pm_buffer_append_varuint(pm_buffer_t *buffer, uint32_t value);
void pm_buffer_append_varsint(pm_buffer_t *buffer, int32_t value);
void pm_buffer_append_double(pm_buffer_t *buffer, double value);
typedef enum {
    PM_BUFFER_ESCAPING_RUBY,
    PM_BUFFER_ESCAPING_JSON
} pm_buffer_escaping_t;
void pm_buffer_append_source(pm_buffer_t *buffer, const uint8_t *source, size_t length, pm_buffer_escaping_t escaping);
void pm_buffer_prepend_string(pm_buffer_t *buffer, const char *value, size_t length);
void pm_buffer_concat(pm_buffer_t *destination, const pm_buffer_t *source);
void pm_buffer_clear(pm_buffer_t *buffer);
void pm_buffer_rstrip(pm_buffer_t *buffer);
size_t pm_buffer_index(const pm_buffer_t *buffer, char value);
void pm_buffer_insert(pm_buffer_t *buffer, size_t index, const char *value, size_t length);
 void pm_buffer_free(pm_buffer_t *buffer);
typedef struct {
    size_t length;
    uint32_t *values;
    uint32_t value;
    _Bool negative;
} pm_integer_t;
typedef enum {
    PM_INTEGER_BASE_DEFAULT,
    PM_INTEGER_BASE_BINARY,
    PM_INTEGER_BASE_OCTAL,
    PM_INTEGER_BASE_DECIMAL,
    PM_INTEGER_BASE_HEXADECIMAL,
    PM_INTEGER_BASE_UNKNOWN
} pm_integer_base_t;
void pm_integer_parse(pm_integer_t *integer, pm_integer_base_t base, const uint8_t *start, const uint8_t *end);
int pm_integer_compare(const pm_integer_t *left, const pm_integer_t *right);
void pm_integers_reduce(pm_integer_t *numerator, pm_integer_t *denominator);
 void pm_integer_string(pm_buffer_t *buffer, const pm_integer_t *integer);
 void pm_integer_free(pm_integer_t *integer);
int pm_strncasecmp(const uint8_t *string1, const uint8_t *string2, size_t length);
typedef struct {
    size_t (*char_width)(const uint8_t *b, ptrdiff_t n);
    size_t (*alpha_char)(const uint8_t *b, ptrdiff_t n);
    size_t (*alnum_char)(const uint8_t *b, ptrdiff_t n);
    _Bool (*isupper_char)(const uint8_t *b, ptrdiff_t n);
    const char *name;
    _Bool multibyte;
} pm_encoding_t;
size_t pm_encoding_utf_8_char_width(const uint8_t *b, ptrdiff_t n);
size_t pm_encoding_utf_8_alpha_char(const uint8_t *b, ptrdiff_t n);
size_t pm_encoding_utf_8_alnum_char(const uint8_t *b, ptrdiff_t n);
_Bool pm_encoding_utf_8_isupper_char(const uint8_t *b, ptrdiff_t n);
extern const uint8_t pm_encoding_unicode_table[256];
typedef enum {
    PM_ENCODING_UTF_8 = 0,
    PM_ENCODING_US_ASCII,
    PM_ENCODING_ASCII_8BIT,
    PM_ENCODING_EUC_JP,
    PM_ENCODING_WINDOWS_31J,
    PM_ENCODING_BIG5,
    PM_ENCODING_BIG5_HKSCS,
    PM_ENCODING_BIG5_UAO,
    PM_ENCODING_CESU_8,
    PM_ENCODING_CP51932,
    PM_ENCODING_CP850,
    PM_ENCODING_CP852,
    PM_ENCODING_CP855,
    PM_ENCODING_CP949,
    PM_ENCODING_CP950,
    PM_ENCODING_CP951,
    PM_ENCODING_EMACS_MULE,
    PM_ENCODING_EUC_JP_MS,
    PM_ENCODING_EUC_JIS_2004,
    PM_ENCODING_EUC_KR,
    PM_ENCODING_EUC_TW,
    PM_ENCODING_GB12345,
    PM_ENCODING_GB18030,
    PM_ENCODING_GB1988,
    PM_ENCODING_GB2312,
    PM_ENCODING_GBK,
    PM_ENCODING_IBM437,
    PM_ENCODING_IBM720,
    PM_ENCODING_IBM737,
    PM_ENCODING_IBM775,
    PM_ENCODING_IBM852,
    PM_ENCODING_IBM855,
    PM_ENCODING_IBM857,
    PM_ENCODING_IBM860,
    PM_ENCODING_IBM861,
    PM_ENCODING_IBM862,
    PM_ENCODING_IBM863,
    PM_ENCODING_IBM864,
    PM_ENCODING_IBM865,
    PM_ENCODING_IBM866,
    PM_ENCODING_IBM869,
    PM_ENCODING_ISO_8859_1,
    PM_ENCODING_ISO_8859_2,
    PM_ENCODING_ISO_8859_3,
    PM_ENCODING_ISO_8859_4,
    PM_ENCODING_ISO_8859_5,
    PM_ENCODING_ISO_8859_6,
    PM_ENCODING_ISO_8859_7,
    PM_ENCODING_ISO_8859_8,
    PM_ENCODING_ISO_8859_9,
    PM_ENCODING_ISO_8859_10,
    PM_ENCODING_ISO_8859_11,
    PM_ENCODING_ISO_8859_13,
    PM_ENCODING_ISO_8859_14,
    PM_ENCODING_ISO_8859_15,
    PM_ENCODING_ISO_8859_16,
    PM_ENCODING_KOI8_R,
    PM_ENCODING_KOI8_U,
    PM_ENCODING_MAC_CENT_EURO,
    PM_ENCODING_MAC_CROATIAN,
    PM_ENCODING_MAC_CYRILLIC,
    PM_ENCODING_MAC_GREEK,
    PM_ENCODING_MAC_ICELAND,
    PM_ENCODING_MAC_JAPANESE,
    PM_ENCODING_MAC_ROMAN,
    PM_ENCODING_MAC_ROMANIA,
    PM_ENCODING_MAC_THAI,
    PM_ENCODING_MAC_TURKISH,
    PM_ENCODING_MAC_UKRAINE,
    PM_ENCODING_SHIFT_JIS,
    PM_ENCODING_SJIS_DOCOMO,
    PM_ENCODING_SJIS_KDDI,
    PM_ENCODING_SJIS_SOFTBANK,
    PM_ENCODING_STATELESS_ISO_2022_JP,
    PM_ENCODING_STATELESS_ISO_2022_JP_KDDI,
    PM_ENCODING_TIS_620,
    PM_ENCODING_UTF8_MAC,
    PM_ENCODING_UTF8_DOCOMO,
    PM_ENCODING_UTF8_KDDI,
    PM_ENCODING_UTF8_SOFTBANK,
    PM_ENCODING_WINDOWS_1250,
    PM_ENCODING_WINDOWS_1251,
    PM_ENCODING_WINDOWS_1252,
    PM_ENCODING_WINDOWS_1253,
    PM_ENCODING_WINDOWS_1254,
    PM_ENCODING_WINDOWS_1255,
    PM_ENCODING_WINDOWS_1256,
    PM_ENCODING_WINDOWS_1257,
    PM_ENCODING_WINDOWS_1258,
    PM_ENCODING_WINDOWS_874,
    PM_ENCODING_MAXIMUM
} pm_encoding_type_t;
extern const pm_encoding_t pm_encodings[PM_ENCODING_MAXIMUM];
const pm_encoding_t * pm_encoding_find(const uint8_t *start, const uint8_t *end);
void * pm_memchr(const void *source, int character, size_t number, _Bool encoding_changed, const pm_encoding_t *encoding);
typedef uint32_t pm_constant_id_t;
typedef struct {
    size_t size;
    size_t capacity;
    pm_constant_id_t *ids;
} pm_constant_id_list_t;
void pm_constant_id_list_init(pm_constant_id_list_t *list);
void pm_constant_id_list_init_capacity(pm_constant_id_list_t *list, size_t capacity);
_Bool pm_constant_id_list_append(pm_constant_id_list_t *list, pm_constant_id_t id);
void pm_constant_id_list_insert(pm_constant_id_list_t *list, size_t index, pm_constant_id_t id);
_Bool pm_constant_id_list_includes(pm_constant_id_list_t *list, pm_constant_id_t id);
void pm_constant_id_list_free(pm_constant_id_list_t *list);
typedef unsigned int pm_constant_pool_bucket_type_t;
static const pm_constant_pool_bucket_type_t PM_CONSTANT_POOL_BUCKET_DEFAULT = 0;
static const pm_constant_pool_bucket_type_t PM_CONSTANT_POOL_BUCKET_OWNED = 1;
static const pm_constant_pool_bucket_type_t PM_CONSTANT_POOL_BUCKET_CONSTANT = 2;
typedef struct {
    unsigned int id: 30;
    pm_constant_pool_bucket_type_t type: 2;
    uint32_t hash;
} pm_constant_pool_bucket_t;
typedef struct {
    const uint8_t *start;
    size_t length;
} pm_constant_t;
typedef struct {
    pm_constant_pool_bucket_t *buckets;
    pm_constant_t *constants;
    uint32_t size;
    uint32_t capacity;
} pm_constant_pool_t;
_Bool pm_constant_pool_init(pm_constant_pool_t *pool, uint32_t capacity);
pm_constant_t * pm_constant_pool_id_to_constant(const pm_constant_pool_t *pool, pm_constant_id_t constant_id);
pm_constant_id_t pm_constant_pool_find(const pm_constant_pool_t *pool, const uint8_t *start, size_t length);
pm_constant_id_t pm_constant_pool_insert_shared(pm_constant_pool_t *pool, const uint8_t *start, size_t length);
pm_constant_id_t pm_constant_pool_insert_owned(pm_constant_pool_t *pool, uint8_t *start, size_t length);
pm_constant_id_t pm_constant_pool_insert_constant(pm_constant_pool_t *pool, const uint8_t *start, size_t length);
void pm_constant_pool_free(pm_constant_pool_t *pool);

struct flock
  {
    short int l_type;
    short int l_whence;
    __off_t l_start;
    __off_t l_len;
    __pid_t l_pid;
  };
struct flock64
  {
    short int l_type;
    short int l_whence;
    __off64_t l_start;
    __off64_t l_len;
    __pid_t l_pid;
  };
struct iovec
  {
    void *iov_base;
    size_t iov_len;
  };
enum __pid_type
  {
    F_OWNER_TID = 0,
    F_OWNER_PID,
    F_OWNER_PGRP,
    F_OWNER_GID = F_OWNER_PGRP
  };
struct f_owner_ex
  {
    enum __pid_type type;
    __pid_t pid;
  };
struct file_handle
{
  unsigned int handle_bytes;
  int handle_type;
  unsigned char f_handle[0];
};

extern __ssize_t readahead (int __fd, __off64_t __offset, size_t __count)
    __attribute__ ((__nothrow__ , __leaf__));
extern int sync_file_range (int __fd, __off64_t __offset, __off64_t __count,
       unsigned int __flags);
extern __ssize_t vmsplice (int __fdout, const struct iovec *__iov,
      size_t __count, unsigned int __flags);
extern __ssize_t splice (int __fdin, __off64_t *__offin, int __fdout,
    __off64_t *__offout, size_t __len,
    unsigned int __flags);
extern __ssize_t tee (int __fdin, int __fdout, size_t __len,
        unsigned int __flags);
extern int fallocate (int __fd, int __mode, __off_t __offset, __off_t __len);
extern int fallocate64 (int __fd, int __mode, __off64_t __offset,
   __off64_t __len);
extern int name_to_handle_at (int __dfd, const char *__name,
         struct file_handle *__handle, int *__mnt_id,
         int __flags) __attribute__ ((__nothrow__ , __leaf__));
extern int open_by_handle_at (int __mountdirfd, struct file_handle *__handle,
         int __flags);

extern int fcntl (int __fd, int __cmd, ...);
extern int fcntl64 (int __fd, int __cmd, ...);
extern int open (const char *__file, int __oflag, ...) __attribute__ ((__nonnull__ (1)));
extern int open64 (const char *__file, int __oflag, ...) __attribute__ ((__nonnull__ (1)));
extern int openat (int __fd, const char *__file, int __oflag, ...)
     __attribute__ ((__nonnull__ (2)));
extern int openat64 (int __fd, const char *__file, int __oflag, ...)
     __attribute__ ((__nonnull__ (2)));
extern int creat (const char *__file, mode_t __mode) __attribute__ ((__nonnull__ (1)));
extern int creat64 (const char *__file, mode_t __mode) __attribute__ ((__nonnull__ (1)));
extern int posix_fadvise (int __fd, off_t __offset, off_t __len,
     int __advise) __attribute__ ((__nothrow__ , __leaf__));
extern int posix_fadvise64 (int __fd, off64_t __offset, off64_t __len,
       int __advise) __attribute__ ((__nothrow__ , __leaf__));
extern int posix_fallocate (int __fd, off_t __offset, off_t __len);
extern int posix_fallocate64 (int __fd, off64_t __offset, off64_t __len);


int memfd_create (const char *__name, unsigned int __flags) __attribute__ ((__nothrow__ , __leaf__));
int mlock2 (const void *__addr, size_t __length, unsigned int __flags) __attribute__ ((__nothrow__ , __leaf__));
int pkey_alloc (unsigned int __flags, unsigned int __access_rights) __attribute__ ((__nothrow__ , __leaf__));
int pkey_set (int __key, unsigned int __access_rights) __attribute__ ((__nothrow__ , __leaf__));
int pkey_get (int __key) __attribute__ ((__nothrow__ , __leaf__));
int pkey_free (int __key) __attribute__ ((__nothrow__ , __leaf__));
int pkey_mprotect (void *__addr, size_t __len, int __prot, int __pkey) __attribute__ ((__nothrow__ , __leaf__));


extern void *mmap (void *__addr, size_t __len, int __prot,
     int __flags, int __fd, __off_t __offset) __attribute__ ((__nothrow__ , __leaf__));
extern void *mmap64 (void *__addr, size_t __len, int __prot,
       int __flags, int __fd, __off64_t __offset) __attribute__ ((__nothrow__ , __leaf__));
extern int munmap (void *__addr, size_t __len) __attribute__ ((__nothrow__ , __leaf__));
extern int mprotect (void *__addr, size_t __len, int __prot) __attribute__ ((__nothrow__ , __leaf__));
extern int msync (void *__addr, size_t __len, int __flags);
extern int madvise (void *__addr, size_t __len, int __advice) __attribute__ ((__nothrow__ , __leaf__));
extern int posix_madvise (void *__addr, size_t __len, int __advice) __attribute__ ((__nothrow__ , __leaf__));
extern int mlock (const void *__addr, size_t __len) __attribute__ ((__nothrow__ , __leaf__));
extern int munlock (const void *__addr, size_t __len) __attribute__ ((__nothrow__ , __leaf__));
extern int mlockall (int __flags) __attribute__ ((__nothrow__ , __leaf__));
extern int munlockall (void) __attribute__ ((__nothrow__ , __leaf__));
extern int mincore (void *__start, size_t __len, unsigned char *__vec)
     __attribute__ ((__nothrow__ , __leaf__));
extern void *mremap (void *__addr, size_t __old_len, size_t __new_len,
       int __flags, ...) __attribute__ ((__nothrow__ , __leaf__));
extern int remap_file_pages (void *__start, size_t __size, int __prot,
        size_t __pgoff, int __flags) __attribute__ ((__nothrow__ , __leaf__));
extern int shm_open (const char *__name, int __oflag, mode_t __mode);
extern int shm_unlink (const char *__name);

typedef struct {
    const uint8_t *source;
    size_t length;
    enum {
        PM_STRING_CONSTANT,
        PM_STRING_SHARED,
        PM_STRING_OWNED,
        PM_STRING_MAPPED
    } type;
} pm_string_t;
 size_t pm_string_sizeof(void);
void pm_string_shared_init(pm_string_t *string, const uint8_t *start, const uint8_t *end);
void pm_string_owned_init(pm_string_t *string, uint8_t *source, size_t length);
void pm_string_constant_init(pm_string_t *string, const char *source, size_t length);
typedef enum {
    PM_STRING_INIT_SUCCESS = 0,
    PM_STRING_INIT_ERROR_GENERIC = 1,
    PM_STRING_INIT_ERROR_DIRECTORY = 2
} pm_string_init_result_t;
 pm_string_init_result_t pm_string_mapped_init(pm_string_t *string, const char *filepath);
 pm_string_init_result_t pm_string_file_init(pm_string_t *string, const char *filepath);
void pm_string_ensure_owned(pm_string_t *string);
int pm_string_compare(const pm_string_t *left, const pm_string_t *right);
 size_t pm_string_length(const pm_string_t *string);
 const uint8_t * pm_string_source(const pm_string_t *string);
 void pm_string_free(pm_string_t *string);
typedef enum pm_token_type {
    PM_TOKEN_EOF = 1,
    PM_TOKEN_MISSING,
    PM_TOKEN_NOT_PROVIDED,
    PM_TOKEN_AMPERSAND,
    PM_TOKEN_AMPERSAND_AMPERSAND,
    PM_TOKEN_AMPERSAND_AMPERSAND_EQUAL,
    PM_TOKEN_AMPERSAND_DOT,
    PM_TOKEN_AMPERSAND_EQUAL,
    PM_TOKEN_BACKTICK,
    PM_TOKEN_BACK_REFERENCE,
    PM_TOKEN_BANG,
    PM_TOKEN_BANG_EQUAL,
    PM_TOKEN_BANG_TILDE,
    PM_TOKEN_BRACE_LEFT,
    PM_TOKEN_BRACE_RIGHT,
    PM_TOKEN_BRACKET_LEFT,
    PM_TOKEN_BRACKET_LEFT_ARRAY,
    PM_TOKEN_BRACKET_LEFT_RIGHT,
    PM_TOKEN_BRACKET_LEFT_RIGHT_EQUAL,
    PM_TOKEN_BRACKET_RIGHT,
    PM_TOKEN_CARET,
    PM_TOKEN_CARET_EQUAL,
    PM_TOKEN_CHARACTER_LITERAL,
    PM_TOKEN_CLASS_VARIABLE,
    PM_TOKEN_COLON,
    PM_TOKEN_COLON_COLON,
    PM_TOKEN_COMMA,
    PM_TOKEN_COMMENT,
    PM_TOKEN_CONSTANT,
    PM_TOKEN_DOT,
    PM_TOKEN_DOT_DOT,
    PM_TOKEN_DOT_DOT_DOT,
    PM_TOKEN_EMBDOC_BEGIN,
    PM_TOKEN_EMBDOC_END,
    PM_TOKEN_EMBDOC_LINE,
    PM_TOKEN_EMBEXPR_BEGIN,
    PM_TOKEN_EMBEXPR_END,
    PM_TOKEN_EMBVAR,
    PM_TOKEN_EQUAL,
    PM_TOKEN_EQUAL_EQUAL,
    PM_TOKEN_EQUAL_EQUAL_EQUAL,
    PM_TOKEN_EQUAL_GREATER,
    PM_TOKEN_EQUAL_TILDE,
    PM_TOKEN_FLOAT,
    PM_TOKEN_FLOAT_IMAGINARY,
    PM_TOKEN_FLOAT_RATIONAL,
    PM_TOKEN_FLOAT_RATIONAL_IMAGINARY,
    PM_TOKEN_GLOBAL_VARIABLE,
    PM_TOKEN_GREATER,
    PM_TOKEN_GREATER_EQUAL,
    PM_TOKEN_GREATER_GREATER,
    PM_TOKEN_GREATER_GREATER_EQUAL,
    PM_TOKEN_HEREDOC_END,
    PM_TOKEN_HEREDOC_START,
    PM_TOKEN_IDENTIFIER,
    PM_TOKEN_IGNORED_NEWLINE,
    PM_TOKEN_INSTANCE_VARIABLE,
    PM_TOKEN_INTEGER,
    PM_TOKEN_INTEGER_IMAGINARY,
    PM_TOKEN_INTEGER_RATIONAL,
    PM_TOKEN_INTEGER_RATIONAL_IMAGINARY,
    PM_TOKEN_KEYWORD_ALIAS,
    PM_TOKEN_KEYWORD_AND,
    PM_TOKEN_KEYWORD_BEGIN,
    PM_TOKEN_KEYWORD_BEGIN_UPCASE,
    PM_TOKEN_KEYWORD_BREAK,
    PM_TOKEN_KEYWORD_CASE,
    PM_TOKEN_KEYWORD_CLASS,
    PM_TOKEN_KEYWORD_DEF,
    PM_TOKEN_KEYWORD_DEFINED,
    PM_TOKEN_KEYWORD_DO,
    PM_TOKEN_KEYWORD_DO_LOOP,
    PM_TOKEN_KEYWORD_ELSE,
    PM_TOKEN_KEYWORD_ELSIF,
    PM_TOKEN_KEYWORD_END,
    PM_TOKEN_KEYWORD_END_UPCASE,
    PM_TOKEN_KEYWORD_ENSURE,
    PM_TOKEN_KEYWORD_FALSE,
    PM_TOKEN_KEYWORD_FOR,
    PM_TOKEN_KEYWORD_IF,
    PM_TOKEN_KEYWORD_IF_MODIFIER,
    PM_TOKEN_KEYWORD_IN,
    PM_TOKEN_KEYWORD_MODULE,
    PM_TOKEN_KEYWORD_NEXT,
    PM_TOKEN_KEYWORD_NIL,
    PM_TOKEN_KEYWORD_NOT,
    PM_TOKEN_KEYWORD_OR,
    PM_TOKEN_KEYWORD_REDO,
    PM_TOKEN_KEYWORD_RESCUE,
    PM_TOKEN_KEYWORD_RESCUE_MODIFIER,
    PM_TOKEN_KEYWORD_RETRY,
    PM_TOKEN_KEYWORD_RETURN,
    PM_TOKEN_KEYWORD_SELF,
    PM_TOKEN_KEYWORD_SUPER,
    PM_TOKEN_KEYWORD_THEN,
    PM_TOKEN_KEYWORD_TRUE,
    PM_TOKEN_KEYWORD_UNDEF,
    PM_TOKEN_KEYWORD_UNLESS,
    PM_TOKEN_KEYWORD_UNLESS_MODIFIER,
    PM_TOKEN_KEYWORD_UNTIL,
    PM_TOKEN_KEYWORD_UNTIL_MODIFIER,
    PM_TOKEN_KEYWORD_WHEN,
    PM_TOKEN_KEYWORD_WHILE,
    PM_TOKEN_KEYWORD_WHILE_MODIFIER,
    PM_TOKEN_KEYWORD_YIELD,
    PM_TOKEN_KEYWORD___ENCODING__,
    PM_TOKEN_KEYWORD___FILE__,
    PM_TOKEN_KEYWORD___LINE__,
    PM_TOKEN_LABEL,
    PM_TOKEN_LABEL_END,
    PM_TOKEN_LAMBDA_BEGIN,
    PM_TOKEN_LESS,
    PM_TOKEN_LESS_EQUAL,
    PM_TOKEN_LESS_EQUAL_GREATER,
    PM_TOKEN_LESS_LESS,
    PM_TOKEN_LESS_LESS_EQUAL,
    PM_TOKEN_METHOD_NAME,
    PM_TOKEN_MINUS,
    PM_TOKEN_MINUS_EQUAL,
    PM_TOKEN_MINUS_GREATER,
    PM_TOKEN_NEWLINE,
    PM_TOKEN_NUMBERED_REFERENCE,
    PM_TOKEN_PARENTHESIS_LEFT,
    PM_TOKEN_PARENTHESIS_LEFT_PARENTHESES,
    PM_TOKEN_PARENTHESIS_RIGHT,
    PM_TOKEN_PERCENT,
    PM_TOKEN_PERCENT_EQUAL,
    PM_TOKEN_PERCENT_LOWER_I,
    PM_TOKEN_PERCENT_LOWER_W,
    PM_TOKEN_PERCENT_LOWER_X,
    PM_TOKEN_PERCENT_UPPER_I,
    PM_TOKEN_PERCENT_UPPER_W,
    PM_TOKEN_PIPE,
    PM_TOKEN_PIPE_EQUAL,
    PM_TOKEN_PIPE_PIPE,
    PM_TOKEN_PIPE_PIPE_EQUAL,
    PM_TOKEN_PLUS,
    PM_TOKEN_PLUS_EQUAL,
    PM_TOKEN_QUESTION_MARK,
    PM_TOKEN_REGEXP_BEGIN,
    PM_TOKEN_REGEXP_END,
    PM_TOKEN_SEMICOLON,
    PM_TOKEN_SLASH,
    PM_TOKEN_SLASH_EQUAL,
    PM_TOKEN_STAR,
    PM_TOKEN_STAR_EQUAL,
    PM_TOKEN_STAR_STAR,
    PM_TOKEN_STAR_STAR_EQUAL,
    PM_TOKEN_STRING_BEGIN,
    PM_TOKEN_STRING_CONTENT,
    PM_TOKEN_STRING_END,
    PM_TOKEN_SYMBOL_BEGIN,
    PM_TOKEN_TILDE,
    PM_TOKEN_UAMPERSAND,
    PM_TOKEN_UCOLON_COLON,
    PM_TOKEN_UDOT_DOT,
    PM_TOKEN_UDOT_DOT_DOT,
    PM_TOKEN_UMINUS,
    PM_TOKEN_UMINUS_NUM,
    PM_TOKEN_UPLUS,
    PM_TOKEN_USTAR,
    PM_TOKEN_USTAR_STAR,
    PM_TOKEN_WORDS_SEP,
    PM_TOKEN___END__,
    PM_TOKEN_MAXIMUM,
} pm_token_type_t;
typedef struct {
    pm_token_type_t type;
    const uint8_t *start;
    const uint8_t *end;
} pm_token_t;
typedef struct {
    const uint8_t *start;
    const uint8_t *end;
} pm_location_t;
struct pm_node;
typedef struct pm_node_list {
    size_t size;
    size_t capacity;
    struct pm_node **nodes;
} pm_node_list_t;
enum pm_node_type {
    PM_ALIAS_GLOBAL_VARIABLE_NODE = 1,
    PM_ALIAS_METHOD_NODE = 2,
    PM_ALTERNATION_PATTERN_NODE = 3,
    PM_AND_NODE = 4,
    PM_ARGUMENTS_NODE = 5,
    PM_ARRAY_NODE = 6,
    PM_ARRAY_PATTERN_NODE = 7,
    PM_ASSOC_NODE = 8,
    PM_ASSOC_SPLAT_NODE = 9,
    PM_BACK_REFERENCE_READ_NODE = 10,
    PM_BEGIN_NODE = 11,
    PM_BLOCK_ARGUMENT_NODE = 12,
    PM_BLOCK_LOCAL_VARIABLE_NODE = 13,
    PM_BLOCK_NODE = 14,
    PM_BLOCK_PARAMETER_NODE = 15,
    PM_BLOCK_PARAMETERS_NODE = 16,
    PM_BREAK_NODE = 17,
    PM_CALL_AND_WRITE_NODE = 18,
    PM_CALL_NODE = 19,
    PM_CALL_OPERATOR_WRITE_NODE = 20,
    PM_CALL_OR_WRITE_NODE = 21,
    PM_CALL_TARGET_NODE = 22,
    PM_CAPTURE_PATTERN_NODE = 23,
    PM_CASE_MATCH_NODE = 24,
    PM_CASE_NODE = 25,
    PM_CLASS_NODE = 26,
    PM_CLASS_VARIABLE_AND_WRITE_NODE = 27,
    PM_CLASS_VARIABLE_OPERATOR_WRITE_NODE = 28,
    PM_CLASS_VARIABLE_OR_WRITE_NODE = 29,
    PM_CLASS_VARIABLE_READ_NODE = 30,
    PM_CLASS_VARIABLE_TARGET_NODE = 31,
    PM_CLASS_VARIABLE_WRITE_NODE = 32,
    PM_CONSTANT_AND_WRITE_NODE = 33,
    PM_CONSTANT_OPERATOR_WRITE_NODE = 34,
    PM_CONSTANT_OR_WRITE_NODE = 35,
    PM_CONSTANT_PATH_AND_WRITE_NODE = 36,
    PM_CONSTANT_PATH_NODE = 37,
    PM_CONSTANT_PATH_OPERATOR_WRITE_NODE = 38,
    PM_CONSTANT_PATH_OR_WRITE_NODE = 39,
    PM_CONSTANT_PATH_TARGET_NODE = 40,
    PM_CONSTANT_PATH_WRITE_NODE = 41,
    PM_CONSTANT_READ_NODE = 42,
    PM_CONSTANT_TARGET_NODE = 43,
    PM_CONSTANT_WRITE_NODE = 44,
    PM_DEF_NODE = 45,
    PM_DEFINED_NODE = 46,
    PM_ELSE_NODE = 47,
    PM_EMBEDDED_STATEMENTS_NODE = 48,
    PM_EMBEDDED_VARIABLE_NODE = 49,
    PM_ENSURE_NODE = 50,
    PM_FALSE_NODE = 51,
    PM_FIND_PATTERN_NODE = 52,
    PM_FLIP_FLOP_NODE = 53,
    PM_FLOAT_NODE = 54,
    PM_FOR_NODE = 55,
    PM_FORWARDING_ARGUMENTS_NODE = 56,
    PM_FORWARDING_PARAMETER_NODE = 57,
    PM_FORWARDING_SUPER_NODE = 58,
    PM_GLOBAL_VARIABLE_AND_WRITE_NODE = 59,
    PM_GLOBAL_VARIABLE_OPERATOR_WRITE_NODE = 60,
    PM_GLOBAL_VARIABLE_OR_WRITE_NODE = 61,
    PM_GLOBAL_VARIABLE_READ_NODE = 62,
    PM_GLOBAL_VARIABLE_TARGET_NODE = 63,
    PM_GLOBAL_VARIABLE_WRITE_NODE = 64,
    PM_HASH_NODE = 65,
    PM_HASH_PATTERN_NODE = 66,
    PM_IF_NODE = 67,
    PM_IMAGINARY_NODE = 68,
    PM_IMPLICIT_NODE = 69,
    PM_IMPLICIT_REST_NODE = 70,
    PM_IN_NODE = 71,
    PM_INDEX_AND_WRITE_NODE = 72,
    PM_INDEX_OPERATOR_WRITE_NODE = 73,
    PM_INDEX_OR_WRITE_NODE = 74,
    PM_INDEX_TARGET_NODE = 75,
    PM_INSTANCE_VARIABLE_AND_WRITE_NODE = 76,
    PM_INSTANCE_VARIABLE_OPERATOR_WRITE_NODE = 77,
    PM_INSTANCE_VARIABLE_OR_WRITE_NODE = 78,
    PM_INSTANCE_VARIABLE_READ_NODE = 79,
    PM_INSTANCE_VARIABLE_TARGET_NODE = 80,
    PM_INSTANCE_VARIABLE_WRITE_NODE = 81,
    PM_INTEGER_NODE = 82,
    PM_INTERPOLATED_MATCH_LAST_LINE_NODE = 83,
    PM_INTERPOLATED_REGULAR_EXPRESSION_NODE = 84,
    PM_INTERPOLATED_STRING_NODE = 85,
    PM_INTERPOLATED_SYMBOL_NODE = 86,
    PM_INTERPOLATED_X_STRING_NODE = 87,
    PM_IT_LOCAL_VARIABLE_READ_NODE = 88,
    PM_IT_PARAMETERS_NODE = 89,
    PM_KEYWORD_HASH_NODE = 90,
    PM_KEYWORD_REST_PARAMETER_NODE = 91,
    PM_LAMBDA_NODE = 92,
    PM_LOCAL_VARIABLE_AND_WRITE_NODE = 93,
    PM_LOCAL_VARIABLE_OPERATOR_WRITE_NODE = 94,
    PM_LOCAL_VARIABLE_OR_WRITE_NODE = 95,
    PM_LOCAL_VARIABLE_READ_NODE = 96,
    PM_LOCAL_VARIABLE_TARGET_NODE = 97,
    PM_LOCAL_VARIABLE_WRITE_NODE = 98,
    PM_MATCH_LAST_LINE_NODE = 99,
    PM_MATCH_PREDICATE_NODE = 100,
    PM_MATCH_REQUIRED_NODE = 101,
    PM_MATCH_WRITE_NODE = 102,
    PM_MISSING_NODE = 103,
    PM_MODULE_NODE = 104,
    PM_MULTI_TARGET_NODE = 105,
    PM_MULTI_WRITE_NODE = 106,
    PM_NEXT_NODE = 107,
    PM_NIL_NODE = 108,
    PM_NO_KEYWORDS_PARAMETER_NODE = 109,
    PM_NUMBERED_PARAMETERS_NODE = 110,
    PM_NUMBERED_REFERENCE_READ_NODE = 111,
    PM_OPTIONAL_KEYWORD_PARAMETER_NODE = 112,
    PM_OPTIONAL_PARAMETER_NODE = 113,
    PM_OR_NODE = 114,
    PM_PARAMETERS_NODE = 115,
    PM_PARENTHESES_NODE = 116,
    PM_PINNED_EXPRESSION_NODE = 117,
    PM_PINNED_VARIABLE_NODE = 118,
    PM_POST_EXECUTION_NODE = 119,
    PM_PRE_EXECUTION_NODE = 120,
    PM_PROGRAM_NODE = 121,
    PM_RANGE_NODE = 122,
    PM_RATIONAL_NODE = 123,
    PM_REDO_NODE = 124,
    PM_REGULAR_EXPRESSION_NODE = 125,
    PM_REQUIRED_KEYWORD_PARAMETER_NODE = 126,
    PM_REQUIRED_PARAMETER_NODE = 127,
    PM_RESCUE_MODIFIER_NODE = 128,
    PM_RESCUE_NODE = 129,
    PM_REST_PARAMETER_NODE = 130,
    PM_RETRY_NODE = 131,
    PM_RETURN_NODE = 132,
    PM_SELF_NODE = 133,
    PM_SHAREABLE_CONSTANT_NODE = 134,
    PM_SINGLETON_CLASS_NODE = 135,
    PM_SOURCE_ENCODING_NODE = 136,
    PM_SOURCE_FILE_NODE = 137,
    PM_SOURCE_LINE_NODE = 138,
    PM_SPLAT_NODE = 139,
    PM_STATEMENTS_NODE = 140,
    PM_STRING_NODE = 141,
    PM_SUPER_NODE = 142,
    PM_SYMBOL_NODE = 143,
    PM_TRUE_NODE = 144,
    PM_UNDEF_NODE = 145,
    PM_UNLESS_NODE = 146,
    PM_UNTIL_NODE = 147,
    PM_WHEN_NODE = 148,
    PM_WHILE_NODE = 149,
    PM_X_STRING_NODE = 150,
    PM_YIELD_NODE = 151,
    PM_SCOPE_NODE
};
typedef uint16_t pm_node_type_t;
typedef uint16_t pm_node_flags_t;
static const pm_node_flags_t PM_NODE_FLAG_NEWLINE = 0x1;
static const pm_node_flags_t PM_NODE_FLAG_STATIC_LITERAL = 0x2;
typedef struct pm_node {
    pm_node_type_t type;
    pm_node_flags_t flags;
    uint32_t node_id;
    pm_location_t location;
} pm_node_t;
typedef struct pm_alias_global_variable_node {
    pm_node_t base;
    struct pm_node *new_name;
    struct pm_node *old_name;
    pm_location_t keyword_loc;
} pm_alias_global_variable_node_t;
typedef struct pm_alias_method_node {
    pm_node_t base;
    struct pm_node *new_name;
    struct pm_node *old_name;
    pm_location_t keyword_loc;
} pm_alias_method_node_t;
typedef struct pm_alternation_pattern_node {
    pm_node_t base;
    struct pm_node *left;
    struct pm_node *right;
    pm_location_t operator_loc;
} pm_alternation_pattern_node_t;
typedef struct pm_and_node {
    pm_node_t base;
    struct pm_node *left;
    struct pm_node *right;
    pm_location_t operator_loc;
} pm_and_node_t;
typedef struct pm_arguments_node {
    pm_node_t base;
    struct pm_node_list arguments;
} pm_arguments_node_t;
typedef struct pm_array_node {
    pm_node_t base;
    struct pm_node_list elements;
    pm_location_t opening_loc;
    pm_location_t closing_loc;
} pm_array_node_t;
typedef struct pm_array_pattern_node {
    pm_node_t base;
    struct pm_node *constant;
    struct pm_node_list requireds;
    struct pm_node *rest;
    struct pm_node_list posts;
    pm_location_t opening_loc;
    pm_location_t closing_loc;
} pm_array_pattern_node_t;
typedef struct pm_assoc_node {
    pm_node_t base;
    struct pm_node *key;
    struct pm_node *value;
    pm_location_t operator_loc;
} pm_assoc_node_t;
typedef struct pm_assoc_splat_node {
    pm_node_t base;
    struct pm_node *value;
    pm_location_t operator_loc;
} pm_assoc_splat_node_t;
typedef struct pm_back_reference_read_node {
    pm_node_t base;
    pm_constant_id_t name;
} pm_back_reference_read_node_t;
typedef struct pm_begin_node {
    pm_node_t base;
    pm_location_t begin_keyword_loc;
    struct pm_statements_node *statements;
    struct pm_rescue_node *rescue_clause;
    struct pm_else_node *else_clause;
    struct pm_ensure_node *ensure_clause;
    pm_location_t end_keyword_loc;
} pm_begin_node_t;
typedef struct pm_block_argument_node {
    pm_node_t base;
    struct pm_node *expression;
    pm_location_t operator_loc;
} pm_block_argument_node_t;
typedef struct pm_block_local_variable_node {
    pm_node_t base;
    pm_constant_id_t name;
} pm_block_local_variable_node_t;
typedef struct pm_block_node {
    pm_node_t base;
    pm_constant_id_list_t locals;
    struct pm_node *parameters;
    struct pm_node *body;
    pm_location_t opening_loc;
    pm_location_t closing_loc;
} pm_block_node_t;
typedef struct pm_block_parameter_node {
    pm_node_t base;
    pm_constant_id_t name;
    pm_location_t name_loc;
    pm_location_t operator_loc;
} pm_block_parameter_node_t;
typedef struct pm_block_parameters_node {
    pm_node_t base;
    struct pm_parameters_node *parameters;
    struct pm_node_list locals;
    pm_location_t opening_loc;
    pm_location_t closing_loc;
} pm_block_parameters_node_t;
typedef struct pm_break_node {
    pm_node_t base;
    struct pm_arguments_node *arguments;
    pm_location_t keyword_loc;
} pm_break_node_t;
typedef struct pm_call_and_write_node {
    pm_node_t base;
    struct pm_node *receiver;
    pm_location_t call_operator_loc;
    pm_location_t message_loc;
    pm_constant_id_t read_name;
    pm_constant_id_t write_name;
    pm_location_t operator_loc;
    struct pm_node *value;
} pm_call_and_write_node_t;
typedef struct pm_call_node {
    pm_node_t base;
    struct pm_node *receiver;
    pm_location_t call_operator_loc;
    pm_constant_id_t name;
    pm_location_t message_loc;
    pm_location_t opening_loc;
    struct pm_arguments_node *arguments;
    pm_location_t closing_loc;
    struct pm_node *block;
} pm_call_node_t;
typedef struct pm_call_operator_write_node {
    pm_node_t base;
    struct pm_node *receiver;
    pm_location_t call_operator_loc;
    pm_location_t message_loc;
    pm_constant_id_t read_name;
    pm_constant_id_t write_name;
    pm_constant_id_t binary_operator;
    pm_location_t binary_operator_loc;
    struct pm_node *value;
} pm_call_operator_write_node_t;
typedef struct pm_call_or_write_node {
    pm_node_t base;
    struct pm_node *receiver;
    pm_location_t call_operator_loc;
    pm_location_t message_loc;
    pm_constant_id_t read_name;
    pm_constant_id_t write_name;
    pm_location_t operator_loc;
    struct pm_node *value;
} pm_call_or_write_node_t;
typedef struct pm_call_target_node {
    pm_node_t base;
    struct pm_node *receiver;
    pm_location_t call_operator_loc;
    pm_constant_id_t name;
    pm_location_t message_loc;
} pm_call_target_node_t;
typedef struct pm_capture_pattern_node {
    pm_node_t base;
    struct pm_node *value;
    struct pm_local_variable_target_node *target;
    pm_location_t operator_loc;
} pm_capture_pattern_node_t;
typedef struct pm_case_match_node {
    pm_node_t base;
    struct pm_node *predicate;
    struct pm_node_list conditions;
    struct pm_else_node *else_clause;
    pm_location_t case_keyword_loc;
    pm_location_t end_keyword_loc;
} pm_case_match_node_t;
typedef struct pm_case_node {
    pm_node_t base;
    struct pm_node *predicate;
    struct pm_node_list conditions;
    struct pm_else_node *else_clause;
    pm_location_t case_keyword_loc;
    pm_location_t end_keyword_loc;
} pm_case_node_t;
typedef struct pm_class_node {
    pm_node_t base;
    pm_constant_id_list_t locals;
    pm_location_t class_keyword_loc;
    struct pm_node *constant_path;
    pm_location_t inheritance_operator_loc;
    struct pm_node *superclass;
    struct pm_node *body;
    pm_location_t end_keyword_loc;
    pm_constant_id_t name;
} pm_class_node_t;
typedef struct pm_class_variable_and_write_node {
    pm_node_t base;
    pm_constant_id_t name;
    pm_location_t name_loc;
    pm_location_t operator_loc;
    struct pm_node *value;
} pm_class_variable_and_write_node_t;
typedef struct pm_class_variable_operator_write_node {
    pm_node_t base;
    pm_constant_id_t name;
    pm_location_t name_loc;
    pm_location_t binary_operator_loc;
    struct pm_node *value;
    pm_constant_id_t binary_operator;
} pm_class_variable_operator_write_node_t;
typedef struct pm_class_variable_or_write_node {
    pm_node_t base;
    pm_constant_id_t name;
    pm_location_t name_loc;
    pm_location_t operator_loc;
    struct pm_node *value;
} pm_class_variable_or_write_node_t;
typedef struct pm_class_variable_read_node {
    pm_node_t base;
    pm_constant_id_t name;
} pm_class_variable_read_node_t;
typedef struct pm_class_variable_target_node {
    pm_node_t base;
    pm_constant_id_t name;
} pm_class_variable_target_node_t;
typedef struct pm_class_variable_write_node {
    pm_node_t base;
    pm_constant_id_t name;
    pm_location_t name_loc;
    struct pm_node *value;
    pm_location_t operator_loc;
} pm_class_variable_write_node_t;
typedef struct pm_constant_and_write_node {
    pm_node_t base;
    pm_constant_id_t name;
    pm_location_t name_loc;
    pm_location_t operator_loc;
    struct pm_node *value;
} pm_constant_and_write_node_t;
typedef struct pm_constant_operator_write_node {
    pm_node_t base;
    pm_constant_id_t name;
    pm_location_t name_loc;
    pm_location_t binary_operator_loc;
    struct pm_node *value;
    pm_constant_id_t binary_operator;
} pm_constant_operator_write_node_t;
typedef struct pm_constant_or_write_node {
    pm_node_t base;
    pm_constant_id_t name;
    pm_location_t name_loc;
    pm_location_t operator_loc;
    struct pm_node *value;
} pm_constant_or_write_node_t;
typedef struct pm_constant_path_and_write_node {
    pm_node_t base;
    struct pm_constant_path_node *target;
    pm_location_t operator_loc;
    struct pm_node *value;
} pm_constant_path_and_write_node_t;
typedef struct pm_constant_path_node {
    pm_node_t base;
    struct pm_node *parent;
    pm_constant_id_t name;
    pm_location_t delimiter_loc;
    pm_location_t name_loc;
} pm_constant_path_node_t;
typedef struct pm_constant_path_operator_write_node {
    pm_node_t base;
    struct pm_constant_path_node *target;
    pm_location_t binary_operator_loc;
    struct pm_node *value;
    pm_constant_id_t binary_operator;
} pm_constant_path_operator_write_node_t;
typedef struct pm_constant_path_or_write_node {
    pm_node_t base;
    struct pm_constant_path_node *target;
    pm_location_t operator_loc;
    struct pm_node *value;
} pm_constant_path_or_write_node_t;
typedef struct pm_constant_path_target_node {
    pm_node_t base;
    struct pm_node *parent;
    pm_constant_id_t name;
    pm_location_t delimiter_loc;
    pm_location_t name_loc;
} pm_constant_path_target_node_t;
typedef struct pm_constant_path_write_node {
    pm_node_t base;
    struct pm_constant_path_node *target;
    pm_location_t operator_loc;
    struct pm_node *value;
} pm_constant_path_write_node_t;
typedef struct pm_constant_read_node {
    pm_node_t base;
    pm_constant_id_t name;
} pm_constant_read_node_t;
typedef struct pm_constant_target_node {
    pm_node_t base;
    pm_constant_id_t name;
} pm_constant_target_node_t;
typedef struct pm_constant_write_node {
    pm_node_t base;
    pm_constant_id_t name;
    pm_location_t name_loc;
    struct pm_node *value;
    pm_location_t operator_loc;
} pm_constant_write_node_t;
typedef struct pm_def_node {
    pm_node_t base;
    pm_constant_id_t name;
    pm_location_t name_loc;
    struct pm_node *receiver;
    struct pm_parameters_node *parameters;
    struct pm_node *body;
    pm_constant_id_list_t locals;
    pm_location_t def_keyword_loc;
    pm_location_t operator_loc;
    pm_location_t lparen_loc;
    pm_location_t rparen_loc;
    pm_location_t equal_loc;
    pm_location_t end_keyword_loc;
} pm_def_node_t;
typedef struct pm_defined_node {
    pm_node_t base;
    pm_location_t lparen_loc;
    struct pm_node *value;
    pm_location_t rparen_loc;
    pm_location_t keyword_loc;
} pm_defined_node_t;
typedef struct pm_else_node {
    pm_node_t base;
    pm_location_t else_keyword_loc;
    struct pm_statements_node *statements;
    pm_location_t end_keyword_loc;
} pm_else_node_t;
typedef struct pm_embedded_statements_node {
    pm_node_t base;
    pm_location_t opening_loc;
    struct pm_statements_node *statements;
    pm_location_t closing_loc;
} pm_embedded_statements_node_t;
typedef struct pm_embedded_variable_node {
    pm_node_t base;
    pm_location_t operator_loc;
    struct pm_node *variable;
} pm_embedded_variable_node_t;
typedef struct pm_ensure_node {
    pm_node_t base;
    pm_location_t ensure_keyword_loc;
    struct pm_statements_node *statements;
    pm_location_t end_keyword_loc;
} pm_ensure_node_t;
typedef struct pm_false_node {
    pm_node_t base;
} pm_false_node_t;
typedef struct pm_find_pattern_node {
    pm_node_t base;
    struct pm_node *constant;
    struct pm_splat_node *left;
    struct pm_node_list requireds;
    struct pm_node *right;
    pm_location_t opening_loc;
    pm_location_t closing_loc;
} pm_find_pattern_node_t;
typedef struct pm_flip_flop_node {
    pm_node_t base;
    struct pm_node *left;
    struct pm_node *right;
    pm_location_t operator_loc;
} pm_flip_flop_node_t;
typedef struct pm_float_node {
    pm_node_t base;
    double value;
} pm_float_node_t;
typedef struct pm_for_node {
    pm_node_t base;
    struct pm_node *index;
    struct pm_node *collection;
    struct pm_statements_node *statements;
    pm_location_t for_keyword_loc;
    pm_location_t in_keyword_loc;
    pm_location_t do_keyword_loc;
    pm_location_t end_keyword_loc;
} pm_for_node_t;
typedef struct pm_forwarding_arguments_node {
    pm_node_t base;
} pm_forwarding_arguments_node_t;
typedef struct pm_forwarding_parameter_node {
    pm_node_t base;
} pm_forwarding_parameter_node_t;
typedef struct pm_forwarding_super_node {
    pm_node_t base;
    struct pm_block_node *block;
} pm_forwarding_super_node_t;
typedef struct pm_global_variable_and_write_node {
    pm_node_t base;
    pm_constant_id_t name;
    pm_location_t name_loc;
    pm_location_t operator_loc;
    struct pm_node *value;
} pm_global_variable_and_write_node_t;
typedef struct pm_global_variable_operator_write_node {
    pm_node_t base;
    pm_constant_id_t name;
    pm_location_t name_loc;
    pm_location_t binary_operator_loc;
    struct pm_node *value;
    pm_constant_id_t binary_operator;
} pm_global_variable_operator_write_node_t;
typedef struct pm_global_variable_or_write_node {
    pm_node_t base;
    pm_constant_id_t name;
    pm_location_t name_loc;
    pm_location_t operator_loc;
    struct pm_node *value;
} pm_global_variable_or_write_node_t;
typedef struct pm_global_variable_read_node {
    pm_node_t base;
    pm_constant_id_t name;
} pm_global_variable_read_node_t;
typedef struct pm_global_variable_target_node {
    pm_node_t base;
    pm_constant_id_t name;
} pm_global_variable_target_node_t;
typedef struct pm_global_variable_write_node {
    pm_node_t base;
    pm_constant_id_t name;
    pm_location_t name_loc;
    struct pm_node *value;
    pm_location_t operator_loc;
} pm_global_variable_write_node_t;
typedef struct pm_hash_node {
    pm_node_t base;
    pm_location_t opening_loc;
    struct pm_node_list elements;
    pm_location_t closing_loc;
} pm_hash_node_t;
typedef struct pm_hash_pattern_node {
    pm_node_t base;
    struct pm_node *constant;
    struct pm_node_list elements;
    struct pm_node *rest;
    pm_location_t opening_loc;
    pm_location_t closing_loc;
} pm_hash_pattern_node_t;
typedef struct pm_if_node {
    pm_node_t base;
    pm_location_t if_keyword_loc;
    struct pm_node *predicate;
    pm_location_t then_keyword_loc;
    struct pm_statements_node *statements;
    struct pm_node *subsequent;
    pm_location_t end_keyword_loc;
} pm_if_node_t;
typedef struct pm_imaginary_node {
    pm_node_t base;
    struct pm_node *numeric;
} pm_imaginary_node_t;
typedef struct pm_implicit_node {
    pm_node_t base;
    struct pm_node *value;
} pm_implicit_node_t;
typedef struct pm_implicit_rest_node {
    pm_node_t base;
} pm_implicit_rest_node_t;
typedef struct pm_in_node {
    pm_node_t base;
    struct pm_node *pattern;
    struct pm_statements_node *statements;
    pm_location_t in_loc;
    pm_location_t then_loc;
} pm_in_node_t;
typedef struct pm_index_and_write_node {
    pm_node_t base;
    struct pm_node *receiver;
    pm_location_t call_operator_loc;
    pm_location_t opening_loc;
    struct pm_arguments_node *arguments;
    pm_location_t closing_loc;
    struct pm_block_argument_node *block;
    pm_location_t operator_loc;
    struct pm_node *value;
} pm_index_and_write_node_t;
typedef struct pm_index_operator_write_node {
    pm_node_t base;
    struct pm_node *receiver;
    pm_location_t call_operator_loc;
    pm_location_t opening_loc;
    struct pm_arguments_node *arguments;
    pm_location_t closing_loc;
    struct pm_block_argument_node *block;
    pm_constant_id_t binary_operator;
    pm_location_t binary_operator_loc;
    struct pm_node *value;
} pm_index_operator_write_node_t;
typedef struct pm_index_or_write_node {
    pm_node_t base;
    struct pm_node *receiver;
    pm_location_t call_operator_loc;
    pm_location_t opening_loc;
    struct pm_arguments_node *arguments;
    pm_location_t closing_loc;
    struct pm_block_argument_node *block;
    pm_location_t operator_loc;
    struct pm_node *value;
} pm_index_or_write_node_t;
typedef struct pm_index_target_node {
    pm_node_t base;
    struct pm_node *receiver;
    pm_location_t opening_loc;
    struct pm_arguments_node *arguments;
    pm_location_t closing_loc;
    struct pm_block_argument_node *block;
} pm_index_target_node_t;
typedef struct pm_instance_variable_and_write_node {
    pm_node_t base;
    pm_constant_id_t name;
    pm_location_t name_loc;
    pm_location_t operator_loc;
    struct pm_node *value;
} pm_instance_variable_and_write_node_t;
typedef struct pm_instance_variable_operator_write_node {
    pm_node_t base;
    pm_constant_id_t name;
    pm_location_t name_loc;
    pm_location_t binary_operator_loc;
    struct pm_node *value;
    pm_constant_id_t binary_operator;
} pm_instance_variable_operator_write_node_t;
typedef struct pm_instance_variable_or_write_node {
    pm_node_t base;
    pm_constant_id_t name;
    pm_location_t name_loc;
    pm_location_t operator_loc;
    struct pm_node *value;
} pm_instance_variable_or_write_node_t;
typedef struct pm_instance_variable_read_node {
    pm_node_t base;
    pm_constant_id_t name;
} pm_instance_variable_read_node_t;
typedef struct pm_instance_variable_target_node {
    pm_node_t base;
    pm_constant_id_t name;
} pm_instance_variable_target_node_t;
typedef struct pm_instance_variable_write_node {
    pm_node_t base;
    pm_constant_id_t name;
    pm_location_t name_loc;
    struct pm_node *value;
    pm_location_t operator_loc;
} pm_instance_variable_write_node_t;
typedef struct pm_integer_node {
    pm_node_t base;
    pm_integer_t value;
} pm_integer_node_t;
typedef struct pm_interpolated_match_last_line_node {
    pm_node_t base;
    pm_location_t opening_loc;
    struct pm_node_list parts;
    pm_location_t closing_loc;
} pm_interpolated_match_last_line_node_t;
typedef struct pm_interpolated_regular_expression_node {
    pm_node_t base;
    pm_location_t opening_loc;
    struct pm_node_list parts;
    pm_location_t closing_loc;
} pm_interpolated_regular_expression_node_t;
typedef struct pm_interpolated_string_node {
    pm_node_t base;
    pm_location_t opening_loc;
    struct pm_node_list parts;
    pm_location_t closing_loc;
} pm_interpolated_string_node_t;
typedef struct pm_interpolated_symbol_node {
    pm_node_t base;
    pm_location_t opening_loc;
    struct pm_node_list parts;
    pm_location_t closing_loc;
} pm_interpolated_symbol_node_t;
typedef struct pm_interpolated_x_string_node {
    pm_node_t base;
    pm_location_t opening_loc;
    struct pm_node_list parts;
    pm_location_t closing_loc;
} pm_interpolated_x_string_node_t;
typedef struct pm_it_local_variable_read_node {
    pm_node_t base;
} pm_it_local_variable_read_node_t;
typedef struct pm_it_parameters_node {
    pm_node_t base;
} pm_it_parameters_node_t;
typedef struct pm_keyword_hash_node {
    pm_node_t base;
    struct pm_node_list elements;
} pm_keyword_hash_node_t;
typedef struct pm_keyword_rest_parameter_node {
    pm_node_t base;
    pm_constant_id_t name;
    pm_location_t name_loc;
    pm_location_t operator_loc;
} pm_keyword_rest_parameter_node_t;
typedef struct pm_lambda_node {
    pm_node_t base;
    pm_constant_id_list_t locals;
    pm_location_t operator_loc;
    pm_location_t opening_loc;
    pm_location_t closing_loc;
    struct pm_node *parameters;
    struct pm_node *body;
} pm_lambda_node_t;
typedef struct pm_local_variable_and_write_node {
    pm_node_t base;
    pm_location_t name_loc;
    pm_location_t operator_loc;
    struct pm_node *value;
    pm_constant_id_t name;
    uint32_t depth;
} pm_local_variable_and_write_node_t;
typedef struct pm_local_variable_operator_write_node {
    pm_node_t base;
    pm_location_t name_loc;
    pm_location_t binary_operator_loc;
    struct pm_node *value;
    pm_constant_id_t name;
    pm_constant_id_t binary_operator;
    uint32_t depth;
} pm_local_variable_operator_write_node_t;
typedef struct pm_local_variable_or_write_node {
    pm_node_t base;
    pm_location_t name_loc;
    pm_location_t operator_loc;
    struct pm_node *value;
    pm_constant_id_t name;
    uint32_t depth;
} pm_local_variable_or_write_node_t;
typedef struct pm_local_variable_read_node {
    pm_node_t base;
    pm_constant_id_t name;
    uint32_t depth;
} pm_local_variable_read_node_t;
typedef struct pm_local_variable_target_node {
    pm_node_t base;
    pm_constant_id_t name;
    uint32_t depth;
} pm_local_variable_target_node_t;
typedef struct pm_local_variable_write_node {
    pm_node_t base;
    pm_constant_id_t name;
    uint32_t depth;
    pm_location_t name_loc;
    struct pm_node *value;
    pm_location_t operator_loc;
} pm_local_variable_write_node_t;
typedef struct pm_match_last_line_node {
    pm_node_t base;
    pm_location_t opening_loc;
    pm_location_t content_loc;
    pm_location_t closing_loc;
    pm_string_t unescaped;
} pm_match_last_line_node_t;
typedef struct pm_match_predicate_node {
    pm_node_t base;
    struct pm_node *value;
    struct pm_node *pattern;
    pm_location_t operator_loc;
} pm_match_predicate_node_t;
typedef struct pm_match_required_node {
    pm_node_t base;
    struct pm_node *value;
    struct pm_node *pattern;
    pm_location_t operator_loc;
} pm_match_required_node_t;
typedef struct pm_match_write_node {
    pm_node_t base;
    struct pm_call_node *call;
    struct pm_node_list targets;
} pm_match_write_node_t;
typedef struct pm_missing_node {
    pm_node_t base;
} pm_missing_node_t;
typedef struct pm_module_node {
    pm_node_t base;
    pm_constant_id_list_t locals;
    pm_location_t module_keyword_loc;
    struct pm_node *constant_path;
    struct pm_node *body;
    pm_location_t end_keyword_loc;
    pm_constant_id_t name;
} pm_module_node_t;
typedef struct pm_multi_target_node {
    pm_node_t base;
    struct pm_node_list lefts;
    struct pm_node *rest;
    struct pm_node_list rights;
    pm_location_t lparen_loc;
    pm_location_t rparen_loc;
} pm_multi_target_node_t;
typedef struct pm_multi_write_node {
    pm_node_t base;
    struct pm_node_list lefts;
    struct pm_node *rest;
    struct pm_node_list rights;
    pm_location_t lparen_loc;
    pm_location_t rparen_loc;
    pm_location_t operator_loc;
    struct pm_node *value;
} pm_multi_write_node_t;
typedef struct pm_next_node {
    pm_node_t base;
    struct pm_arguments_node *arguments;
    pm_location_t keyword_loc;
} pm_next_node_t;
typedef struct pm_nil_node {
    pm_node_t base;
} pm_nil_node_t;
typedef struct pm_no_keywords_parameter_node {
    pm_node_t base;
    pm_location_t operator_loc;
    pm_location_t keyword_loc;
} pm_no_keywords_parameter_node_t;
typedef struct pm_numbered_parameters_node {
    pm_node_t base;
    uint8_t maximum;
} pm_numbered_parameters_node_t;
typedef struct pm_numbered_reference_read_node {
    pm_node_t base;
    uint32_t number;
} pm_numbered_reference_read_node_t;
typedef struct pm_optional_keyword_parameter_node {
    pm_node_t base;
    pm_constant_id_t name;
    pm_location_t name_loc;
    struct pm_node *value;
} pm_optional_keyword_parameter_node_t;
typedef struct pm_optional_parameter_node {
    pm_node_t base;
    pm_constant_id_t name;
    pm_location_t name_loc;
    pm_location_t operator_loc;
    struct pm_node *value;
} pm_optional_parameter_node_t;
typedef struct pm_or_node {
    pm_node_t base;
    struct pm_node *left;
    struct pm_node *right;
    pm_location_t operator_loc;
} pm_or_node_t;
typedef struct pm_parameters_node {
    pm_node_t base;
    struct pm_node_list requireds;
    struct pm_node_list optionals;
    struct pm_node *rest;
    struct pm_node_list posts;
    struct pm_node_list keywords;
    struct pm_node *keyword_rest;
    struct pm_block_parameter_node *block;
} pm_parameters_node_t;
typedef struct pm_parentheses_node {
    pm_node_t base;
    struct pm_node *body;
    pm_location_t opening_loc;
    pm_location_t closing_loc;
} pm_parentheses_node_t;
typedef struct pm_pinned_expression_node {
    pm_node_t base;
    struct pm_node *expression;
    pm_location_t operator_loc;
    pm_location_t lparen_loc;
    pm_location_t rparen_loc;
} pm_pinned_expression_node_t;
typedef struct pm_pinned_variable_node {
    pm_node_t base;
    struct pm_node *variable;
    pm_location_t operator_loc;
} pm_pinned_variable_node_t;
typedef struct pm_post_execution_node {
    pm_node_t base;
    struct pm_statements_node *statements;
    pm_location_t keyword_loc;
    pm_location_t opening_loc;
    pm_location_t closing_loc;
} pm_post_execution_node_t;
typedef struct pm_pre_execution_node {
    pm_node_t base;
    struct pm_statements_node *statements;
    pm_location_t keyword_loc;
    pm_location_t opening_loc;
    pm_location_t closing_loc;
} pm_pre_execution_node_t;
typedef struct pm_program_node {
    pm_node_t base;
    pm_constant_id_list_t locals;
    struct pm_statements_node *statements;
} pm_program_node_t;
typedef struct pm_range_node {
    pm_node_t base;
    struct pm_node *left;
    struct pm_node *right;
    pm_location_t operator_loc;
} pm_range_node_t;
typedef struct pm_rational_node {
    pm_node_t base;
    pm_integer_t numerator;
    pm_integer_t denominator;
} pm_rational_node_t;
typedef struct pm_redo_node {
    pm_node_t base;
} pm_redo_node_t;
typedef struct pm_regular_expression_node {
    pm_node_t base;
    pm_location_t opening_loc;
    pm_location_t content_loc;
    pm_location_t closing_loc;
    pm_string_t unescaped;
} pm_regular_expression_node_t;
typedef struct pm_required_keyword_parameter_node {
    pm_node_t base;
    pm_constant_id_t name;
    pm_location_t name_loc;
} pm_required_keyword_parameter_node_t;
typedef struct pm_required_parameter_node {
    pm_node_t base;
    pm_constant_id_t name;
} pm_required_parameter_node_t;
typedef struct pm_rescue_modifier_node {
    pm_node_t base;
    struct pm_node *expression;
    pm_location_t keyword_loc;
    struct pm_node *rescue_expression;
} pm_rescue_modifier_node_t;
typedef struct pm_rescue_node {
    pm_node_t base;
    pm_location_t keyword_loc;
    struct pm_node_list exceptions;
    pm_location_t operator_loc;
    struct pm_node *reference;
    struct pm_statements_node *statements;
    struct pm_rescue_node *subsequent;
} pm_rescue_node_t;
typedef struct pm_rest_parameter_node {
    pm_node_t base;
    pm_constant_id_t name;
    pm_location_t name_loc;
    pm_location_t operator_loc;
} pm_rest_parameter_node_t;
typedef struct pm_retry_node {
    pm_node_t base;
} pm_retry_node_t;
typedef struct pm_return_node {
    pm_node_t base;
    pm_location_t keyword_loc;
    struct pm_arguments_node *arguments;
} pm_return_node_t;
typedef struct pm_self_node {
    pm_node_t base;
} pm_self_node_t;
typedef struct pm_shareable_constant_node {
    pm_node_t base;
    struct pm_node *write;
} pm_shareable_constant_node_t;
typedef struct pm_singleton_class_node {
    pm_node_t base;
    pm_constant_id_list_t locals;
    pm_location_t class_keyword_loc;
    pm_location_t operator_loc;
    struct pm_node *expression;
    struct pm_node *body;
    pm_location_t end_keyword_loc;
} pm_singleton_class_node_t;
typedef struct pm_source_encoding_node {
    pm_node_t base;
} pm_source_encoding_node_t;
typedef struct pm_source_file_node {
    pm_node_t base;
    pm_string_t filepath;
} pm_source_file_node_t;
typedef struct pm_source_line_node {
    pm_node_t base;
} pm_source_line_node_t;
typedef struct pm_splat_node {
    pm_node_t base;
    pm_location_t operator_loc;
    struct pm_node *expression;
} pm_splat_node_t;
typedef struct pm_statements_node {
    pm_node_t base;
    struct pm_node_list body;
} pm_statements_node_t;
typedef struct pm_string_node {
    pm_node_t base;
    pm_location_t opening_loc;
    pm_location_t content_loc;
    pm_location_t closing_loc;
    pm_string_t unescaped;
} pm_string_node_t;
typedef struct pm_super_node {
    pm_node_t base;
    pm_location_t keyword_loc;
    pm_location_t lparen_loc;
    struct pm_arguments_node *arguments;
    pm_location_t rparen_loc;
    struct pm_node *block;
} pm_super_node_t;
typedef struct pm_symbol_node {
    pm_node_t base;
    pm_location_t opening_loc;
    pm_location_t value_loc;
    pm_location_t closing_loc;
    pm_string_t unescaped;
} pm_symbol_node_t;
typedef struct pm_true_node {
    pm_node_t base;
} pm_true_node_t;
typedef struct pm_undef_node {
    pm_node_t base;
    struct pm_node_list names;
    pm_location_t keyword_loc;
} pm_undef_node_t;
typedef struct pm_unless_node {
    pm_node_t base;
    pm_location_t keyword_loc;
    struct pm_node *predicate;
    pm_location_t then_keyword_loc;
    struct pm_statements_node *statements;
    struct pm_else_node *else_clause;
    pm_location_t end_keyword_loc;
} pm_unless_node_t;
typedef struct pm_until_node {
    pm_node_t base;
    pm_location_t keyword_loc;
    pm_location_t closing_loc;
    struct pm_node *predicate;
    struct pm_statements_node *statements;
} pm_until_node_t;
typedef struct pm_when_node {
    pm_node_t base;
    pm_location_t keyword_loc;
    struct pm_node_list conditions;
    pm_location_t then_keyword_loc;
    struct pm_statements_node *statements;
} pm_when_node_t;
typedef struct pm_while_node {
    pm_node_t base;
    pm_location_t keyword_loc;
    pm_location_t closing_loc;
    struct pm_node *predicate;
    struct pm_statements_node *statements;
} pm_while_node_t;
typedef struct pm_x_string_node {
    pm_node_t base;
    pm_location_t opening_loc;
    pm_location_t content_loc;
    pm_location_t closing_loc;
    pm_string_t unescaped;
} pm_x_string_node_t;
typedef struct pm_yield_node {
    pm_node_t base;
    pm_location_t keyword_loc;
    pm_location_t lparen_loc;
    struct pm_arguments_node *arguments;
    pm_location_t rparen_loc;
} pm_yield_node_t;
typedef enum pm_arguments_node_flags {
    PM_ARGUMENTS_NODE_FLAGS_CONTAINS_FORWARDING = 4,
    PM_ARGUMENTS_NODE_FLAGS_CONTAINS_KEYWORDS = 8,
    PM_ARGUMENTS_NODE_FLAGS_CONTAINS_KEYWORD_SPLAT = 16,
    PM_ARGUMENTS_NODE_FLAGS_CONTAINS_SPLAT = 32,
    PM_ARGUMENTS_NODE_FLAGS_CONTAINS_MULTIPLE_SPLATS = 64,
} pm_arguments_node_flags_t;
typedef enum pm_array_node_flags {
    PM_ARRAY_NODE_FLAGS_CONTAINS_SPLAT = 4,
} pm_array_node_flags_t;
typedef enum pm_call_node_flags {
    PM_CALL_NODE_FLAGS_SAFE_NAVIGATION = 4,
    PM_CALL_NODE_FLAGS_VARIABLE_CALL = 8,
    PM_CALL_NODE_FLAGS_ATTRIBUTE_WRITE = 16,
    PM_CALL_NODE_FLAGS_IGNORE_VISIBILITY = 32,
} pm_call_node_flags_t;
typedef enum pm_encoding_flags {
    PM_ENCODING_FLAGS_FORCED_UTF8_ENCODING = 4,
    PM_ENCODING_FLAGS_FORCED_BINARY_ENCODING = 8,
} pm_encoding_flags_t;
typedef enum pm_integer_base_flags {
    PM_INTEGER_BASE_FLAGS_BINARY = 4,
    PM_INTEGER_BASE_FLAGS_DECIMAL = 8,
    PM_INTEGER_BASE_FLAGS_OCTAL = 16,
    PM_INTEGER_BASE_FLAGS_HEXADECIMAL = 32,
} pm_integer_base_flags_t;
typedef enum pm_interpolated_string_node_flags {
    PM_INTERPOLATED_STRING_NODE_FLAGS_FROZEN = 4,
    PM_INTERPOLATED_STRING_NODE_FLAGS_MUTABLE = 8,
} pm_interpolated_string_node_flags_t;
typedef enum pm_keyword_hash_node_flags {
    PM_KEYWORD_HASH_NODE_FLAGS_SYMBOL_KEYS = 4,
} pm_keyword_hash_node_flags_t;
typedef enum pm_loop_flags {
    PM_LOOP_FLAGS_BEGIN_MODIFIER = 4,
} pm_loop_flags_t;
typedef enum pm_parameter_flags {
    PM_PARAMETER_FLAGS_REPEATED_PARAMETER = 4,
} pm_parameter_flags_t;
typedef enum pm_range_flags {
    PM_RANGE_FLAGS_EXCLUDE_END = 4,
} pm_range_flags_t;
typedef enum pm_regular_expression_flags {
    PM_REGULAR_EXPRESSION_FLAGS_IGNORE_CASE = 4,
    PM_REGULAR_EXPRESSION_FLAGS_EXTENDED = 8,
    PM_REGULAR_EXPRESSION_FLAGS_MULTI_LINE = 16,
    PM_REGULAR_EXPRESSION_FLAGS_ONCE = 32,
    PM_REGULAR_EXPRESSION_FLAGS_EUC_JP = 64,
    PM_REGULAR_EXPRESSION_FLAGS_ASCII_8BIT = 128,
    PM_REGULAR_EXPRESSION_FLAGS_WINDOWS_31J = 256,
    PM_REGULAR_EXPRESSION_FLAGS_UTF_8 = 512,
    PM_REGULAR_EXPRESSION_FLAGS_FORCED_UTF8_ENCODING = 1024,
    PM_REGULAR_EXPRESSION_FLAGS_FORCED_BINARY_ENCODING = 2048,
    PM_REGULAR_EXPRESSION_FLAGS_FORCED_US_ASCII_ENCODING = 4096,
} pm_regular_expression_flags_t;
typedef enum pm_shareable_constant_node_flags {
    PM_SHAREABLE_CONSTANT_NODE_FLAGS_LITERAL = 4,
    PM_SHAREABLE_CONSTANT_NODE_FLAGS_EXPERIMENTAL_EVERYTHING = 8,
    PM_SHAREABLE_CONSTANT_NODE_FLAGS_EXPERIMENTAL_COPY = 16,
} pm_shareable_constant_node_flags_t;
typedef enum pm_string_flags {
    PM_STRING_FLAGS_FORCED_UTF8_ENCODING = 4,
    PM_STRING_FLAGS_FORCED_BINARY_ENCODING = 8,
    PM_STRING_FLAGS_FROZEN = 16,
    PM_STRING_FLAGS_MUTABLE = 32,
} pm_string_flags_t;
typedef enum pm_symbol_flags {
    PM_SYMBOL_FLAGS_FORCED_UTF8_ENCODING = 4,
    PM_SYMBOL_FLAGS_FORCED_BINARY_ENCODING = 8,
    PM_SYMBOL_FLAGS_FORCED_US_ASCII_ENCODING = 16,
} pm_symbol_flags_t;
typedef struct pm_list_node {
    struct pm_list_node *next;
} pm_list_node_t;
typedef struct {
    size_t size;
    pm_list_node_t *head;
    pm_list_node_t *tail;
} pm_list_t;
 _Bool pm_list_empty_p(pm_list_t *list);
 size_t pm_list_size(pm_list_t *list);
void pm_list_append(pm_list_t *list, pm_list_node_t *node);
 void pm_list_free(pm_list_t *list);
typedef enum {
    PM_ERR_ALIAS_ARGUMENT,
    PM_ERR_ALIAS_ARGUMENT_NUMBERED_REFERENCE,
    PM_ERR_AMPAMPEQ_MULTI_ASSIGN,
    PM_ERR_ARGUMENT_AFTER_BLOCK,
    PM_ERR_ARGUMENT_AFTER_FORWARDING_ELLIPSES,
    PM_ERR_ARGUMENT_BARE_HASH,
    PM_ERR_ARGUMENT_BLOCK_FORWARDING,
    PM_ERR_ARGUMENT_BLOCK_MULTI,
    PM_ERR_ARGUMENT_CONFLICT_AMPERSAND,
    PM_ERR_ARGUMENT_CONFLICT_STAR,
    PM_ERR_ARGUMENT_CONFLICT_STAR_STAR,
    PM_ERR_ARGUMENT_FORMAL_CLASS,
    PM_ERR_ARGUMENT_FORMAL_CONSTANT,
    PM_ERR_ARGUMENT_FORMAL_GLOBAL,
    PM_ERR_ARGUMENT_FORMAL_IVAR,
    PM_ERR_ARGUMENT_FORWARDING_UNBOUND,
    PM_ERR_ARGUMENT_NO_FORWARDING_AMPERSAND,
    PM_ERR_ARGUMENT_NO_FORWARDING_ELLIPSES,
    PM_ERR_ARGUMENT_NO_FORWARDING_STAR,
    PM_ERR_ARGUMENT_NO_FORWARDING_STAR_STAR,
    PM_ERR_ARGUMENT_SPLAT_AFTER_ASSOC_SPLAT,
    PM_ERR_ARGUMENT_SPLAT_AFTER_SPLAT,
    PM_ERR_ARGUMENT_TERM_PAREN,
    PM_ERR_ARGUMENT_UNEXPECTED_BLOCK,
    PM_ERR_ARRAY_ELEMENT,
    PM_ERR_ARRAY_EXPRESSION,
    PM_ERR_ARRAY_EXPRESSION_AFTER_STAR,
    PM_ERR_ARRAY_SEPARATOR,
    PM_ERR_ARRAY_TERM,
    PM_ERR_BEGIN_LONELY_ELSE,
    PM_ERR_BEGIN_TERM,
    PM_ERR_BEGIN_UPCASE_BRACE,
    PM_ERR_BEGIN_UPCASE_TERM,
    PM_ERR_BEGIN_UPCASE_TOPLEVEL,
    PM_ERR_BLOCK_PARAM_LOCAL_VARIABLE,
    PM_ERR_BLOCK_PARAM_PIPE_TERM,
    PM_ERR_BLOCK_TERM_BRACE,
    PM_ERR_BLOCK_TERM_END,
    PM_ERR_CANNOT_PARSE_EXPRESSION,
    PM_ERR_CANNOT_PARSE_STRING_PART,
    PM_ERR_CASE_EXPRESSION_AFTER_CASE,
    PM_ERR_CASE_EXPRESSION_AFTER_WHEN,
    PM_ERR_CASE_MATCH_MISSING_PREDICATE,
    PM_ERR_CASE_MISSING_CONDITIONS,
    PM_ERR_CASE_TERM,
    PM_ERR_CLASS_IN_METHOD,
    PM_ERR_CLASS_NAME,
    PM_ERR_CLASS_SUPERCLASS,
    PM_ERR_CLASS_TERM,
    PM_ERR_CLASS_UNEXPECTED_END,
    PM_ERR_CLASS_VARIABLE_BARE,
    PM_ERR_CONDITIONAL_ELSIF_PREDICATE,
    PM_ERR_CONDITIONAL_IF_PREDICATE,
    PM_ERR_CONDITIONAL_PREDICATE_TERM,
    PM_ERR_CONDITIONAL_TERM,
    PM_ERR_CONDITIONAL_TERM_ELSE,
    PM_ERR_CONDITIONAL_UNLESS_PREDICATE,
    PM_ERR_CONDITIONAL_UNTIL_PREDICATE,
    PM_ERR_CONDITIONAL_WHILE_PREDICATE,
    PM_ERR_CONSTANT_PATH_COLON_COLON_CONSTANT,
    PM_ERR_DEF_ENDLESS,
    PM_ERR_DEF_ENDLESS_SETTER,
    PM_ERR_DEF_NAME,
    PM_ERR_DEF_PARAMS_TERM,
    PM_ERR_DEF_PARAMS_TERM_PAREN,
    PM_ERR_DEF_RECEIVER,
    PM_ERR_DEF_RECEIVER_TERM,
    PM_ERR_DEF_TERM,
    PM_ERR_DEFINED_EXPRESSION,
    PM_ERR_EMBDOC_TERM,
    PM_ERR_EMBEXPR_END,
    PM_ERR_EMBVAR_INVALID,
    PM_ERR_END_UPCASE_BRACE,
    PM_ERR_END_UPCASE_TERM,
    PM_ERR_ESCAPE_INVALID_CONTROL,
    PM_ERR_ESCAPE_INVALID_CONTROL_REPEAT,
    PM_ERR_ESCAPE_INVALID_HEXADECIMAL,
    PM_ERR_ESCAPE_INVALID_META,
    PM_ERR_ESCAPE_INVALID_META_REPEAT,
    PM_ERR_ESCAPE_INVALID_UNICODE,
    PM_ERR_ESCAPE_INVALID_UNICODE_CM_FLAGS,
    PM_ERR_ESCAPE_INVALID_UNICODE_LIST,
    PM_ERR_ESCAPE_INVALID_UNICODE_LITERAL,
    PM_ERR_ESCAPE_INVALID_UNICODE_LONG,
    PM_ERR_ESCAPE_INVALID_UNICODE_SHORT,
    PM_ERR_ESCAPE_INVALID_UNICODE_TERM,
    PM_ERR_EXPECT_ARGUMENT,
    PM_ERR_EXPECT_EOL_AFTER_STATEMENT,
    PM_ERR_EXPECT_EXPRESSION_AFTER_AMPAMPEQ,
    PM_ERR_EXPECT_EXPRESSION_AFTER_COMMA,
    PM_ERR_EXPECT_EXPRESSION_AFTER_EQUAL,
    PM_ERR_EXPECT_EXPRESSION_AFTER_LESS_LESS,
    PM_ERR_EXPECT_EXPRESSION_AFTER_LPAREN,
    PM_ERR_EXPECT_EXPRESSION_AFTER_OPERATOR,
    PM_ERR_EXPECT_EXPRESSION_AFTER_PIPEPIPEEQ,
    PM_ERR_EXPECT_EXPRESSION_AFTER_QUESTION,
    PM_ERR_EXPECT_EXPRESSION_AFTER_SPLAT,
    PM_ERR_EXPECT_EXPRESSION_AFTER_SPLAT_HASH,
    PM_ERR_EXPECT_EXPRESSION_AFTER_STAR,
    PM_ERR_EXPECT_FOR_DELIMITER,
    PM_ERR_EXPECT_IDENT_REQ_PARAMETER,
    PM_ERR_EXPECT_IN_DELIMITER,
    PM_ERR_EXPECT_LPAREN_REQ_PARAMETER,
    PM_ERR_EXPECT_MESSAGE,
    PM_ERR_EXPECT_RBRACKET,
    PM_ERR_EXPECT_RPAREN,
    PM_ERR_EXPECT_RPAREN_AFTER_MULTI,
    PM_ERR_EXPECT_RPAREN_REQ_PARAMETER,
    PM_ERR_EXPECT_SINGLETON_CLASS_DELIMITER,
    PM_ERR_EXPECT_STRING_CONTENT,
    PM_ERR_EXPECT_WHEN_DELIMITER,
    PM_ERR_EXPRESSION_BARE_HASH,
    PM_ERR_EXPRESSION_NOT_WRITABLE,
    PM_ERR_EXPRESSION_NOT_WRITABLE_ENCODING,
    PM_ERR_EXPRESSION_NOT_WRITABLE_FALSE,
    PM_ERR_EXPRESSION_NOT_WRITABLE_FILE,
    PM_ERR_EXPRESSION_NOT_WRITABLE_LINE,
    PM_ERR_EXPRESSION_NOT_WRITABLE_NIL,
    PM_ERR_EXPRESSION_NOT_WRITABLE_NUMBERED,
    PM_ERR_EXPRESSION_NOT_WRITABLE_SELF,
    PM_ERR_EXPRESSION_NOT_WRITABLE_TRUE,
    PM_ERR_FLOAT_PARSE,
    PM_ERR_FOR_COLLECTION,
    PM_ERR_FOR_IN,
    PM_ERR_FOR_INDEX,
    PM_ERR_FOR_TERM,
    PM_ERR_GLOBAL_VARIABLE_BARE,
    PM_ERR_HASH_EXPRESSION_AFTER_LABEL,
    PM_ERR_HASH_KEY,
    PM_ERR_HASH_ROCKET,
    PM_ERR_HASH_TERM,
    PM_ERR_HASH_VALUE,
    PM_ERR_HEREDOC_IDENTIFIER,
    PM_ERR_HEREDOC_TERM,
    PM_ERR_INCOMPLETE_QUESTION_MARK,
    PM_ERR_INCOMPLETE_VARIABLE_CLASS,
    PM_ERR_INCOMPLETE_VARIABLE_CLASS_3_3,
    PM_ERR_INCOMPLETE_VARIABLE_INSTANCE,
    PM_ERR_INCOMPLETE_VARIABLE_INSTANCE_3_3,
    PM_ERR_INSTANCE_VARIABLE_BARE,
    PM_ERR_INVALID_BLOCK_EXIT,
    PM_ERR_INVALID_CHARACTER,
    PM_ERR_INVALID_COMMA,
    PM_ERR_INVALID_ENCODING_MAGIC_COMMENT,
    PM_ERR_INVALID_ESCAPE_CHARACTER,
    PM_ERR_INVALID_FLOAT_EXPONENT,
    PM_ERR_INVALID_LOCAL_VARIABLE_READ,
    PM_ERR_INVALID_LOCAL_VARIABLE_WRITE,
    PM_ERR_INVALID_MULTIBYTE_CHAR,
    PM_ERR_INVALID_MULTIBYTE_CHARACTER,
    PM_ERR_INVALID_MULTIBYTE_ESCAPE,
    PM_ERR_INVALID_NUMBER_BINARY,
    PM_ERR_INVALID_NUMBER_DECIMAL,
    PM_ERR_INVALID_NUMBER_FRACTION,
    PM_ERR_INVALID_NUMBER_HEXADECIMAL,
    PM_ERR_INVALID_NUMBER_OCTAL,
    PM_ERR_INVALID_NUMBER_UNDERSCORE_INNER,
    PM_ERR_INVALID_NUMBER_UNDERSCORE_TRAILING,
    PM_ERR_INVALID_PERCENT,
    PM_ERR_INVALID_PERCENT_EOF,
    PM_ERR_INVALID_PRINTABLE_CHARACTER,
    PM_ERR_INVALID_RETRY_AFTER_ELSE,
    PM_ERR_INVALID_RETRY_AFTER_ENSURE,
    PM_ERR_INVALID_RETRY_WITHOUT_RESCUE,
    PM_ERR_INVALID_SYMBOL,
    PM_ERR_INVALID_VARIABLE_GLOBAL,
    PM_ERR_INVALID_VARIABLE_GLOBAL_3_3,
    PM_ERR_INVALID_YIELD,
    PM_ERR_IT_NOT_ALLOWED_NUMBERED,
    PM_ERR_IT_NOT_ALLOWED_ORDINARY,
    PM_ERR_LAMBDA_OPEN,
    PM_ERR_LAMBDA_TERM_BRACE,
    PM_ERR_LAMBDA_TERM_END,
    PM_ERR_LIST_I_LOWER_ELEMENT,
    PM_ERR_LIST_I_LOWER_TERM,
    PM_ERR_LIST_I_UPPER_ELEMENT,
    PM_ERR_LIST_I_UPPER_TERM,
    PM_ERR_LIST_W_LOWER_ELEMENT,
    PM_ERR_LIST_W_LOWER_TERM,
    PM_ERR_LIST_W_UPPER_ELEMENT,
    PM_ERR_LIST_W_UPPER_TERM,
    PM_ERR_MALLOC_FAILED,
    PM_ERR_MIXED_ENCODING,
    PM_ERR_MODULE_IN_METHOD,
    PM_ERR_MODULE_NAME,
    PM_ERR_MODULE_TERM,
    PM_ERR_MULTI_ASSIGN_MULTI_SPLATS,
    PM_ERR_MULTI_ASSIGN_UNEXPECTED_REST,
    PM_ERR_NESTING_TOO_DEEP,
    PM_ERR_NO_LOCAL_VARIABLE,
    PM_ERR_NON_ASSOCIATIVE_OPERATOR,
    PM_ERR_NOT_EXPRESSION,
    PM_ERR_NUMBER_LITERAL_UNDERSCORE,
    PM_ERR_NUMBERED_PARAMETER_INNER_BLOCK,
    PM_ERR_NUMBERED_PARAMETER_IT,
    PM_ERR_NUMBERED_PARAMETER_ORDINARY,
    PM_ERR_NUMBERED_PARAMETER_OUTER_BLOCK,
    PM_ERR_OPERATOR_MULTI_ASSIGN,
    PM_ERR_OPERATOR_WRITE_ARGUMENTS,
    PM_ERR_OPERATOR_WRITE_BLOCK,
    PM_ERR_PARAMETER_ASSOC_SPLAT_MULTI,
    PM_ERR_PARAMETER_BLOCK_MULTI,
    PM_ERR_PARAMETER_CIRCULAR,
    PM_ERR_PARAMETER_FORWARDING_AFTER_REST,
    PM_ERR_PARAMETER_METHOD_NAME,
    PM_ERR_PARAMETER_NAME_DUPLICATED,
    PM_ERR_PARAMETER_NO_DEFAULT,
    PM_ERR_PARAMETER_NO_DEFAULT_KW,
    PM_ERR_PARAMETER_NUMBERED_RESERVED,
    PM_ERR_PARAMETER_ORDER,
    PM_ERR_PARAMETER_SPLAT_MULTI,
    PM_ERR_PARAMETER_STAR,
    PM_ERR_PARAMETER_UNEXPECTED_FWD,
    PM_ERR_PARAMETER_UNEXPECTED_NO_KW,
    PM_ERR_PARAMETER_WILD_LOOSE_COMMA,
    PM_ERR_PATTERN_ARRAY_MULTIPLE_RESTS,
    PM_ERR_PATTERN_CAPTURE_DUPLICATE,
    PM_ERR_PATTERN_EXPRESSION_AFTER_BRACKET,
    PM_ERR_PATTERN_EXPRESSION_AFTER_COMMA,
    PM_ERR_PATTERN_EXPRESSION_AFTER_HROCKET,
    PM_ERR_PATTERN_EXPRESSION_AFTER_IN,
    PM_ERR_PATTERN_EXPRESSION_AFTER_KEY,
    PM_ERR_PATTERN_EXPRESSION_AFTER_PAREN,
    PM_ERR_PATTERN_EXPRESSION_AFTER_PIN,
    PM_ERR_PATTERN_EXPRESSION_AFTER_PIPE,
    PM_ERR_PATTERN_EXPRESSION_AFTER_RANGE,
    PM_ERR_PATTERN_EXPRESSION_AFTER_REST,
    PM_ERR_PATTERN_FIND_MISSING_INNER,
    PM_ERR_PATTERN_HASH_IMPLICIT,
    PM_ERR_PATTERN_HASH_KEY,
    PM_ERR_PATTERN_HASH_KEY_DUPLICATE,
    PM_ERR_PATTERN_HASH_KEY_INTERPOLATED,
    PM_ERR_PATTERN_HASH_KEY_LABEL,
    PM_ERR_PATTERN_HASH_KEY_LOCALS,
    PM_ERR_PATTERN_IDENT_AFTER_HROCKET,
    PM_ERR_PATTERN_LABEL_AFTER_COMMA,
    PM_ERR_PATTERN_REST,
    PM_ERR_PATTERN_TERM_BRACE,
    PM_ERR_PATTERN_TERM_BRACKET,
    PM_ERR_PATTERN_TERM_PAREN,
    PM_ERR_PIPEPIPEEQ_MULTI_ASSIGN,
    PM_ERR_REGEXP_ENCODING_OPTION_MISMATCH,
    PM_ERR_REGEXP_INCOMPAT_CHAR_ENCODING,
    PM_ERR_REGEXP_INVALID_UNICODE_RANGE,
    PM_ERR_REGEXP_NON_ESCAPED_MBC,
    PM_ERR_REGEXP_PARSE_ERROR,
    PM_ERR_REGEXP_TERM,
    PM_ERR_REGEXP_UNKNOWN_OPTIONS,
    PM_ERR_REGEXP_UTF8_CHAR_NON_UTF8_REGEXP,
    PM_ERR_RESCUE_EXPRESSION,
    PM_ERR_RESCUE_MODIFIER_VALUE,
    PM_ERR_RESCUE_TERM,
    PM_ERR_RESCUE_VARIABLE,
    PM_ERR_RETURN_INVALID,
    PM_ERR_SCRIPT_NOT_FOUND,
    PM_ERR_SINGLETON_FOR_LITERALS,
    PM_ERR_STATEMENT_ALIAS,
    PM_ERR_STATEMENT_POSTEXE_END,
    PM_ERR_STATEMENT_PREEXE_BEGIN,
    PM_ERR_STATEMENT_UNDEF,
    PM_ERR_STRING_CONCATENATION,
    PM_ERR_STRING_INTERPOLATED_TERM,
    PM_ERR_STRING_LITERAL_EOF,
    PM_ERR_STRING_LITERAL_TERM,
    PM_ERR_SYMBOL_INVALID,
    PM_ERR_SYMBOL_TERM_DYNAMIC,
    PM_ERR_SYMBOL_TERM_INTERPOLATED,
    PM_ERR_TERNARY_COLON,
    PM_ERR_TERNARY_EXPRESSION_FALSE,
    PM_ERR_TERNARY_EXPRESSION_TRUE,
    PM_ERR_UNARY_DISALLOWED,
    PM_ERR_UNARY_RECEIVER,
    PM_ERR_UNDEF_ARGUMENT,
    PM_ERR_UNEXPECTED_BLOCK_ARGUMENT,
    PM_ERR_UNEXPECTED_INDEX_BLOCK,
    PM_ERR_UNEXPECTED_INDEX_KEYWORDS,
    PM_ERR_UNEXPECTED_LABEL,
    PM_ERR_UNEXPECTED_MULTI_WRITE,
    PM_ERR_UNEXPECTED_RANGE_OPERATOR,
    PM_ERR_UNEXPECTED_SAFE_NAVIGATION,
    PM_ERR_UNEXPECTED_TOKEN_CLOSE_CONTEXT,
    PM_ERR_UNEXPECTED_TOKEN_IGNORE,
    PM_ERR_UNTIL_TERM,
    PM_ERR_VOID_EXPRESSION,
    PM_ERR_WHILE_TERM,
    PM_ERR_WRITE_TARGET_IN_METHOD,
    PM_ERR_WRITE_TARGET_READONLY,
    PM_ERR_WRITE_TARGET_UNEXPECTED,
    PM_ERR_XSTRING_TERM,
    PM_WARN_AMBIGUOUS_BINARY_OPERATOR,
    PM_WARN_AMBIGUOUS_FIRST_ARGUMENT_MINUS,
    PM_WARN_AMBIGUOUS_FIRST_ARGUMENT_PLUS,
    PM_WARN_AMBIGUOUS_PREFIX_AMPERSAND,
    PM_WARN_AMBIGUOUS_PREFIX_STAR,
    PM_WARN_AMBIGUOUS_PREFIX_STAR_STAR,
    PM_WARN_AMBIGUOUS_SLASH,
    PM_WARN_COMPARISON_AFTER_COMPARISON,
    PM_WARN_DOT_DOT_DOT_EOL,
    PM_WARN_EQUAL_IN_CONDITIONAL,
    PM_WARN_EQUAL_IN_CONDITIONAL_3_3,
    PM_WARN_END_IN_METHOD,
    PM_WARN_DUPLICATED_HASH_KEY,
    PM_WARN_DUPLICATED_WHEN_CLAUSE,
    PM_WARN_FLOAT_OUT_OF_RANGE,
    PM_WARN_IGNORED_FROZEN_STRING_LITERAL,
    PM_WARN_INDENTATION_MISMATCH,
    PM_WARN_INTEGER_IN_FLIP_FLOP,
    PM_WARN_INVALID_CHARACTER,
    PM_WARN_INVALID_MAGIC_COMMENT_VALUE,
    PM_WARN_INVALID_NUMBERED_REFERENCE,
    PM_WARN_KEYWORD_EOL,
    PM_WARN_LITERAL_IN_CONDITION_DEFAULT,
    PM_WARN_LITERAL_IN_CONDITION_VERBOSE,
    PM_WARN_SHAREABLE_CONSTANT_VALUE_LINE,
    PM_WARN_SHEBANG_CARRIAGE_RETURN,
    PM_WARN_UNEXPECTED_CARRIAGE_RETURN,
    PM_WARN_UNREACHABLE_STATEMENT,
    PM_WARN_UNUSED_LOCAL_VARIABLE,
    PM_WARN_VOID_STATEMENT,
} pm_diagnostic_id_t;
typedef struct {
    pm_list_node_t node;
    pm_location_t location;
    pm_diagnostic_id_t diag_id;
    const char *message;
    _Bool owned;
    uint8_t level;
} pm_diagnostic_t;
typedef enum {
    PM_ERROR_LEVEL_SYNTAX = 0,
    PM_ERROR_LEVEL_ARGUMENT = 1,
    PM_ERROR_LEVEL_LOAD = 2
} pm_error_level_t;
typedef enum {
    PM_WARNING_LEVEL_DEFAULT = 0,
    PM_WARNING_LEVEL_VERBOSE = 1
} pm_warning_level_t;
const char * pm_diagnostic_id_human(pm_diagnostic_id_t diag_id);
_Bool pm_diagnostic_list_append(pm_list_t *list, const uint8_t *start, const uint8_t *end, pm_diagnostic_id_t diag_id);
_Bool pm_diagnostic_list_append_format(pm_list_t *list, const uint8_t *start, const uint8_t *end, pm_diagnostic_id_t diag_id, ...);
void pm_diagnostic_list_free(pm_list_t *list);
typedef struct pm_options_scope {
    size_t locals_count;
    pm_string_t *locals;
} pm_options_scope_t;
struct pm_options;
typedef void (*pm_options_shebang_callback_t)(struct pm_options *options, const uint8_t *source, size_t length, void *shebang_callback_data);
typedef enum {
    PM_OPTIONS_VERSION_LATEST = 0,
    PM_OPTIONS_VERSION_CRUBY_3_3 = 1
} pm_options_version_t;
typedef struct pm_options {
    pm_options_shebang_callback_t shebang_callback;
    void *shebang_callback_data;
    pm_string_t filepath;
    int32_t line;
    pm_string_t encoding;
    size_t scopes_count;
    pm_options_scope_t *scopes;
    pm_options_version_t version;
    uint8_t command_line;
    int8_t frozen_string_literal;
    _Bool encoding_locked;
    _Bool main_script;
    _Bool partial_script;
} pm_options_t;
static const uint8_t PM_OPTIONS_COMMAND_LINE_A = 0x1;
static const uint8_t PM_OPTIONS_COMMAND_LINE_E = 0x2;
static const uint8_t PM_OPTIONS_COMMAND_LINE_L = 0x4;
static const uint8_t PM_OPTIONS_COMMAND_LINE_N = 0x8;
static const uint8_t PM_OPTIONS_COMMAND_LINE_P = 0x10;
static const uint8_t PM_OPTIONS_COMMAND_LINE_X = 0x20;
 void pm_options_shebang_callback_set(pm_options_t *options, pm_options_shebang_callback_t shebang_callback, void *shebang_callback_data);
 void pm_options_filepath_set(pm_options_t *options, const char *filepath);
 void pm_options_line_set(pm_options_t *options, int32_t line);
 void pm_options_encoding_set(pm_options_t *options, const char *encoding);
 void pm_options_encoding_locked_set(pm_options_t *options, _Bool encoding_locked);
 void pm_options_frozen_string_literal_set(pm_options_t *options, _Bool frozen_string_literal);
 void pm_options_command_line_set(pm_options_t *options, uint8_t command_line);
 _Bool pm_options_version_set(pm_options_t *options, const char *version, size_t length);
 void pm_options_main_script_set(pm_options_t *options, _Bool main_script);
 void pm_options_partial_script_set(pm_options_t *options, _Bool partial_script);
 _Bool pm_options_scopes_init(pm_options_t *options, size_t scopes_count);
 const pm_options_scope_t * pm_options_scope_get(const pm_options_t *options, size_t index);
 _Bool pm_options_scope_init(pm_options_scope_t *scope, size_t locals_count);
 const pm_string_t * pm_options_scope_local_get(const pm_options_scope_t *scope, size_t index);
 void pm_options_free(pm_options_t *options);
void pm_options_read(pm_options_t *options, const char *data);
typedef struct {
    pm_node_t **nodes;
    uint32_t size;
    uint32_t capacity;
} pm_node_hash_t;
typedef struct {
    pm_node_hash_t integer_nodes;
    pm_node_hash_t float_nodes;
    pm_node_hash_t number_nodes;
    pm_node_hash_t string_nodes;
    pm_node_hash_t regexp_nodes;
    pm_node_hash_t symbol_nodes;
    pm_node_t *true_node;
    pm_node_t *false_node;
    pm_node_t *nil_node;
    pm_node_t *source_encoding_node;
} pm_static_literals_t;
pm_node_t * pm_static_literals_add(const pm_newline_list_t *newline_list, int32_t start_line, pm_static_literals_t *literals, pm_node_t *node, _Bool replace);
void pm_static_literals_free(pm_static_literals_t *literals);
void pm_static_literal_inspect(pm_buffer_t *buffer, const pm_newline_list_t *newline_list, int32_t start_line, const char *encoding_name, const pm_node_t *node);
typedef enum {
    PM_LEX_STATE_BIT_BEG,
    PM_LEX_STATE_BIT_END,
    PM_LEX_STATE_BIT_ENDARG,
    PM_LEX_STATE_BIT_ENDFN,
    PM_LEX_STATE_BIT_ARG,
    PM_LEX_STATE_BIT_CMDARG,
    PM_LEX_STATE_BIT_MID,
    PM_LEX_STATE_BIT_FNAME,
    PM_LEX_STATE_BIT_DOT,
    PM_LEX_STATE_BIT_CLASS,
    PM_LEX_STATE_BIT_LABEL,
    PM_LEX_STATE_BIT_LABELED,
    PM_LEX_STATE_BIT_FITEM
} pm_lex_state_bit_t;
typedef enum {
    PM_LEX_STATE_NONE = 0,
    PM_LEX_STATE_BEG = (1 << PM_LEX_STATE_BIT_BEG),
    PM_LEX_STATE_END = (1 << PM_LEX_STATE_BIT_END),
    PM_LEX_STATE_ENDARG = (1 << PM_LEX_STATE_BIT_ENDARG),
    PM_LEX_STATE_ENDFN = (1 << PM_LEX_STATE_BIT_ENDFN),
    PM_LEX_STATE_ARG = (1 << PM_LEX_STATE_BIT_ARG),
    PM_LEX_STATE_CMDARG = (1 << PM_LEX_STATE_BIT_CMDARG),
    PM_LEX_STATE_MID = (1 << PM_LEX_STATE_BIT_MID),
    PM_LEX_STATE_FNAME = (1 << PM_LEX_STATE_BIT_FNAME),
    PM_LEX_STATE_DOT = (1 << PM_LEX_STATE_BIT_DOT),
    PM_LEX_STATE_CLASS = (1 << PM_LEX_STATE_BIT_CLASS),
    PM_LEX_STATE_LABEL = (1 << PM_LEX_STATE_BIT_LABEL),
    PM_LEX_STATE_LABELED = (1 << PM_LEX_STATE_BIT_LABELED),
    PM_LEX_STATE_FITEM = (1 << PM_LEX_STATE_BIT_FITEM),
    PM_LEX_STATE_BEG_ANY = PM_LEX_STATE_BEG | PM_LEX_STATE_MID | PM_LEX_STATE_CLASS,
    PM_LEX_STATE_ARG_ANY = PM_LEX_STATE_ARG | PM_LEX_STATE_CMDARG,
    PM_LEX_STATE_END_ANY = PM_LEX_STATE_END | PM_LEX_STATE_ENDARG | PM_LEX_STATE_ENDFN
} pm_lex_state_t;
typedef enum {
    PM_HEREDOC_QUOTE_NONE,
    PM_HEREDOC_QUOTE_SINGLE = '\'',
    PM_HEREDOC_QUOTE_DOUBLE = '"',
    PM_HEREDOC_QUOTE_BACKTICK = '`',
} pm_heredoc_quote_t;
typedef enum {
    PM_HEREDOC_INDENT_NONE,
    PM_HEREDOC_INDENT_DASH,
    PM_HEREDOC_INDENT_TILDE,
} pm_heredoc_indent_t;
typedef struct {
    const uint8_t *ident_start;
    size_t ident_length;
    pm_heredoc_quote_t quote;
    pm_heredoc_indent_t indent;
} pm_heredoc_lex_mode_t;
typedef struct pm_lex_mode {
    enum {
        PM_LEX_DEFAULT,
        PM_LEX_EMBEXPR,
        PM_LEX_EMBVAR,
        PM_LEX_HEREDOC,
        PM_LEX_LIST,
        PM_LEX_REGEXP,
        PM_LEX_STRING
    } mode;
    union {
        struct {
            size_t nesting;
            _Bool interpolation;
            uint8_t incrementor;
            uint8_t terminator;
            uint8_t breakpoints[11];
        } list;
        struct {
            size_t nesting;
            uint8_t incrementor;
            uint8_t terminator;
            uint8_t breakpoints[7];
        } regexp;
        struct {
            size_t nesting;
            _Bool interpolation;
            _Bool label_allowed;
            uint8_t incrementor;
            uint8_t terminator;
            uint8_t breakpoints[7];
        } string;
        struct {
            pm_heredoc_lex_mode_t base;
            const uint8_t *next_start;
            size_t *common_whitespace;
            _Bool line_continuation;
        } heredoc;
    } as;
    struct pm_lex_mode *prev;
} pm_lex_mode_t;
typedef struct pm_parser pm_parser_t;
typedef enum {
    PM_CONTEXT_NONE = 0,
    PM_CONTEXT_BEGIN,
    PM_CONTEXT_BEGIN_ENSURE,
    PM_CONTEXT_BEGIN_ELSE,
    PM_CONTEXT_BEGIN_RESCUE,
    PM_CONTEXT_BLOCK_BRACES,
    PM_CONTEXT_BLOCK_KEYWORDS,
    PM_CONTEXT_BLOCK_ENSURE,
    PM_CONTEXT_BLOCK_ELSE,
    PM_CONTEXT_BLOCK_RESCUE,
    PM_CONTEXT_CASE_WHEN,
    PM_CONTEXT_CASE_IN,
    PM_CONTEXT_CLASS,
    PM_CONTEXT_CLASS_ENSURE,
    PM_CONTEXT_CLASS_ELSE,
    PM_CONTEXT_CLASS_RESCUE,
    PM_CONTEXT_DEF,
    PM_CONTEXT_DEF_ENSURE,
    PM_CONTEXT_DEF_ELSE,
    PM_CONTEXT_DEF_RESCUE,
    PM_CONTEXT_DEF_PARAMS,
    PM_CONTEXT_DEFINED,
    PM_CONTEXT_DEFAULT_PARAMS,
    PM_CONTEXT_ELSE,
    PM_CONTEXT_ELSIF,
    PM_CONTEXT_EMBEXPR,
    PM_CONTEXT_FOR,
    PM_CONTEXT_FOR_INDEX,
    PM_CONTEXT_IF,
    PM_CONTEXT_LAMBDA_BRACES,
    PM_CONTEXT_LAMBDA_DO_END,
    PM_CONTEXT_LAMBDA_ENSURE,
    PM_CONTEXT_LAMBDA_ELSE,
    PM_CONTEXT_LAMBDA_RESCUE,
    PM_CONTEXT_LOOP_PREDICATE,
    PM_CONTEXT_MAIN,
    PM_CONTEXT_MODULE,
    PM_CONTEXT_MODULE_ENSURE,
    PM_CONTEXT_MODULE_ELSE,
    PM_CONTEXT_MODULE_RESCUE,
    PM_CONTEXT_MULTI_TARGET,
    PM_CONTEXT_PARENS,
    PM_CONTEXT_POSTEXE,
    PM_CONTEXT_PREDICATE,
    PM_CONTEXT_PREEXE,
    PM_CONTEXT_RESCUE_MODIFIER,
    PM_CONTEXT_SCLASS,
    PM_CONTEXT_SCLASS_ENSURE,
    PM_CONTEXT_SCLASS_ELSE,
    PM_CONTEXT_SCLASS_RESCUE,
    PM_CONTEXT_TERNARY,
    PM_CONTEXT_UNLESS,
    PM_CONTEXT_UNTIL,
    PM_CONTEXT_WHILE,
} pm_context_t;
typedef struct pm_context_node {
    pm_context_t context;
    struct pm_context_node *prev;
} pm_context_node_t;
typedef enum {
    PM_COMMENT_INLINE,
    PM_COMMENT_EMBDOC
} pm_comment_type_t;
typedef struct pm_comment {
    pm_list_node_t node;
    pm_location_t location;
    pm_comment_type_t type;
} pm_comment_t;
typedef struct {
    pm_list_node_t node;
    const uint8_t *key_start;
    const uint8_t *value_start;
    uint32_t key_length;
    uint32_t value_length;
} pm_magic_comment_t;
typedef void (*pm_encoding_changed_callback_t)(pm_parser_t *parser);
typedef struct {
    void *data;
    void (*callback)(void *data, pm_parser_t *parser, pm_token_t *token);
} pm_lex_callback_t;
typedef uint8_t pm_shareable_constant_value_t;
static const pm_shareable_constant_value_t PM_SCOPE_SHAREABLE_CONSTANT_NONE = 0x0;
static const pm_shareable_constant_value_t PM_SCOPE_SHAREABLE_CONSTANT_LITERAL = PM_SHAREABLE_CONSTANT_NODE_FLAGS_LITERAL;
static const pm_shareable_constant_value_t PM_SCOPE_SHAREABLE_CONSTANT_EXPERIMENTAL_EVERYTHING = PM_SHAREABLE_CONSTANT_NODE_FLAGS_EXPERIMENTAL_EVERYTHING;
static const pm_shareable_constant_value_t PM_SCOPE_SHAREABLE_CONSTANT_EXPERIMENTAL_COPY = PM_SHAREABLE_CONSTANT_NODE_FLAGS_EXPERIMENTAL_COPY;
typedef struct {
    pm_constant_id_t name;
    pm_location_t location;
    uint32_t index;
    uint32_t reads;
    uint32_t hash;
} pm_local_t;
typedef struct pm_locals {
    uint32_t size;
    uint32_t capacity;
    pm_local_t *locals;
} pm_locals_t;
typedef uint8_t pm_scope_parameters_t;
static const pm_scope_parameters_t PM_SCOPE_PARAMETERS_NONE = 0x0;
static const pm_scope_parameters_t PM_SCOPE_PARAMETERS_FORWARDING_POSITIONALS = 0x1;
static const pm_scope_parameters_t PM_SCOPE_PARAMETERS_FORWARDING_KEYWORDS = 0x2;
static const pm_scope_parameters_t PM_SCOPE_PARAMETERS_FORWARDING_BLOCK = 0x4;
static const pm_scope_parameters_t PM_SCOPE_PARAMETERS_FORWARDING_ALL = 0x8;
static const pm_scope_parameters_t PM_SCOPE_PARAMETERS_IMPLICIT_DISALLOWED = 0x10;
static const pm_scope_parameters_t PM_SCOPE_PARAMETERS_NUMBERED_INNER = 0x20;
static const pm_scope_parameters_t PM_SCOPE_PARAMETERS_NUMBERED_FOUND = 0x40;
typedef struct pm_scope {
    struct pm_scope *previous;
    pm_locals_t locals;
    pm_node_list_t implicit_parameters;
    pm_scope_parameters_t parameters;
    pm_shareable_constant_value_t shareable_constant;
    _Bool closed;
} pm_scope_t;
typedef uint32_t pm_state_stack_t;
struct pm_parser {
    uint32_t node_id;
    pm_lex_state_t lex_state;
    int enclosure_nesting;
    int lambda_enclosure_nesting;
    int brace_nesting;
    pm_state_stack_t do_loop_stack;
    pm_state_stack_t accepts_block_stack;
    struct {
        pm_lex_mode_t *current;
        pm_lex_mode_t stack[4];
        size_t index;
    } lex_modes;
    const uint8_t *start;
    const uint8_t *end;
    pm_token_t previous;
    pm_token_t current;
    const uint8_t *next_start;
    const uint8_t *heredoc_end;
    pm_list_t comment_list;
    pm_list_t magic_comment_list;
    pm_location_t data_loc;
    pm_list_t warning_list;
    pm_list_t error_list;
    pm_scope_t *current_scope;
    pm_context_node_t *current_context;
    pm_static_literals_t *current_hash_keys;
    const pm_encoding_t *encoding;
    pm_encoding_changed_callback_t encoding_changed_callback;
    const uint8_t *encoding_comment_start;
    pm_lex_callback_t *lex_callback;
    pm_string_t filepath;
    pm_constant_pool_t constant_pool;
    pm_newline_list_t newline_list;
    pm_node_flags_t integer_base;
    pm_string_t current_string;
    int32_t start_line;
    const pm_encoding_t *explicit_encoding;
    pm_node_list_t *current_block_exits;
    pm_options_version_t version;
    uint8_t command_line;
    int8_t frozen_string_literal;
    _Bool parsing_eval;
    _Bool partial_script;
    _Bool command_start;
    _Bool recovering;
    _Bool encoding_locked;
    _Bool encoding_changed;
    _Bool pattern_matching_newlines;
    _Bool in_keyword_arg;
    _Bool semantic_token_seen;
    _Bool current_regular_expression_ascii_only;
    _Bool warn_mismatched_indentation;
};
const uint8_t * pm_strpbrk(pm_parser_t *parser, const uint8_t *source, const uint8_t *charset, ptrdiff_t length, _Bool validate);
void pm_node_list_append(pm_node_list_t *list, pm_node_t *node);
void pm_node_list_prepend(pm_node_list_t *list, pm_node_t *node);
void pm_node_list_concat(pm_node_list_t *list, pm_node_list_t *other);
void pm_node_list_free(pm_node_list_t *list);
 void pm_node_destroy(pm_parser_t *parser, struct pm_node *node);
 const char * pm_node_type_to_str(pm_node_type_t node_type);
 void pm_visit_node(const pm_node_t *node, _Bool (*visitor)(const pm_node_t *node, void *data), void *data);
 void pm_visit_child_nodes(const pm_node_t *node, _Bool (*visitor)(const pm_node_t *node, void *data), void *data);
typedef enum pm_pack_version {
    PM_PACK_VERSION_3_2_0
} pm_pack_version;
typedef enum pm_pack_variant {
    PM_PACK_VARIANT_PACK,
    PM_PACK_VARIANT_UNPACK
} pm_pack_variant;
typedef enum pm_pack_type {
    PM_PACK_SPACE,
    PM_PACK_COMMENT,
    PM_PACK_INTEGER,
    PM_PACK_UTF8,
    PM_PACK_BER,
    PM_PACK_FLOAT,
    PM_PACK_STRING_SPACE_PADDED,
    PM_PACK_STRING_NULL_PADDED,
    PM_PACK_STRING_NULL_TERMINATED,
    PM_PACK_STRING_MSB,
    PM_PACK_STRING_LSB,
    PM_PACK_STRING_HEX_HIGH,
    PM_PACK_STRING_HEX_LOW,
    PM_PACK_STRING_UU,
    PM_PACK_STRING_MIME,
    PM_PACK_STRING_BASE64,
    PM_PACK_STRING_FIXED,
    PM_PACK_STRING_POINTER,
    PM_PACK_MOVE,
    PM_PACK_BACK,
    PM_PACK_NULL,
    PM_PACK_END
} pm_pack_type;
typedef enum pm_pack_signed {
    PM_PACK_UNSIGNED,
    PM_PACK_SIGNED,
    PM_PACK_SIGNED_NA
} pm_pack_signed;
typedef enum pm_pack_endian {
    PM_PACK_AGNOSTIC_ENDIAN,
    PM_PACK_LITTLE_ENDIAN,
    PM_PACK_BIG_ENDIAN,
    PM_PACK_NATIVE_ENDIAN,
    PM_PACK_ENDIAN_NA
} pm_pack_endian;
typedef enum pm_pack_size {
    PM_PACK_SIZE_SHORT,
    PM_PACK_SIZE_INT,
    PM_PACK_SIZE_LONG,
    PM_PACK_SIZE_LONG_LONG,
    PM_PACK_SIZE_8,
    PM_PACK_SIZE_16,
    PM_PACK_SIZE_32,
    PM_PACK_SIZE_64,
    PM_PACK_SIZE_P,
    PM_PACK_SIZE_NA
} pm_pack_size;
typedef enum pm_pack_length_type {
    PM_PACK_LENGTH_FIXED,
    PM_PACK_LENGTH_MAX,
    PM_PACK_LENGTH_RELATIVE,
    PM_PACK_LENGTH_NA
} pm_pack_length_type;
typedef enum pm_pack_encoding {
    PM_PACK_ENCODING_START,
    PM_PACK_ENCODING_ASCII_8BIT,
    PM_PACK_ENCODING_US_ASCII,
    PM_PACK_ENCODING_UTF_8
} pm_pack_encoding;
typedef enum pm_pack_result {
    PM_PACK_OK,
    PM_PACK_ERROR_UNSUPPORTED_DIRECTIVE,
    PM_PACK_ERROR_UNKNOWN_DIRECTIVE,
    PM_PACK_ERROR_LENGTH_TOO_BIG,
    PM_PACK_ERROR_BANG_NOT_ALLOWED,
    PM_PACK_ERROR_DOUBLE_ENDIAN
} pm_pack_result;
 pm_pack_result
pm_pack_parse(
    pm_pack_variant variant,
    const char **format,
    const char *format_end,
    pm_pack_type *type,
    pm_pack_signed *signed_type,
    pm_pack_endian *endian,
    pm_pack_size *size,
    pm_pack_length_type *length_type,
    uint64_t *length,
    pm_pack_encoding *encoding
);
 size_t pm_size_to_native(pm_pack_size size);
 void pm_prettyprint(pm_buffer_t *output_buffer, const pm_parser_t *parser, const pm_node_t *node);
typedef void (*pm_regexp_name_callback_t)(const pm_string_t *name, void *data);
typedef void (*pm_regexp_error_callback_t)(const uint8_t *start, const uint8_t *end, const char *message, void *data);
 void pm_regexp_parse(pm_parser_t *parser, const uint8_t *source, size_t size, _Bool extended_mode, pm_regexp_name_callback_t name_callback, void *name_data, pm_regexp_error_callback_t error_callback, void *error_data);

struct lconv
{
  char *decimal_point;
  char *thousands_sep;
  char *grouping;
  char *int_curr_symbol;
  char *currency_symbol;
  char *mon_decimal_point;
  char *mon_thousands_sep;
  char *mon_grouping;
  char *positive_sign;
  char *negative_sign;
  char int_frac_digits;
  char frac_digits;
  char p_cs_precedes;
  char p_sep_by_space;
  char n_cs_precedes;
  char n_sep_by_space;
  char p_sign_posn;
  char n_sign_posn;
  char int_p_cs_precedes;
  char int_p_sep_by_space;
  char int_n_cs_precedes;
  char int_n_sep_by_space;
  char int_p_sign_posn;
  char int_n_sign_posn;
};
extern char *setlocale (int __category, const char *__locale) __attribute__ ((__nothrow__ , __leaf__));
extern struct lconv *localeconv (void) __attribute__ ((__nothrow__ , __leaf__));
extern locale_t newlocale (int __category_mask, const char *__locale,
      locale_t __base) __attribute__ ((__nothrow__ , __leaf__));
extern locale_t duplocale (locale_t __dataset) __attribute__ ((__nothrow__ , __leaf__));
extern void freelocale (locale_t __dataset) __attribute__ ((__nothrow__ , __leaf__));
extern locale_t uselocale (locale_t __dataset) __attribute__ ((__nothrow__ , __leaf__));

 const char * pm_version(void);
 void pm_parser_init(pm_parser_t *parser, const uint8_t *source, size_t size, const pm_options_t *options);
 void pm_parser_register_encoding_changed_callback(pm_parser_t *parser, pm_encoding_changed_callback_t callback);
 void pm_parser_free(pm_parser_t *parser);
 pm_node_t * pm_parse(pm_parser_t *parser);
typedef char * (pm_parse_stream_fgets_t)(char *string, int size, void *stream);
 pm_node_t * pm_parse_stream(pm_parser_t *parser, pm_buffer_t *buffer, void *stream, pm_parse_stream_fgets_t *fgets, const pm_options_t *options);
 void pm_serialize_parse_stream(pm_buffer_t *buffer, void *stream, pm_parse_stream_fgets_t *fgets, const char *data);
void pm_serialize_comment_list(pm_parser_t *parser, pm_list_t *list, pm_buffer_t *buffer);
void pm_serialize_encoding(const pm_encoding_t *encoding, pm_buffer_t *buffer);
void pm_serialize_content(pm_parser_t *parser, pm_node_t *node, pm_buffer_t *buffer);
 void pm_serialize(pm_parser_t *parser, pm_node_t *node, pm_buffer_t *buffer);
 void pm_serialize_parse(pm_buffer_t *buffer, const uint8_t *source, size_t size, const char *data);
 void pm_serialize_parse_comments(pm_buffer_t *buffer, const uint8_t *source, size_t size, const char *data);
 void pm_serialize_lex(pm_buffer_t *buffer, const uint8_t *source, size_t size, const char *data);
 void pm_serialize_parse_lex(pm_buffer_t *buffer, const uint8_t *source, size_t size, const char *data);
 _Bool pm_parse_success_p(const uint8_t *source, size_t size, const char *data);
 const char * pm_token_type_name(pm_token_type_t token_type);
const char * pm_token_type_human(pm_token_type_t token_type);
 void pm_dump_json(pm_buffer_t *buffer, const pm_parser_t *parser, const pm_node_t *node);
typedef enum {
    PM_STRING_QUERY_ERROR = -1,
    PM_STRING_QUERY_FALSE,
    PM_STRING_QUERY_TRUE
} pm_string_query_t;
 pm_string_query_t pm_string_query_local(const uint8_t *source, size_t length, const char *encoding_name);
 pm_string_query_t pm_string_query_constant(const uint8_t *source, size_t length, const char *encoding_name);
 pm_string_query_t pm_string_query_method_name(const uint8_t *source, size_t length, const char *encoding_name);
typedef struct pm_local_index_struct {
    int index, level;
} pm_local_index_t;
struct iseq_link_anchor;
typedef struct pm_scope_node {
    pm_node_t base;
    struct pm_scope_node *previous;
    pm_node_t *ast_node;
    pm_node_t *parameters;
    pm_node_t *body;
    pm_constant_id_list_t locals;
    const pm_parser_t *parser;
    rb_encoding *encoding;
    VALUE *script_lines;
    rb_encoding *filepath_encoding;
    int local_table_for_iseq_size;
    ID *constants;
    st_table *index_lookup_table;
    int coverage_enabled;
    struct iseq_link_anchor *pre_execution_anchor;
} pm_scope_node_t;
void pm_scope_node_init(const pm_node_t *node, pm_scope_node_t *scope, pm_scope_node_t *previous);
void pm_scope_node_destroy(pm_scope_node_t *scope_node);
typedef struct {
    pm_parser_t parser;
    pm_options_t options;
    pm_string_t input;
    pm_scope_node_t node;
    _Bool parsed;
} pm_parse_result_t;
VALUE pm_load_file(pm_parse_result_t *result, VALUE filepath, _Bool load_error);
VALUE pm_parse_file(pm_parse_result_t *result, VALUE filepath, VALUE *script_lines);
VALUE pm_load_parse_file(pm_parse_result_t *result, VALUE filepath, VALUE *script_lines);
VALUE pm_parse_string(pm_parse_result_t *result, VALUE source, VALUE filepath, VALUE *script_lines);
VALUE pm_parse_stdin(pm_parse_result_t *result);
void pm_parse_result_free(pm_parse_result_t *result);
rb_iseq_t *pm_iseq_new(pm_scope_node_t *node, VALUE name, VALUE path, VALUE realpath, const rb_iseq_t *parent, enum rb_iseq_type, int *error_state);
rb_iseq_t *pm_iseq_new_top(pm_scope_node_t *node, VALUE name, VALUE path, VALUE realpath, const rb_iseq_t *parent, int *error_state);
rb_iseq_t *pm_iseq_new_main(pm_scope_node_t *node, VALUE path, VALUE realpath, const rb_iseq_t *parent, int opt, int *error_state);
rb_iseq_t *pm_iseq_new_eval(pm_scope_node_t *node, VALUE name, VALUE path, VALUE realpath, int first_lineno, const rb_iseq_t *parent, int isolated_depth, int *error_state);
rb_iseq_t *pm_iseq_new_with_opt(pm_scope_node_t *node, VALUE name, VALUE path, VALUE realpath, int first_lineno, const rb_iseq_t *parent, int isolated_depth, enum rb_iseq_type, const rb_compile_option_t *option, int *error_state);
VALUE pm_iseq_compile_node(rb_iseq_t *iseq, pm_scope_node_t *node);
extern const int ruby_api_version[];
typedef void (*rb_iseq_callback)(const rb_iseq_t *, void *);
extern const ID rb_iseq_shared_exc_local_tbl[];
static inline rb_snum_t
ISEQ_FLIP_CNT_INCREMENT(const rb_iseq_t *iseq)
{
    rb_snum_t cnt = ((iseq)->body)->variable.flip_count;
    ((iseq)->body)->variable.flip_count += 1;
    return cnt;
}
static inline VALUE *
ISEQ_ORIGINAL_ISEQ(const rb_iseq_t *iseq)
{
    return ((iseq)->body)->variable.original_iseq;
}
static inline void
ISEQ_ORIGINAL_ISEQ_CLEAR(const rb_iseq_t *iseq)
{
    void *ptr = ((iseq)->body)->variable.original_iseq;
    ((iseq)->body)->variable.original_iseq = ((void *)0);
    ruby_xfree(ptr);
}
static inline VALUE *
ISEQ_ORIGINAL_ISEQ_ALLOC(const rb_iseq_t *iseq, long size)
{
    return ((iseq)->body)->variable.original_iseq =
        ((VALUE *)ruby_xmalloc2((size), sizeof(VALUE)));
}
struct iseq_compile_data {
    const VALUE err_info;
    const VALUE catch_table_ary;
    struct iseq_label_data *start_label;
    struct iseq_label_data *end_label;
    struct iseq_label_data *redo_label;
    const rb_iseq_t *current_block;
    struct iseq_compile_data_ensure_node_stack *ensure_node_stack;
    struct {
      struct iseq_compile_data_storage *storage_head;
      struct iseq_compile_data_storage *storage_current;
    } node;
    struct {
      struct iseq_compile_data_storage *storage_head;
      struct iseq_compile_data_storage *storage_current;
    } insn;
    _Bool in_rescue;
    int loopval_popped;
    int last_line;
    int label_no;
    int node_level;
    int isolated_depth;
    unsigned int ci_index;
    unsigned int ic_index;
    const rb_compile_option_t *option;
    struct rb_id_table *ivar_cache_table;
    const struct rb_builtin_function *builtin_function_table;
    const NODE *root_node;
    _Bool catch_except_p;
};
static inline struct iseq_compile_data *
ISEQ_COMPILE_DATA(const rb_iseq_t *iseq)
{
    if (iseq->flags & ((VALUE)RUBY_FL_USER6)) {
        return iseq->aux.compile_data;
    }
    else {
        return ((void *)0);
    }
}
static inline void
ISEQ_COMPILE_DATA_ALLOC(rb_iseq_t *iseq)
{
    iseq->aux.compile_data = (((struct iseq_compile_data *)ruby_xcalloc((1), sizeof(struct iseq_compile_data))));
    iseq->flags |= ((VALUE)RUBY_FL_USER6);
}
static inline void
ISEQ_COMPILE_DATA_CLEAR(rb_iseq_t *iseq)
{
    iseq->flags &= ~((VALUE)RUBY_FL_USER6);
    iseq->aux.compile_data = ((void *)0);
}
static inline rb_iseq_t *
iseq_imemo_alloc(void)
{
    return ((rb_iseq_t *)rb_imemo_new((imemo_iseq), (0)));
}
VALUE rb_iseq_ibf_dump(const rb_iseq_t *iseq, VALUE opt);
void rb_ibf_load_iseq_complete(rb_iseq_t *iseq);
const rb_iseq_t *rb_iseq_ibf_load(VALUE str);
const rb_iseq_t *rb_iseq_ibf_load_bytes(const char *cstr, size_t);
VALUE rb_iseq_ibf_load_extra_data(VALUE str);
void rb_iseq_init_trace(rb_iseq_t *iseq);
int rb_iseq_add_local_tracepoint_recursively(const rb_iseq_t *iseq, rb_event_flag_t turnon_events, VALUE tpval, unsigned int target_line, _Bool target_bmethod);
int rb_iseq_remove_local_tracepoint_recursively(const rb_iseq_t *iseq, VALUE tpval);
const rb_iseq_t *rb_iseq_load_iseq(VALUE fname);
int rb_iseq_opt_frozen_string_literal(void);
unsigned int *rb_iseq_insns_info_decode_positions(const struct rb_iseq_constant_body *body);
int rb_vm_insn_addr2opcode(const void *addr);

#pragma GCC visibility push(default)

VALUE rb_iseq_compile_node(rb_iseq_t *iseq, const NODE *node);
VALUE rb_iseq_compile_callback(rb_iseq_t *iseq, const struct rb_iseq_new_with_callback_callback_func * ifunc);
VALUE *rb_iseq_original_iseq(const rb_iseq_t *iseq);
void rb_iseq_build_from_ary(rb_iseq_t *iseq, VALUE misc,
                            VALUE locals, VALUE args,
                            VALUE exception, VALUE body);
void rb_iseq_mark_and_pin_insn_storage(struct iseq_compile_data_storage *arena);
VALUE rb_iseq_load(VALUE data, VALUE parent, VALUE opt);
VALUE rb_iseq_parameters(const rb_iseq_t *iseq, int is_proc);
unsigned int rb_iseq_line_no(const rb_iseq_t *iseq, size_t pos);
int rb_iseq_node_id(const rb_iseq_t *iseq, size_t pos);
void rb_iseq_trace_set(const rb_iseq_t *iseq, rb_event_flag_t turnon_events);
void rb_iseq_trace_set_all(rb_event_flag_t turnon_events);
void rb_iseq_insns_info_encode_positions(const rb_iseq_t *iseq);
struct rb_iseq_constant_body *rb_iseq_constant_body_alloc(void);
VALUE rb_iseqw_new(const rb_iseq_t *iseq);
const rb_iseq_t *rb_iseqw_to_iseq(VALUE iseqw);
VALUE rb_iseq_absolute_path(const rb_iseq_t *iseq);
int rb_iseq_from_eval_p(const rb_iseq_t *iseq);
VALUE rb_iseq_type(const rb_iseq_t *iseq);
VALUE rb_iseq_label(const rb_iseq_t *iseq);
VALUE rb_iseq_base_label(const rb_iseq_t *iseq);
VALUE rb_iseq_first_lineno(const rb_iseq_t *iseq);
VALUE rb_iseq_method_name(const rb_iseq_t *iseq);
void rb_iseq_code_location(const rb_iseq_t *iseq, int *first_lineno, int *first_column, int *last_lineno, int *last_column);
void rb_iseq_remove_coverage_all(void);
const rb_iseq_t *rb_method_iseq(VALUE body);
const rb_iseq_t *rb_proc_get_iseq(VALUE proc, int *is_proc);
struct rb_compile_option_struct {
    unsigned int inline_const_cache: 1;
    unsigned int peephole_optimization: 1;
    unsigned int tailcall_optimization: 1;
    unsigned int specialized_instruction: 1;
    unsigned int operands_unification: 1;
    unsigned int instructions_unification: 1;
    signed int frozen_string_literal: 2;
    unsigned int debug_frozen_string_literal: 1;
    unsigned int coverage_enabled: 1;
    int debug_level;
};
struct iseq_insn_info_entry {
    int line_no;
    int node_id;
    rb_event_flag_t events;
};
enum rb_catch_type {
    CATCH_TYPE_RESCUE = __builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)),
    CATCH_TYPE_ENSURE = __builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)),
    CATCH_TYPE_RETRY = __builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)),
    CATCH_TYPE_BREAK = __builtin_choose_expr( __builtin_constant_p(4), ((VALUE)(4)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(4)),
    CATCH_TYPE_REDO = __builtin_choose_expr( __builtin_constant_p(5), ((VALUE)(5)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(5)),
    CATCH_TYPE_NEXT = __builtin_choose_expr( __builtin_constant_p(6), ((VALUE)(6)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(6))
};
struct iseq_catch_table_entry {
    enum rb_catch_type type;
    rb_iseq_t *iseq;
    unsigned int start;
    unsigned int end;
    unsigned int cont;
    unsigned int sp;
};

struct iseq_catch_table {
    unsigned int size;
    struct iseq_catch_table_entry entries[];
} __attribute__((packed));
static inline int
iseq_catch_table_bytes(int n)
{
    enum {
        catch_table_entry_size = sizeof(struct iseq_catch_table_entry),
        catch_table_entries_max = (0x7fffffff - __builtin_offsetof (struct iseq_catch_table, entries)) / catch_table_entry_size
    };
    if (n > catch_table_entries_max) rb_fatal("too large iseq_catch_table - %d", n);
    return (int)(__builtin_offsetof (struct iseq_catch_table, entries) +
                 n * catch_table_entry_size);
}
struct iseq_compile_data_storage {
    struct iseq_compile_data_storage *next;
    unsigned int pos;
    unsigned int size;
    char buff[];
};
enum defined_type {
    DEFINED_NOT_DEFINED,
    DEFINED_NIL = 1,
    DEFINED_IVAR,
    DEFINED_LVAR,
    DEFINED_GVAR,
    DEFINED_CVAR,
    DEFINED_CONST,
    DEFINED_METHOD,
    DEFINED_YIELD,
    DEFINED_ZSUPER,
    DEFINED_SELF,
    DEFINED_TRUE,
    DEFINED_FALSE,
    DEFINED_ASGN,
    DEFINED_EXPR,
    DEFINED_REF,
    DEFINED_FUNC,
    DEFINED_CONST_FROM
};
VALUE rb_iseq_defined_string(enum defined_type type);
VALUE rb_iseq_local_variables(const rb_iseq_t *iseq);
attr_index_t rb_estimate_iv_count(VALUE klass, const rb_iseq_t * initialize_iseq);
void rb_free_encoded_insn_data(void);

#pragma GCC visibility pop

struct rb_ractor_local_storage_type {
    void (*mark)(void *ptr);
    void (*free)(void *ptr);
};
typedef struct rb_ractor_local_key_struct *rb_ractor_local_key_t;

#pragma GCC visibility push(default)

extern VALUE rb_cRactor;
VALUE rb_ractor_stdin(void);
VALUE rb_ractor_stdout(void);
VALUE rb_ractor_stderr(void);
void rb_ractor_stdin_set(VALUE io);
void rb_ractor_stdout_set(VALUE io);
void rb_ractor_stderr_set(VALUE io);
rb_ractor_local_key_t rb_ractor_local_storage_value_newkey(void);
VALUE rb_ractor_local_storage_value(rb_ractor_local_key_t key);
_Bool rb_ractor_local_storage_value_lookup(rb_ractor_local_key_t key, VALUE *val);
void rb_ractor_local_storage_value_set(rb_ractor_local_key_t key, VALUE val);
extern const struct rb_ractor_local_storage_type rb_ractor_local_storage_type_free;
rb_ractor_local_key_t rb_ractor_local_storage_ptr_newkey(const struct rb_ractor_local_storage_type *type);
void *rb_ractor_local_storage_ptr(rb_ractor_local_key_t key);
void rb_ractor_local_storage_ptr_set(rb_ractor_local_key_t key, void *ptr);
VALUE rb_ractor_make_shareable(VALUE obj);
VALUE rb_ractor_make_shareable_copy(VALUE obj);

#pragma GCC visibility pop

static inline _Bool
rb_ractor_shareable_p(VALUE obj)
{
    _Bool rb_ractor_shareable_p_continue(VALUE obj);
    if (RB_SPECIAL_CONST_P(obj)) {
        return 1;
    }
    else if (RB_FL_TEST_RAW((obj), RUBY_FL_SHAREABLE)) {
        return 1;
    }
    else {
        return rb_ractor_shareable_p_continue(obj);
    }
}

#pragma GCC visibility push(default)

extern OnigEncoding OnigEncDefaultCharEncoding;

#pragma GCC visibility pop

struct re_patter_buffer;
struct re_registers;
typedef struct re_pattern_buffer Regexp;
struct rmatch_offset {
    long beg;
    long end;
};
struct rb_matchext_struct {
    struct re_registers regs;
    struct rmatch_offset *char_offset;
    int char_offset_num_allocated;
};
typedef struct rb_matchext_struct rb_matchext_t;
struct RMatch {
    struct RBasic basic;
    VALUE str;
    VALUE regexp;
};
__attribute__((__pure__))
__attribute__((__artificial__))
static inline struct re_registers *
RMATCH_REGS(VALUE match)
{
    ((void)0);
    return &((rb_matchext_t *)((char *)(match) + sizeof(struct RMatch)))->regs;
}
struct re_registers;

#pragma GCC visibility push(default)

VALUE rb_reg_regcomp(VALUE str);
long rb_reg_search(VALUE re, VALUE str, long pos, int dir);
VALUE rb_reg_regsub(VALUE repl, VALUE src, struct re_registers *regs, VALUE rexp);
long rb_reg_adjust_startpos(VALUE re, VALUE str, long pos, int dir);
VALUE rb_reg_quote(VALUE str);
regex_t *rb_reg_prepare_re(VALUE re, VALUE str);
OnigPosition rb_reg_onig_match(VALUE re, VALUE str,
                               OnigPosition (*match)(regex_t *reg, VALUE str, struct re_registers *regs, void *args),
                               void *args, struct re_registers *regs);
int rb_reg_region_copy(struct re_registers *dst, const struct re_registers *src);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

extern const signed char ruby_digit36_to_number_table[];
extern const char ruby_hexdigits[];
unsigned long ruby_scan_digits(const char *str, ssize_t len, int base, size_t *retlen, int *overflow);

__attribute__((__nonnull__ ()))
unsigned long ruby_scan_oct(const char *str, size_t len, size_t *consumed);
__attribute__((__nonnull__ ()))
unsigned long ruby_scan_hex(const char *str, size_t len, size_t *ret);
__attribute__((__nonnull__ (1)))
void ruby_setenv(const char *key, const char *val);
__attribute__((__nonnull__ ()))
void ruby_unsetenv(const char *key);
[[nodiscard]]
__attribute__((__malloc__))
__attribute__((__returns_nonnull__))
__attribute__((__nonnull__ ()))
char *ruby_strdup(const char *str);
[[nodiscard]]
__attribute__((__malloc__))
__attribute__((__returns_nonnull__))
char *ruby_getcwd(void);
__attribute__((__nonnull__ (1)))
double ruby_strtod(const char *str, char **endptr);
__attribute__((__nonnull__ (2)))
void ruby_each_words(const char *str, void (*func)(const char *word, int len, void *argv), void *argv);

#pragma GCC visibility pop

enum rb_debug_counter_type {
RB_DEBUG_COUNTER_mc_inline_hit,
RB_DEBUG_COUNTER_mc_inline_miss_klass,
RB_DEBUG_COUNTER_mc_inline_miss_invalidated,
RB_DEBUG_COUNTER_mc_inline_miss_empty,
RB_DEBUG_COUNTER_mc_inline_miss_same_cc,
RB_DEBUG_COUNTER_mc_inline_miss_same_cme,
RB_DEBUG_COUNTER_mc_inline_miss_same_def,
RB_DEBUG_COUNTER_mc_inline_miss_diff,
RB_DEBUG_COUNTER_cvar_write_inline_hit,
RB_DEBUG_COUNTER_cvar_read_inline_hit,
RB_DEBUG_COUNTER_cvar_inline_miss,
RB_DEBUG_COUNTER_cvar_class_invalidate,
RB_DEBUG_COUNTER_cvar_include_invalidate,
RB_DEBUG_COUNTER_mc_cme_complement,
RB_DEBUG_COUNTER_mc_cme_complement_hit,
RB_DEBUG_COUNTER_mc_search,
RB_DEBUG_COUNTER_mc_search_notfound,
RB_DEBUG_COUNTER_mc_search_super,
RB_DEBUG_COUNTER_ci_packed,
RB_DEBUG_COUNTER_ci_kw,
RB_DEBUG_COUNTER_ci_nokw,
RB_DEBUG_COUNTER_ci_runtime,
RB_DEBUG_COUNTER_cc_new,
RB_DEBUG_COUNTER_cc_temp,
RB_DEBUG_COUNTER_cc_found_in_ccs,
RB_DEBUG_COUNTER_cc_not_found_in_ccs,
RB_DEBUG_COUNTER_cc_ent_invalidate,
RB_DEBUG_COUNTER_cc_cme_invalidate,
RB_DEBUG_COUNTER_cc_invalidate_leaf,
RB_DEBUG_COUNTER_cc_invalidate_leaf_ccs,
RB_DEBUG_COUNTER_cc_invalidate_leaf_callable,
RB_DEBUG_COUNTER_cc_invalidate_tree,
RB_DEBUG_COUNTER_cc_invalidate_tree_cme,
RB_DEBUG_COUNTER_cc_invalidate_tree_callable,
RB_DEBUG_COUNTER_cc_invalidate_negative,
RB_DEBUG_COUNTER_ccs_free,
RB_DEBUG_COUNTER_ccs_maxlen,
RB_DEBUG_COUNTER_ccs_found,
RB_DEBUG_COUNTER_ccs_not_found,
RB_DEBUG_COUNTER_call0_public,
RB_DEBUG_COUNTER_call0_other,
RB_DEBUG_COUNTER_gccct_hit,
RB_DEBUG_COUNTER_gccct_miss,
RB_DEBUG_COUNTER_gccct_null,
RB_DEBUG_COUNTER_iseq_num,
RB_DEBUG_COUNTER_iseq_cd_num,
RB_DEBUG_COUNTER_ccf_general,
RB_DEBUG_COUNTER_ccf_iseq_setup,
RB_DEBUG_COUNTER_ccf_iseq_setup_0start,
RB_DEBUG_COUNTER_ccf_iseq_setup_tailcall_0start,
RB_DEBUG_COUNTER_ccf_iseq_fix,
RB_DEBUG_COUNTER_ccf_iseq_opt,
RB_DEBUG_COUNTER_ccf_iseq_kw1,
RB_DEBUG_COUNTER_ccf_iseq_kw2,
RB_DEBUG_COUNTER_ccf_cfunc,
RB_DEBUG_COUNTER_ccf_cfunc_with_frame,
RB_DEBUG_COUNTER_ccf_ivar,
RB_DEBUG_COUNTER_ccf_attrset,
RB_DEBUG_COUNTER_ccf_method_missing,
RB_DEBUG_COUNTER_ccf_zsuper,
RB_DEBUG_COUNTER_ccf_bmethod,
RB_DEBUG_COUNTER_ccf_opt_send,
RB_DEBUG_COUNTER_ccf_opt_call,
RB_DEBUG_COUNTER_ccf_opt_block_call,
RB_DEBUG_COUNTER_ccf_opt_struct_aref,
RB_DEBUG_COUNTER_ccf_opt_struct_aset,
RB_DEBUG_COUNTER_ccf_super_method,
RB_DEBUG_COUNTER_ccf_cfunc_other,
RB_DEBUG_COUNTER_ccf_cfunc_only_splat,
RB_DEBUG_COUNTER_ccf_cfunc_only_splat_kw,
RB_DEBUG_COUNTER_ccf_iseq_bmethod,
RB_DEBUG_COUNTER_ccf_noniseq_bmethod,
RB_DEBUG_COUNTER_ccf_opt_send_complex,
RB_DEBUG_COUNTER_ccf_opt_send_simple,
RB_DEBUG_COUNTER_frame_push,
RB_DEBUG_COUNTER_frame_push_method,
RB_DEBUG_COUNTER_frame_push_block,
RB_DEBUG_COUNTER_frame_push_class,
RB_DEBUG_COUNTER_frame_push_top,
RB_DEBUG_COUNTER_frame_push_cfunc,
RB_DEBUG_COUNTER_frame_push_ifunc,
RB_DEBUG_COUNTER_frame_push_eval,
RB_DEBUG_COUNTER_frame_push_rescue,
RB_DEBUG_COUNTER_frame_push_dummy,
RB_DEBUG_COUNTER_frame_R2R,
RB_DEBUG_COUNTER_frame_R2C,
RB_DEBUG_COUNTER_frame_C2C,
RB_DEBUG_COUNTER_frame_C2R,
RB_DEBUG_COUNTER_ivar_get_obj_hit,
RB_DEBUG_COUNTER_ivar_get_obj_miss,
RB_DEBUG_COUNTER_ivar_get_ic_hit,
RB_DEBUG_COUNTER_ivar_get_ic_miss,
RB_DEBUG_COUNTER_ivar_set_ic_hit,
RB_DEBUG_COUNTER_ivar_set_obj_hit,
RB_DEBUG_COUNTER_ivar_set_obj_miss,
RB_DEBUG_COUNTER_ivar_set_ic_miss,
RB_DEBUG_COUNTER_ivar_set_ic_miss_noobject,
RB_DEBUG_COUNTER_ivar_get_base,
RB_DEBUG_COUNTER_ivar_set_base,
RB_DEBUG_COUNTER_ivar_get_ic_miss_set,
RB_DEBUG_COUNTER_ivar_get_cc_miss_set,
RB_DEBUG_COUNTER_ivar_get_ic_miss_unset,
RB_DEBUG_COUNTER_ivar_get_cc_miss_unset,
RB_DEBUG_COUNTER_lvar_get,
RB_DEBUG_COUNTER_lvar_get_dynamic,
RB_DEBUG_COUNTER_lvar_set,
RB_DEBUG_COUNTER_lvar_set_dynamic,
RB_DEBUG_COUNTER_lvar_set_slowpath,
RB_DEBUG_COUNTER_gc_count,
RB_DEBUG_COUNTER_gc_minor_newobj,
RB_DEBUG_COUNTER_gc_minor_malloc,
RB_DEBUG_COUNTER_gc_minor_method,
RB_DEBUG_COUNTER_gc_minor_capi,
RB_DEBUG_COUNTER_gc_minor_stress,
RB_DEBUG_COUNTER_gc_major_nofree,
RB_DEBUG_COUNTER_gc_major_oldgen,
RB_DEBUG_COUNTER_gc_major_shady,
RB_DEBUG_COUNTER_gc_major_force,
RB_DEBUG_COUNTER_gc_major_oldmalloc,
RB_DEBUG_COUNTER_gc_enter_start,
RB_DEBUG_COUNTER_gc_enter_continue,
RB_DEBUG_COUNTER_gc_enter_rest,
RB_DEBUG_COUNTER_gc_enter_finalizer,
RB_DEBUG_COUNTER_gc_isptr_trial,
RB_DEBUG_COUNTER_gc_isptr_range,
RB_DEBUG_COUNTER_gc_isptr_align,
RB_DEBUG_COUNTER_gc_isptr_maybe,
RB_DEBUG_COUNTER_obj_newobj,
RB_DEBUG_COUNTER_obj_newobj_slowpath,
RB_DEBUG_COUNTER_obj_newobj_wb_unprotected,
RB_DEBUG_COUNTER_obj_free,
RB_DEBUG_COUNTER_obj_promote,
RB_DEBUG_COUNTER_obj_wb_unprotect,
RB_DEBUG_COUNTER_obj_obj_embed,
RB_DEBUG_COUNTER_obj_obj_ptr,
RB_DEBUG_COUNTER_obj_obj_too_complex,
RB_DEBUG_COUNTER_obj_str_ptr,
RB_DEBUG_COUNTER_obj_str_embed,
RB_DEBUG_COUNTER_obj_str_shared,
RB_DEBUG_COUNTER_obj_str_nofree,
RB_DEBUG_COUNTER_obj_str_fstr,
RB_DEBUG_COUNTER_obj_ary_embed,
RB_DEBUG_COUNTER_obj_ary_ptr,
RB_DEBUG_COUNTER_obj_ary_extracapa,
RB_DEBUG_COUNTER_obj_ary_shared_create,
RB_DEBUG_COUNTER_obj_ary_shared,
RB_DEBUG_COUNTER_obj_ary_shared_root_occupied,
RB_DEBUG_COUNTER_obj_hash_empty,
RB_DEBUG_COUNTER_obj_hash_1,
RB_DEBUG_COUNTER_obj_hash_2,
RB_DEBUG_COUNTER_obj_hash_3,
RB_DEBUG_COUNTER_obj_hash_4,
RB_DEBUG_COUNTER_obj_hash_5_8,
RB_DEBUG_COUNTER_obj_hash_g8,
RB_DEBUG_COUNTER_obj_hash_null,
RB_DEBUG_COUNTER_obj_hash_ar,
RB_DEBUG_COUNTER_obj_hash_st,
RB_DEBUG_COUNTER_obj_hash_force_convert,
RB_DEBUG_COUNTER_obj_struct_embed,
RB_DEBUG_COUNTER_obj_struct_ptr,
RB_DEBUG_COUNTER_obj_data_empty,
RB_DEBUG_COUNTER_obj_data_xfree,
RB_DEBUG_COUNTER_obj_data_imm_free,
RB_DEBUG_COUNTER_obj_data_zombie,
RB_DEBUG_COUNTER_obj_match_under4,
RB_DEBUG_COUNTER_obj_match_ge4,
RB_DEBUG_COUNTER_obj_match_ge8,
RB_DEBUG_COUNTER_obj_match_ptr,
RB_DEBUG_COUNTER_obj_iclass_ptr,
RB_DEBUG_COUNTER_obj_class_ptr,
RB_DEBUG_COUNTER_obj_module_ptr,
RB_DEBUG_COUNTER_obj_bignum_ptr,
RB_DEBUG_COUNTER_obj_bignum_embed,
RB_DEBUG_COUNTER_obj_float,
RB_DEBUG_COUNTER_obj_complex,
RB_DEBUG_COUNTER_obj_rational,
RB_DEBUG_COUNTER_obj_regexp_ptr,
RB_DEBUG_COUNTER_obj_file_ptr,
RB_DEBUG_COUNTER_obj_symbol,
RB_DEBUG_COUNTER_obj_imemo_ment,
RB_DEBUG_COUNTER_obj_imemo_iseq,
RB_DEBUG_COUNTER_obj_imemo_env,
RB_DEBUG_COUNTER_obj_imemo_tmpbuf,
RB_DEBUG_COUNTER_obj_imemo_ast,
RB_DEBUG_COUNTER_obj_imemo_cref,
RB_DEBUG_COUNTER_obj_imemo_svar,
RB_DEBUG_COUNTER_obj_imemo_throw_data,
RB_DEBUG_COUNTER_obj_imemo_ifunc,
RB_DEBUG_COUNTER_obj_imemo_memo,
RB_DEBUG_COUNTER_obj_imemo_parser_strterm,
RB_DEBUG_COUNTER_obj_imemo_callinfo,
RB_DEBUG_COUNTER_obj_imemo_callcache,
RB_DEBUG_COUNTER_obj_imemo_constcache,
RB_DEBUG_COUNTER_artable_hint_hit,
RB_DEBUG_COUNTER_artable_hint_miss,
RB_DEBUG_COUNTER_artable_hint_notfound,
RB_DEBUG_COUNTER_heap_xmalloc,
RB_DEBUG_COUNTER_heap_xrealloc,
RB_DEBUG_COUNTER_heap_xfree,
RB_DEBUG_COUNTER_vm_sync_lock,
RB_DEBUG_COUNTER_vm_sync_lock_enter,
RB_DEBUG_COUNTER_vm_sync_lock_enter_nb,
RB_DEBUG_COUNTER_vm_sync_lock_enter_cr,
RB_DEBUG_COUNTER_vm_sync_barrier,
    RB_DEBUG_COUNTER_MAX
};
void rb_debug_counter_show_results(const char *msg);

#pragma GCC visibility push(default)

size_t ruby_debug_counter_get(const char **names_ptr, size_t *counters_ptr);
void ruby_debug_counter_reset(void);
void ruby_debug_counter_show_at_exit(int enable);

#pragma GCC visibility pop


#pragma GCC visibility push(default)

struct RNode;
VALUE ruby_debug_print_value(int level, int debug_level, const char *header, VALUE v);
void ruby_debug_print_v(VALUE v);
ID ruby_debug_print_id(int level, int debug_level, const char *header, ID id);
struct RNode *ruby_debug_print_node(int level, int debug_level, const char *header, const struct RNode *node);
void ruby_debug_print_n(const struct RNode *node);
int ruby_debug_print_indent(int level, int debug_level, int indent_level);
void ruby_debug_gc_check_func(void);
void ruby_set_debug_option(const char *str);

#pragma GCC visibility pop

extern enum ruby_debug_log_mode {
    ruby_debug_log_disabled = 0x00,
    ruby_debug_log_memory = 0x01,
    ruby_debug_log_stderr = 0x02,
    ruby_debug_log_file = 0x04,
} ruby_debug_log_mode;
__attribute__((__format__(__printf__, 4, 5)))
void ruby_debug_log(const char *file, int line, const char *func_name, const char *fmt, ...);
void ruby_debug_log_print(unsigned int n);
_Bool ruby_debug_log_filter(const char *func_name, const char *file_name);
_Bool rb_vm_locked_p(void);
void rb_vm_lock_body(void);
void rb_vm_unlock_body(void);
struct rb_ractor_struct;
__attribute__((__noinline__)) void rb_vm_lock_enter_body_cr(struct rb_ractor_struct *cr, unsigned int *lev );
__attribute__((__noinline__)) void rb_vm_lock_enter_body_nb(unsigned int *lev );
__attribute__((__noinline__)) void rb_vm_lock_enter_body(unsigned int *lev );
void rb_vm_lock_leave_body(unsigned int *lev );
void rb_vm_barrier(void);
extern struct rb_ractor_struct *ruby_single_main_ractor;
static inline _Bool
rb_multi_ractor_p(void)
{
    if ((__builtin_expect(!!(ruby_single_main_ractor), 1))) {
        ((void)0);
        return 0;
    }
    else {
        return 1;
    }
}
static inline void
rb_vm_lock(const char *file, int line)
{
    ((void)0);
    if (rb_multi_ractor_p()) {
        rb_vm_lock_body();
    }
}
static inline void
rb_vm_unlock(const char *file, int line)
{
    if (rb_multi_ractor_p()) {
        rb_vm_unlock_body();
    }
}
static inline void
rb_vm_lock_enter(unsigned int *lev, const char *file, int line)
{
    ((void)0);
    if (rb_multi_ractor_p()) {
        rb_vm_lock_enter_body(lev );
    }
}
static inline void
rb_vm_lock_enter_nb(unsigned int *lev, const char *file, int line)
{
    ((void)0);
    if (rb_multi_ractor_p()) {
        rb_vm_lock_enter_body_nb(lev );
    }
}
static inline void
rb_vm_lock_leave(unsigned int *lev, const char *file, int line)
{
    if (rb_multi_ractor_p()) {
        rb_vm_lock_leave_body(lev );
    }
}
static inline void
rb_vm_lock_enter_cr(struct rb_ractor_struct *cr, unsigned int *levp, const char *file, int line)
{
    ((void)0);
    rb_vm_lock_enter_body_cr(cr, levp );
}
static inline void
rb_vm_lock_leave_cr(struct rb_ractor_struct *cr, unsigned int *levp, const char *file, int line)
{
    rb_vm_lock_leave_body(levp );
}
struct rb_subclass_entry {
    VALUE klass;
    struct rb_subclass_entry *next;
    struct rb_subclass_entry *prev;
};
typedef struct rb_subclass_entry rb_subclass_entry_t;
struct rb_cvar_class_tbl_entry {
    uint32_t index;
    rb_serial_t global_cvar_state;
    const rb_cref_t * cref;
    VALUE class_value;
};
struct rb_classext_struct {
    VALUE *iv_ptr;
    struct rb_id_table *const_tbl;
    struct rb_id_table *callable_m_tbl;
    struct rb_id_table *cc_tbl;
    struct rb_id_table *cvc_tbl;
    size_t superclass_depth;
    VALUE *superclasses;
    struct rb_subclass_entry *subclasses;
    struct rb_subclass_entry *subclass_entry;
    struct rb_subclass_entry *module_subclass_entry;
    const VALUE origin_;
    const VALUE refined_class;
    union {
        struct {
            rb_alloc_func_t allocator;
        } class;
        struct {
            VALUE attached_object;
        } singleton_class;
    } as;
    const VALUE includer;
    attr_index_t max_iv_count;
    unsigned char variation_count;
    _Bool permanent_classpath : 1;
    _Bool cloned : 1;
    VALUE classpath;
};
typedef struct rb_classext_struct rb_classext_t;
__extension__ _Static_assert(8 < (1 << (sizeof(((rb_classext_t *)0)->variation_count) * 8)), "shape_max_variations" ": " "SHAPE_MAX_VARIATIONS < (1 << (sizeof(((rb_classext_t *)0)->variation_count) * CHAR_BIT))");
struct RClass {
    struct RBasic basic;
    VALUE super;
    struct rb_id_table *m_tbl;
};
__extension__ _Static_assert(sizeof(struct RClass) + sizeof(rb_classext_t) <= 4 * (sizeof(struct RBasic) + sizeof(VALUE[3])), "sizeof_rb_classext_t" ": " "sizeof(struct RClass) + sizeof(rb_classext_t) <= 4 * RVALUE_SIZE");
struct RClass_and_rb_classext_t {
    struct RClass rclass;
    rb_classext_t classext;
};
static inline st_table *
RCLASS_IV_HASH(VALUE obj)
{
    ((void)0);
    ((void)0);
    return (st_table *)((&((struct RClass_and_rb_classext_t*)(obj))->classext)->iv_ptr);
}
static inline void
RCLASS_SET_IV_HASH(VALUE obj, const st_table *tbl)
{
    ((void)0);
    ((void)0);
    ((&((struct RClass_and_rb_classext_t*)(obj))->classext)->iv_ptr) = (VALUE *)tbl;
}
static inline uint32_t
RCLASS_IV_COUNT(VALUE obj)
{
    ((void)0);
    if (rb_shape_obj_too_complex(obj)) {
        uint32_t count;
        { unsigned int _lev; rb_vm_lock_enter(&_lev, "internal/class.h", 141);;
        {
            count = (uint32_t)rb_st_table_size(RCLASS_IV_HASH(obj));
        }
        rb_vm_lock_leave(&_lev, "internal/class.h", 145); };
        return count;
    }
    else {
        return rb_shape_get_shape_by_id(RCLASS_SHAPE_ID(obj))->next_iv_index;
    }
}
static inline void
RCLASS_SET_M_TBL(VALUE klass, struct rb_id_table *table)
{
    ((void)0);
    (((struct RClass *)(klass))->m_tbl) = table;
}
void rb_class_subclass_add(VALUE super, VALUE klass);
void rb_class_remove_from_super_subclasses(VALUE);
void rb_class_update_superclasses(VALUE);
size_t rb_class_superclasses_memsize(VALUE);
void rb_class_remove_subclass_head(VALUE);
int rb_singleton_class_internal_p(VALUE sklass);
VALUE rb_class_boot(VALUE);
VALUE rb_class_s_alloc(VALUE klass);
VALUE rb_module_s_alloc(VALUE klass);
void rb_module_set_initialized(VALUE module);
void rb_module_check_initializable(VALUE module);
VALUE rb_make_metaclass(VALUE, VALUE);
VALUE rb_include_class_new(VALUE, VALUE);
void rb_class_foreach_subclass(VALUE klass, void (*f)(VALUE, VALUE), VALUE);
void rb_class_detach_subclasses(VALUE);
void rb_class_detach_module_subclasses(VALUE);
void rb_class_remove_from_module_subclasses(VALUE);
VALUE rb_define_class_id_under_no_pin(VALUE outer, ID id, VALUE super);
VALUE rb_obj_methods(int argc, const VALUE *argv, VALUE obj);
VALUE rb_obj_protected_methods(int argc, const VALUE *argv, VALUE obj);
VALUE rb_obj_private_methods(int argc, const VALUE *argv, VALUE obj);
VALUE rb_obj_public_methods(int argc, const VALUE *argv, VALUE obj);
VALUE rb_class_undefined_instance_methods(VALUE mod);
VALUE rb_special_singleton_class(VALUE);
VALUE rb_singleton_class_clone_and_attach(VALUE obj, VALUE attach);
VALUE rb_singleton_class_get(VALUE obj);
void rb_undef_methods_from(VALUE klass, VALUE super);
static inline void RCLASS_SET_ORIGIN(VALUE klass, VALUE origin);
static inline void RICLASS_SET_ORIGIN_SHARED_MTBL(VALUE iclass);
static inline VALUE RCLASS_SUPER(VALUE klass);
static inline VALUE RCLASS_SET_SUPER(VALUE klass, VALUE super);
static inline void RCLASS_SET_INCLUDER(VALUE iclass, VALUE klass);
VALUE rb_class_inherited(VALUE, VALUE);
VALUE rb_keyword_error_new(const char *, VALUE);
static inline _Bool
RCLASS_SINGLETON_P(VALUE klass)
{
    return RB_TYPE_P(klass, RUBY_T_CLASS) && RB_FL_TEST_RAW(klass, ((VALUE)RUBY_FL_SINGLETON));
}
static inline rb_alloc_func_t
RCLASS_ALLOCATOR(VALUE klass)
{
    if (RCLASS_SINGLETON_P(klass)) {
        return 0;
    }
    return (&((struct RClass_and_rb_classext_t*)(klass))->classext)->as.class.allocator;
}
static inline void
RCLASS_SET_ALLOCATOR(VALUE klass, rb_alloc_func_t allocator)
{
    ((void) (0));
    (&((struct RClass_and_rb_classext_t*)(klass))->classext)->as.class.allocator = allocator;
}
static inline void
RCLASS_SET_ORIGIN(VALUE klass, VALUE origin)
{
    (rb_obj_write((VALUE)(klass), (VALUE *)(&((&((struct RClass_and_rb_classext_t*)(klass))->classext)->origin_)), (VALUE)(origin), "internal/class.h", 224));
    if (klass != origin) RB_FL_SET(origin, ((VALUE)RUBY_FL_USER0));
}
static inline void
RICLASS_SET_ORIGIN_SHARED_MTBL(VALUE iclass)
{
    RB_FL_SET(iclass, ((VALUE)RUBY_FL_USER3));
}
static inline _Bool
RICLASS_OWNS_M_TBL_P(VALUE iclass)
{
    return RB_FL_TEST_RAW(iclass, ((VALUE)RUBY_FL_USER0) | ((VALUE)RUBY_FL_USER3)) == ((VALUE)RUBY_FL_USER0);
}
static inline void
RCLASS_SET_INCLUDER(VALUE iclass, VALUE klass)
{
    (rb_obj_write((VALUE)(iclass), (VALUE *)(&((&((struct RClass_and_rb_classext_t*)(iclass))->classext)->includer)), (VALUE)(klass), "internal/class.h", 243));
}
static inline VALUE
RCLASS_SUPER(VALUE klass)
{
    return ((struct RClass *)(klass))->super;
}
static inline VALUE
RCLASS_SET_SUPER(VALUE klass, VALUE super)
{
    if (super) {
        rb_class_remove_from_super_subclasses(klass);
        rb_class_subclass_add(super, klass);
    }
    (rb_obj_write((VALUE)(klass), (VALUE *)(&((struct RClass *)(klass))->super), (VALUE)(super), "internal/class.h", 259));
    rb_class_update_superclasses(klass);
    return super;
}
static inline void
RCLASS_SET_CLASSPATH(VALUE klass, VALUE classpath, _Bool permanent)
{
    ((void) (0));
    ((void) (0));
    (rb_obj_write((VALUE)(klass), (VALUE *)(&((&((struct RClass_and_rb_classext_t*)(klass))->classext)->classpath)), (VALUE)(classpath), "internal/class.h", 270));
    (&((struct RClass_and_rb_classext_t*)(klass))->classext)->permanent_classpath = permanent;
}
static inline VALUE
RCLASS_SET_ATTACHED_OBJECT(VALUE klass, VALUE attached_object)
{
    ((void) (0));
    (rb_obj_write((VALUE)(klass), (VALUE *)(&(&((struct RClass_and_rb_classext_t*)(klass))->classext)->as.singleton_class.attached_object), (VALUE)(attached_object), "internal/class.h", 279));
    return attached_object;
}
enum vm_call_flag_bits {
    VM_CALL_ARGS_SPLAT_bit,
    VM_CALL_ARGS_BLOCKARG_bit,
    VM_CALL_FCALL_bit,
    VM_CALL_VCALL_bit,
    VM_CALL_ARGS_SIMPLE_bit,
    VM_CALL_KWARG_bit,
    VM_CALL_KW_SPLAT_bit,
    VM_CALL_TAILCALL_bit,
    VM_CALL_SUPER_bit,
    VM_CALL_ZSUPER_bit,
    VM_CALL_OPT_SEND_bit,
    VM_CALL_KW_SPLAT_MUT_bit,
    VM_CALL_ARGS_SPLAT_MUT_bit,
    VM_CALL_FORWARDING_bit,
    VM_CALL__END
};
struct rb_callinfo_kwarg {
    int keyword_len;
    int references;
    VALUE keywords[];
};
static inline size_t
rb_callinfo_kwarg_bytes(int keyword_len)
{
    return rb_size_mul_add_or_raise(
        keyword_len,
        sizeof(VALUE),
        sizeof(struct rb_callinfo_kwarg),
        rb_eRuntimeError);
}
struct rb_callinfo {
    VALUE flags;
    const struct rb_callinfo_kwarg *kwarg;
    VALUE mid;
    VALUE flag;
    VALUE argc;
};
static inline _Bool
vm_ci_packed_p(const struct rb_callinfo *ci)
{
    if (!1) {
        return 0;
    }
    if ((__builtin_expect(!!(((VALUE)ci) & 0x01), 1))) {
        return 1;
    }
    else {
        ((void)0);
        return 0;
    }
}
static inline _Bool
vm_ci_p(const struct rb_callinfo *ci)
{
    if (vm_ci_packed_p(ci) || imemo_type_p((VALUE)(ci), imemo_callinfo)) {
        return 1;
    }
    else {
        return 0;
    }
}
static inline ID
vm_ci_mid(const struct rb_callinfo *ci)
{
    if (vm_ci_packed_p(ci)) {
        return (((VALUE)ci) >> (1 + 15 + 16)) & ((((VALUE)1)<<32) - 1);
    }
    else {
        return (ID)ci->mid;
    }
}
static inline unsigned int
vm_ci_flag(const struct rb_callinfo *ci)
{
    if (vm_ci_packed_p(ci)) {
        return (unsigned int)((((VALUE)ci) >> (1 + 15)) & ((((VALUE)1)<<16) - 1));
    }
    else {
        return (unsigned int)ci->flag;
    }
}
static inline unsigned int
vm_ci_argc(const struct rb_callinfo *ci)
{
    if (vm_ci_packed_p(ci)) {
        return (unsigned int)((((VALUE)ci) >> (1)) & ((((VALUE)1)<<15) - 1));
    }
    else {
        return (unsigned int)ci->argc;
    }
}
static inline const struct rb_callinfo_kwarg *
vm_ci_kwarg(const struct rb_callinfo *ci)
{
    if (vm_ci_packed_p(ci)) {
        return ((void *)0);
    }
    else {
        return ci->kwarg;
    }
}
static inline void
vm_ci_dump(const struct rb_callinfo *ci)
{
    if (vm_ci_packed_p(ci)) {
        ruby_debug_printf("packed_ci ID:%s flag:%x argc:%u\n",
                          rb_id2name(vm_ci_mid(ci)), vm_ci_flag(ci), vm_ci_argc(ci));
    }
    else {
        rb_obj_info_dump_loc((VALUE)(ci), "vm_callinfo.h", 183, __func__);
    }
}
const struct rb_callinfo *rb_vm_ci_lookup(ID mid, unsigned int flag, unsigned int argc, const struct rb_callinfo_kwarg *kwarg);
void rb_vm_ci_free(const struct rb_callinfo *);
static inline const struct rb_callinfo *
vm_ci_new_(ID mid, unsigned int flag, unsigned int argc, const struct rb_callinfo_kwarg *kwarg, const char *file, int line)
{
    if (1 && (((mid ) & ~((((VALUE)1)<<32) - 1)) ? 0 : ((flag) & ~((((VALUE)1)<<16) - 1)) ? 0 : ((argc) & ~((((VALUE)1)<<15) - 1)) ? 0 : (kwarg) ? 0 : 1)) {
        ((void)0);
        return ((const struct rb_callinfo *) ((((VALUE)(mid )) << (1 + 15 + 16)) | (((VALUE)(flag)) << (1 + 15)) | (((VALUE)(argc)) << (1)) | RUBY_FIXNUM_FLAG));
    }
    const _Bool debug = 0;
    if (debug) ruby_debug_printf("%s:%d ", file, line);
    const struct rb_callinfo *ci = rb_vm_ci_lookup(mid, flag, argc, kwarg);
    if (debug) rb_obj_info_dump_loc((VALUE)(ci), "vm_callinfo.h", 221, __func__);
    if (kwarg) {
        ((void)0);
    }
    else {
        ((void)0);
    }
    ((void)0);
    ((void)0);
    return ci;
}
static inline const struct rb_callinfo *
vm_ci_new_runtime_(ID mid, unsigned int flag, unsigned int argc, const struct rb_callinfo_kwarg *kwarg, const char *file, int line)
{
    ((void)0);
    return vm_ci_new_(mid, flag, argc, kwarg, file, line);
}
static inline _Bool
vm_ci_markable(const struct rb_callinfo *ci)
{
    if (! ci) {
        return 0;
    }
    else if (vm_ci_packed_p(ci)) {
        return 1;
    }
    else {
        ((void)0);
        return ! RB_FL_ANY_RAW((VALUE)ci, ((VALUE)RUBY_FL_USER4));
    }
}
typedef VALUE (*vm_call_handler)(
    struct rb_execution_context_struct *ec,
    struct rb_control_frame_struct *cfp,
    struct rb_calling_info *calling);
struct rb_callcache {
    const VALUE flags;
    const VALUE klass;
    const struct rb_callable_method_entry_struct * const cme_;
    const vm_call_handler call_;
    union {
        struct {
          uintptr_t value;
        } attr;
        const enum method_missing_reason method_missing_reason;
        VALUE v;
        const struct rb_builtin_function *bf;
    } aux_;
};
enum vm_cc_type {
    cc_type_normal,
    cc_type_super,
    cc_type_refinement,
};
extern const struct rb_callcache *rb_vm_empty_cc(void);
extern const struct rb_callcache *rb_vm_empty_cc_for_super(void);
static inline void vm_cc_attr_index_set(const struct rb_callcache *cc, attr_index_t index, shape_id_t dest_shape_id);
static inline void
vm_cc_attr_index_initialize(const struct rb_callcache *cc, shape_id_t shape_id)
{
    vm_cc_attr_index_set(cc, (attr_index_t)-1, shape_id);
}
static inline const struct rb_callcache *
vm_cc_new(VALUE klass,
          const struct rb_callable_method_entry_struct *cme,
          vm_call_handler call,
          enum vm_cc_type type)
{
    struct rb_callcache *cc = ((struct rb_callcache *)rb_imemo_new((imemo_callcache), (klass)));
    *((struct rb_callable_method_entry_struct **)&cc->cme_) = (struct rb_callable_method_entry_struct *)cme;
    *((vm_call_handler *)&cc->call_) = call;
    ((void)0);
    switch (type) {
      case cc_type_normal:
        break;
      case cc_type_super:
        *(VALUE *)&cc->flags |= ((VALUE)RUBY_FL_USER6);
        break;
      case cc_type_refinement:
        *(VALUE *)&cc->flags |= ((VALUE)RUBY_FL_USER7);
        break;
    }
    if (cme->def->type == VM_METHOD_TYPE_ATTRSET || cme->def->type == VM_METHOD_TYPE_IVAR) {
        vm_cc_attr_index_initialize(cc, (((uintptr_t)1 << 32) - 1));
    }
    ((void)0);
    return cc;
}
static inline _Bool
vm_cc_super_p(const struct rb_callcache *cc)
{
    return (cc->flags & ((VALUE)RUBY_FL_USER6)) != 0;
}
static inline _Bool
vm_cc_refinement_p(const struct rb_callcache *cc)
{
    return (cc->flags & ((VALUE)RUBY_FL_USER7)) != 0;
}
static inline _Bool
vm_cc_class_check(const struct rb_callcache *cc, VALUE klass)
{
    ((void)0);
    ((void)0);
    return cc->klass == klass;
}
static inline int
vm_cc_markable(const struct rb_callcache *cc)
{
    ((void)0);
    return RB_FL_TEST_RAW((VALUE)cc, ((VALUE)RUBY_FL_FREEZE)) == 0;
}
static inline const struct rb_callable_method_entry_struct *
vm_cc_cme(const struct rb_callcache *cc)
{
    ((void)0);
    ((void)0);
    return cc->cme_;
}
static inline vm_call_handler
vm_cc_call(const struct rb_callcache *cc)
{
    ((void)0);
    ((void)0);
    return cc->call_;
}
static inline attr_index_t
vm_cc_attr_index(const struct rb_callcache *cc)
{
    ((void)0);
    return (attr_index_t)((cc->aux_.attr.value & (((VALUE)-1) >> 32)) - 1);
}
static inline shape_id_t
vm_cc_attr_index_dest_shape_id(const struct rb_callcache *cc)
{
    ((void)0);
    return cc->aux_.attr.value >> ((8 * 8) - 32);
}
static inline void
vm_cc_atomic_shape_and_index(const struct rb_callcache *cc, shape_id_t * shape_id, attr_index_t * index)
{
    uintptr_t cache_value = cc->aux_.attr.value;
    *shape_id = (shape_id_t)(cache_value >> ((8 * 8) - 32));
    *index = (attr_index_t)(cache_value & (((VALUE)-1) >> 32)) - 1;
    return;
}
static inline void
vm_ic_atomic_shape_and_index(const struct iseq_inline_iv_cache_entry *ic, shape_id_t * shape_id, attr_index_t * index)
{
    uintptr_t cache_value = ic->value;
    *shape_id = (shape_id_t)(cache_value >> ((8 * 8) - 32));
    *index = (attr_index_t)(cache_value & (((VALUE)-1) >> 32)) - 1;
    return;
}
static inline shape_id_t
vm_ic_attr_index_dest_shape_id(const struct iseq_inline_iv_cache_entry *ic)
{
    return (shape_id_t)(ic->value >> ((8 * 8) - 32));
}
static inline unsigned int
vm_cc_cmethod_missing_reason(const struct rb_callcache *cc)
{
    ((void)0);
    return cc->aux_.method_missing_reason;
}
static inline _Bool
vm_cc_invalidated_p(const struct rb_callcache *cc)
{
    if (cc->klass && !((vm_cc_cme(cc))->flags & ((VALUE)RUBY_FL_USER9))) {
        return 0;
    }
    else {
        return 1;
    }
}
static inline _Bool
vm_cc_valid_p(const struct rb_callcache *cc, const rb_callable_method_entry_t *cc_cme, VALUE klass)
{
    ((void)0);
    if (cc->klass == klass && !((cc_cme)->flags & ((VALUE)RUBY_FL_USER9))) {
        return 1;
    }
    else {
        return 0;
    }
}
static inline void
vm_cc_call_set(const struct rb_callcache *cc, vm_call_handler call)
{
    ((void)0);
    ((void)0);
    *(vm_call_handler *)&cc->call_ = call;
}
static inline void
set_vm_cc_ivar(const struct rb_callcache *cc)
{
    *(VALUE *)&cc->flags |= ((VALUE)RUBY_FL_USER4);
}
static inline void
vm_cc_attr_index_set(const struct rb_callcache *cc, attr_index_t index, shape_id_t dest_shape_id)
{
    uintptr_t *attr_value = (uintptr_t *)&cc->aux_.attr.value;
    if (!vm_cc_markable(cc)) {
        *attr_value = (uintptr_t)(((uintptr_t)1 << 32) - 1) << ((8 * 8) - 32);
        return;
    }
    ((void)0);
    ((void)0);
    *attr_value = (attr_index_t)(index + 1) | ((uintptr_t)(dest_shape_id) << ((8 * 8) - 32));
    set_vm_cc_ivar(cc);
}
static inline _Bool
vm_cc_ivar_p(const struct rb_callcache *cc)
{
    return (cc->flags & ((VALUE)RUBY_FL_USER4)) != 0;
}
static inline void
vm_ic_attr_index_set(const rb_iseq_t *iseq, const struct iseq_inline_iv_cache_entry *ic, attr_index_t index, shape_id_t dest_shape_id)
{
    *(uintptr_t *)&ic->value = ((uintptr_t)dest_shape_id << ((8 * 8) - 32)) | (attr_index_t)(index + 1);
}
static inline void
vm_ic_attr_index_initialize(const struct iseq_inline_iv_cache_entry *ic, shape_id_t shape_id)
{
    *(uintptr_t *)&ic->value = (uintptr_t)shape_id << ((8 * 8) - 32);
}
static inline void
vm_cc_method_missing_reason_set(const struct rb_callcache *cc, enum method_missing_reason reason)
{
    ((void)0);
    ((void)0);
    *(enum method_missing_reason *)&cc->aux_.method_missing_reason = reason;
}
static inline void
vm_cc_bf_set(const struct rb_callcache *cc, const struct rb_builtin_function *bf)
{
    ((void)0);
    ((void)0);
    *(const struct rb_builtin_function **)&cc->aux_.bf = bf;
    *(VALUE *)&cc->flags |= ((VALUE)RUBY_FL_USER5);
}
static inline _Bool
vm_cc_bf_p(const struct rb_callcache *cc)
{
    return (cc->flags & ((VALUE)RUBY_FL_USER5)) != 0;
}
static inline void
vm_cc_invalidate(const struct rb_callcache *cc)
{
    ((void)0);
    ((void)0);
    ((void)0);
    *(VALUE *)&cc->klass = 0;
    ((void)0);
}
struct rb_call_data {
    const struct rb_callinfo *ci;
    const struct rb_callcache *cc;
};
struct rb_class_cc_entries {
    int capa;
    int len;
    const struct rb_callable_method_entry_struct *cme;
    struct rb_class_cc_entries_entry {
        unsigned int argc;
        unsigned int flag;
        const struct rb_callcache *cc;
    } *entries;
};
void rb_vm_ccs_free(struct rb_class_cc_entries *ccs);
extern uint64_t rb_yjit_call_threshold;
extern uint64_t rb_yjit_cold_threshold;
extern uint64_t rb_yjit_live_iseq_count;
extern uint64_t rb_yjit_iseq_alloc_count;
extern _Bool rb_yjit_enabled_p;
void rb_yjit_incr_counter(const char *counter_name);
void rb_yjit_invalidate_all_method_lookup_assumptions(void);
void rb_yjit_cme_invalidate(rb_callable_method_entry_t *cme);
void rb_yjit_collect_binding_alloc(void);
void rb_yjit_collect_binding_set(void);
void rb_yjit_compile_iseq(const rb_iseq_t *iseq, rb_execution_context_t *ec, _Bool jit_exception);
void rb_yjit_init(_Bool yjit_enabled);
void rb_yjit_free_at_exit();
void rb_yjit_bop_redefined(int redefined_flag, enum ruby_basic_operators bop);
void rb_yjit_constant_state_changed(ID id);
void rb_yjit_iseq_mark(void *payload);
void rb_yjit_iseq_update_references(const rb_iseq_t *iseq);
void rb_yjit_iseq_free(const rb_iseq_t *iseq);
void rb_yjit_before_ractor_spawn(void);
void rb_yjit_constant_ic_update(const rb_iseq_t *const iseq, IC ic, unsigned insn_idx);
void rb_yjit_tracing_invalidate_all(void);
void rb_yjit_show_usage(int help, int highlight, unsigned int width, int columns);
void rb_yjit_lazy_push_frame(const VALUE *pc);
void rb_yjit_invalidate_no_singleton_class(VALUE klass);
void rb_yjit_invalidate_ep_is_bp(const rb_iseq_t *iseq);
struct rb_builtin_function {
    const void * const func_ptr;
    const int argc;
    const int index;
    const char * const name;
};
void rb_load_with_builtin_functions(const char *feature_name, const struct rb_builtin_function *table);
typedef VALUE (*rb_builtin_arity0_function_type)(rb_execution_context_t *ec, VALUE self);
typedef VALUE (*rb_builtin_arity1_function_type)(rb_execution_context_t *ec, VALUE self,
        VALUE);
typedef VALUE (*rb_builtin_arity2_function_type)(rb_execution_context_t *ec, VALUE self,
        VALUE, VALUE);
typedef VALUE (*rb_builtin_arity3_function_type)(rb_execution_context_t *ec, VALUE self,
        VALUE, VALUE, VALUE);
typedef VALUE (*rb_builtin_arity4_function_type)(rb_execution_context_t *ec, VALUE self,
        VALUE, VALUE, VALUE, VALUE);
typedef VALUE (*rb_builtin_arity5_function_type)(rb_execution_context_t *ec, VALUE self,
        VALUE, VALUE, VALUE, VALUE, VALUE);
typedef VALUE (*rb_builtin_arity6_function_type)(rb_execution_context_t *ec, VALUE self,
        VALUE, VALUE, VALUE, VALUE, VALUE, VALUE);
typedef VALUE (*rb_builtin_arity7_function_type)(rb_execution_context_t *ec, VALUE self,
        VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE);
typedef VALUE (*rb_builtin_arity8_function_type)(rb_execution_context_t *ec, VALUE self,
        VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE);
typedef VALUE (*rb_builtin_arity9_function_type)(rb_execution_context_t *ec, VALUE self,
        VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE);
typedef VALUE (*rb_builtin_arity10_function_type)(rb_execution_context_t *ec, VALUE self,
        VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE);
typedef VALUE (*rb_builtin_arity11_function_type)(rb_execution_context_t *ec, VALUE self,
        VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE);
typedef VALUE (*rb_builtin_arity12_function_type)(rb_execution_context_t *ec, VALUE self,
        VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE);
typedef VALUE (*rb_builtin_arity13_function_type)(rb_execution_context_t *ec, VALUE self,
        VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE);
typedef VALUE (*rb_builtin_arity14_function_type)(rb_execution_context_t *ec, VALUE self,
        VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE);
typedef VALUE (*rb_builtin_arity15_function_type)(rb_execution_context_t *ec, VALUE self,
        VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE, VALUE);
static inline void rb_builtin_function_check_arity0(rb_builtin_arity0_function_type f){}
static inline void rb_builtin_function_check_arity1(rb_builtin_arity1_function_type f){}
static inline void rb_builtin_function_check_arity2(rb_builtin_arity2_function_type f){}
static inline void rb_builtin_function_check_arity3(rb_builtin_arity3_function_type f){}
static inline void rb_builtin_function_check_arity4(rb_builtin_arity4_function_type f){}
static inline void rb_builtin_function_check_arity5(rb_builtin_arity5_function_type f){}
static inline void rb_builtin_function_check_arity6(rb_builtin_arity6_function_type f){}
static inline void rb_builtin_function_check_arity7(rb_builtin_arity7_function_type f){}
static inline void rb_builtin_function_check_arity8(rb_builtin_arity8_function_type f){}
static inline void rb_builtin_function_check_arity9(rb_builtin_arity9_function_type f){}
static inline void rb_builtin_function_check_arity10(rb_builtin_arity10_function_type f){}
static inline void rb_builtin_function_check_arity11(rb_builtin_arity11_function_type f){}
static inline void rb_builtin_function_check_arity12(rb_builtin_arity12_function_type f){}
static inline void rb_builtin_function_check_arity13(rb_builtin_arity13_function_type f){}
static inline void rb_builtin_function_check_arity14(rb_builtin_arity14_function_type f){}
static inline void rb_builtin_function_check_arity15(rb_builtin_arity15_function_type f){}
__attribute__((__pure__)) VALUE rb_vm_lvar_exposed(rb_execution_context_t *ec, int index);
VALUE rb_vm_lvar_exposed(rb_execution_context_t *ec, int index);
__attribute__((__pure__)) static inline VALUE rb_vm_lvar(rb_execution_context_t *ec, int index);
static inline VALUE
rb_vm_lvar(rb_execution_context_t *ec, int index)
{
    return ec->cfp->ep[index];
}
static inline VALUE
rb_builtin_basic_definition_p(rb_execution_context_t *ec, VALUE klass, VALUE id_sym)
{
    return rb_method_basic_definition_p(klass, rb_sym2id(id_sym)) ? ((VALUE)RUBY_Qtrue) : ((VALUE)RUBY_Qfalse);
}
struct builtin_binary {
    const char *feature;
    const unsigned char *bin;
    size_t bin_size;
};
enum ruby_vminsn_type {
    YARVINSN_nop,
    YARVINSN_getlocal,
    YARVINSN_setlocal,
    YARVINSN_getblockparam,
    YARVINSN_setblockparam,
    YARVINSN_getblockparamproxy,
    YARVINSN_getspecial,
    YARVINSN_setspecial,
    YARVINSN_getinstancevariable,
    YARVINSN_setinstancevariable,
    YARVINSN_getclassvariable,
    YARVINSN_setclassvariable,
    YARVINSN_opt_getconstant_path,
    YARVINSN_getconstant,
    YARVINSN_setconstant,
    YARVINSN_getglobal,
    YARVINSN_setglobal,
    YARVINSN_putnil,
    YARVINSN_putself,
    YARVINSN_putobject,
    YARVINSN_putspecialobject,
    YARVINSN_putstring,
    YARVINSN_putchilledstring,
    YARVINSN_concatstrings,
    YARVINSN_anytostring,
    YARVINSN_toregexp,
    YARVINSN_intern,
    YARVINSN_newarray,
    YARVINSN_pushtoarraykwsplat,
    YARVINSN_duparray,
    YARVINSN_duphash,
    YARVINSN_expandarray,
    YARVINSN_concatarray,
    YARVINSN_concattoarray,
    YARVINSN_pushtoarray,
    YARVINSN_splatarray,
    YARVINSN_splatkw,
    YARVINSN_newhash,
    YARVINSN_newrange,
    YARVINSN_pop,
    YARVINSN_dup,
    YARVINSN_dupn,
    YARVINSN_swap,
    YARVINSN_opt_reverse,
    YARVINSN_topn,
    YARVINSN_setn,
    YARVINSN_adjuststack,
    YARVINSN_defined,
    YARVINSN_definedivar,
    YARVINSN_checkmatch,
    YARVINSN_checkkeyword,
    YARVINSN_checktype,
    YARVINSN_defineclass,
    YARVINSN_definemethod,
    YARVINSN_definesmethod,
    YARVINSN_send,
    YARVINSN_sendforward,
    YARVINSN_opt_send_without_block,
    YARVINSN_objtostring,
    YARVINSN_opt_ary_freeze,
    YARVINSN_opt_hash_freeze,
    YARVINSN_opt_str_freeze,
    YARVINSN_opt_nil_p,
    YARVINSN_opt_str_uminus,
    YARVINSN_opt_duparray_send,
    YARVINSN_opt_newarray_send,
    YARVINSN_invokesuper,
    YARVINSN_invokesuperforward,
    YARVINSN_invokeblock,
    YARVINSN_leave,
    YARVINSN_throw,
    YARVINSN_jump,
    YARVINSN_branchif,
    YARVINSN_branchunless,
    YARVINSN_branchnil,
    YARVINSN_once,
    YARVINSN_opt_case_dispatch,
    YARVINSN_opt_plus,
    YARVINSN_opt_minus,
    YARVINSN_opt_mult,
    YARVINSN_opt_div,
    YARVINSN_opt_mod,
    YARVINSN_opt_eq,
    YARVINSN_opt_neq,
    YARVINSN_opt_lt,
    YARVINSN_opt_le,
    YARVINSN_opt_gt,
    YARVINSN_opt_ge,
    YARVINSN_opt_ltlt,
    YARVINSN_opt_and,
    YARVINSN_opt_or,
    YARVINSN_opt_aref,
    YARVINSN_opt_aset,
    YARVINSN_opt_aset_with,
    YARVINSN_opt_aref_with,
    YARVINSN_opt_length,
    YARVINSN_opt_size,
    YARVINSN_opt_empty_p,
    YARVINSN_opt_succ,
    YARVINSN_opt_not,
    YARVINSN_opt_regexpmatch2,
    YARVINSN_invokebuiltin,
    YARVINSN_opt_invokebuiltin_delegate,
    YARVINSN_opt_invokebuiltin_delegate_leave,
    YARVINSN_getlocal_WC_0,
    YARVINSN_getlocal_WC_1,
    YARVINSN_setlocal_WC_0,
    YARVINSN_setlocal_WC_1,
    YARVINSN_putobject_INT2FIX_0_,
    YARVINSN_putobject_INT2FIX_1_,
    YARVINSN_trace_nop,
    YARVINSN_trace_getlocal,
    YARVINSN_trace_setlocal,
    YARVINSN_trace_getblockparam,
    YARVINSN_trace_setblockparam,
    YARVINSN_trace_getblockparamproxy,
    YARVINSN_trace_getspecial,
    YARVINSN_trace_setspecial,
    YARVINSN_trace_getinstancevariable,
    YARVINSN_trace_setinstancevariable,
    YARVINSN_trace_getclassvariable,
    YARVINSN_trace_setclassvariable,
    YARVINSN_trace_opt_getconstant_path,
    YARVINSN_trace_getconstant,
    YARVINSN_trace_setconstant,
    YARVINSN_trace_getglobal,
    YARVINSN_trace_setglobal,
    YARVINSN_trace_putnil,
    YARVINSN_trace_putself,
    YARVINSN_trace_putobject,
    YARVINSN_trace_putspecialobject,
    YARVINSN_trace_putstring,
    YARVINSN_trace_putchilledstring,
    YARVINSN_trace_concatstrings,
    YARVINSN_trace_anytostring,
    YARVINSN_trace_toregexp,
    YARVINSN_trace_intern,
    YARVINSN_trace_newarray,
    YARVINSN_trace_pushtoarraykwsplat,
    YARVINSN_trace_duparray,
    YARVINSN_trace_duphash,
    YARVINSN_trace_expandarray,
    YARVINSN_trace_concatarray,
    YARVINSN_trace_concattoarray,
    YARVINSN_trace_pushtoarray,
    YARVINSN_trace_splatarray,
    YARVINSN_trace_splatkw,
    YARVINSN_trace_newhash,
    YARVINSN_trace_newrange,
    YARVINSN_trace_pop,
    YARVINSN_trace_dup,
    YARVINSN_trace_dupn,
    YARVINSN_trace_swap,
    YARVINSN_trace_opt_reverse,
    YARVINSN_trace_topn,
    YARVINSN_trace_setn,
    YARVINSN_trace_adjuststack,
    YARVINSN_trace_defined,
    YARVINSN_trace_definedivar,
    YARVINSN_trace_checkmatch,
    YARVINSN_trace_checkkeyword,
    YARVINSN_trace_checktype,
    YARVINSN_trace_defineclass,
    YARVINSN_trace_definemethod,
    YARVINSN_trace_definesmethod,
    YARVINSN_trace_send,
    YARVINSN_trace_sendforward,
    YARVINSN_trace_opt_send_without_block,
    YARVINSN_trace_objtostring,
    YARVINSN_trace_opt_ary_freeze,
    YARVINSN_trace_opt_hash_freeze,
    YARVINSN_trace_opt_str_freeze,
    YARVINSN_trace_opt_nil_p,
    YARVINSN_trace_opt_str_uminus,
    YARVINSN_trace_opt_duparray_send,
    YARVINSN_trace_opt_newarray_send,
    YARVINSN_trace_invokesuper,
    YARVINSN_trace_invokesuperforward,
    YARVINSN_trace_invokeblock,
    YARVINSN_trace_leave,
    YARVINSN_trace_throw,
    YARVINSN_trace_jump,
    YARVINSN_trace_branchif,
    YARVINSN_trace_branchunless,
    YARVINSN_trace_branchnil,
    YARVINSN_trace_once,
    YARVINSN_trace_opt_case_dispatch,
    YARVINSN_trace_opt_plus,
    YARVINSN_trace_opt_minus,
    YARVINSN_trace_opt_mult,
    YARVINSN_trace_opt_div,
    YARVINSN_trace_opt_mod,
    YARVINSN_trace_opt_eq,
    YARVINSN_trace_opt_neq,
    YARVINSN_trace_opt_lt,
    YARVINSN_trace_opt_le,
    YARVINSN_trace_opt_gt,
    YARVINSN_trace_opt_ge,
    YARVINSN_trace_opt_ltlt,
    YARVINSN_trace_opt_and,
    YARVINSN_trace_opt_or,
    YARVINSN_trace_opt_aref,
    YARVINSN_trace_opt_aset,
    YARVINSN_trace_opt_aset_with,
    YARVINSN_trace_opt_aref_with,
    YARVINSN_trace_opt_length,
    YARVINSN_trace_opt_size,
    YARVINSN_trace_opt_empty_p,
    YARVINSN_trace_opt_succ,
    YARVINSN_trace_opt_not,
    YARVINSN_trace_opt_regexpmatch2,
    YARVINSN_trace_invokebuiltin,
    YARVINSN_trace_opt_invokebuiltin_delegate,
    YARVINSN_trace_opt_invokebuiltin_delegate_leave,
    YARVINSN_trace_getlocal_WC_0,
    YARVINSN_trace_getlocal_WC_1,
    YARVINSN_trace_setlocal_WC_0,
    YARVINSN_trace_setlocal_WC_1,
    YARVINSN_trace_putobject_INT2FIX_0_,
    YARVINSN_trace_putobject_INT2FIX_1_,
    VM_INSTRUCTION_SIZE
};
enum ruby_insn_type_chars {
    TS_VARIABLE = '.',
    TS_CALLDATA = 'C',
    TS_CDHASH = 'H',
    TS_IC = 'K',
    TS_IVC = 'A',
    TS_ICVARC = 'J',
    TS_ID = 'I',
    TS_ISE = 'T',
    TS_ISEQ = 'S',
    TS_OFFSET = 'O',
    TS_VALUE = 'V',
    TS_LINDEX = 'L',
    TS_FUNCPTR = 'F',
    TS_NUM = 'N',
    TS_BUILTIN = 'R',
};
static inline union iseq_inline_storage_entry *
ISEQ_IS_ENTRY_START(const struct rb_iseq_constant_body *body, char op_type)
{
    unsigned int relative_ic_offset = 0;
    switch (op_type) {
      case TS_IC:
        relative_ic_offset += body->ise_size;
      case TS_ISE:
        relative_ic_offset += body->icvarc_size;
      case TS_ICVARC:
        relative_ic_offset += body->ivc_size;
      case TS_IVC:
        break;
      default:
        rb_bug("Wrong op type");
    }
    return &body->is_entries[relative_ic_offset];
}
__attribute__((__const__)) __attribute__ ((__unused__)) static const char *insn_name(VALUE insn);

#pragma GCC visibility push(default)

extern const int rb_vm_max_insn_name_size;
extern const char rb_vm_insn_name_base[];
extern const unsigned short rb_vm_insn_name_offset[VM_INSTRUCTION_SIZE];

#pragma GCC visibility pop

const char *
insn_name(VALUE i)
{
    return &rb_vm_insn_name_base[rb_vm_insn_name_offset[i]];
}
__attribute__((__const__)) __attribute__ ((__unused__)) static int insn_len(VALUE insn);

#pragma GCC visibility push(default)

extern const uint8_t rb_vm_insn_len_info[VM_INSTRUCTION_SIZE];

#pragma GCC visibility pop

int
insn_len(VALUE i)
{
    return rb_vm_insn_len_info[i];
}
__attribute__((__const__)) __attribute__ ((__unused__)) static const char *insn_op_types(VALUE insn);
__attribute__((__const__)) __attribute__ ((__unused__)) static int insn_op_type(VALUE insn, long pos);

#pragma GCC visibility push(default)

extern const char rb_vm_insn_op_base[];
extern const unsigned short rb_vm_insn_op_offset[VM_INSTRUCTION_SIZE];

#pragma GCC visibility pop

const char *
insn_op_types(VALUE i)
{
    return &rb_vm_insn_op_base[rb_vm_insn_op_offset[i]];
}
int
insn_op_type(VALUE i, long j)
{
    if (j >= insn_len(i)) {
        return 0;
    }
    else {
        return insn_op_types(i)[j];
    }
}
static _Bool leafness_of_check_ints = 0;
static _Bool
leafness_of_defined(rb_num_t op_type)
{
    switch (op_type) {
      case DEFINED_IVAR:
      case DEFINED_GVAR:
      case DEFINED_CVAR:
      case DEFINED_YIELD:
      case DEFINED_REF:
      case DEFINED_ZSUPER:
        return 0;
      case DEFINED_CONST:
      case DEFINED_CONST_FROM:
        return 0;
      case DEFINED_FUNC:
      case DEFINED_METHOD:
        return 0;
      default:
        rb_bug("unknown operand %ld: blame @shyouhei.", op_type);
    }
}
static _Bool
leafness_of_checkmatch(rb_num_t flag)
{
    if (flag == VM_CHECKMATCH_TYPE_WHEN) {
        return 1;
    }
    else {
        return 0;
    }
}
static rb_snum_t
sp_inc_of_sendish(const struct rb_callinfo *ci)
{
    const int argb = (vm_ci_flag(ci) & ((0x01 << VM_CALL_ARGS_BLOCKARG_bit) | (0x01 << VM_CALL_FORWARDING_bit))) ? 1 : 0;
    const int argc = vm_ci_argc(ci);
    const int recv = 1;
    const int retn = 1;
    return 0 - argb - argc - recv + retn;
}
static rb_snum_t
sp_inc_of_invokeblock(const struct rb_callinfo *ci)
{
    return sp_inc_of_sendish(ci) + 1;
}
typedef long OFFSET;
typedef unsigned long lindex_t;
typedef VALUE GENTRY;
typedef rb_iseq_t *ISEQ;
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_nop(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_nop(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_nop(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_nop(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_nop(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_nop(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_nop(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_nop(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_nop(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_getlocal(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_getlocal(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_getlocal(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_getlocal(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_getlocal(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_getlocal(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_getlocal(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_getlocal(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_getlocal(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_setlocal(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_setlocal(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_setlocal(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_setlocal(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_setlocal(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_setlocal(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_setlocal(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_setlocal(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_setlocal(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_getblockparam(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_getblockparam(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_getblockparam(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_getblockparam(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_getblockparam(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_getblockparam(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_getblockparam(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_getblockparam(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_getblockparam(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_setblockparam(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_setblockparam(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_setblockparam(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_setblockparam(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_setblockparam(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_setblockparam(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_setblockparam(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_setblockparam(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_setblockparam(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_getblockparamproxy(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_getblockparamproxy(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_getblockparamproxy(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_getblockparamproxy(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_getblockparamproxy(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_getblockparamproxy(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_getblockparamproxy(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_getblockparamproxy(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_getblockparamproxy(lindex_t idx, rb_num_t level);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_getspecial(rb_num_t key, rb_num_t type);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_getspecial(rb_num_t key, rb_num_t type);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_getspecial(rb_num_t key, rb_num_t type);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_getspecial(rb_num_t key, rb_num_t type);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_getspecial(rb_num_t key, rb_num_t type);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_getspecial(rb_num_t key, rb_num_t type);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_getspecial(rb_num_t key, rb_num_t type);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_getspecial(rb_num_t key, rb_num_t type);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_getspecial(rb_num_t key, rb_num_t type);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_setspecial(rb_num_t key);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_setspecial(rb_num_t key);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_setspecial(rb_num_t key);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_setspecial(rb_num_t key);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_setspecial(rb_num_t key);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_setspecial(rb_num_t key);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_setspecial(rb_num_t key);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_setspecial(rb_num_t key);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_setspecial(rb_num_t key);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_getinstancevariable(ID id, IVC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_getinstancevariable(ID id, IVC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_getinstancevariable(ID id, IVC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_getinstancevariable(ID id, IVC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_getinstancevariable(ID id, IVC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_getinstancevariable(ID id, IVC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_getinstancevariable(ID id, IVC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_getinstancevariable(ID id, IVC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_getinstancevariable(ID id, IVC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_setinstancevariable(ID id, IVC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_setinstancevariable(ID id, IVC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_setinstancevariable(ID id, IVC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_setinstancevariable(ID id, IVC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_setinstancevariable(ID id, IVC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_setinstancevariable(ID id, IVC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_setinstancevariable(ID id, IVC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_setinstancevariable(ID id, IVC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_setinstancevariable(ID id, IVC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_getclassvariable(ID id, ICVARC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_getclassvariable(ID id, ICVARC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_getclassvariable(ID id, ICVARC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_getclassvariable(ID id, ICVARC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_getclassvariable(ID id, ICVARC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_getclassvariable(ID id, ICVARC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_getclassvariable(ID id, ICVARC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_getclassvariable(ID id, ICVARC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_getclassvariable(ID id, ICVARC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_setclassvariable(ID id, ICVARC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_setclassvariable(ID id, ICVARC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_setclassvariable(ID id, ICVARC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_setclassvariable(ID id, ICVARC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_setclassvariable(ID id, ICVARC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_setclassvariable(ID id, ICVARC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_setclassvariable(ID id, ICVARC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_setclassvariable(ID id, ICVARC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_setclassvariable(ID id, ICVARC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_opt_getconstant_path(IC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_opt_getconstant_path(IC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_opt_getconstant_path(IC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_opt_getconstant_path(IC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_opt_getconstant_path(IC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_opt_getconstant_path(IC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_opt_getconstant_path(IC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_opt_getconstant_path(IC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_opt_getconstant_path(IC ic);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_getconstant(ID id);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_getconstant(ID id);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_getconstant(ID id);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_getconstant(ID id);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_getconstant(ID id);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_getconstant(ID id);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_getconstant(ID id);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_getconstant(ID id);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_getconstant(ID id);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_setconstant(ID id);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_setconstant(ID id);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_setconstant(ID id);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_setconstant(ID id);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_setconstant(ID id);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_setconstant(ID id);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_setconstant(ID id);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_setconstant(ID id);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_setconstant(ID id);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_getglobal(ID gid);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_getglobal(ID gid);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_getglobal(ID gid);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_getglobal(ID gid);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_getglobal(ID gid);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_getglobal(ID gid);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_getglobal(ID gid);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_getglobal(ID gid);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_getglobal(ID gid);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_setglobal(ID gid);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_setglobal(ID gid);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_setglobal(ID gid);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_setglobal(ID gid);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_setglobal(ID gid);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_setglobal(ID gid);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_setglobal(ID gid);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_setglobal(ID gid);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_setglobal(ID gid);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_putnil(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_putnil(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_putnil(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_putnil(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_putnil(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_putnil(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_putnil(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_putnil(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_putnil(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_putself(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_putself(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_putself(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_putself(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_putself(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_putself(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_putself(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_putself(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_putself(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_putobject(VALUE val);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_putobject(VALUE val);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_putobject(VALUE val);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_putobject(VALUE val);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_putobject(VALUE val);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_putobject(VALUE val);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_putobject(VALUE val);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_putobject(VALUE val);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_putobject(VALUE val);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_putspecialobject(rb_num_t value_type);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_putspecialobject(rb_num_t value_type);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_putspecialobject(rb_num_t value_type);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_putspecialobject(rb_num_t value_type);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_putspecialobject(rb_num_t value_type);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_putspecialobject(rb_num_t value_type);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_putspecialobject(rb_num_t value_type);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_putspecialobject(rb_num_t value_type);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_putspecialobject(rb_num_t value_type);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_putstring(VALUE str);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_putstring(VALUE str);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_putstring(VALUE str);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_putstring(VALUE str);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_putstring(VALUE str);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_putstring(VALUE str);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_putstring(VALUE str);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_putstring(VALUE str);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_putstring(VALUE str);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_putchilledstring(VALUE str);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_putchilledstring(VALUE str);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_putchilledstring(VALUE str);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_putchilledstring(VALUE str);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_putchilledstring(VALUE str);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_putchilledstring(VALUE str);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_putchilledstring(VALUE str);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_putchilledstring(VALUE str);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_putchilledstring(VALUE str);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_concatstrings(rb_num_t num);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_concatstrings(rb_num_t num);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_concatstrings(rb_num_t num);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_concatstrings(rb_num_t num);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_concatstrings(rb_num_t num);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_concatstrings(rb_num_t num);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_concatstrings(rb_num_t num);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_concatstrings(rb_num_t num);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_concatstrings(rb_num_t num);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_anytostring(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_anytostring(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_anytostring(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_anytostring(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_anytostring(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_anytostring(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_anytostring(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_anytostring(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_anytostring(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_toregexp(rb_num_t opt, rb_num_t cnt);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_toregexp(rb_num_t opt, rb_num_t cnt);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_toregexp(rb_num_t opt, rb_num_t cnt);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_toregexp(rb_num_t opt, rb_num_t cnt);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_toregexp(rb_num_t opt, rb_num_t cnt);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_toregexp(rb_num_t opt, rb_num_t cnt);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_toregexp(rb_num_t opt, rb_num_t cnt);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_toregexp(rb_num_t opt, rb_num_t cnt);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_toregexp(rb_num_t opt, rb_num_t cnt);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_intern(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_intern(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_intern(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_intern(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_intern(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_intern(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_intern(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_intern(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_intern(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_newarray(rb_num_t num);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_newarray(rb_num_t num);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_newarray(rb_num_t num);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_newarray(rb_num_t num);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_newarray(rb_num_t num);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_newarray(rb_num_t num);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_newarray(rb_num_t num);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_newarray(rb_num_t num);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_newarray(rb_num_t num);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_pushtoarraykwsplat(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_pushtoarraykwsplat(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_pushtoarraykwsplat(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_pushtoarraykwsplat(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_pushtoarraykwsplat(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_pushtoarraykwsplat(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_pushtoarraykwsplat(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_pushtoarraykwsplat(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_pushtoarraykwsplat(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_duparray(VALUE ary);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_duparray(VALUE ary);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_duparray(VALUE ary);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_duparray(VALUE ary);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_duparray(VALUE ary);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_duparray(VALUE ary);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_duparray(VALUE ary);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_duparray(VALUE ary);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_duparray(VALUE ary);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_duphash(VALUE hash);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_duphash(VALUE hash);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_duphash(VALUE hash);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_duphash(VALUE hash);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_duphash(VALUE hash);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_duphash(VALUE hash);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_duphash(VALUE hash);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_duphash(VALUE hash);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_duphash(VALUE hash);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_expandarray(rb_num_t num, rb_num_t flag);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_expandarray(rb_num_t num, rb_num_t flag);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_expandarray(rb_num_t num, rb_num_t flag);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_expandarray(rb_num_t num, rb_num_t flag);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_expandarray(rb_num_t num, rb_num_t flag);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_expandarray(rb_num_t num, rb_num_t flag);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_expandarray(rb_num_t num, rb_num_t flag);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_expandarray(rb_num_t num, rb_num_t flag);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_expandarray(rb_num_t num, rb_num_t flag);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_concatarray(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_concatarray(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_concatarray(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_concatarray(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_concatarray(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_concatarray(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_concatarray(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_concatarray(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_concatarray(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_concattoarray(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_concattoarray(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_concattoarray(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_concattoarray(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_concattoarray(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_concattoarray(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_concattoarray(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_concattoarray(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_concattoarray(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_pushtoarray(rb_num_t num);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_pushtoarray(rb_num_t num);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_pushtoarray(rb_num_t num);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_pushtoarray(rb_num_t num);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_pushtoarray(rb_num_t num);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_pushtoarray(rb_num_t num);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_pushtoarray(rb_num_t num);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_pushtoarray(rb_num_t num);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_pushtoarray(rb_num_t num);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_splatarray(VALUE flag);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_splatarray(VALUE flag);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_splatarray(VALUE flag);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_splatarray(VALUE flag);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_splatarray(VALUE flag);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_splatarray(VALUE flag);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_splatarray(VALUE flag);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_splatarray(VALUE flag);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_splatarray(VALUE flag);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_splatkw(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_splatkw(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_splatkw(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_splatkw(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_splatkw(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_splatkw(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_splatkw(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_splatkw(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_splatkw(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_newhash(rb_num_t num);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_newhash(rb_num_t num);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_newhash(rb_num_t num);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_newhash(rb_num_t num);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_newhash(rb_num_t num);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_newhash(rb_num_t num);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_newhash(rb_num_t num);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_newhash(rb_num_t num);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_newhash(rb_num_t num);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_newrange(rb_num_t flag);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_newrange(rb_num_t flag);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_newrange(rb_num_t flag);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_newrange(rb_num_t flag);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_newrange(rb_num_t flag);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_newrange(rb_num_t flag);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_newrange(rb_num_t flag);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_newrange(rb_num_t flag);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_newrange(rb_num_t flag);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_pop(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_pop(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_pop(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_pop(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_pop(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_pop(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_pop(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_pop(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_pop(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_dup(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_dup(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_dup(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_dup(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_dup(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_dup(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_dup(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_dup(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_dup(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_dupn(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_dupn(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_dupn(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_dupn(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_dupn(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_dupn(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_dupn(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_dupn(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_dupn(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_swap(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_swap(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_swap(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_swap(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_swap(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_swap(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_swap(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_swap(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_swap(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_opt_reverse(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_opt_reverse(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_opt_reverse(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_opt_reverse(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_opt_reverse(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_opt_reverse(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_opt_reverse(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_opt_reverse(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_opt_reverse(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_topn(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_topn(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_topn(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_topn(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_topn(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_topn(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_topn(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_topn(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_topn(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_setn(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_setn(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_setn(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_setn(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_setn(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_setn(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_setn(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_setn(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_setn(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_adjuststack(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_adjuststack(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_adjuststack(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_adjuststack(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_adjuststack(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_adjuststack(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_adjuststack(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_adjuststack(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_adjuststack(rb_num_t n);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_defined(rb_num_t op_type, VALUE obj, VALUE pushval);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_defined(rb_num_t op_type, VALUE obj, VALUE pushval);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_defined(rb_num_t op_type, VALUE obj, VALUE pushval);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_defined(rb_num_t op_type, VALUE obj, VALUE pushval);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_defined(rb_num_t op_type, VALUE obj, VALUE pushval);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_defined(rb_num_t op_type, VALUE obj, VALUE pushval);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_defined(rb_num_t op_type, VALUE obj, VALUE pushval);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_defined(rb_num_t op_type, VALUE obj, VALUE pushval);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_defined(rb_num_t op_type, VALUE obj, VALUE pushval);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_definedivar(ID id, IVC ic, VALUE pushval);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_definedivar(ID id, IVC ic, VALUE pushval);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_definedivar(ID id, IVC ic, VALUE pushval);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_definedivar(ID id, IVC ic, VALUE pushval);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_definedivar(ID id, IVC ic, VALUE pushval);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_definedivar(ID id, IVC ic, VALUE pushval);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_definedivar(ID id, IVC ic, VALUE pushval);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_definedivar(ID id, IVC ic, VALUE pushval);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_definedivar(ID id, IVC ic, VALUE pushval);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_checkmatch(rb_num_t flag);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_checkmatch(rb_num_t flag);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_checkmatch(rb_num_t flag);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_checkmatch(rb_num_t flag);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_checkmatch(rb_num_t flag);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_checkmatch(rb_num_t flag);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_checkmatch(rb_num_t flag);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_checkmatch(rb_num_t flag);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_checkmatch(rb_num_t flag);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_checkkeyword(lindex_t kw_bits_index, lindex_t keyword_index);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_checkkeyword(lindex_t kw_bits_index, lindex_t keyword_index);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_checkkeyword(lindex_t kw_bits_index, lindex_t keyword_index);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_checkkeyword(lindex_t kw_bits_index, lindex_t keyword_index);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_checkkeyword(lindex_t kw_bits_index, lindex_t keyword_index);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_checkkeyword(lindex_t kw_bits_index, lindex_t keyword_index);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_checkkeyword(lindex_t kw_bits_index, lindex_t keyword_index);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_checkkeyword(lindex_t kw_bits_index, lindex_t keyword_index);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_checkkeyword(lindex_t kw_bits_index, lindex_t keyword_index);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_checktype(rb_num_t type);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_checktype(rb_num_t type);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_checktype(rb_num_t type);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_checktype(rb_num_t type);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_checktype(rb_num_t type);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_checktype(rb_num_t type);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_checktype(rb_num_t type);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_checktype(rb_num_t type);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_checktype(rb_num_t type);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_defineclass(ID id, ISEQ class_iseq, rb_num_t flags);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_defineclass(ID id, ISEQ class_iseq, rb_num_t flags);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_defineclass(ID id, ISEQ class_iseq, rb_num_t flags);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_defineclass(ID id, ISEQ class_iseq, rb_num_t flags);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_defineclass(ID id, ISEQ class_iseq, rb_num_t flags);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_defineclass(ID id, ISEQ class_iseq, rb_num_t flags);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_defineclass(ID id, ISEQ class_iseq, rb_num_t flags);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_defineclass(ID id, ISEQ class_iseq, rb_num_t flags);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_defineclass(ID id, ISEQ class_iseq, rb_num_t flags);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_definemethod(ID id, ISEQ iseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_definemethod(ID id, ISEQ iseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_definemethod(ID id, ISEQ iseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_definemethod(ID id, ISEQ iseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_definemethod(ID id, ISEQ iseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_definemethod(ID id, ISEQ iseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_definemethod(ID id, ISEQ iseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_definemethod(ID id, ISEQ iseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_definemethod(ID id, ISEQ iseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_definesmethod(ID id, ISEQ iseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_definesmethod(ID id, ISEQ iseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_definesmethod(ID id, ISEQ iseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_definesmethod(ID id, ISEQ iseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_definesmethod(ID id, ISEQ iseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_definesmethod(ID id, ISEQ iseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_definesmethod(ID id, ISEQ iseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_definesmethod(ID id, ISEQ iseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_definesmethod(ID id, ISEQ iseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_send(CALL_DATA cd, ISEQ blockiseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_comptime_sp_inc_send(CALL_INFO ci, ISEQ blockiseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_send(CALL_DATA cd, ISEQ blockiseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_send(CALL_DATA cd, ISEQ blockiseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_send(CALL_DATA cd, ISEQ blockiseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_send(CALL_DATA cd, ISEQ blockiseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_send(CALL_DATA cd, ISEQ blockiseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_send(CALL_DATA cd, ISEQ blockiseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_send(CALL_DATA cd, ISEQ blockiseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_send(CALL_DATA cd, ISEQ blockiseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_sendforward(CALL_DATA cd, ISEQ blockiseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_comptime_sp_inc_sendforward(CALL_INFO ci, ISEQ blockiseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_sendforward(CALL_DATA cd, ISEQ blockiseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_sendforward(CALL_DATA cd, ISEQ blockiseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_sendforward(CALL_DATA cd, ISEQ blockiseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_sendforward(CALL_DATA cd, ISEQ blockiseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_sendforward(CALL_DATA cd, ISEQ blockiseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_sendforward(CALL_DATA cd, ISEQ blockiseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_sendforward(CALL_DATA cd, ISEQ blockiseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_sendforward(CALL_DATA cd, ISEQ blockiseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_opt_send_without_block(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_comptime_sp_inc_opt_send_without_block(CALL_INFO ci);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_opt_send_without_block(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_opt_send_without_block(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_opt_send_without_block(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_opt_send_without_block(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_opt_send_without_block(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_opt_send_without_block(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_opt_send_without_block(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_opt_send_without_block(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_objtostring(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_objtostring(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_objtostring(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_objtostring(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_objtostring(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_objtostring(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_objtostring(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_objtostring(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_objtostring(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_opt_ary_freeze(VALUE ary, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_opt_ary_freeze(VALUE ary, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_opt_ary_freeze(VALUE ary, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_opt_ary_freeze(VALUE ary, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_opt_ary_freeze(VALUE ary, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_opt_ary_freeze(VALUE ary, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_opt_ary_freeze(VALUE ary, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_opt_ary_freeze(VALUE ary, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_opt_ary_freeze(VALUE ary, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_opt_hash_freeze(VALUE hash, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_opt_hash_freeze(VALUE hash, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_opt_hash_freeze(VALUE hash, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_opt_hash_freeze(VALUE hash, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_opt_hash_freeze(VALUE hash, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_opt_hash_freeze(VALUE hash, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_opt_hash_freeze(VALUE hash, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_opt_hash_freeze(VALUE hash, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_opt_hash_freeze(VALUE hash, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_opt_str_freeze(VALUE str, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_opt_str_freeze(VALUE str, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_opt_str_freeze(VALUE str, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_opt_str_freeze(VALUE str, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_opt_str_freeze(VALUE str, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_opt_str_freeze(VALUE str, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_opt_str_freeze(VALUE str, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_opt_str_freeze(VALUE str, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_opt_str_freeze(VALUE str, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_opt_nil_p(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_opt_nil_p(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_opt_nil_p(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_opt_nil_p(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_opt_nil_p(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_opt_nil_p(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_opt_nil_p(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_opt_nil_p(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_opt_nil_p(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_opt_str_uminus(VALUE str, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_opt_str_uminus(VALUE str, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_opt_str_uminus(VALUE str, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_opt_str_uminus(VALUE str, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_opt_str_uminus(VALUE str, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_opt_str_uminus(VALUE str, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_opt_str_uminus(VALUE str, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_opt_str_uminus(VALUE str, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_opt_str_uminus(VALUE str, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_opt_duparray_send(VALUE ary, ID method, rb_num_t argc);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_comptime_sp_inc_opt_duparray_send(VALUE ary, ID method, rb_num_t argc);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_opt_duparray_send(VALUE ary, ID method, rb_num_t argc);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_opt_duparray_send(VALUE ary, ID method, rb_num_t argc);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_opt_duparray_send(VALUE ary, ID method, rb_num_t argc);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_opt_duparray_send(VALUE ary, ID method, rb_num_t argc);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_opt_duparray_send(VALUE ary, ID method, rb_num_t argc);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_opt_duparray_send(VALUE ary, ID method, rb_num_t argc);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_opt_duparray_send(VALUE ary, ID method, rb_num_t argc);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_opt_duparray_send(VALUE ary, ID method, rb_num_t argc);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_opt_newarray_send(rb_num_t num, rb_num_t method);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_comptime_sp_inc_opt_newarray_send(rb_num_t num, rb_num_t method);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_opt_newarray_send(rb_num_t num, rb_num_t method);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_opt_newarray_send(rb_num_t num, rb_num_t method);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_opt_newarray_send(rb_num_t num, rb_num_t method);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_opt_newarray_send(rb_num_t num, rb_num_t method);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_opt_newarray_send(rb_num_t num, rb_num_t method);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_opt_newarray_send(rb_num_t num, rb_num_t method);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_opt_newarray_send(rb_num_t num, rb_num_t method);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_opt_newarray_send(rb_num_t num, rb_num_t method);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_invokesuper(CALL_DATA cd, ISEQ blockiseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_comptime_sp_inc_invokesuper(CALL_INFO ci, ISEQ blockiseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_invokesuper(CALL_DATA cd, ISEQ blockiseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_invokesuper(CALL_DATA cd, ISEQ blockiseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_invokesuper(CALL_DATA cd, ISEQ blockiseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_invokesuper(CALL_DATA cd, ISEQ blockiseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_invokesuper(CALL_DATA cd, ISEQ blockiseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_invokesuper(CALL_DATA cd, ISEQ blockiseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_invokesuper(CALL_DATA cd, ISEQ blockiseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_invokesuper(CALL_DATA cd, ISEQ blockiseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_invokesuperforward(CALL_DATA cd, ISEQ blockiseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_comptime_sp_inc_invokesuperforward(CALL_INFO ci, ISEQ blockiseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_invokesuperforward(CALL_DATA cd, ISEQ blockiseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_invokesuperforward(CALL_DATA cd, ISEQ blockiseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_invokesuperforward(CALL_DATA cd, ISEQ blockiseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_invokesuperforward(CALL_DATA cd, ISEQ blockiseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_invokesuperforward(CALL_DATA cd, ISEQ blockiseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_invokesuperforward(CALL_DATA cd, ISEQ blockiseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_invokesuperforward(CALL_DATA cd, ISEQ blockiseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_invokesuperforward(CALL_DATA cd, ISEQ blockiseq);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_invokeblock(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_comptime_sp_inc_invokeblock(CALL_INFO ci);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_invokeblock(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_invokeblock(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_invokeblock(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_invokeblock(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_invokeblock(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_invokeblock(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_invokeblock(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_invokeblock(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_leave(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_leave(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_leave(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_leave(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_leave(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_leave(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_leave(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_leave(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_leave(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_throw(rb_num_t throw_state);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_throw(rb_num_t throw_state);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_throw(rb_num_t throw_state);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_throw(rb_num_t throw_state);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_throw(rb_num_t throw_state);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_throw(rb_num_t throw_state);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_throw(rb_num_t throw_state);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_throw(rb_num_t throw_state);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_throw(rb_num_t throw_state);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_jump(OFFSET dst);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_jump(OFFSET dst);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_jump(OFFSET dst);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_jump(OFFSET dst);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_jump(OFFSET dst);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_jump(OFFSET dst);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_jump(OFFSET dst);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_jump(OFFSET dst);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_jump(OFFSET dst);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_branchif(OFFSET dst);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_branchif(OFFSET dst);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_branchif(OFFSET dst);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_branchif(OFFSET dst);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_branchif(OFFSET dst);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_branchif(OFFSET dst);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_branchif(OFFSET dst);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_branchif(OFFSET dst);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_branchif(OFFSET dst);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_branchunless(OFFSET dst);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_branchunless(OFFSET dst);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_branchunless(OFFSET dst);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_branchunless(OFFSET dst);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_branchunless(OFFSET dst);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_branchunless(OFFSET dst);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_branchunless(OFFSET dst);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_branchunless(OFFSET dst);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_branchunless(OFFSET dst);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_branchnil(OFFSET dst);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_branchnil(OFFSET dst);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_branchnil(OFFSET dst);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_branchnil(OFFSET dst);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_branchnil(OFFSET dst);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_branchnil(OFFSET dst);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_branchnil(OFFSET dst);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_branchnil(OFFSET dst);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_branchnil(OFFSET dst);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_once(ISEQ iseq, ISE ise);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_once(ISEQ iseq, ISE ise);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_once(ISEQ iseq, ISE ise);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_once(ISEQ iseq, ISE ise);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_once(ISEQ iseq, ISE ise);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_once(ISEQ iseq, ISE ise);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_once(ISEQ iseq, ISE ise);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_once(ISEQ iseq, ISE ise);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_once(ISEQ iseq, ISE ise);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_opt_case_dispatch(CDHASH hash, OFFSET else_offset);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_opt_case_dispatch(CDHASH hash, OFFSET else_offset);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_opt_case_dispatch(CDHASH hash, OFFSET else_offset);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_opt_case_dispatch(CDHASH hash, OFFSET else_offset);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_opt_case_dispatch(CDHASH hash, OFFSET else_offset);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_opt_case_dispatch(CDHASH hash, OFFSET else_offset);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_opt_case_dispatch(CDHASH hash, OFFSET else_offset);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_opt_case_dispatch(CDHASH hash, OFFSET else_offset);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_opt_case_dispatch(CDHASH hash, OFFSET else_offset);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_opt_plus(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_opt_plus(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_opt_plus(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_opt_plus(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_opt_plus(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_opt_plus(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_opt_plus(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_opt_plus(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_opt_plus(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_opt_minus(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_opt_minus(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_opt_minus(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_opt_minus(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_opt_minus(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_opt_minus(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_opt_minus(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_opt_minus(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_opt_minus(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_opt_mult(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_opt_mult(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_opt_mult(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_opt_mult(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_opt_mult(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_opt_mult(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_opt_mult(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_opt_mult(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_opt_mult(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_opt_div(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_opt_div(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_opt_div(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_opt_div(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_opt_div(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_opt_div(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_opt_div(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_opt_div(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_opt_div(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_opt_mod(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_opt_mod(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_opt_mod(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_opt_mod(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_opt_mod(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_opt_mod(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_opt_mod(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_opt_mod(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_opt_mod(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_opt_eq(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_opt_eq(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_opt_eq(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_opt_eq(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_opt_eq(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_opt_eq(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_opt_eq(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_opt_eq(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_opt_eq(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_opt_neq(CALL_DATA cd_eq, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_opt_neq(CALL_DATA cd_eq, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_opt_neq(CALL_DATA cd_eq, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_opt_neq(CALL_DATA cd_eq, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_opt_neq(CALL_DATA cd_eq, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_opt_neq(CALL_DATA cd_eq, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_opt_neq(CALL_DATA cd_eq, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_opt_neq(CALL_DATA cd_eq, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_opt_neq(CALL_DATA cd_eq, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_opt_lt(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_opt_lt(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_opt_lt(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_opt_lt(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_opt_lt(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_opt_lt(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_opt_lt(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_opt_lt(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_opt_lt(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_opt_le(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_opt_le(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_opt_le(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_opt_le(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_opt_le(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_opt_le(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_opt_le(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_opt_le(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_opt_le(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_opt_gt(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_opt_gt(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_opt_gt(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_opt_gt(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_opt_gt(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_opt_gt(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_opt_gt(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_opt_gt(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_opt_gt(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_opt_ge(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_opt_ge(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_opt_ge(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_opt_ge(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_opt_ge(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_opt_ge(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_opt_ge(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_opt_ge(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_opt_ge(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_opt_ltlt(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_opt_ltlt(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_opt_ltlt(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_opt_ltlt(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_opt_ltlt(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_opt_ltlt(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_opt_ltlt(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_opt_ltlt(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_opt_ltlt(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_opt_and(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_opt_and(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_opt_and(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_opt_and(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_opt_and(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_opt_and(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_opt_and(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_opt_and(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_opt_and(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_opt_or(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_opt_or(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_opt_or(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_opt_or(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_opt_or(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_opt_or(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_opt_or(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_opt_or(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_opt_or(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_opt_aref(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_opt_aref(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_opt_aref(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_opt_aref(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_opt_aref(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_opt_aref(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_opt_aref(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_opt_aref(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_opt_aref(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_opt_aset(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_opt_aset(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_opt_aset(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_opt_aset(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_opt_aset(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_opt_aset(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_opt_aset(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_opt_aset(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_opt_aset(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_opt_aset_with(VALUE key, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_opt_aset_with(VALUE key, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_opt_aset_with(VALUE key, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_opt_aset_with(VALUE key, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_opt_aset_with(VALUE key, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_opt_aset_with(VALUE key, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_opt_aset_with(VALUE key, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_opt_aset_with(VALUE key, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_opt_aset_with(VALUE key, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_opt_aref_with(VALUE key, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_opt_aref_with(VALUE key, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_opt_aref_with(VALUE key, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_opt_aref_with(VALUE key, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_opt_aref_with(VALUE key, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_opt_aref_with(VALUE key, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_opt_aref_with(VALUE key, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_opt_aref_with(VALUE key, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_opt_aref_with(VALUE key, CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_opt_length(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_opt_length(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_opt_length(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_opt_length(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_opt_length(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_opt_length(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_opt_length(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_opt_length(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_opt_length(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_opt_size(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_opt_size(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_opt_size(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_opt_size(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_opt_size(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_opt_size(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_opt_size(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_opt_size(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_opt_size(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_opt_empty_p(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_opt_empty_p(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_opt_empty_p(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_opt_empty_p(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_opt_empty_p(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_opt_empty_p(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_opt_empty_p(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_opt_empty_p(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_opt_empty_p(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_opt_succ(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_opt_succ(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_opt_succ(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_opt_succ(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_opt_succ(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_opt_succ(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_opt_succ(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_opt_succ(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_opt_succ(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_opt_not(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_opt_not(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_opt_not(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_opt_not(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_opt_not(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_opt_not(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_opt_not(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_opt_not(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_opt_not(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_opt_regexpmatch2(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_opt_regexpmatch2(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_opt_regexpmatch2(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_opt_regexpmatch2(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_opt_regexpmatch2(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_opt_regexpmatch2(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_opt_regexpmatch2(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_opt_regexpmatch2(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_opt_regexpmatch2(CALL_DATA cd);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_invokebuiltin(RB_BUILTIN bf);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_invokebuiltin(RB_BUILTIN bf);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_invokebuiltin(RB_BUILTIN bf);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_invokebuiltin(RB_BUILTIN bf);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_invokebuiltin(RB_BUILTIN bf);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_invokebuiltin(RB_BUILTIN bf);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_invokebuiltin(RB_BUILTIN bf);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_invokebuiltin(RB_BUILTIN bf);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_invokebuiltin(RB_BUILTIN bf);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_opt_invokebuiltin_delegate(RB_BUILTIN bf, rb_num_t index);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_opt_invokebuiltin_delegate(RB_BUILTIN bf, rb_num_t index);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_opt_invokebuiltin_delegate(RB_BUILTIN bf, rb_num_t index);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_opt_invokebuiltin_delegate(RB_BUILTIN bf, rb_num_t index);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_opt_invokebuiltin_delegate(RB_BUILTIN bf, rb_num_t index);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_opt_invokebuiltin_delegate(RB_BUILTIN bf, rb_num_t index);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_opt_invokebuiltin_delegate(RB_BUILTIN bf, rb_num_t index);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_opt_invokebuiltin_delegate(RB_BUILTIN bf, rb_num_t index);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_opt_invokebuiltin_delegate(RB_BUILTIN bf, rb_num_t index);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_opt_invokebuiltin_delegate_leave(RB_BUILTIN bf, rb_num_t index);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_opt_invokebuiltin_delegate_leave(RB_BUILTIN bf, rb_num_t index);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_opt_invokebuiltin_delegate_leave(RB_BUILTIN bf, rb_num_t index);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_opt_invokebuiltin_delegate_leave(RB_BUILTIN bf, rb_num_t index);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_opt_invokebuiltin_delegate_leave(RB_BUILTIN bf, rb_num_t index);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_opt_invokebuiltin_delegate_leave(RB_BUILTIN bf, rb_num_t index);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_opt_invokebuiltin_delegate_leave(RB_BUILTIN bf, rb_num_t index);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_opt_invokebuiltin_delegate_leave(RB_BUILTIN bf, rb_num_t index);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_opt_invokebuiltin_delegate_leave(RB_BUILTIN bf, rb_num_t index);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_getlocal_WC_0(lindex_t idx);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_getlocal_WC_0(lindex_t idx);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_getlocal_WC_0(lindex_t idx);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_getlocal_WC_0(lindex_t idx);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_getlocal_WC_0(lindex_t idx);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_getlocal_WC_0(lindex_t idx);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_getlocal_WC_0(lindex_t idx);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_getlocal_WC_0(lindex_t idx);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_getlocal_WC_0(lindex_t idx);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_getlocal_WC_1(lindex_t idx);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_getlocal_WC_1(lindex_t idx);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_getlocal_WC_1(lindex_t idx);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_getlocal_WC_1(lindex_t idx);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_getlocal_WC_1(lindex_t idx);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_getlocal_WC_1(lindex_t idx);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_getlocal_WC_1(lindex_t idx);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_getlocal_WC_1(lindex_t idx);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_getlocal_WC_1(lindex_t idx);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_setlocal_WC_0(lindex_t idx);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_setlocal_WC_0(lindex_t idx);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_setlocal_WC_0(lindex_t idx);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_setlocal_WC_0(lindex_t idx);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_setlocal_WC_0(lindex_t idx);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_setlocal_WC_0(lindex_t idx);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_setlocal_WC_0(lindex_t idx);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_setlocal_WC_0(lindex_t idx);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_setlocal_WC_0(lindex_t idx);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_setlocal_WC_1(lindex_t idx);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_setlocal_WC_1(lindex_t idx);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_setlocal_WC_1(lindex_t idx);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_setlocal_WC_1(lindex_t idx);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_setlocal_WC_1(lindex_t idx);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_setlocal_WC_1(lindex_t idx);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_setlocal_WC_1(lindex_t idx);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_setlocal_WC_1(lindex_t idx);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_setlocal_WC_1(lindex_t idx);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_putobject_INT2FIX_0_(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_putobject_INT2FIX_0_(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_putobject_INT2FIX_0_(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_putobject_INT2FIX_0_(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_putobject_INT2FIX_0_(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_putobject_INT2FIX_0_(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_putobject_INT2FIX_0_(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_putobject_INT2FIX_0_(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_putobject_INT2FIX_0_(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static enum ruby_vminsn_type attr_bin_putobject_INT2FIX_1_(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_handles_sp_putobject_INT2FIX_1_(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool attr_leaf_putobject_INT2FIX_1_(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static const char* attr_name_putobject_INT2FIX_1_(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_open_putobject_INT2FIX_1_(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_popn_putobject_INT2FIX_1_(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_retn_putobject_INT2FIX_1_(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_snum_t attr_sp_inc_putobject_INT2FIX_1_(void);
__attribute__((__pure__)) __attribute__ ((__unused__)) static rb_num_t attr_width_putobject_INT2FIX_1_(void);
enum ruby_vminsn_type
attr_bin_nop(void)
{
    return YARVINSN_nop;
}
_Bool
attr_handles_sp_nop(void)
{
    return 0;
}
_Bool
attr_leaf_nop(void)
{
    return 1;
}
const char*
attr_name_nop(void)
{
    return insn_name(YARVINSN_nop);
}
rb_num_t
attr_open_nop(void)
{
    return 0;
}
rb_num_t
attr_popn_nop(void)
{
    return 0;
}
rb_num_t
attr_retn_nop(void)
{
    return 0;
}
rb_snum_t
attr_sp_inc_nop(void)
{
    return 0;
}
rb_num_t
attr_width_nop(void)
{
    return 1;
}
enum ruby_vminsn_type
attr_bin_getlocal(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return YARVINSN_getlocal;
}
_Bool
attr_handles_sp_getlocal(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return 0;
}
_Bool
attr_leaf_getlocal(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return 1;
}
const char*
attr_name_getlocal(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return insn_name(YARVINSN_getlocal);
}
rb_num_t
attr_open_getlocal(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return 2;
}
rb_num_t
attr_popn_getlocal(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return 0;
}
rb_num_t
attr_retn_getlocal(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return 1;
}
rb_snum_t
attr_sp_inc_getlocal(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return 1;
}
rb_num_t
attr_width_getlocal(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return 3;
}
enum ruby_vminsn_type
attr_bin_setlocal(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return YARVINSN_setlocal;
}
_Bool
attr_handles_sp_setlocal(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return 0;
}
_Bool
attr_leaf_setlocal(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return 1;
}
const char*
attr_name_setlocal(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return insn_name(YARVINSN_setlocal);
}
rb_num_t
attr_open_setlocal(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return 2;
}
rb_num_t
attr_popn_setlocal(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return 1;
}
rb_num_t
attr_retn_setlocal(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return 0;
}
rb_snum_t
attr_sp_inc_setlocal(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return -1;
}
rb_num_t
attr_width_setlocal(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return 3;
}
enum ruby_vminsn_type
attr_bin_getblockparam(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return YARVINSN_getblockparam;
}
_Bool
attr_handles_sp_getblockparam(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return 0;
}
_Bool
attr_leaf_getblockparam(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return 1;
}
const char*
attr_name_getblockparam(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return insn_name(YARVINSN_getblockparam);
}
rb_num_t
attr_open_getblockparam(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return 2;
}
rb_num_t
attr_popn_getblockparam(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return 0;
}
rb_num_t
attr_retn_getblockparam(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return 1;
}
rb_snum_t
attr_sp_inc_getblockparam(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return 1;
}
rb_num_t
attr_width_getblockparam(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return 3;
}
enum ruby_vminsn_type
attr_bin_setblockparam(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return YARVINSN_setblockparam;
}
_Bool
attr_handles_sp_setblockparam(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return 0;
}
_Bool
attr_leaf_setblockparam(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return 1;
}
const char*
attr_name_setblockparam(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return insn_name(YARVINSN_setblockparam);
}
rb_num_t
attr_open_setblockparam(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return 2;
}
rb_num_t
attr_popn_setblockparam(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return 1;
}
rb_num_t
attr_retn_setblockparam(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return 0;
}
rb_snum_t
attr_sp_inc_setblockparam(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return -1;
}
rb_num_t
attr_width_setblockparam(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return 3;
}
enum ruby_vminsn_type
attr_bin_getblockparamproxy(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return YARVINSN_getblockparamproxy;
}
_Bool
attr_handles_sp_getblockparamproxy(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return 0;
}
_Bool
attr_leaf_getblockparamproxy(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return 1;
}
const char*
attr_name_getblockparamproxy(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return insn_name(YARVINSN_getblockparamproxy);
}
rb_num_t
attr_open_getblockparamproxy(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return 2;
}
rb_num_t
attr_popn_getblockparamproxy(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return 0;
}
rb_num_t
attr_retn_getblockparamproxy(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return 1;
}
rb_snum_t
attr_sp_inc_getblockparamproxy(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return 1;
}
rb_num_t
attr_width_getblockparamproxy(
    __attribute__ ((__unused__)) lindex_t idx,
    __attribute__ ((__unused__)) rb_num_t level
)
{
    return 3;
}
enum ruby_vminsn_type
attr_bin_getspecial(
    __attribute__ ((__unused__)) rb_num_t key,
    __attribute__ ((__unused__)) rb_num_t type
)
{
    return YARVINSN_getspecial;
}
_Bool
attr_handles_sp_getspecial(
    __attribute__ ((__unused__)) rb_num_t key,
    __attribute__ ((__unused__)) rb_num_t type
)
{
    return 0;
}
_Bool
attr_leaf_getspecial(
    __attribute__ ((__unused__)) rb_num_t key,
    __attribute__ ((__unused__)) rb_num_t type
)
{
    return
(type == 0) ? 1 : 0;
}
const char*
attr_name_getspecial(
    __attribute__ ((__unused__)) rb_num_t key,
    __attribute__ ((__unused__)) rb_num_t type
)
{
    return insn_name(YARVINSN_getspecial);
}
rb_num_t
attr_open_getspecial(
    __attribute__ ((__unused__)) rb_num_t key,
    __attribute__ ((__unused__)) rb_num_t type
)
{
    return 2;
}
rb_num_t
attr_popn_getspecial(
    __attribute__ ((__unused__)) rb_num_t key,
    __attribute__ ((__unused__)) rb_num_t type
)
{
    return 0;
}
rb_num_t
attr_retn_getspecial(
    __attribute__ ((__unused__)) rb_num_t key,
    __attribute__ ((__unused__)) rb_num_t type
)
{
    return 1;
}
rb_snum_t
attr_sp_inc_getspecial(
    __attribute__ ((__unused__)) rb_num_t key,
    __attribute__ ((__unused__)) rb_num_t type
)
{
    return 1;
}
rb_num_t
attr_width_getspecial(
    __attribute__ ((__unused__)) rb_num_t key,
    __attribute__ ((__unused__)) rb_num_t type
)
{
    return 3;
}
enum ruby_vminsn_type
attr_bin_setspecial(__attribute__ ((__unused__)) rb_num_t key)
{
    return YARVINSN_setspecial;
}
_Bool
attr_handles_sp_setspecial(__attribute__ ((__unused__)) rb_num_t key)
{
    return 0;
}
_Bool
attr_leaf_setspecial(__attribute__ ((__unused__)) rb_num_t key)
{
    return 1;
}
const char*
attr_name_setspecial(__attribute__ ((__unused__)) rb_num_t key)
{
    return insn_name(YARVINSN_setspecial);
}
rb_num_t
attr_open_setspecial(__attribute__ ((__unused__)) rb_num_t key)
{
    return 1;
}
rb_num_t
attr_popn_setspecial(__attribute__ ((__unused__)) rb_num_t key)
{
    return 1;
}
rb_num_t
attr_retn_setspecial(__attribute__ ((__unused__)) rb_num_t key)
{
    return 0;
}
rb_snum_t
attr_sp_inc_setspecial(__attribute__ ((__unused__)) rb_num_t key)
{
    return -1;
}
rb_num_t
attr_width_setspecial(__attribute__ ((__unused__)) rb_num_t key)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_getinstancevariable(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) IVC ic
)
{
    return YARVINSN_getinstancevariable;
}
_Bool
attr_handles_sp_getinstancevariable(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) IVC ic
)
{
    return 0;
}
_Bool
attr_leaf_getinstancevariable(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) IVC ic
)
{
    return
0;
}
const char*
attr_name_getinstancevariable(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) IVC ic
)
{
    return insn_name(YARVINSN_getinstancevariable);
}
rb_num_t
attr_open_getinstancevariable(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) IVC ic
)
{
    return 2;
}
rb_num_t
attr_popn_getinstancevariable(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) IVC ic
)
{
    return 0;
}
rb_num_t
attr_retn_getinstancevariable(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) IVC ic
)
{
    return 1;
}
rb_snum_t
attr_sp_inc_getinstancevariable(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) IVC ic
)
{
    return 1;
}
rb_num_t
attr_width_getinstancevariable(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) IVC ic
)
{
    return 3;
}
enum ruby_vminsn_type
attr_bin_setinstancevariable(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) IVC ic
)
{
    return YARVINSN_setinstancevariable;
}
_Bool
attr_handles_sp_setinstancevariable(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) IVC ic
)
{
    return 0;
}
_Bool
attr_leaf_setinstancevariable(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) IVC ic
)
{
    return
0;
}
const char*
attr_name_setinstancevariable(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) IVC ic
)
{
    return insn_name(YARVINSN_setinstancevariable);
}
rb_num_t
attr_open_setinstancevariable(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) IVC ic
)
{
    return 2;
}
rb_num_t
attr_popn_setinstancevariable(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) IVC ic
)
{
    return 1;
}
rb_num_t
attr_retn_setinstancevariable(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) IVC ic
)
{
    return 0;
}
rb_snum_t
attr_sp_inc_setinstancevariable(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) IVC ic
)
{
    return -1;
}
rb_num_t
attr_width_setinstancevariable(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) IVC ic
)
{
    return 3;
}
enum ruby_vminsn_type
attr_bin_getclassvariable(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ICVARC ic
)
{
    return YARVINSN_getclassvariable;
}
_Bool
attr_handles_sp_getclassvariable(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ICVARC ic
)
{
    return 0;
}
_Bool
attr_leaf_getclassvariable(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ICVARC ic
)
{
    return
0;
}
const char*
attr_name_getclassvariable(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ICVARC ic
)
{
    return insn_name(YARVINSN_getclassvariable);
}
rb_num_t
attr_open_getclassvariable(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ICVARC ic
)
{
    return 2;
}
rb_num_t
attr_popn_getclassvariable(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ICVARC ic
)
{
    return 0;
}
rb_num_t
attr_retn_getclassvariable(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ICVARC ic
)
{
    return 1;
}
rb_snum_t
attr_sp_inc_getclassvariable(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ICVARC ic
)
{
    return 1;
}
rb_num_t
attr_width_getclassvariable(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ICVARC ic
)
{
    return 3;
}
enum ruby_vminsn_type
attr_bin_setclassvariable(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ICVARC ic
)
{
    return YARVINSN_setclassvariable;
}
_Bool
attr_handles_sp_setclassvariable(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ICVARC ic
)
{
    return 0;
}
_Bool
attr_leaf_setclassvariable(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ICVARC ic
)
{
    return
0;
}
const char*
attr_name_setclassvariable(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ICVARC ic
)
{
    return insn_name(YARVINSN_setclassvariable);
}
rb_num_t
attr_open_setclassvariable(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ICVARC ic
)
{
    return 2;
}
rb_num_t
attr_popn_setclassvariable(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ICVARC ic
)
{
    return 1;
}
rb_num_t
attr_retn_setclassvariable(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ICVARC ic
)
{
    return 0;
}
rb_snum_t
attr_sp_inc_setclassvariable(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ICVARC ic
)
{
    return -1;
}
rb_num_t
attr_width_setclassvariable(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ICVARC ic
)
{
    return 3;
}
enum ruby_vminsn_type
attr_bin_opt_getconstant_path(__attribute__ ((__unused__)) IC ic)
{
    return YARVINSN_opt_getconstant_path;
}
_Bool
attr_handles_sp_opt_getconstant_path(__attribute__ ((__unused__)) IC ic)
{
    return 0;
}
_Bool
attr_leaf_opt_getconstant_path(__attribute__ ((__unused__)) IC ic)
{
    return
0;
}
const char*
attr_name_opt_getconstant_path(__attribute__ ((__unused__)) IC ic)
{
    return insn_name(YARVINSN_opt_getconstant_path);
}
rb_num_t
attr_open_opt_getconstant_path(__attribute__ ((__unused__)) IC ic)
{
    return 1;
}
rb_num_t
attr_popn_opt_getconstant_path(__attribute__ ((__unused__)) IC ic)
{
    return 0;
}
rb_num_t
attr_retn_opt_getconstant_path(__attribute__ ((__unused__)) IC ic)
{
    return 1;
}
rb_snum_t
attr_sp_inc_opt_getconstant_path(__attribute__ ((__unused__)) IC ic)
{
    return 1;
}
rb_num_t
attr_width_opt_getconstant_path(__attribute__ ((__unused__)) IC ic)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_getconstant(__attribute__ ((__unused__)) ID id)
{
    return YARVINSN_getconstant;
}
_Bool
attr_handles_sp_getconstant(__attribute__ ((__unused__)) ID id)
{
    return 0;
}
_Bool
attr_leaf_getconstant(__attribute__ ((__unused__)) ID id)
{
    return
0;
}
const char*
attr_name_getconstant(__attribute__ ((__unused__)) ID id)
{
    return insn_name(YARVINSN_getconstant);
}
rb_num_t
attr_open_getconstant(__attribute__ ((__unused__)) ID id)
{
    return 1;
}
rb_num_t
attr_popn_getconstant(__attribute__ ((__unused__)) ID id)
{
    return 2;
}
rb_num_t
attr_retn_getconstant(__attribute__ ((__unused__)) ID id)
{
    return 1;
}
rb_snum_t
attr_sp_inc_getconstant(__attribute__ ((__unused__)) ID id)
{
    return -1;
}
rb_num_t
attr_width_getconstant(__attribute__ ((__unused__)) ID id)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_setconstant(__attribute__ ((__unused__)) ID id)
{
    return YARVINSN_setconstant;
}
_Bool
attr_handles_sp_setconstant(__attribute__ ((__unused__)) ID id)
{
    return 0;
}
_Bool
attr_leaf_setconstant(__attribute__ ((__unused__)) ID id)
{
    return
0;
}
const char*
attr_name_setconstant(__attribute__ ((__unused__)) ID id)
{
    return insn_name(YARVINSN_setconstant);
}
rb_num_t
attr_open_setconstant(__attribute__ ((__unused__)) ID id)
{
    return 1;
}
rb_num_t
attr_popn_setconstant(__attribute__ ((__unused__)) ID id)
{
    return 2;
}
rb_num_t
attr_retn_setconstant(__attribute__ ((__unused__)) ID id)
{
    return 0;
}
rb_snum_t
attr_sp_inc_setconstant(__attribute__ ((__unused__)) ID id)
{
    return -2;
}
rb_num_t
attr_width_setconstant(__attribute__ ((__unused__)) ID id)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_getglobal(__attribute__ ((__unused__)) ID gid)
{
    return YARVINSN_getglobal;
}
_Bool
attr_handles_sp_getglobal(__attribute__ ((__unused__)) ID gid)
{
    return 0;
}
_Bool
attr_leaf_getglobal(__attribute__ ((__unused__)) ID gid)
{
    return
0;
}
const char*
attr_name_getglobal(__attribute__ ((__unused__)) ID gid)
{
    return insn_name(YARVINSN_getglobal);
}
rb_num_t
attr_open_getglobal(__attribute__ ((__unused__)) ID gid)
{
    return 1;
}
rb_num_t
attr_popn_getglobal(__attribute__ ((__unused__)) ID gid)
{
    return 0;
}
rb_num_t
attr_retn_getglobal(__attribute__ ((__unused__)) ID gid)
{
    return 1;
}
rb_snum_t
attr_sp_inc_getglobal(__attribute__ ((__unused__)) ID gid)
{
    return 1;
}
rb_num_t
attr_width_getglobal(__attribute__ ((__unused__)) ID gid)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_setglobal(__attribute__ ((__unused__)) ID gid)
{
    return YARVINSN_setglobal;
}
_Bool
attr_handles_sp_setglobal(__attribute__ ((__unused__)) ID gid)
{
    return 0;
}
_Bool
attr_leaf_setglobal(__attribute__ ((__unused__)) ID gid)
{
    return
0;
}
const char*
attr_name_setglobal(__attribute__ ((__unused__)) ID gid)
{
    return insn_name(YARVINSN_setglobal);
}
rb_num_t
attr_open_setglobal(__attribute__ ((__unused__)) ID gid)
{
    return 1;
}
rb_num_t
attr_popn_setglobal(__attribute__ ((__unused__)) ID gid)
{
    return 1;
}
rb_num_t
attr_retn_setglobal(__attribute__ ((__unused__)) ID gid)
{
    return 0;
}
rb_snum_t
attr_sp_inc_setglobal(__attribute__ ((__unused__)) ID gid)
{
    return -1;
}
rb_num_t
attr_width_setglobal(__attribute__ ((__unused__)) ID gid)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_putnil(void)
{
    return YARVINSN_putnil;
}
_Bool
attr_handles_sp_putnil(void)
{
    return 0;
}
_Bool
attr_leaf_putnil(void)
{
    return 1;
}
const char*
attr_name_putnil(void)
{
    return insn_name(YARVINSN_putnil);
}
rb_num_t
attr_open_putnil(void)
{
    return 0;
}
rb_num_t
attr_popn_putnil(void)
{
    return 0;
}
rb_num_t
attr_retn_putnil(void)
{
    return 1;
}
rb_snum_t
attr_sp_inc_putnil(void)
{
    return 1;
}
rb_num_t
attr_width_putnil(void)
{
    return 1;
}
enum ruby_vminsn_type
attr_bin_putself(void)
{
    return YARVINSN_putself;
}
_Bool
attr_handles_sp_putself(void)
{
    return 0;
}
_Bool
attr_leaf_putself(void)
{
    return 1;
}
const char*
attr_name_putself(void)
{
    return insn_name(YARVINSN_putself);
}
rb_num_t
attr_open_putself(void)
{
    return 0;
}
rb_num_t
attr_popn_putself(void)
{
    return 0;
}
rb_num_t
attr_retn_putself(void)
{
    return 1;
}
rb_snum_t
attr_sp_inc_putself(void)
{
    return 1;
}
rb_num_t
attr_width_putself(void)
{
    return 1;
}
enum ruby_vminsn_type
attr_bin_putobject(__attribute__ ((__unused__)) VALUE val)
{
    return YARVINSN_putobject;
}
_Bool
attr_handles_sp_putobject(__attribute__ ((__unused__)) VALUE val)
{
    return 0;
}
_Bool
attr_leaf_putobject(__attribute__ ((__unused__)) VALUE val)
{
    return 1;
}
const char*
attr_name_putobject(__attribute__ ((__unused__)) VALUE val)
{
    return insn_name(YARVINSN_putobject);
}
rb_num_t
attr_open_putobject(__attribute__ ((__unused__)) VALUE val)
{
    return 1;
}
rb_num_t
attr_popn_putobject(__attribute__ ((__unused__)) VALUE val)
{
    return 0;
}
rb_num_t
attr_retn_putobject(__attribute__ ((__unused__)) VALUE val)
{
    return 1;
}
rb_snum_t
attr_sp_inc_putobject(__attribute__ ((__unused__)) VALUE val)
{
    return 1;
}
rb_num_t
attr_width_putobject(__attribute__ ((__unused__)) VALUE val)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_putspecialobject(__attribute__ ((__unused__)) rb_num_t value_type)
{
    return YARVINSN_putspecialobject;
}
_Bool
attr_handles_sp_putspecialobject(__attribute__ ((__unused__)) rb_num_t value_type)
{
    return 0;
}
_Bool
attr_leaf_putspecialobject(__attribute__ ((__unused__)) rb_num_t value_type)
{
    return
(value_type == VM_SPECIAL_OBJECT_VMCORE);
}
const char*
attr_name_putspecialobject(__attribute__ ((__unused__)) rb_num_t value_type)
{
    return insn_name(YARVINSN_putspecialobject);
}
rb_num_t
attr_open_putspecialobject(__attribute__ ((__unused__)) rb_num_t value_type)
{
    return 1;
}
rb_num_t
attr_popn_putspecialobject(__attribute__ ((__unused__)) rb_num_t value_type)
{
    return 0;
}
rb_num_t
attr_retn_putspecialobject(__attribute__ ((__unused__)) rb_num_t value_type)
{
    return 1;
}
rb_snum_t
attr_sp_inc_putspecialobject(__attribute__ ((__unused__)) rb_num_t value_type)
{
    return 1;
}
rb_num_t
attr_width_putspecialobject(__attribute__ ((__unused__)) rb_num_t value_type)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_putstring(__attribute__ ((__unused__)) VALUE str)
{
    return YARVINSN_putstring;
}
_Bool
attr_handles_sp_putstring(__attribute__ ((__unused__)) VALUE str)
{
    return 0;
}
_Bool
attr_leaf_putstring(__attribute__ ((__unused__)) VALUE str)
{
    return 1;
}
const char*
attr_name_putstring(__attribute__ ((__unused__)) VALUE str)
{
    return insn_name(YARVINSN_putstring);
}
rb_num_t
attr_open_putstring(__attribute__ ((__unused__)) VALUE str)
{
    return 1;
}
rb_num_t
attr_popn_putstring(__attribute__ ((__unused__)) VALUE str)
{
    return 0;
}
rb_num_t
attr_retn_putstring(__attribute__ ((__unused__)) VALUE str)
{
    return 1;
}
rb_snum_t
attr_sp_inc_putstring(__attribute__ ((__unused__)) VALUE str)
{
    return 1;
}
rb_num_t
attr_width_putstring(__attribute__ ((__unused__)) VALUE str)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_putchilledstring(__attribute__ ((__unused__)) VALUE str)
{
    return YARVINSN_putchilledstring;
}
_Bool
attr_handles_sp_putchilledstring(__attribute__ ((__unused__)) VALUE str)
{
    return 0;
}
_Bool
attr_leaf_putchilledstring(__attribute__ ((__unused__)) VALUE str)
{
    return 1;
}
const char*
attr_name_putchilledstring(__attribute__ ((__unused__)) VALUE str)
{
    return insn_name(YARVINSN_putchilledstring);
}
rb_num_t
attr_open_putchilledstring(__attribute__ ((__unused__)) VALUE str)
{
    return 1;
}
rb_num_t
attr_popn_putchilledstring(__attribute__ ((__unused__)) VALUE str)
{
    return 0;
}
rb_num_t
attr_retn_putchilledstring(__attribute__ ((__unused__)) VALUE str)
{
    return 1;
}
rb_snum_t
attr_sp_inc_putchilledstring(__attribute__ ((__unused__)) VALUE str)
{
    return 1;
}
rb_num_t
attr_width_putchilledstring(__attribute__ ((__unused__)) VALUE str)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_concatstrings(__attribute__ ((__unused__)) rb_num_t num)
{
    return YARVINSN_concatstrings;
}
_Bool
attr_handles_sp_concatstrings(__attribute__ ((__unused__)) rb_num_t num)
{
    return 0;
}
_Bool
attr_leaf_concatstrings(__attribute__ ((__unused__)) rb_num_t num)
{
    return
0;
}
const char*
attr_name_concatstrings(__attribute__ ((__unused__)) rb_num_t num)
{
    return insn_name(YARVINSN_concatstrings);
}
rb_num_t
attr_open_concatstrings(__attribute__ ((__unused__)) rb_num_t num)
{
    return 1;
}
rb_num_t
attr_popn_concatstrings(__attribute__ ((__unused__)) rb_num_t num)
{
    return 0;
}
rb_num_t
attr_retn_concatstrings(__attribute__ ((__unused__)) rb_num_t num)
{
    return 1;
}
rb_snum_t
attr_sp_inc_concatstrings(__attribute__ ((__unused__)) rb_num_t num)
{
    return
1 - (rb_snum_t)num;
}
rb_num_t
attr_width_concatstrings(__attribute__ ((__unused__)) rb_num_t num)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_anytostring(void)
{
    return YARVINSN_anytostring;
}
_Bool
attr_handles_sp_anytostring(void)
{
    return 0;
}
_Bool
attr_leaf_anytostring(void)
{
    return 1;
}
const char*
attr_name_anytostring(void)
{
    return insn_name(YARVINSN_anytostring);
}
rb_num_t
attr_open_anytostring(void)
{
    return 0;
}
rb_num_t
attr_popn_anytostring(void)
{
    return 2;
}
rb_num_t
attr_retn_anytostring(void)
{
    return 1;
}
rb_snum_t
attr_sp_inc_anytostring(void)
{
    return -1;
}
rb_num_t
attr_width_anytostring(void)
{
    return 1;
}
enum ruby_vminsn_type
attr_bin_toregexp(
    __attribute__ ((__unused__)) rb_num_t opt,
    __attribute__ ((__unused__)) rb_num_t cnt
)
{
    return YARVINSN_toregexp;
}
_Bool
attr_handles_sp_toregexp(
    __attribute__ ((__unused__)) rb_num_t opt,
    __attribute__ ((__unused__)) rb_num_t cnt
)
{
    return 0;
}
_Bool
attr_leaf_toregexp(
    __attribute__ ((__unused__)) rb_num_t opt,
    __attribute__ ((__unused__)) rb_num_t cnt
)
{
    return
0;
}
const char*
attr_name_toregexp(
    __attribute__ ((__unused__)) rb_num_t opt,
    __attribute__ ((__unused__)) rb_num_t cnt
)
{
    return insn_name(YARVINSN_toregexp);
}
rb_num_t
attr_open_toregexp(
    __attribute__ ((__unused__)) rb_num_t opt,
    __attribute__ ((__unused__)) rb_num_t cnt
)
{
    return 2;
}
rb_num_t
attr_popn_toregexp(
    __attribute__ ((__unused__)) rb_num_t opt,
    __attribute__ ((__unused__)) rb_num_t cnt
)
{
    return 0;
}
rb_num_t
attr_retn_toregexp(
    __attribute__ ((__unused__)) rb_num_t opt,
    __attribute__ ((__unused__)) rb_num_t cnt
)
{
    return 1;
}
rb_snum_t
attr_sp_inc_toregexp(
    __attribute__ ((__unused__)) rb_num_t opt,
    __attribute__ ((__unused__)) rb_num_t cnt
)
{
    return
1 - (rb_snum_t)cnt;
}
rb_num_t
attr_width_toregexp(
    __attribute__ ((__unused__)) rb_num_t opt,
    __attribute__ ((__unused__)) rb_num_t cnt
)
{
    return 3;
}
enum ruby_vminsn_type
attr_bin_intern(void)
{
    return YARVINSN_intern;
}
_Bool
attr_handles_sp_intern(void)
{
    return 0;
}
_Bool
attr_leaf_intern(void)
{
    return 1;
}
const char*
attr_name_intern(void)
{
    return insn_name(YARVINSN_intern);
}
rb_num_t
attr_open_intern(void)
{
    return 0;
}
rb_num_t
attr_popn_intern(void)
{
    return 1;
}
rb_num_t
attr_retn_intern(void)
{
    return 1;
}
rb_snum_t
attr_sp_inc_intern(void)
{
    return 0;
}
rb_num_t
attr_width_intern(void)
{
    return 1;
}
enum ruby_vminsn_type
attr_bin_newarray(__attribute__ ((__unused__)) rb_num_t num)
{
    return YARVINSN_newarray;
}
_Bool
attr_handles_sp_newarray(__attribute__ ((__unused__)) rb_num_t num)
{
    return 0;
}
_Bool
attr_leaf_newarray(__attribute__ ((__unused__)) rb_num_t num)
{
    return 1;
}
const char*
attr_name_newarray(__attribute__ ((__unused__)) rb_num_t num)
{
    return insn_name(YARVINSN_newarray);
}
rb_num_t
attr_open_newarray(__attribute__ ((__unused__)) rb_num_t num)
{
    return 1;
}
rb_num_t
attr_popn_newarray(__attribute__ ((__unused__)) rb_num_t num)
{
    return 0;
}
rb_num_t
attr_retn_newarray(__attribute__ ((__unused__)) rb_num_t num)
{
    return 1;
}
rb_snum_t
attr_sp_inc_newarray(__attribute__ ((__unused__)) rb_num_t num)
{
    return
1 - (rb_snum_t)num;
}
rb_num_t
attr_width_newarray(__attribute__ ((__unused__)) rb_num_t num)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_pushtoarraykwsplat(void)
{
    return YARVINSN_pushtoarraykwsplat;
}
_Bool
attr_handles_sp_pushtoarraykwsplat(void)
{
    return 0;
}
_Bool
attr_leaf_pushtoarraykwsplat(void)
{
    return 1;
}
const char*
attr_name_pushtoarraykwsplat(void)
{
    return insn_name(YARVINSN_pushtoarraykwsplat);
}
rb_num_t
attr_open_pushtoarraykwsplat(void)
{
    return 0;
}
rb_num_t
attr_popn_pushtoarraykwsplat(void)
{
    return 2;
}
rb_num_t
attr_retn_pushtoarraykwsplat(void)
{
    return 1;
}
rb_snum_t
attr_sp_inc_pushtoarraykwsplat(void)
{
    return -1;
}
rb_num_t
attr_width_pushtoarraykwsplat(void)
{
    return 1;
}
enum ruby_vminsn_type
attr_bin_duparray(__attribute__ ((__unused__)) VALUE ary)
{
    return YARVINSN_duparray;
}
_Bool
attr_handles_sp_duparray(__attribute__ ((__unused__)) VALUE ary)
{
    return 0;
}
_Bool
attr_leaf_duparray(__attribute__ ((__unused__)) VALUE ary)
{
    return 1;
}
const char*
attr_name_duparray(__attribute__ ((__unused__)) VALUE ary)
{
    return insn_name(YARVINSN_duparray);
}
rb_num_t
attr_open_duparray(__attribute__ ((__unused__)) VALUE ary)
{
    return 1;
}
rb_num_t
attr_popn_duparray(__attribute__ ((__unused__)) VALUE ary)
{
    return 0;
}
rb_num_t
attr_retn_duparray(__attribute__ ((__unused__)) VALUE ary)
{
    return 1;
}
rb_snum_t
attr_sp_inc_duparray(__attribute__ ((__unused__)) VALUE ary)
{
    return 1;
}
rb_num_t
attr_width_duparray(__attribute__ ((__unused__)) VALUE ary)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_duphash(__attribute__ ((__unused__)) VALUE hash)
{
    return YARVINSN_duphash;
}
_Bool
attr_handles_sp_duphash(__attribute__ ((__unused__)) VALUE hash)
{
    return 0;
}
_Bool
attr_leaf_duphash(__attribute__ ((__unused__)) VALUE hash)
{
    return 1;
}
const char*
attr_name_duphash(__attribute__ ((__unused__)) VALUE hash)
{
    return insn_name(YARVINSN_duphash);
}
rb_num_t
attr_open_duphash(__attribute__ ((__unused__)) VALUE hash)
{
    return 1;
}
rb_num_t
attr_popn_duphash(__attribute__ ((__unused__)) VALUE hash)
{
    return 0;
}
rb_num_t
attr_retn_duphash(__attribute__ ((__unused__)) VALUE hash)
{
    return 1;
}
rb_snum_t
attr_sp_inc_duphash(__attribute__ ((__unused__)) VALUE hash)
{
    return 1;
}
rb_num_t
attr_width_duphash(__attribute__ ((__unused__)) VALUE hash)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_expandarray(
    __attribute__ ((__unused__)) rb_num_t num,
    __attribute__ ((__unused__)) rb_num_t flag
)
{
    return YARVINSN_expandarray;
}
_Bool
attr_handles_sp_expandarray(
    __attribute__ ((__unused__)) rb_num_t num,
    __attribute__ ((__unused__)) rb_num_t flag
)
{
    return
1;
}
_Bool
attr_leaf_expandarray(
    __attribute__ ((__unused__)) rb_num_t num,
    __attribute__ ((__unused__)) rb_num_t flag
)
{
    return
0;
}
const char*
attr_name_expandarray(
    __attribute__ ((__unused__)) rb_num_t num,
    __attribute__ ((__unused__)) rb_num_t flag
)
{
    return insn_name(YARVINSN_expandarray);
}
rb_num_t
attr_open_expandarray(
    __attribute__ ((__unused__)) rb_num_t num,
    __attribute__ ((__unused__)) rb_num_t flag
)
{
    return 2;
}
rb_num_t
attr_popn_expandarray(
    __attribute__ ((__unused__)) rb_num_t num,
    __attribute__ ((__unused__)) rb_num_t flag
)
{
    return 1;
}
rb_num_t
attr_retn_expandarray(
    __attribute__ ((__unused__)) rb_num_t num,
    __attribute__ ((__unused__)) rb_num_t flag
)
{
    return 0;
}
rb_snum_t
attr_sp_inc_expandarray(
    __attribute__ ((__unused__)) rb_num_t num,
    __attribute__ ((__unused__)) rb_num_t flag
)
{
    return
(rb_snum_t)num - 1 + (flag & 1 ? 1 : 0);
}
rb_num_t
attr_width_expandarray(
    __attribute__ ((__unused__)) rb_num_t num,
    __attribute__ ((__unused__)) rb_num_t flag
)
{
    return 3;
}
enum ruby_vminsn_type
attr_bin_concatarray(void)
{
    return YARVINSN_concatarray;
}
_Bool
attr_handles_sp_concatarray(void)
{
    return 0;
}
_Bool
attr_leaf_concatarray(void)
{
    return
0;
}
const char*
attr_name_concatarray(void)
{
    return insn_name(YARVINSN_concatarray);
}
rb_num_t
attr_open_concatarray(void)
{
    return 0;
}
rb_num_t
attr_popn_concatarray(void)
{
    return 2;
}
rb_num_t
attr_retn_concatarray(void)
{
    return 1;
}
rb_snum_t
attr_sp_inc_concatarray(void)
{
    return -1;
}
rb_num_t
attr_width_concatarray(void)
{
    return 1;
}
enum ruby_vminsn_type
attr_bin_concattoarray(void)
{
    return YARVINSN_concattoarray;
}
_Bool
attr_handles_sp_concattoarray(void)
{
    return 0;
}
_Bool
attr_leaf_concattoarray(void)
{
    return
0;
}
const char*
attr_name_concattoarray(void)
{
    return insn_name(YARVINSN_concattoarray);
}
rb_num_t
attr_open_concattoarray(void)
{
    return 0;
}
rb_num_t
attr_popn_concattoarray(void)
{
    return 2;
}
rb_num_t
attr_retn_concattoarray(void)
{
    return 1;
}
rb_snum_t
attr_sp_inc_concattoarray(void)
{
    return -1;
}
rb_num_t
attr_width_concattoarray(void)
{
    return 1;
}
enum ruby_vminsn_type
attr_bin_pushtoarray(__attribute__ ((__unused__)) rb_num_t num)
{
    return YARVINSN_pushtoarray;
}
_Bool
attr_handles_sp_pushtoarray(__attribute__ ((__unused__)) rb_num_t num)
{
    return 0;
}
_Bool
attr_leaf_pushtoarray(__attribute__ ((__unused__)) rb_num_t num)
{
    return 1;
}
const char*
attr_name_pushtoarray(__attribute__ ((__unused__)) rb_num_t num)
{
    return insn_name(YARVINSN_pushtoarray);
}
rb_num_t
attr_open_pushtoarray(__attribute__ ((__unused__)) rb_num_t num)
{
    return 1;
}
rb_num_t
attr_popn_pushtoarray(__attribute__ ((__unused__)) rb_num_t num)
{
    return 0;
}
rb_num_t
attr_retn_pushtoarray(__attribute__ ((__unused__)) rb_num_t num)
{
    return 1;
}
rb_snum_t
attr_sp_inc_pushtoarray(__attribute__ ((__unused__)) rb_num_t num)
{
    return
-(rb_snum_t)num;
}
rb_num_t
attr_width_pushtoarray(__attribute__ ((__unused__)) rb_num_t num)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_splatarray(__attribute__ ((__unused__)) VALUE flag)
{
    return YARVINSN_splatarray;
}
_Bool
attr_handles_sp_splatarray(__attribute__ ((__unused__)) VALUE flag)
{
    return 0;
}
_Bool
attr_leaf_splatarray(__attribute__ ((__unused__)) VALUE flag)
{
    return
0;
}
const char*
attr_name_splatarray(__attribute__ ((__unused__)) VALUE flag)
{
    return insn_name(YARVINSN_splatarray);
}
rb_num_t
attr_open_splatarray(__attribute__ ((__unused__)) VALUE flag)
{
    return 1;
}
rb_num_t
attr_popn_splatarray(__attribute__ ((__unused__)) VALUE flag)
{
    return 1;
}
rb_num_t
attr_retn_splatarray(__attribute__ ((__unused__)) VALUE flag)
{
    return 1;
}
rb_snum_t
attr_sp_inc_splatarray(__attribute__ ((__unused__)) VALUE flag)
{
    return 0;
}
rb_num_t
attr_width_splatarray(__attribute__ ((__unused__)) VALUE flag)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_splatkw(void)
{
    return YARVINSN_splatkw;
}
_Bool
attr_handles_sp_splatkw(void)
{
    return 0;
}
_Bool
attr_leaf_splatkw(void)
{
    return
0;
}
const char*
attr_name_splatkw(void)
{
    return insn_name(YARVINSN_splatkw);
}
rb_num_t
attr_open_splatkw(void)
{
    return 0;
}
rb_num_t
attr_popn_splatkw(void)
{
    return 2;
}
rb_num_t
attr_retn_splatkw(void)
{
    return 2;
}
rb_snum_t
attr_sp_inc_splatkw(void)
{
    return 0;
}
rb_num_t
attr_width_splatkw(void)
{
    return 1;
}
enum ruby_vminsn_type
attr_bin_newhash(__attribute__ ((__unused__)) rb_num_t num)
{
    return YARVINSN_newhash;
}
_Bool
attr_handles_sp_newhash(__attribute__ ((__unused__)) rb_num_t num)
{
    return 0;
}
_Bool
attr_leaf_newhash(__attribute__ ((__unused__)) rb_num_t num)
{
    return
0;
}
const char*
attr_name_newhash(__attribute__ ((__unused__)) rb_num_t num)
{
    return insn_name(YARVINSN_newhash);
}
rb_num_t
attr_open_newhash(__attribute__ ((__unused__)) rb_num_t num)
{
    return 1;
}
rb_num_t
attr_popn_newhash(__attribute__ ((__unused__)) rb_num_t num)
{
    return 0;
}
rb_num_t
attr_retn_newhash(__attribute__ ((__unused__)) rb_num_t num)
{
    return 1;
}
rb_snum_t
attr_sp_inc_newhash(__attribute__ ((__unused__)) rb_num_t num)
{
    return
1 - (rb_snum_t)num;
}
rb_num_t
attr_width_newhash(__attribute__ ((__unused__)) rb_num_t num)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_newrange(__attribute__ ((__unused__)) rb_num_t flag)
{
    return YARVINSN_newrange;
}
_Bool
attr_handles_sp_newrange(__attribute__ ((__unused__)) rb_num_t flag)
{
    return 0;
}
_Bool
attr_leaf_newrange(__attribute__ ((__unused__)) rb_num_t flag)
{
    return
0;
}
const char*
attr_name_newrange(__attribute__ ((__unused__)) rb_num_t flag)
{
    return insn_name(YARVINSN_newrange);
}
rb_num_t
attr_open_newrange(__attribute__ ((__unused__)) rb_num_t flag)
{
    return 1;
}
rb_num_t
attr_popn_newrange(__attribute__ ((__unused__)) rb_num_t flag)
{
    return 2;
}
rb_num_t
attr_retn_newrange(__attribute__ ((__unused__)) rb_num_t flag)
{
    return 1;
}
rb_snum_t
attr_sp_inc_newrange(__attribute__ ((__unused__)) rb_num_t flag)
{
    return -1;
}
rb_num_t
attr_width_newrange(__attribute__ ((__unused__)) rb_num_t flag)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_pop(void)
{
    return YARVINSN_pop;
}
_Bool
attr_handles_sp_pop(void)
{
    return 0;
}
_Bool
attr_leaf_pop(void)
{
    return 1;
}
const char*
attr_name_pop(void)
{
    return insn_name(YARVINSN_pop);
}
rb_num_t
attr_open_pop(void)
{
    return 0;
}
rb_num_t
attr_popn_pop(void)
{
    return 1;
}
rb_num_t
attr_retn_pop(void)
{
    return 0;
}
rb_snum_t
attr_sp_inc_pop(void)
{
    return -1;
}
rb_num_t
attr_width_pop(void)
{
    return 1;
}
enum ruby_vminsn_type
attr_bin_dup(void)
{
    return YARVINSN_dup;
}
_Bool
attr_handles_sp_dup(void)
{
    return 0;
}
_Bool
attr_leaf_dup(void)
{
    return 1;
}
const char*
attr_name_dup(void)
{
    return insn_name(YARVINSN_dup);
}
rb_num_t
attr_open_dup(void)
{
    return 0;
}
rb_num_t
attr_popn_dup(void)
{
    return 1;
}
rb_num_t
attr_retn_dup(void)
{
    return 2;
}
rb_snum_t
attr_sp_inc_dup(void)
{
    return 1;
}
rb_num_t
attr_width_dup(void)
{
    return 1;
}
enum ruby_vminsn_type
attr_bin_dupn(__attribute__ ((__unused__)) rb_num_t n)
{
    return YARVINSN_dupn;
}
_Bool
attr_handles_sp_dupn(__attribute__ ((__unused__)) rb_num_t n)
{
    return 0;
}
_Bool
attr_leaf_dupn(__attribute__ ((__unused__)) rb_num_t n)
{
    return 1;
}
const char*
attr_name_dupn(__attribute__ ((__unused__)) rb_num_t n)
{
    return insn_name(YARVINSN_dupn);
}
rb_num_t
attr_open_dupn(__attribute__ ((__unused__)) rb_num_t n)
{
    return 1;
}
rb_num_t
attr_popn_dupn(__attribute__ ((__unused__)) rb_num_t n)
{
    return 0;
}
rb_num_t
attr_retn_dupn(__attribute__ ((__unused__)) rb_num_t n)
{
    return 0;
}
rb_snum_t
attr_sp_inc_dupn(__attribute__ ((__unused__)) rb_num_t n)
{
    return
n;
}
rb_num_t
attr_width_dupn(__attribute__ ((__unused__)) rb_num_t n)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_swap(void)
{
    return YARVINSN_swap;
}
_Bool
attr_handles_sp_swap(void)
{
    return 0;
}
_Bool
attr_leaf_swap(void)
{
    return 1;
}
const char*
attr_name_swap(void)
{
    return insn_name(YARVINSN_swap);
}
rb_num_t
attr_open_swap(void)
{
    return 0;
}
rb_num_t
attr_popn_swap(void)
{
    return 2;
}
rb_num_t
attr_retn_swap(void)
{
    return 2;
}
rb_snum_t
attr_sp_inc_swap(void)
{
    return 0;
}
rb_num_t
attr_width_swap(void)
{
    return 1;
}
enum ruby_vminsn_type
attr_bin_opt_reverse(__attribute__ ((__unused__)) rb_num_t n)
{
    return YARVINSN_opt_reverse;
}
_Bool
attr_handles_sp_opt_reverse(__attribute__ ((__unused__)) rb_num_t n)
{
    return 0;
}
_Bool
attr_leaf_opt_reverse(__attribute__ ((__unused__)) rb_num_t n)
{
    return 1;
}
const char*
attr_name_opt_reverse(__attribute__ ((__unused__)) rb_num_t n)
{
    return insn_name(YARVINSN_opt_reverse);
}
rb_num_t
attr_open_opt_reverse(__attribute__ ((__unused__)) rb_num_t n)
{
    return 1;
}
rb_num_t
attr_popn_opt_reverse(__attribute__ ((__unused__)) rb_num_t n)
{
    return 0;
}
rb_num_t
attr_retn_opt_reverse(__attribute__ ((__unused__)) rb_num_t n)
{
    return 0;
}
rb_snum_t
attr_sp_inc_opt_reverse(__attribute__ ((__unused__)) rb_num_t n)
{
    return
0;
}
rb_num_t
attr_width_opt_reverse(__attribute__ ((__unused__)) rb_num_t n)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_topn(__attribute__ ((__unused__)) rb_num_t n)
{
    return YARVINSN_topn;
}
_Bool
attr_handles_sp_topn(__attribute__ ((__unused__)) rb_num_t n)
{
    return 0;
}
_Bool
attr_leaf_topn(__attribute__ ((__unused__)) rb_num_t n)
{
    return 1;
}
const char*
attr_name_topn(__attribute__ ((__unused__)) rb_num_t n)
{
    return insn_name(YARVINSN_topn);
}
rb_num_t
attr_open_topn(__attribute__ ((__unused__)) rb_num_t n)
{
    return 1;
}
rb_num_t
attr_popn_topn(__attribute__ ((__unused__)) rb_num_t n)
{
    return 0;
}
rb_num_t
attr_retn_topn(__attribute__ ((__unused__)) rb_num_t n)
{
    return 1;
}
rb_snum_t
attr_sp_inc_topn(__attribute__ ((__unused__)) rb_num_t n)
{
    return
1;
}
rb_num_t
attr_width_topn(__attribute__ ((__unused__)) rb_num_t n)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_setn(__attribute__ ((__unused__)) rb_num_t n)
{
    return YARVINSN_setn;
}
_Bool
attr_handles_sp_setn(__attribute__ ((__unused__)) rb_num_t n)
{
    return 0;
}
_Bool
attr_leaf_setn(__attribute__ ((__unused__)) rb_num_t n)
{
    return 1;
}
const char*
attr_name_setn(__attribute__ ((__unused__)) rb_num_t n)
{
    return insn_name(YARVINSN_setn);
}
rb_num_t
attr_open_setn(__attribute__ ((__unused__)) rb_num_t n)
{
    return 1;
}
rb_num_t
attr_popn_setn(__attribute__ ((__unused__)) rb_num_t n)
{
    return 1;
}
rb_num_t
attr_retn_setn(__attribute__ ((__unused__)) rb_num_t n)
{
    return 1;
}
rb_snum_t
attr_sp_inc_setn(__attribute__ ((__unused__)) rb_num_t n)
{
    return
0;
}
rb_num_t
attr_width_setn(__attribute__ ((__unused__)) rb_num_t n)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_adjuststack(__attribute__ ((__unused__)) rb_num_t n)
{
    return YARVINSN_adjuststack;
}
_Bool
attr_handles_sp_adjuststack(__attribute__ ((__unused__)) rb_num_t n)
{
    return 0;
}
_Bool
attr_leaf_adjuststack(__attribute__ ((__unused__)) rb_num_t n)
{
    return 1;
}
const char*
attr_name_adjuststack(__attribute__ ((__unused__)) rb_num_t n)
{
    return insn_name(YARVINSN_adjuststack);
}
rb_num_t
attr_open_adjuststack(__attribute__ ((__unused__)) rb_num_t n)
{
    return 1;
}
rb_num_t
attr_popn_adjuststack(__attribute__ ((__unused__)) rb_num_t n)
{
    return 0;
}
rb_num_t
attr_retn_adjuststack(__attribute__ ((__unused__)) rb_num_t n)
{
    return 0;
}
rb_snum_t
attr_sp_inc_adjuststack(__attribute__ ((__unused__)) rb_num_t n)
{
    return
-(rb_snum_t)n;
}
rb_num_t
attr_width_adjuststack(__attribute__ ((__unused__)) rb_num_t n)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_defined(
    __attribute__ ((__unused__)) rb_num_t op_type,
    __attribute__ ((__unused__)) VALUE obj,
    __attribute__ ((__unused__)) VALUE pushval
)
{
    return YARVINSN_defined;
}
_Bool
attr_handles_sp_defined(
    __attribute__ ((__unused__)) rb_num_t op_type,
    __attribute__ ((__unused__)) VALUE obj,
    __attribute__ ((__unused__)) VALUE pushval
)
{
    return 0;
}
_Bool
attr_leaf_defined(
    __attribute__ ((__unused__)) rb_num_t op_type,
    __attribute__ ((__unused__)) VALUE obj,
    __attribute__ ((__unused__)) VALUE pushval
)
{
    return
leafness_of_defined(op_type);
}
const char*
attr_name_defined(
    __attribute__ ((__unused__)) rb_num_t op_type,
    __attribute__ ((__unused__)) VALUE obj,
    __attribute__ ((__unused__)) VALUE pushval
)
{
    return insn_name(YARVINSN_defined);
}
rb_num_t
attr_open_defined(
    __attribute__ ((__unused__)) rb_num_t op_type,
    __attribute__ ((__unused__)) VALUE obj,
    __attribute__ ((__unused__)) VALUE pushval
)
{
    return 3;
}
rb_num_t
attr_popn_defined(
    __attribute__ ((__unused__)) rb_num_t op_type,
    __attribute__ ((__unused__)) VALUE obj,
    __attribute__ ((__unused__)) VALUE pushval
)
{
    return 1;
}
rb_num_t
attr_retn_defined(
    __attribute__ ((__unused__)) rb_num_t op_type,
    __attribute__ ((__unused__)) VALUE obj,
    __attribute__ ((__unused__)) VALUE pushval
)
{
    return 1;
}
rb_snum_t
attr_sp_inc_defined(
    __attribute__ ((__unused__)) rb_num_t op_type,
    __attribute__ ((__unused__)) VALUE obj,
    __attribute__ ((__unused__)) VALUE pushval
)
{
    return 0;
}
rb_num_t
attr_width_defined(
    __attribute__ ((__unused__)) rb_num_t op_type,
    __attribute__ ((__unused__)) VALUE obj,
    __attribute__ ((__unused__)) VALUE pushval
)
{
    return 4;
}
enum ruby_vminsn_type
attr_bin_definedivar(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) IVC ic,
    __attribute__ ((__unused__)) VALUE pushval
)
{
    return YARVINSN_definedivar;
}
_Bool
attr_handles_sp_definedivar(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) IVC ic,
    __attribute__ ((__unused__)) VALUE pushval
)
{
    return 0;
}
_Bool
attr_leaf_definedivar(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) IVC ic,
    __attribute__ ((__unused__)) VALUE pushval
)
{
    return
0;
}
const char*
attr_name_definedivar(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) IVC ic,
    __attribute__ ((__unused__)) VALUE pushval
)
{
    return insn_name(YARVINSN_definedivar);
}
rb_num_t
attr_open_definedivar(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) IVC ic,
    __attribute__ ((__unused__)) VALUE pushval
)
{
    return 3;
}
rb_num_t
attr_popn_definedivar(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) IVC ic,
    __attribute__ ((__unused__)) VALUE pushval
)
{
    return 0;
}
rb_num_t
attr_retn_definedivar(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) IVC ic,
    __attribute__ ((__unused__)) VALUE pushval
)
{
    return 1;
}
rb_snum_t
attr_sp_inc_definedivar(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) IVC ic,
    __attribute__ ((__unused__)) VALUE pushval
)
{
    return 1;
}
rb_num_t
attr_width_definedivar(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) IVC ic,
    __attribute__ ((__unused__)) VALUE pushval
)
{
    return 4;
}
enum ruby_vminsn_type
attr_bin_checkmatch(__attribute__ ((__unused__)) rb_num_t flag)
{
    return YARVINSN_checkmatch;
}
_Bool
attr_handles_sp_checkmatch(__attribute__ ((__unused__)) rb_num_t flag)
{
    return 0;
}
_Bool
attr_leaf_checkmatch(__attribute__ ((__unused__)) rb_num_t flag)
{
    return
leafness_of_checkmatch(flag);
}
const char*
attr_name_checkmatch(__attribute__ ((__unused__)) rb_num_t flag)
{
    return insn_name(YARVINSN_checkmatch);
}
rb_num_t
attr_open_checkmatch(__attribute__ ((__unused__)) rb_num_t flag)
{
    return 1;
}
rb_num_t
attr_popn_checkmatch(__attribute__ ((__unused__)) rb_num_t flag)
{
    return 2;
}
rb_num_t
attr_retn_checkmatch(__attribute__ ((__unused__)) rb_num_t flag)
{
    return 1;
}
rb_snum_t
attr_sp_inc_checkmatch(__attribute__ ((__unused__)) rb_num_t flag)
{
    return -1;
}
rb_num_t
attr_width_checkmatch(__attribute__ ((__unused__)) rb_num_t flag)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_checkkeyword(
    __attribute__ ((__unused__)) lindex_t kw_bits_index,
    __attribute__ ((__unused__)) lindex_t keyword_index
)
{
    return YARVINSN_checkkeyword;
}
_Bool
attr_handles_sp_checkkeyword(
    __attribute__ ((__unused__)) lindex_t kw_bits_index,
    __attribute__ ((__unused__)) lindex_t keyword_index
)
{
    return 0;
}
_Bool
attr_leaf_checkkeyword(
    __attribute__ ((__unused__)) lindex_t kw_bits_index,
    __attribute__ ((__unused__)) lindex_t keyword_index
)
{
    return 1;
}
const char*
attr_name_checkkeyword(
    __attribute__ ((__unused__)) lindex_t kw_bits_index,
    __attribute__ ((__unused__)) lindex_t keyword_index
)
{
    return insn_name(YARVINSN_checkkeyword);
}
rb_num_t
attr_open_checkkeyword(
    __attribute__ ((__unused__)) lindex_t kw_bits_index,
    __attribute__ ((__unused__)) lindex_t keyword_index
)
{
    return 2;
}
rb_num_t
attr_popn_checkkeyword(
    __attribute__ ((__unused__)) lindex_t kw_bits_index,
    __attribute__ ((__unused__)) lindex_t keyword_index
)
{
    return 0;
}
rb_num_t
attr_retn_checkkeyword(
    __attribute__ ((__unused__)) lindex_t kw_bits_index,
    __attribute__ ((__unused__)) lindex_t keyword_index
)
{
    return 1;
}
rb_snum_t
attr_sp_inc_checkkeyword(
    __attribute__ ((__unused__)) lindex_t kw_bits_index,
    __attribute__ ((__unused__)) lindex_t keyword_index
)
{
    return 1;
}
rb_num_t
attr_width_checkkeyword(
    __attribute__ ((__unused__)) lindex_t kw_bits_index,
    __attribute__ ((__unused__)) lindex_t keyword_index
)
{
    return 3;
}
enum ruby_vminsn_type
attr_bin_checktype(__attribute__ ((__unused__)) rb_num_t type)
{
    return YARVINSN_checktype;
}
_Bool
attr_handles_sp_checktype(__attribute__ ((__unused__)) rb_num_t type)
{
    return 0;
}
_Bool
attr_leaf_checktype(__attribute__ ((__unused__)) rb_num_t type)
{
    return 1;
}
const char*
attr_name_checktype(__attribute__ ((__unused__)) rb_num_t type)
{
    return insn_name(YARVINSN_checktype);
}
rb_num_t
attr_open_checktype(__attribute__ ((__unused__)) rb_num_t type)
{
    return 1;
}
rb_num_t
attr_popn_checktype(__attribute__ ((__unused__)) rb_num_t type)
{
    return 1;
}
rb_num_t
attr_retn_checktype(__attribute__ ((__unused__)) rb_num_t type)
{
    return 1;
}
rb_snum_t
attr_sp_inc_checktype(__attribute__ ((__unused__)) rb_num_t type)
{
    return 0;
}
rb_num_t
attr_width_checktype(__attribute__ ((__unused__)) rb_num_t type)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_defineclass(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ISEQ class_iseq,
    __attribute__ ((__unused__)) rb_num_t flags
)
{
    return YARVINSN_defineclass;
}
_Bool
attr_handles_sp_defineclass(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ISEQ class_iseq,
    __attribute__ ((__unused__)) rb_num_t flags
)
{
    return 1;
}
_Bool
attr_leaf_defineclass(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ISEQ class_iseq,
    __attribute__ ((__unused__)) rb_num_t flags
)
{
    return 0;
}
const char*
attr_name_defineclass(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ISEQ class_iseq,
    __attribute__ ((__unused__)) rb_num_t flags
)
{
    return insn_name(YARVINSN_defineclass);
}
rb_num_t
attr_open_defineclass(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ISEQ class_iseq,
    __attribute__ ((__unused__)) rb_num_t flags
)
{
    return 3;
}
rb_num_t
attr_popn_defineclass(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ISEQ class_iseq,
    __attribute__ ((__unused__)) rb_num_t flags
)
{
    return 2;
}
rb_num_t
attr_retn_defineclass(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ISEQ class_iseq,
    __attribute__ ((__unused__)) rb_num_t flags
)
{
    return 1;
}
rb_snum_t
attr_sp_inc_defineclass(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ISEQ class_iseq,
    __attribute__ ((__unused__)) rb_num_t flags
)
{
    return -1;
}
rb_num_t
attr_width_defineclass(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ISEQ class_iseq,
    __attribute__ ((__unused__)) rb_num_t flags
)
{
    return 4;
}
enum ruby_vminsn_type
attr_bin_definemethod(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ISEQ iseq
)
{
    return YARVINSN_definemethod;
}
_Bool
attr_handles_sp_definemethod(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ISEQ iseq
)
{
    return 1;
}
_Bool
attr_leaf_definemethod(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ISEQ iseq
)
{
    return 0;
}
const char*
attr_name_definemethod(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ISEQ iseq
)
{
    return insn_name(YARVINSN_definemethod);
}
rb_num_t
attr_open_definemethod(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ISEQ iseq
)
{
    return 2;
}
rb_num_t
attr_popn_definemethod(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ISEQ iseq
)
{
    return 0;
}
rb_num_t
attr_retn_definemethod(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ISEQ iseq
)
{
    return 0;
}
rb_snum_t
attr_sp_inc_definemethod(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ISEQ iseq
)
{
    return 0;
}
rb_num_t
attr_width_definemethod(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ISEQ iseq
)
{
    return 3;
}
enum ruby_vminsn_type
attr_bin_definesmethod(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ISEQ iseq
)
{
    return YARVINSN_definesmethod;
}
_Bool
attr_handles_sp_definesmethod(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ISEQ iseq
)
{
    return 1;
}
_Bool
attr_leaf_definesmethod(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ISEQ iseq
)
{
    return 0;
}
const char*
attr_name_definesmethod(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ISEQ iseq
)
{
    return insn_name(YARVINSN_definesmethod);
}
rb_num_t
attr_open_definesmethod(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ISEQ iseq
)
{
    return 2;
}
rb_num_t
attr_popn_definesmethod(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ISEQ iseq
)
{
    return 1;
}
rb_num_t
attr_retn_definesmethod(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ISEQ iseq
)
{
    return 0;
}
rb_snum_t
attr_sp_inc_definesmethod(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ISEQ iseq
)
{
    return -1;
}
rb_num_t
attr_width_definesmethod(
    __attribute__ ((__unused__)) ID id,
    __attribute__ ((__unused__)) ISEQ iseq
)
{
    return 3;
}
enum ruby_vminsn_type
attr_bin_send(
    __attribute__ ((__unused__)) CALL_DATA cd,
    __attribute__ ((__unused__)) ISEQ blockiseq
)
{
    return YARVINSN_send;
}
rb_snum_t
attr_comptime_sp_inc_send(
    __attribute__ ((__unused__)) CALL_INFO ci,
    __attribute__ ((__unused__)) ISEQ blockiseq
)
{
    return
sp_inc_of_sendish(ci);
}
_Bool
attr_handles_sp_send(
    __attribute__ ((__unused__)) CALL_DATA cd,
    __attribute__ ((__unused__)) ISEQ blockiseq
)
{
    return 1;
}
_Bool
attr_leaf_send(
    __attribute__ ((__unused__)) CALL_DATA cd,
    __attribute__ ((__unused__)) ISEQ blockiseq
)
{
    return 0;
}
const char*
attr_name_send(
    __attribute__ ((__unused__)) CALL_DATA cd,
    __attribute__ ((__unused__)) ISEQ blockiseq
)
{
    return insn_name(YARVINSN_send);
}
rb_num_t
attr_open_send(
    __attribute__ ((__unused__)) CALL_DATA cd,
    __attribute__ ((__unused__)) ISEQ blockiseq
)
{
    return 2;
}
rb_num_t
attr_popn_send(
    __attribute__ ((__unused__)) CALL_DATA cd,
    __attribute__ ((__unused__)) ISEQ blockiseq
)
{
    return 0;
}
rb_num_t
attr_retn_send(
    __attribute__ ((__unused__)) CALL_DATA cd,
    __attribute__ ((__unused__)) ISEQ blockiseq
)
{
    return 1;
}
rb_snum_t
attr_sp_inc_send(
    __attribute__ ((__unused__)) CALL_DATA cd,
    __attribute__ ((__unused__)) ISEQ blockiseq
)
{
    return
sp_inc_of_sendish(cd->ci);
}
rb_num_t
attr_width_send(
    __attribute__ ((__unused__)) CALL_DATA cd,
    __attribute__ ((__unused__)) ISEQ blockiseq
)
{
    return 3;
}
enum ruby_vminsn_type
attr_bin_sendforward(
    __attribute__ ((__unused__)) CALL_DATA cd,
    __attribute__ ((__unused__)) ISEQ blockiseq
)
{
    return YARVINSN_sendforward;
}
rb_snum_t
attr_comptime_sp_inc_sendforward(
    __attribute__ ((__unused__)) CALL_INFO ci,
    __attribute__ ((__unused__)) ISEQ blockiseq
)
{
    return
sp_inc_of_sendish(ci);
}
_Bool
attr_handles_sp_sendforward(
    __attribute__ ((__unused__)) CALL_DATA cd,
    __attribute__ ((__unused__)) ISEQ blockiseq
)
{
    return 1;
}
_Bool
attr_leaf_sendforward(
    __attribute__ ((__unused__)) CALL_DATA cd,
    __attribute__ ((__unused__)) ISEQ blockiseq
)
{
    return 0;
}
const char*
attr_name_sendforward(
    __attribute__ ((__unused__)) CALL_DATA cd,
    __attribute__ ((__unused__)) ISEQ blockiseq
)
{
    return insn_name(YARVINSN_sendforward);
}
rb_num_t
attr_open_sendforward(
    __attribute__ ((__unused__)) CALL_DATA cd,
    __attribute__ ((__unused__)) ISEQ blockiseq
)
{
    return 2;
}
rb_num_t
attr_popn_sendforward(
    __attribute__ ((__unused__)) CALL_DATA cd,
    __attribute__ ((__unused__)) ISEQ blockiseq
)
{
    return 0;
}
rb_num_t
attr_retn_sendforward(
    __attribute__ ((__unused__)) CALL_DATA cd,
    __attribute__ ((__unused__)) ISEQ blockiseq
)
{
    return 1;
}
rb_snum_t
attr_sp_inc_sendforward(
    __attribute__ ((__unused__)) CALL_DATA cd,
    __attribute__ ((__unused__)) ISEQ blockiseq
)
{
    return
sp_inc_of_sendish(cd->ci);
}
rb_num_t
attr_width_sendforward(
    __attribute__ ((__unused__)) CALL_DATA cd,
    __attribute__ ((__unused__)) ISEQ blockiseq
)
{
    return 3;
}
enum ruby_vminsn_type
attr_bin_opt_send_without_block(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return YARVINSN_opt_send_without_block;
}
rb_snum_t
attr_comptime_sp_inc_opt_send_without_block(__attribute__ ((__unused__)) CALL_INFO ci)
{
    return
sp_inc_of_sendish(ci);
}
_Bool
attr_handles_sp_opt_send_without_block(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return
1;
}
_Bool
attr_leaf_opt_send_without_block(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return ! attr_handles_sp_opt_send_without_block(cd);
}
const char*
attr_name_opt_send_without_block(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return insn_name(YARVINSN_opt_send_without_block);
}
rb_num_t
attr_open_opt_send_without_block(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_num_t
attr_popn_opt_send_without_block(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 0;
}
rb_num_t
attr_retn_opt_send_without_block(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_snum_t
attr_sp_inc_opt_send_without_block(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return
sp_inc_of_sendish(cd->ci);
}
rb_num_t
attr_width_opt_send_without_block(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_objtostring(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return YARVINSN_objtostring;
}
_Bool
attr_handles_sp_objtostring(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 0;
}
_Bool
attr_leaf_objtostring(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return
0;
}
const char*
attr_name_objtostring(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return insn_name(YARVINSN_objtostring);
}
rb_num_t
attr_open_objtostring(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_num_t
attr_popn_objtostring(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_num_t
attr_retn_objtostring(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_snum_t
attr_sp_inc_objtostring(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 0;
}
rb_num_t
attr_width_objtostring(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_opt_ary_freeze(
    __attribute__ ((__unused__)) VALUE ary,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return YARVINSN_opt_ary_freeze;
}
_Bool
attr_handles_sp_opt_ary_freeze(
    __attribute__ ((__unused__)) VALUE ary,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 0;
}
_Bool
attr_leaf_opt_ary_freeze(
    __attribute__ ((__unused__)) VALUE ary,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 1;
}
const char*
attr_name_opt_ary_freeze(
    __attribute__ ((__unused__)) VALUE ary,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return insn_name(YARVINSN_opt_ary_freeze);
}
rb_num_t
attr_open_opt_ary_freeze(
    __attribute__ ((__unused__)) VALUE ary,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 2;
}
rb_num_t
attr_popn_opt_ary_freeze(
    __attribute__ ((__unused__)) VALUE ary,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 0;
}
rb_num_t
attr_retn_opt_ary_freeze(
    __attribute__ ((__unused__)) VALUE ary,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 1;
}
rb_snum_t
attr_sp_inc_opt_ary_freeze(
    __attribute__ ((__unused__)) VALUE ary,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 1;
}
rb_num_t
attr_width_opt_ary_freeze(
    __attribute__ ((__unused__)) VALUE ary,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 3;
}
enum ruby_vminsn_type
attr_bin_opt_hash_freeze(
    __attribute__ ((__unused__)) VALUE hash,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return YARVINSN_opt_hash_freeze;
}
_Bool
attr_handles_sp_opt_hash_freeze(
    __attribute__ ((__unused__)) VALUE hash,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 0;
}
_Bool
attr_leaf_opt_hash_freeze(
    __attribute__ ((__unused__)) VALUE hash,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 1;
}
const char*
attr_name_opt_hash_freeze(
    __attribute__ ((__unused__)) VALUE hash,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return insn_name(YARVINSN_opt_hash_freeze);
}
rb_num_t
attr_open_opt_hash_freeze(
    __attribute__ ((__unused__)) VALUE hash,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 2;
}
rb_num_t
attr_popn_opt_hash_freeze(
    __attribute__ ((__unused__)) VALUE hash,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 0;
}
rb_num_t
attr_retn_opt_hash_freeze(
    __attribute__ ((__unused__)) VALUE hash,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 1;
}
rb_snum_t
attr_sp_inc_opt_hash_freeze(
    __attribute__ ((__unused__)) VALUE hash,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 1;
}
rb_num_t
attr_width_opt_hash_freeze(
    __attribute__ ((__unused__)) VALUE hash,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 3;
}
enum ruby_vminsn_type
attr_bin_opt_str_freeze(
    __attribute__ ((__unused__)) VALUE str,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return YARVINSN_opt_str_freeze;
}
_Bool
attr_handles_sp_opt_str_freeze(
    __attribute__ ((__unused__)) VALUE str,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 0;
}
_Bool
attr_leaf_opt_str_freeze(
    __attribute__ ((__unused__)) VALUE str,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 1;
}
const char*
attr_name_opt_str_freeze(
    __attribute__ ((__unused__)) VALUE str,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return insn_name(YARVINSN_opt_str_freeze);
}
rb_num_t
attr_open_opt_str_freeze(
    __attribute__ ((__unused__)) VALUE str,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 2;
}
rb_num_t
attr_popn_opt_str_freeze(
    __attribute__ ((__unused__)) VALUE str,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 0;
}
rb_num_t
attr_retn_opt_str_freeze(
    __attribute__ ((__unused__)) VALUE str,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 1;
}
rb_snum_t
attr_sp_inc_opt_str_freeze(
    __attribute__ ((__unused__)) VALUE str,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 1;
}
rb_num_t
attr_width_opt_str_freeze(
    __attribute__ ((__unused__)) VALUE str,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 3;
}
enum ruby_vminsn_type
attr_bin_opt_nil_p(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return YARVINSN_opt_nil_p;
}
_Bool
attr_handles_sp_opt_nil_p(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 0;
}
_Bool
attr_leaf_opt_nil_p(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
const char*
attr_name_opt_nil_p(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return insn_name(YARVINSN_opt_nil_p);
}
rb_num_t
attr_open_opt_nil_p(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_num_t
attr_popn_opt_nil_p(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_num_t
attr_retn_opt_nil_p(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_snum_t
attr_sp_inc_opt_nil_p(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 0;
}
rb_num_t
attr_width_opt_nil_p(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_opt_str_uminus(
    __attribute__ ((__unused__)) VALUE str,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return YARVINSN_opt_str_uminus;
}
_Bool
attr_handles_sp_opt_str_uminus(
    __attribute__ ((__unused__)) VALUE str,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 0;
}
_Bool
attr_leaf_opt_str_uminus(
    __attribute__ ((__unused__)) VALUE str,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 1;
}
const char*
attr_name_opt_str_uminus(
    __attribute__ ((__unused__)) VALUE str,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return insn_name(YARVINSN_opt_str_uminus);
}
rb_num_t
attr_open_opt_str_uminus(
    __attribute__ ((__unused__)) VALUE str,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 2;
}
rb_num_t
attr_popn_opt_str_uminus(
    __attribute__ ((__unused__)) VALUE str,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 0;
}
rb_num_t
attr_retn_opt_str_uminus(
    __attribute__ ((__unused__)) VALUE str,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 1;
}
rb_snum_t
attr_sp_inc_opt_str_uminus(
    __attribute__ ((__unused__)) VALUE str,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 1;
}
rb_num_t
attr_width_opt_str_uminus(
    __attribute__ ((__unused__)) VALUE str,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 3;
}
enum ruby_vminsn_type
attr_bin_opt_duparray_send(
    __attribute__ ((__unused__)) VALUE ary,
    __attribute__ ((__unused__)) ID method,
    __attribute__ ((__unused__)) rb_num_t argc
)
{
    return YARVINSN_opt_duparray_send;
}
rb_snum_t
attr_comptime_sp_inc_opt_duparray_send(
    __attribute__ ((__unused__)) VALUE ary,
    __attribute__ ((__unused__)) ID method,
    __attribute__ ((__unused__)) rb_num_t argc
)
{
    return
1 - (rb_snum_t)argc;
}
_Bool
attr_handles_sp_opt_duparray_send(
    __attribute__ ((__unused__)) VALUE ary,
    __attribute__ ((__unused__)) ID method,
    __attribute__ ((__unused__)) rb_num_t argc
)
{
    return 0;
}
_Bool
attr_leaf_opt_duparray_send(
    __attribute__ ((__unused__)) VALUE ary,
    __attribute__ ((__unused__)) ID method,
    __attribute__ ((__unused__)) rb_num_t argc
)
{
    return
0;
}
const char*
attr_name_opt_duparray_send(
    __attribute__ ((__unused__)) VALUE ary,
    __attribute__ ((__unused__)) ID method,
    __attribute__ ((__unused__)) rb_num_t argc
)
{
    return insn_name(YARVINSN_opt_duparray_send);
}
rb_num_t
attr_open_opt_duparray_send(
    __attribute__ ((__unused__)) VALUE ary,
    __attribute__ ((__unused__)) ID method,
    __attribute__ ((__unused__)) rb_num_t argc
)
{
    return 3;
}
rb_num_t
attr_popn_opt_duparray_send(
    __attribute__ ((__unused__)) VALUE ary,
    __attribute__ ((__unused__)) ID method,
    __attribute__ ((__unused__)) rb_num_t argc
)
{
    return 0;
}
rb_num_t
attr_retn_opt_duparray_send(
    __attribute__ ((__unused__)) VALUE ary,
    __attribute__ ((__unused__)) ID method,
    __attribute__ ((__unused__)) rb_num_t argc
)
{
    return 1;
}
rb_snum_t
attr_sp_inc_opt_duparray_send(
    __attribute__ ((__unused__)) VALUE ary,
    __attribute__ ((__unused__)) ID method,
    __attribute__ ((__unused__)) rb_num_t argc
)
{
    return
1 - (rb_snum_t)argc;
}
rb_num_t
attr_width_opt_duparray_send(
    __attribute__ ((__unused__)) VALUE ary,
    __attribute__ ((__unused__)) ID method,
    __attribute__ ((__unused__)) rb_num_t argc
)
{
    return 4;
}
enum ruby_vminsn_type
attr_bin_opt_newarray_send(
    __attribute__ ((__unused__)) rb_num_t num,
    __attribute__ ((__unused__)) rb_num_t method
)
{
    return YARVINSN_opt_newarray_send;
}
rb_snum_t
attr_comptime_sp_inc_opt_newarray_send(
    __attribute__ ((__unused__)) rb_num_t num,
    __attribute__ ((__unused__)) rb_num_t method
)
{
    return
1 - (rb_snum_t)num;
}
_Bool
attr_handles_sp_opt_newarray_send(
    __attribute__ ((__unused__)) rb_num_t num,
    __attribute__ ((__unused__)) rb_num_t method
)
{
    return 0;
}
_Bool
attr_leaf_opt_newarray_send(
    __attribute__ ((__unused__)) rb_num_t num,
    __attribute__ ((__unused__)) rb_num_t method
)
{
    return
0;
}
const char*
attr_name_opt_newarray_send(
    __attribute__ ((__unused__)) rb_num_t num,
    __attribute__ ((__unused__)) rb_num_t method
)
{
    return insn_name(YARVINSN_opt_newarray_send);
}
rb_num_t
attr_open_opt_newarray_send(
    __attribute__ ((__unused__)) rb_num_t num,
    __attribute__ ((__unused__)) rb_num_t method
)
{
    return 2;
}
rb_num_t
attr_popn_opt_newarray_send(
    __attribute__ ((__unused__)) rb_num_t num,
    __attribute__ ((__unused__)) rb_num_t method
)
{
    return 0;
}
rb_num_t
attr_retn_opt_newarray_send(
    __attribute__ ((__unused__)) rb_num_t num,
    __attribute__ ((__unused__)) rb_num_t method
)
{
    return 1;
}
rb_snum_t
attr_sp_inc_opt_newarray_send(
    __attribute__ ((__unused__)) rb_num_t num,
    __attribute__ ((__unused__)) rb_num_t method
)
{
    return
1 - (rb_snum_t)num;
}
rb_num_t
attr_width_opt_newarray_send(
    __attribute__ ((__unused__)) rb_num_t num,
    __attribute__ ((__unused__)) rb_num_t method
)
{
    return 3;
}
enum ruby_vminsn_type
attr_bin_invokesuper(
    __attribute__ ((__unused__)) CALL_DATA cd,
    __attribute__ ((__unused__)) ISEQ blockiseq
)
{
    return YARVINSN_invokesuper;
}
rb_snum_t
attr_comptime_sp_inc_invokesuper(
    __attribute__ ((__unused__)) CALL_INFO ci,
    __attribute__ ((__unused__)) ISEQ blockiseq
)
{
    return
sp_inc_of_sendish(ci);
}
_Bool
attr_handles_sp_invokesuper(
    __attribute__ ((__unused__)) CALL_DATA cd,
    __attribute__ ((__unused__)) ISEQ blockiseq
)
{
    return 1;
}
_Bool
attr_leaf_invokesuper(
    __attribute__ ((__unused__)) CALL_DATA cd,
    __attribute__ ((__unused__)) ISEQ blockiseq
)
{
    return 0;
}
const char*
attr_name_invokesuper(
    __attribute__ ((__unused__)) CALL_DATA cd,
    __attribute__ ((__unused__)) ISEQ blockiseq
)
{
    return insn_name(YARVINSN_invokesuper);
}
rb_num_t
attr_open_invokesuper(
    __attribute__ ((__unused__)) CALL_DATA cd,
    __attribute__ ((__unused__)) ISEQ blockiseq
)
{
    return 2;
}
rb_num_t
attr_popn_invokesuper(
    __attribute__ ((__unused__)) CALL_DATA cd,
    __attribute__ ((__unused__)) ISEQ blockiseq
)
{
    return 0;
}
rb_num_t
attr_retn_invokesuper(
    __attribute__ ((__unused__)) CALL_DATA cd,
    __attribute__ ((__unused__)) ISEQ blockiseq
)
{
    return 1;
}
rb_snum_t
attr_sp_inc_invokesuper(
    __attribute__ ((__unused__)) CALL_DATA cd,
    __attribute__ ((__unused__)) ISEQ blockiseq
)
{
    return
sp_inc_of_sendish(cd->ci);
}
rb_num_t
attr_width_invokesuper(
    __attribute__ ((__unused__)) CALL_DATA cd,
    __attribute__ ((__unused__)) ISEQ blockiseq
)
{
    return 3;
}
enum ruby_vminsn_type
attr_bin_invokesuperforward(
    __attribute__ ((__unused__)) CALL_DATA cd,
    __attribute__ ((__unused__)) ISEQ blockiseq
)
{
    return YARVINSN_invokesuperforward;
}
rb_snum_t
attr_comptime_sp_inc_invokesuperforward(
    __attribute__ ((__unused__)) CALL_INFO ci,
    __attribute__ ((__unused__)) ISEQ blockiseq
)
{
    return
sp_inc_of_sendish(ci);
}
_Bool
attr_handles_sp_invokesuperforward(
    __attribute__ ((__unused__)) CALL_DATA cd,
    __attribute__ ((__unused__)) ISEQ blockiseq
)
{
    return 1;
}
_Bool
attr_leaf_invokesuperforward(
    __attribute__ ((__unused__)) CALL_DATA cd,
    __attribute__ ((__unused__)) ISEQ blockiseq
)
{
    return 0;
}
const char*
attr_name_invokesuperforward(
    __attribute__ ((__unused__)) CALL_DATA cd,
    __attribute__ ((__unused__)) ISEQ blockiseq
)
{
    return insn_name(YARVINSN_invokesuperforward);
}
rb_num_t
attr_open_invokesuperforward(
    __attribute__ ((__unused__)) CALL_DATA cd,
    __attribute__ ((__unused__)) ISEQ blockiseq
)
{
    return 2;
}
rb_num_t
attr_popn_invokesuperforward(
    __attribute__ ((__unused__)) CALL_DATA cd,
    __attribute__ ((__unused__)) ISEQ blockiseq
)
{
    return 0;
}
rb_num_t
attr_retn_invokesuperforward(
    __attribute__ ((__unused__)) CALL_DATA cd,
    __attribute__ ((__unused__)) ISEQ blockiseq
)
{
    return 1;
}
rb_snum_t
attr_sp_inc_invokesuperforward(
    __attribute__ ((__unused__)) CALL_DATA cd,
    __attribute__ ((__unused__)) ISEQ blockiseq
)
{
    return
sp_inc_of_sendish(cd->ci);
}
rb_num_t
attr_width_invokesuperforward(
    __attribute__ ((__unused__)) CALL_DATA cd,
    __attribute__ ((__unused__)) ISEQ blockiseq
)
{
    return 3;
}
enum ruby_vminsn_type
attr_bin_invokeblock(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return YARVINSN_invokeblock;
}
rb_snum_t
attr_comptime_sp_inc_invokeblock(__attribute__ ((__unused__)) CALL_INFO ci)
{
    return
sp_inc_of_invokeblock(ci);
}
_Bool
attr_handles_sp_invokeblock(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return
1;
}
_Bool
attr_leaf_invokeblock(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return ! attr_handles_sp_invokeblock(cd);
}
const char*
attr_name_invokeblock(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return insn_name(YARVINSN_invokeblock);
}
rb_num_t
attr_open_invokeblock(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_num_t
attr_popn_invokeblock(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 0;
}
rb_num_t
attr_retn_invokeblock(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_snum_t
attr_sp_inc_invokeblock(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return
sp_inc_of_invokeblock(cd->ci);
}
rb_num_t
attr_width_invokeblock(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_leave(void)
{
    return YARVINSN_leave;
}
_Bool
attr_handles_sp_leave(void)
{
    return
1;
}
_Bool
attr_leaf_leave(void)
{
    return
0;
}
const char*
attr_name_leave(void)
{
    return insn_name(YARVINSN_leave);
}
rb_num_t
attr_open_leave(void)
{
    return 0;
}
rb_num_t
attr_popn_leave(void)
{
    return 1;
}
rb_num_t
attr_retn_leave(void)
{
    return 1;
}
rb_snum_t
attr_sp_inc_leave(void)
{
    return 0;
}
rb_num_t
attr_width_leave(void)
{
    return 1;
}
enum ruby_vminsn_type
attr_bin_throw(__attribute__ ((__unused__)) rb_num_t throw_state)
{
    return YARVINSN_throw;
}
_Bool
attr_handles_sp_throw(__attribute__ ((__unused__)) rb_num_t throw_state)
{
    return 0;
}
_Bool
attr_leaf_throw(__attribute__ ((__unused__)) rb_num_t throw_state)
{
    return
0;
}
const char*
attr_name_throw(__attribute__ ((__unused__)) rb_num_t throw_state)
{
    return insn_name(YARVINSN_throw);
}
rb_num_t
attr_open_throw(__attribute__ ((__unused__)) rb_num_t throw_state)
{
    return 1;
}
rb_num_t
attr_popn_throw(__attribute__ ((__unused__)) rb_num_t throw_state)
{
    return 1;
}
rb_num_t
attr_retn_throw(__attribute__ ((__unused__)) rb_num_t throw_state)
{
    return 1;
}
rb_snum_t
attr_sp_inc_throw(__attribute__ ((__unused__)) rb_num_t throw_state)
{
    return 0;
}
rb_num_t
attr_width_throw(__attribute__ ((__unused__)) rb_num_t throw_state)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_jump(__attribute__ ((__unused__)) OFFSET dst)
{
    return YARVINSN_jump;
}
_Bool
attr_handles_sp_jump(__attribute__ ((__unused__)) OFFSET dst)
{
    return 0;
}
_Bool
attr_leaf_jump(__attribute__ ((__unused__)) OFFSET dst)
{
    return
leafness_of_check_ints;
}
const char*
attr_name_jump(__attribute__ ((__unused__)) OFFSET dst)
{
    return insn_name(YARVINSN_jump);
}
rb_num_t
attr_open_jump(__attribute__ ((__unused__)) OFFSET dst)
{
    return 1;
}
rb_num_t
attr_popn_jump(__attribute__ ((__unused__)) OFFSET dst)
{
    return 0;
}
rb_num_t
attr_retn_jump(__attribute__ ((__unused__)) OFFSET dst)
{
    return 0;
}
rb_snum_t
attr_sp_inc_jump(__attribute__ ((__unused__)) OFFSET dst)
{
    return 0;
}
rb_num_t
attr_width_jump(__attribute__ ((__unused__)) OFFSET dst)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_branchif(__attribute__ ((__unused__)) OFFSET dst)
{
    return YARVINSN_branchif;
}
_Bool
attr_handles_sp_branchif(__attribute__ ((__unused__)) OFFSET dst)
{
    return 0;
}
_Bool
attr_leaf_branchif(__attribute__ ((__unused__)) OFFSET dst)
{
    return
leafness_of_check_ints;
}
const char*
attr_name_branchif(__attribute__ ((__unused__)) OFFSET dst)
{
    return insn_name(YARVINSN_branchif);
}
rb_num_t
attr_open_branchif(__attribute__ ((__unused__)) OFFSET dst)
{
    return 1;
}
rb_num_t
attr_popn_branchif(__attribute__ ((__unused__)) OFFSET dst)
{
    return 1;
}
rb_num_t
attr_retn_branchif(__attribute__ ((__unused__)) OFFSET dst)
{
    return 0;
}
rb_snum_t
attr_sp_inc_branchif(__attribute__ ((__unused__)) OFFSET dst)
{
    return -1;
}
rb_num_t
attr_width_branchif(__attribute__ ((__unused__)) OFFSET dst)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_branchunless(__attribute__ ((__unused__)) OFFSET dst)
{
    return YARVINSN_branchunless;
}
_Bool
attr_handles_sp_branchunless(__attribute__ ((__unused__)) OFFSET dst)
{
    return 0;
}
_Bool
attr_leaf_branchunless(__attribute__ ((__unused__)) OFFSET dst)
{
    return
leafness_of_check_ints;
}
const char*
attr_name_branchunless(__attribute__ ((__unused__)) OFFSET dst)
{
    return insn_name(YARVINSN_branchunless);
}
rb_num_t
attr_open_branchunless(__attribute__ ((__unused__)) OFFSET dst)
{
    return 1;
}
rb_num_t
attr_popn_branchunless(__attribute__ ((__unused__)) OFFSET dst)
{
    return 1;
}
rb_num_t
attr_retn_branchunless(__attribute__ ((__unused__)) OFFSET dst)
{
    return 0;
}
rb_snum_t
attr_sp_inc_branchunless(__attribute__ ((__unused__)) OFFSET dst)
{
    return -1;
}
rb_num_t
attr_width_branchunless(__attribute__ ((__unused__)) OFFSET dst)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_branchnil(__attribute__ ((__unused__)) OFFSET dst)
{
    return YARVINSN_branchnil;
}
_Bool
attr_handles_sp_branchnil(__attribute__ ((__unused__)) OFFSET dst)
{
    return 0;
}
_Bool
attr_leaf_branchnil(__attribute__ ((__unused__)) OFFSET dst)
{
    return
leafness_of_check_ints;
}
const char*
attr_name_branchnil(__attribute__ ((__unused__)) OFFSET dst)
{
    return insn_name(YARVINSN_branchnil);
}
rb_num_t
attr_open_branchnil(__attribute__ ((__unused__)) OFFSET dst)
{
    return 1;
}
rb_num_t
attr_popn_branchnil(__attribute__ ((__unused__)) OFFSET dst)
{
    return 1;
}
rb_num_t
attr_retn_branchnil(__attribute__ ((__unused__)) OFFSET dst)
{
    return 0;
}
rb_snum_t
attr_sp_inc_branchnil(__attribute__ ((__unused__)) OFFSET dst)
{
    return -1;
}
rb_num_t
attr_width_branchnil(__attribute__ ((__unused__)) OFFSET dst)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_once(
    __attribute__ ((__unused__)) ISEQ iseq,
    __attribute__ ((__unused__)) ISE ise
)
{
    return YARVINSN_once;
}
_Bool
attr_handles_sp_once(
    __attribute__ ((__unused__)) ISEQ iseq,
    __attribute__ ((__unused__)) ISE ise
)
{
    return 1;
}
_Bool
attr_leaf_once(
    __attribute__ ((__unused__)) ISEQ iseq,
    __attribute__ ((__unused__)) ISE ise
)
{
    return 0;
}
const char*
attr_name_once(
    __attribute__ ((__unused__)) ISEQ iseq,
    __attribute__ ((__unused__)) ISE ise
)
{
    return insn_name(YARVINSN_once);
}
rb_num_t
attr_open_once(
    __attribute__ ((__unused__)) ISEQ iseq,
    __attribute__ ((__unused__)) ISE ise
)
{
    return 2;
}
rb_num_t
attr_popn_once(
    __attribute__ ((__unused__)) ISEQ iseq,
    __attribute__ ((__unused__)) ISE ise
)
{
    return 0;
}
rb_num_t
attr_retn_once(
    __attribute__ ((__unused__)) ISEQ iseq,
    __attribute__ ((__unused__)) ISE ise
)
{
    return 1;
}
rb_snum_t
attr_sp_inc_once(
    __attribute__ ((__unused__)) ISEQ iseq,
    __attribute__ ((__unused__)) ISE ise
)
{
    return 1;
}
rb_num_t
attr_width_once(
    __attribute__ ((__unused__)) ISEQ iseq,
    __attribute__ ((__unused__)) ISE ise
)
{
    return 3;
}
enum ruby_vminsn_type
attr_bin_opt_case_dispatch(
    __attribute__ ((__unused__)) CDHASH hash,
    __attribute__ ((__unused__)) OFFSET else_offset
)
{
    return YARVINSN_opt_case_dispatch;
}
_Bool
attr_handles_sp_opt_case_dispatch(
    __attribute__ ((__unused__)) CDHASH hash,
    __attribute__ ((__unused__)) OFFSET else_offset
)
{
    return 0;
}
_Bool
attr_leaf_opt_case_dispatch(
    __attribute__ ((__unused__)) CDHASH hash,
    __attribute__ ((__unused__)) OFFSET else_offset
)
{
    return 1;
}
const char*
attr_name_opt_case_dispatch(
    __attribute__ ((__unused__)) CDHASH hash,
    __attribute__ ((__unused__)) OFFSET else_offset
)
{
    return insn_name(YARVINSN_opt_case_dispatch);
}
rb_num_t
attr_open_opt_case_dispatch(
    __attribute__ ((__unused__)) CDHASH hash,
    __attribute__ ((__unused__)) OFFSET else_offset
)
{
    return 2;
}
rb_num_t
attr_popn_opt_case_dispatch(
    __attribute__ ((__unused__)) CDHASH hash,
    __attribute__ ((__unused__)) OFFSET else_offset
)
{
    return 1;
}
rb_num_t
attr_retn_opt_case_dispatch(
    __attribute__ ((__unused__)) CDHASH hash,
    __attribute__ ((__unused__)) OFFSET else_offset
)
{
    return 0;
}
rb_snum_t
attr_sp_inc_opt_case_dispatch(
    __attribute__ ((__unused__)) CDHASH hash,
    __attribute__ ((__unused__)) OFFSET else_offset
)
{
    return
-1;
}
rb_num_t
attr_width_opt_case_dispatch(
    __attribute__ ((__unused__)) CDHASH hash,
    __attribute__ ((__unused__)) OFFSET else_offset
)
{
    return 3;
}
enum ruby_vminsn_type
attr_bin_opt_plus(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return YARVINSN_opt_plus;
}
_Bool
attr_handles_sp_opt_plus(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 0;
}
_Bool
attr_leaf_opt_plus(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
const char*
attr_name_opt_plus(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return insn_name(YARVINSN_opt_plus);
}
rb_num_t
attr_open_opt_plus(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_num_t
attr_popn_opt_plus(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 2;
}
rb_num_t
attr_retn_opt_plus(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_snum_t
attr_sp_inc_opt_plus(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return -1;
}
rb_num_t
attr_width_opt_plus(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_opt_minus(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return YARVINSN_opt_minus;
}
_Bool
attr_handles_sp_opt_minus(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 0;
}
_Bool
attr_leaf_opt_minus(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
const char*
attr_name_opt_minus(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return insn_name(YARVINSN_opt_minus);
}
rb_num_t
attr_open_opt_minus(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_num_t
attr_popn_opt_minus(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 2;
}
rb_num_t
attr_retn_opt_minus(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_snum_t
attr_sp_inc_opt_minus(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return -1;
}
rb_num_t
attr_width_opt_minus(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_opt_mult(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return YARVINSN_opt_mult;
}
_Bool
attr_handles_sp_opt_mult(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 0;
}
_Bool
attr_leaf_opt_mult(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
const char*
attr_name_opt_mult(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return insn_name(YARVINSN_opt_mult);
}
rb_num_t
attr_open_opt_mult(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_num_t
attr_popn_opt_mult(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 2;
}
rb_num_t
attr_retn_opt_mult(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_snum_t
attr_sp_inc_opt_mult(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return -1;
}
rb_num_t
attr_width_opt_mult(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_opt_div(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return YARVINSN_opt_div;
}
_Bool
attr_handles_sp_opt_div(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 0;
}
_Bool
attr_leaf_opt_div(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return
0;
}
const char*
attr_name_opt_div(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return insn_name(YARVINSN_opt_div);
}
rb_num_t
attr_open_opt_div(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_num_t
attr_popn_opt_div(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 2;
}
rb_num_t
attr_retn_opt_div(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_snum_t
attr_sp_inc_opt_div(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return -1;
}
rb_num_t
attr_width_opt_div(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_opt_mod(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return YARVINSN_opt_mod;
}
_Bool
attr_handles_sp_opt_mod(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 0;
}
_Bool
attr_leaf_opt_mod(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return
0;
}
const char*
attr_name_opt_mod(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return insn_name(YARVINSN_opt_mod);
}
rb_num_t
attr_open_opt_mod(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_num_t
attr_popn_opt_mod(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 2;
}
rb_num_t
attr_retn_opt_mod(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_snum_t
attr_sp_inc_opt_mod(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return -1;
}
rb_num_t
attr_width_opt_mod(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_opt_eq(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return YARVINSN_opt_eq;
}
_Bool
attr_handles_sp_opt_eq(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 0;
}
_Bool
attr_leaf_opt_eq(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
const char*
attr_name_opt_eq(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return insn_name(YARVINSN_opt_eq);
}
rb_num_t
attr_open_opt_eq(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_num_t
attr_popn_opt_eq(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 2;
}
rb_num_t
attr_retn_opt_eq(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_snum_t
attr_sp_inc_opt_eq(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return -1;
}
rb_num_t
attr_width_opt_eq(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_opt_neq(
    __attribute__ ((__unused__)) CALL_DATA cd_eq,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return YARVINSN_opt_neq;
}
_Bool
attr_handles_sp_opt_neq(
    __attribute__ ((__unused__)) CALL_DATA cd_eq,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 0;
}
_Bool
attr_leaf_opt_neq(
    __attribute__ ((__unused__)) CALL_DATA cd_eq,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 1;
}
const char*
attr_name_opt_neq(
    __attribute__ ((__unused__)) CALL_DATA cd_eq,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return insn_name(YARVINSN_opt_neq);
}
rb_num_t
attr_open_opt_neq(
    __attribute__ ((__unused__)) CALL_DATA cd_eq,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 2;
}
rb_num_t
attr_popn_opt_neq(
    __attribute__ ((__unused__)) CALL_DATA cd_eq,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 2;
}
rb_num_t
attr_retn_opt_neq(
    __attribute__ ((__unused__)) CALL_DATA cd_eq,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 1;
}
rb_snum_t
attr_sp_inc_opt_neq(
    __attribute__ ((__unused__)) CALL_DATA cd_eq,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return -1;
}
rb_num_t
attr_width_opt_neq(
    __attribute__ ((__unused__)) CALL_DATA cd_eq,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 3;
}
enum ruby_vminsn_type
attr_bin_opt_lt(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return YARVINSN_opt_lt;
}
_Bool
attr_handles_sp_opt_lt(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 0;
}
_Bool
attr_leaf_opt_lt(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
const char*
attr_name_opt_lt(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return insn_name(YARVINSN_opt_lt);
}
rb_num_t
attr_open_opt_lt(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_num_t
attr_popn_opt_lt(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 2;
}
rb_num_t
attr_retn_opt_lt(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_snum_t
attr_sp_inc_opt_lt(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return -1;
}
rb_num_t
attr_width_opt_lt(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_opt_le(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return YARVINSN_opt_le;
}
_Bool
attr_handles_sp_opt_le(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 0;
}
_Bool
attr_leaf_opt_le(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
const char*
attr_name_opt_le(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return insn_name(YARVINSN_opt_le);
}
rb_num_t
attr_open_opt_le(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_num_t
attr_popn_opt_le(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 2;
}
rb_num_t
attr_retn_opt_le(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_snum_t
attr_sp_inc_opt_le(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return -1;
}
rb_num_t
attr_width_opt_le(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_opt_gt(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return YARVINSN_opt_gt;
}
_Bool
attr_handles_sp_opt_gt(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 0;
}
_Bool
attr_leaf_opt_gt(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
const char*
attr_name_opt_gt(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return insn_name(YARVINSN_opt_gt);
}
rb_num_t
attr_open_opt_gt(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_num_t
attr_popn_opt_gt(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 2;
}
rb_num_t
attr_retn_opt_gt(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_snum_t
attr_sp_inc_opt_gt(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return -1;
}
rb_num_t
attr_width_opt_gt(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_opt_ge(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return YARVINSN_opt_ge;
}
_Bool
attr_handles_sp_opt_ge(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 0;
}
_Bool
attr_leaf_opt_ge(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
const char*
attr_name_opt_ge(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return insn_name(YARVINSN_opt_ge);
}
rb_num_t
attr_open_opt_ge(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_num_t
attr_popn_opt_ge(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 2;
}
rb_num_t
attr_retn_opt_ge(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_snum_t
attr_sp_inc_opt_ge(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return -1;
}
rb_num_t
attr_width_opt_ge(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_opt_ltlt(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return YARVINSN_opt_ltlt;
}
_Bool
attr_handles_sp_opt_ltlt(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 0;
}
_Bool
attr_leaf_opt_ltlt(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return
0;
}
const char*
attr_name_opt_ltlt(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return insn_name(YARVINSN_opt_ltlt);
}
rb_num_t
attr_open_opt_ltlt(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_num_t
attr_popn_opt_ltlt(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 2;
}
rb_num_t
attr_retn_opt_ltlt(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_snum_t
attr_sp_inc_opt_ltlt(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return -1;
}
rb_num_t
attr_width_opt_ltlt(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_opt_and(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return YARVINSN_opt_and;
}
_Bool
attr_handles_sp_opt_and(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 0;
}
_Bool
attr_leaf_opt_and(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
const char*
attr_name_opt_and(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return insn_name(YARVINSN_opt_and);
}
rb_num_t
attr_open_opt_and(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_num_t
attr_popn_opt_and(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 2;
}
rb_num_t
attr_retn_opt_and(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_snum_t
attr_sp_inc_opt_and(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return -1;
}
rb_num_t
attr_width_opt_and(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_opt_or(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return YARVINSN_opt_or;
}
_Bool
attr_handles_sp_opt_or(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 0;
}
_Bool
attr_leaf_opt_or(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
const char*
attr_name_opt_or(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return insn_name(YARVINSN_opt_or);
}
rb_num_t
attr_open_opt_or(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_num_t
attr_popn_opt_or(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 2;
}
rb_num_t
attr_retn_opt_or(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_snum_t
attr_sp_inc_opt_or(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return -1;
}
rb_num_t
attr_width_opt_or(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_opt_aref(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return YARVINSN_opt_aref;
}
_Bool
attr_handles_sp_opt_aref(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 0;
}
_Bool
attr_leaf_opt_aref(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return
0;
}
const char*
attr_name_opt_aref(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return insn_name(YARVINSN_opt_aref);
}
rb_num_t
attr_open_opt_aref(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_num_t
attr_popn_opt_aref(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 2;
}
rb_num_t
attr_retn_opt_aref(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_snum_t
attr_sp_inc_opt_aref(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return -1;
}
rb_num_t
attr_width_opt_aref(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_opt_aset(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return YARVINSN_opt_aset;
}
_Bool
attr_handles_sp_opt_aset(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 0;
}
_Bool
attr_leaf_opt_aset(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return
0;
}
const char*
attr_name_opt_aset(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return insn_name(YARVINSN_opt_aset);
}
rb_num_t
attr_open_opt_aset(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_num_t
attr_popn_opt_aset(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 3;
}
rb_num_t
attr_retn_opt_aset(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_snum_t
attr_sp_inc_opt_aset(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return -2;
}
rb_num_t
attr_width_opt_aset(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_opt_aset_with(
    __attribute__ ((__unused__)) VALUE key,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return YARVINSN_opt_aset_with;
}
_Bool
attr_handles_sp_opt_aset_with(
    __attribute__ ((__unused__)) VALUE key,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 0;
}
_Bool
attr_leaf_opt_aset_with(
    __attribute__ ((__unused__)) VALUE key,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return
0;
}
const char*
attr_name_opt_aset_with(
    __attribute__ ((__unused__)) VALUE key,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return insn_name(YARVINSN_opt_aset_with);
}
rb_num_t
attr_open_opt_aset_with(
    __attribute__ ((__unused__)) VALUE key,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 2;
}
rb_num_t
attr_popn_opt_aset_with(
    __attribute__ ((__unused__)) VALUE key,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 2;
}
rb_num_t
attr_retn_opt_aset_with(
    __attribute__ ((__unused__)) VALUE key,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 1;
}
rb_snum_t
attr_sp_inc_opt_aset_with(
    __attribute__ ((__unused__)) VALUE key,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return -1;
}
rb_num_t
attr_width_opt_aset_with(
    __attribute__ ((__unused__)) VALUE key,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 3;
}
enum ruby_vminsn_type
attr_bin_opt_aref_with(
    __attribute__ ((__unused__)) VALUE key,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return YARVINSN_opt_aref_with;
}
_Bool
attr_handles_sp_opt_aref_with(
    __attribute__ ((__unused__)) VALUE key,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 0;
}
_Bool
attr_leaf_opt_aref_with(
    __attribute__ ((__unused__)) VALUE key,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return
0;
}
const char*
attr_name_opt_aref_with(
    __attribute__ ((__unused__)) VALUE key,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return insn_name(YARVINSN_opt_aref_with);
}
rb_num_t
attr_open_opt_aref_with(
    __attribute__ ((__unused__)) VALUE key,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 2;
}
rb_num_t
attr_popn_opt_aref_with(
    __attribute__ ((__unused__)) VALUE key,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 1;
}
rb_num_t
attr_retn_opt_aref_with(
    __attribute__ ((__unused__)) VALUE key,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 1;
}
rb_snum_t
attr_sp_inc_opt_aref_with(
    __attribute__ ((__unused__)) VALUE key,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 0;
}
rb_num_t
attr_width_opt_aref_with(
    __attribute__ ((__unused__)) VALUE key,
    __attribute__ ((__unused__)) CALL_DATA cd
)
{
    return 3;
}
enum ruby_vminsn_type
attr_bin_opt_length(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return YARVINSN_opt_length;
}
_Bool
attr_handles_sp_opt_length(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 0;
}
_Bool
attr_leaf_opt_length(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
const char*
attr_name_opt_length(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return insn_name(YARVINSN_opt_length);
}
rb_num_t
attr_open_opt_length(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_num_t
attr_popn_opt_length(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_num_t
attr_retn_opt_length(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_snum_t
attr_sp_inc_opt_length(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 0;
}
rb_num_t
attr_width_opt_length(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_opt_size(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return YARVINSN_opt_size;
}
_Bool
attr_handles_sp_opt_size(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 0;
}
_Bool
attr_leaf_opt_size(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
const char*
attr_name_opt_size(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return insn_name(YARVINSN_opt_size);
}
rb_num_t
attr_open_opt_size(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_num_t
attr_popn_opt_size(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_num_t
attr_retn_opt_size(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_snum_t
attr_sp_inc_opt_size(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 0;
}
rb_num_t
attr_width_opt_size(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_opt_empty_p(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return YARVINSN_opt_empty_p;
}
_Bool
attr_handles_sp_opt_empty_p(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 0;
}
_Bool
attr_leaf_opt_empty_p(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
const char*
attr_name_opt_empty_p(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return insn_name(YARVINSN_opt_empty_p);
}
rb_num_t
attr_open_opt_empty_p(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_num_t
attr_popn_opt_empty_p(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_num_t
attr_retn_opt_empty_p(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_snum_t
attr_sp_inc_opt_empty_p(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 0;
}
rb_num_t
attr_width_opt_empty_p(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_opt_succ(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return YARVINSN_opt_succ;
}
_Bool
attr_handles_sp_opt_succ(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 0;
}
_Bool
attr_leaf_opt_succ(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
const char*
attr_name_opt_succ(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return insn_name(YARVINSN_opt_succ);
}
rb_num_t
attr_open_opt_succ(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_num_t
attr_popn_opt_succ(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_num_t
attr_retn_opt_succ(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_snum_t
attr_sp_inc_opt_succ(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 0;
}
rb_num_t
attr_width_opt_succ(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_opt_not(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return YARVINSN_opt_not;
}
_Bool
attr_handles_sp_opt_not(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 0;
}
_Bool
attr_leaf_opt_not(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
const char*
attr_name_opt_not(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return insn_name(YARVINSN_opt_not);
}
rb_num_t
attr_open_opt_not(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_num_t
attr_popn_opt_not(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_num_t
attr_retn_opt_not(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_snum_t
attr_sp_inc_opt_not(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 0;
}
rb_num_t
attr_width_opt_not(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_opt_regexpmatch2(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return YARVINSN_opt_regexpmatch2;
}
_Bool
attr_handles_sp_opt_regexpmatch2(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 0;
}
_Bool
attr_leaf_opt_regexpmatch2(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return
0;
}
const char*
attr_name_opt_regexpmatch2(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return insn_name(YARVINSN_opt_regexpmatch2);
}
rb_num_t
attr_open_opt_regexpmatch2(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_num_t
attr_popn_opt_regexpmatch2(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 2;
}
rb_num_t
attr_retn_opt_regexpmatch2(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 1;
}
rb_snum_t
attr_sp_inc_opt_regexpmatch2(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return -1;
}
rb_num_t
attr_width_opt_regexpmatch2(__attribute__ ((__unused__)) CALL_DATA cd)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_invokebuiltin(__attribute__ ((__unused__)) RB_BUILTIN bf)
{
    return YARVINSN_invokebuiltin;
}
_Bool
attr_handles_sp_invokebuiltin(__attribute__ ((__unused__)) RB_BUILTIN bf)
{
    return 0;
}
_Bool
attr_leaf_invokebuiltin(__attribute__ ((__unused__)) RB_BUILTIN bf)
{
    return
0;
}
const char*
attr_name_invokebuiltin(__attribute__ ((__unused__)) RB_BUILTIN bf)
{
    return insn_name(YARVINSN_invokebuiltin);
}
rb_num_t
attr_open_invokebuiltin(__attribute__ ((__unused__)) RB_BUILTIN bf)
{
    return 1;
}
rb_num_t
attr_popn_invokebuiltin(__attribute__ ((__unused__)) RB_BUILTIN bf)
{
    return 0;
}
rb_num_t
attr_retn_invokebuiltin(__attribute__ ((__unused__)) RB_BUILTIN bf)
{
    return 1;
}
rb_snum_t
attr_sp_inc_invokebuiltin(__attribute__ ((__unused__)) RB_BUILTIN bf)
{
    return
1 - bf->argc;
}
rb_num_t
attr_width_invokebuiltin(__attribute__ ((__unused__)) RB_BUILTIN bf)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_opt_invokebuiltin_delegate(
    __attribute__ ((__unused__)) RB_BUILTIN bf,
    __attribute__ ((__unused__)) rb_num_t index
)
{
    return YARVINSN_opt_invokebuiltin_delegate;
}
_Bool
attr_handles_sp_opt_invokebuiltin_delegate(
    __attribute__ ((__unused__)) RB_BUILTIN bf,
    __attribute__ ((__unused__)) rb_num_t index
)
{
    return 0;
}
_Bool
attr_leaf_opt_invokebuiltin_delegate(
    __attribute__ ((__unused__)) RB_BUILTIN bf,
    __attribute__ ((__unused__)) rb_num_t index
)
{
    return
0;
}
const char*
attr_name_opt_invokebuiltin_delegate(
    __attribute__ ((__unused__)) RB_BUILTIN bf,
    __attribute__ ((__unused__)) rb_num_t index
)
{
    return insn_name(YARVINSN_opt_invokebuiltin_delegate);
}
rb_num_t
attr_open_opt_invokebuiltin_delegate(
    __attribute__ ((__unused__)) RB_BUILTIN bf,
    __attribute__ ((__unused__)) rb_num_t index
)
{
    return 2;
}
rb_num_t
attr_popn_opt_invokebuiltin_delegate(
    __attribute__ ((__unused__)) RB_BUILTIN bf,
    __attribute__ ((__unused__)) rb_num_t index
)
{
    return 0;
}
rb_num_t
attr_retn_opt_invokebuiltin_delegate(
    __attribute__ ((__unused__)) RB_BUILTIN bf,
    __attribute__ ((__unused__)) rb_num_t index
)
{
    return 1;
}
rb_snum_t
attr_sp_inc_opt_invokebuiltin_delegate(
    __attribute__ ((__unused__)) RB_BUILTIN bf,
    __attribute__ ((__unused__)) rb_num_t index
)
{
    return 1;
}
rb_num_t
attr_width_opt_invokebuiltin_delegate(
    __attribute__ ((__unused__)) RB_BUILTIN bf,
    __attribute__ ((__unused__)) rb_num_t index
)
{
    return 3;
}
enum ruby_vminsn_type
attr_bin_opt_invokebuiltin_delegate_leave(
    __attribute__ ((__unused__)) RB_BUILTIN bf,
    __attribute__ ((__unused__)) rb_num_t index
)
{
    return YARVINSN_opt_invokebuiltin_delegate_leave;
}
_Bool
attr_handles_sp_opt_invokebuiltin_delegate_leave(
    __attribute__ ((__unused__)) RB_BUILTIN bf,
    __attribute__ ((__unused__)) rb_num_t index
)
{
    return 0;
}
_Bool
attr_leaf_opt_invokebuiltin_delegate_leave(
    __attribute__ ((__unused__)) RB_BUILTIN bf,
    __attribute__ ((__unused__)) rb_num_t index
)
{
    return
0;
}
const char*
attr_name_opt_invokebuiltin_delegate_leave(
    __attribute__ ((__unused__)) RB_BUILTIN bf,
    __attribute__ ((__unused__)) rb_num_t index
)
{
    return insn_name(YARVINSN_opt_invokebuiltin_delegate_leave);
}
rb_num_t
attr_open_opt_invokebuiltin_delegate_leave(
    __attribute__ ((__unused__)) RB_BUILTIN bf,
    __attribute__ ((__unused__)) rb_num_t index
)
{
    return 2;
}
rb_num_t
attr_popn_opt_invokebuiltin_delegate_leave(
    __attribute__ ((__unused__)) RB_BUILTIN bf,
    __attribute__ ((__unused__)) rb_num_t index
)
{
    return 0;
}
rb_num_t
attr_retn_opt_invokebuiltin_delegate_leave(
    __attribute__ ((__unused__)) RB_BUILTIN bf,
    __attribute__ ((__unused__)) rb_num_t index
)
{
    return 1;
}
rb_snum_t
attr_sp_inc_opt_invokebuiltin_delegate_leave(
    __attribute__ ((__unused__)) RB_BUILTIN bf,
    __attribute__ ((__unused__)) rb_num_t index
)
{
    return 1;
}
rb_num_t
attr_width_opt_invokebuiltin_delegate_leave(
    __attribute__ ((__unused__)) RB_BUILTIN bf,
    __attribute__ ((__unused__)) rb_num_t index
)
{
    return 3;
}
enum ruby_vminsn_type
attr_bin_getlocal_WC_0(__attribute__ ((__unused__)) lindex_t idx)
{
    return YARVINSN_getlocal_WC_0;
}
_Bool
attr_handles_sp_getlocal_WC_0(__attribute__ ((__unused__)) lindex_t idx)
{
    return 0;
}
_Bool
attr_leaf_getlocal_WC_0(__attribute__ ((__unused__)) lindex_t idx)
{
    return 1;
}
const char*
attr_name_getlocal_WC_0(__attribute__ ((__unused__)) lindex_t idx)
{
    return insn_name(YARVINSN_getlocal_WC_0);
}
rb_num_t
attr_open_getlocal_WC_0(__attribute__ ((__unused__)) lindex_t idx)
{
    return 1;
}
rb_num_t
attr_popn_getlocal_WC_0(__attribute__ ((__unused__)) lindex_t idx)
{
    return 0;
}
rb_num_t
attr_retn_getlocal_WC_0(__attribute__ ((__unused__)) lindex_t idx)
{
    return 1;
}
rb_snum_t
attr_sp_inc_getlocal_WC_0(__attribute__ ((__unused__)) lindex_t idx)
{
    return 1;
}
rb_num_t
attr_width_getlocal_WC_0(__attribute__ ((__unused__)) lindex_t idx)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_getlocal_WC_1(__attribute__ ((__unused__)) lindex_t idx)
{
    return YARVINSN_getlocal_WC_1;
}
_Bool
attr_handles_sp_getlocal_WC_1(__attribute__ ((__unused__)) lindex_t idx)
{
    return 0;
}
_Bool
attr_leaf_getlocal_WC_1(__attribute__ ((__unused__)) lindex_t idx)
{
    return 1;
}
const char*
attr_name_getlocal_WC_1(__attribute__ ((__unused__)) lindex_t idx)
{
    return insn_name(YARVINSN_getlocal_WC_1);
}
rb_num_t
attr_open_getlocal_WC_1(__attribute__ ((__unused__)) lindex_t idx)
{
    return 1;
}
rb_num_t
attr_popn_getlocal_WC_1(__attribute__ ((__unused__)) lindex_t idx)
{
    return 0;
}
rb_num_t
attr_retn_getlocal_WC_1(__attribute__ ((__unused__)) lindex_t idx)
{
    return 1;
}
rb_snum_t
attr_sp_inc_getlocal_WC_1(__attribute__ ((__unused__)) lindex_t idx)
{
    return 1;
}
rb_num_t
attr_width_getlocal_WC_1(__attribute__ ((__unused__)) lindex_t idx)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_setlocal_WC_0(__attribute__ ((__unused__)) lindex_t idx)
{
    return YARVINSN_setlocal_WC_0;
}
_Bool
attr_handles_sp_setlocal_WC_0(__attribute__ ((__unused__)) lindex_t idx)
{
    return 0;
}
_Bool
attr_leaf_setlocal_WC_0(__attribute__ ((__unused__)) lindex_t idx)
{
    return 1;
}
const char*
attr_name_setlocal_WC_0(__attribute__ ((__unused__)) lindex_t idx)
{
    return insn_name(YARVINSN_setlocal_WC_0);
}
rb_num_t
attr_open_setlocal_WC_0(__attribute__ ((__unused__)) lindex_t idx)
{
    return 1;
}
rb_num_t
attr_popn_setlocal_WC_0(__attribute__ ((__unused__)) lindex_t idx)
{
    return 1;
}
rb_num_t
attr_retn_setlocal_WC_0(__attribute__ ((__unused__)) lindex_t idx)
{
    return 0;
}
rb_snum_t
attr_sp_inc_setlocal_WC_0(__attribute__ ((__unused__)) lindex_t idx)
{
    return -1;
}
rb_num_t
attr_width_setlocal_WC_0(__attribute__ ((__unused__)) lindex_t idx)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_setlocal_WC_1(__attribute__ ((__unused__)) lindex_t idx)
{
    return YARVINSN_setlocal_WC_1;
}
_Bool
attr_handles_sp_setlocal_WC_1(__attribute__ ((__unused__)) lindex_t idx)
{
    return 0;
}
_Bool
attr_leaf_setlocal_WC_1(__attribute__ ((__unused__)) lindex_t idx)
{
    return 1;
}
const char*
attr_name_setlocal_WC_1(__attribute__ ((__unused__)) lindex_t idx)
{
    return insn_name(YARVINSN_setlocal_WC_1);
}
rb_num_t
attr_open_setlocal_WC_1(__attribute__ ((__unused__)) lindex_t idx)
{
    return 1;
}
rb_num_t
attr_popn_setlocal_WC_1(__attribute__ ((__unused__)) lindex_t idx)
{
    return 1;
}
rb_num_t
attr_retn_setlocal_WC_1(__attribute__ ((__unused__)) lindex_t idx)
{
    return 0;
}
rb_snum_t
attr_sp_inc_setlocal_WC_1(__attribute__ ((__unused__)) lindex_t idx)
{
    return -1;
}
rb_num_t
attr_width_setlocal_WC_1(__attribute__ ((__unused__)) lindex_t idx)
{
    return 2;
}
enum ruby_vminsn_type
attr_bin_putobject_INT2FIX_0_(void)
{
    return YARVINSN_putobject_INT2FIX_0_;
}
_Bool
attr_handles_sp_putobject_INT2FIX_0_(void)
{
    return 0;
}
_Bool
attr_leaf_putobject_INT2FIX_0_(void)
{
    return 1;
}
const char*
attr_name_putobject_INT2FIX_0_(void)
{
    return insn_name(YARVINSN_putobject_INT2FIX_0_);
}
rb_num_t
attr_open_putobject_INT2FIX_0_(void)
{
    return 0;
}
rb_num_t
attr_popn_putobject_INT2FIX_0_(void)
{
    return 0;
}
rb_num_t
attr_retn_putobject_INT2FIX_0_(void)
{
    return 1;
}
rb_snum_t
attr_sp_inc_putobject_INT2FIX_0_(void)
{
    return 1;
}
rb_num_t
attr_width_putobject_INT2FIX_0_(void)
{
    return 1;
}
enum ruby_vminsn_type
attr_bin_putobject_INT2FIX_1_(void)
{
    return YARVINSN_putobject_INT2FIX_1_;
}
_Bool
attr_handles_sp_putobject_INT2FIX_1_(void)
{
    return 0;
}
_Bool
attr_leaf_putobject_INT2FIX_1_(void)
{
    return 1;
}
const char*
attr_name_putobject_INT2FIX_1_(void)
{
    return insn_name(YARVINSN_putobject_INT2FIX_1_);
}
rb_num_t
attr_open_putobject_INT2FIX_1_(void)
{
    return 0;
}
rb_num_t
attr_popn_putobject_INT2FIX_1_(void)
{
    return 0;
}
rb_num_t
attr_retn_putobject_INT2FIX_1_(void)
{
    return 1;
}
rb_snum_t
attr_sp_inc_putobject_INT2FIX_1_(void)
{
    return 1;
}
rb_num_t
attr_width_putobject_INT2FIX_1_(void)
{
    return 1;
}
__attribute__((__pure__)) __attribute__ ((__unused__)) static int comptime_insn_stack_increase(int depth, int insn, const VALUE *opes);
__attribute__((__pure__)) static rb_snum_t comptime_insn_stack_increase_dispatch(enum ruby_vminsn_type insn, const VALUE *opes);
rb_snum_t
comptime_insn_stack_increase_dispatch(enum ruby_vminsn_type insn, const VALUE *opes)
{
    static const signed char t[] = {
           0, 1, -1, 1, -1, 1, 1, -1,
           1, -1, 1, -1, 1, -1, -2, 1,
          -1, 1, 1, 1, 1, 1, 1, -127,
          -1, -127, 0, -127, -1, 1, 1, -127,
          -1, -1, -127, 0, 0, -127, -1, -1,
           1, -127, 0, -127, -127, -127, -127, 0,
           1, -1, 1, 0, -1, 0, -1, -127,
        -127, -127, 0, 1, 1, 1, 0, 1,
        -127, -127, -127, -127, -127, 0, 0, 0,
          -1, -1, -1, 1, -127, -1, -1, -1,
          -1, -1, -1, -1, -1, -1, -1, -1,
          -1, -1, -1, -1, -2, -1, 0, 0,
           0, 0, 0, 0, -1, -127, 1, 1,
           1, 1, -1, -1, 1, 1, 0, 0,
           0, 0, 0, 0, 0, 0, 0, 0,
           0, 0, 0, 0, 0, 0, 0, 0,
           0, 0, 0, 0, 0, 0, 0, 0,
           0, 0, 0, 0, 0, 0, 0, 0,
           0, 0, 0, 0, 0, 0, 0, 0,
           0, 0, 0, 0, 0, 0, 0, 0,
           0, 0, 0, 0, 0, 0, 0, 0,
           0, 0, 0, 0, 0, 0, 0, 0,
           0, 0, 0, 0, 0, 0, 0, 0,
           0, 0, 0, 0, 0, 0, 0, 0,
           0, 0, 0, 0, 0, 0, 0, 0,
           0, 0, 0, 0, 0, 0, 0, 0,
           0, 0, 0, 0, 0, 0, 0, 0,
           0, 0, 0, 0,
    };
    signed char c = t[insn];
    __extension__ _Static_assert(((int)(sizeof(t) / sizeof((t)[0]))) == VM_INSTRUCTION_SIZE, "numberof_t" ": " "numberof(t) == VM_INSTRUCTION_SIZE");
    if (c != -127) {
        return c;
    }
    else switch(insn) {
    default:
        __builtin_unreachable();
    case YARVINSN_concatstrings:
        return attr_sp_inc_concatstrings(rb_num2long_inline(opes[0]));
    case YARVINSN_toregexp:
        return attr_sp_inc_toregexp(rb_num2long_inline(opes[0]), rb_num2long_inline(opes[1]));
    case YARVINSN_newarray:
        return attr_sp_inc_newarray(rb_num2long_inline(opes[0]));
    case YARVINSN_expandarray:
        return attr_sp_inc_expandarray(rb_num2long_inline(opes[0]), rb_num2long_inline(opes[1]));
    case YARVINSN_pushtoarray:
        return attr_sp_inc_pushtoarray(rb_num2long_inline(opes[0]));
    case YARVINSN_newhash:
        return attr_sp_inc_newhash(rb_num2long_inline(opes[0]));
    case YARVINSN_dupn:
        return attr_sp_inc_dupn(rb_num2long_inline(opes[0]));
    case YARVINSN_opt_reverse:
        return attr_sp_inc_opt_reverse(rb_num2long_inline(opes[0]));
    case YARVINSN_topn:
        return attr_sp_inc_topn(rb_num2long_inline(opes[0]));
    case YARVINSN_setn:
        return attr_sp_inc_setn(rb_num2long_inline(opes[0]));
    case YARVINSN_adjuststack:
        return attr_sp_inc_adjuststack(rb_num2long_inline(opes[0]));
    case YARVINSN_send:
        return attr_comptime_sp_inc_send((CALL_INFO)(opes[0]), (ISEQ)(opes[1]));
    case YARVINSN_sendforward:
        return attr_comptime_sp_inc_sendforward((CALL_INFO)(opes[0]), (ISEQ)(opes[1]));
    case YARVINSN_opt_send_without_block:
        return attr_comptime_sp_inc_opt_send_without_block((CALL_INFO)(opes[0]));
    case YARVINSN_opt_duparray_send:
        return attr_comptime_sp_inc_opt_duparray_send(opes[0], rb_sym2id(opes[1]), rb_num2long_inline(opes[2]));
    case YARVINSN_opt_newarray_send:
        return attr_comptime_sp_inc_opt_newarray_send(rb_num2long_inline(opes[0]), rb_num2long_inline(opes[1]));
    case YARVINSN_invokesuper:
        return attr_comptime_sp_inc_invokesuper((CALL_INFO)(opes[0]), (ISEQ)(opes[1]));
    case YARVINSN_invokesuperforward:
        return attr_comptime_sp_inc_invokesuperforward((CALL_INFO)(opes[0]), (ISEQ)(opes[1]));
    case YARVINSN_invokeblock:
        return attr_comptime_sp_inc_invokeblock((CALL_INFO)(opes[0]));
    case YARVINSN_opt_case_dispatch:
        return attr_sp_inc_opt_case_dispatch((CDHASH)(opes[0]), (OFFSET)(opes[1]));
    case YARVINSN_invokebuiltin:
        return attr_sp_inc_invokebuiltin((RB_BUILTIN)(opes[0]));
    }
}
int
comptime_insn_stack_increase(int depth, int insn, const VALUE *opes)
{
    enum ruby_vminsn_type itype = (enum ruby_vminsn_type)insn;
    return depth + (int)comptime_insn_stack_increase_dispatch(itype, opes);
}
__attribute__((__pure__)) __attribute__ ((__unused__)) static _Bool insn_may_depend_on_sp_or_pc(int insn, const VALUE *opes);
static _Bool
insn_may_depend_on_sp_or_pc(int insn, const VALUE *opes)
{
    switch (insn) {
      case YARVINSN_getspecial:
      case YARVINSN_getinstancevariable:
      case YARVINSN_setinstancevariable:
      case YARVINSN_getclassvariable:
      case YARVINSN_setclassvariable:
      case YARVINSN_opt_getconstant_path:
      case YARVINSN_getconstant:
      case YARVINSN_setconstant:
      case YARVINSN_getglobal:
      case YARVINSN_setglobal:
      case YARVINSN_putspecialobject:
      case YARVINSN_concatstrings:
      case YARVINSN_toregexp:
      case YARVINSN_expandarray:
      case YARVINSN_concatarray:
      case YARVINSN_concattoarray:
      case YARVINSN_splatarray:
      case YARVINSN_splatkw:
      case YARVINSN_newhash:
      case YARVINSN_newrange:
      case YARVINSN_defined:
      case YARVINSN_definedivar:
      case YARVINSN_checkmatch:
      case YARVINSN_defineclass:
      case YARVINSN_definemethod:
      case YARVINSN_definesmethod:
      case YARVINSN_send:
      case YARVINSN_sendforward:
      case YARVINSN_opt_send_without_block:
      case YARVINSN_objtostring:
      case YARVINSN_opt_duparray_send:
      case YARVINSN_opt_newarray_send:
      case YARVINSN_invokesuper:
      case YARVINSN_invokesuperforward:
      case YARVINSN_invokeblock:
      case YARVINSN_leave:
      case YARVINSN_throw:
      case YARVINSN_jump:
      case YARVINSN_branchif:
      case YARVINSN_branchunless:
      case YARVINSN_branchnil:
      case YARVINSN_once:
      case YARVINSN_opt_div:
      case YARVINSN_opt_mod:
      case YARVINSN_opt_ltlt:
      case YARVINSN_opt_aref:
      case YARVINSN_opt_aset:
      case YARVINSN_opt_aset_with:
      case YARVINSN_opt_aref_with:
      case YARVINSN_opt_regexpmatch2:
      case YARVINSN_invokebuiltin:
      case YARVINSN_opt_invokebuiltin_delegate:
      case YARVINSN_opt_invokebuiltin_delegate_leave:
      case YARVINSN_trace_nop:
      case YARVINSN_trace_getlocal:
      case YARVINSN_trace_setlocal:
      case YARVINSN_trace_getblockparam:
      case YARVINSN_trace_setblockparam:
      case YARVINSN_trace_getblockparamproxy:
      case YARVINSN_trace_getspecial:
      case YARVINSN_trace_setspecial:
      case YARVINSN_trace_getinstancevariable:
      case YARVINSN_trace_setinstancevariable:
      case YARVINSN_trace_getclassvariable:
      case YARVINSN_trace_setclassvariable:
      case YARVINSN_trace_opt_getconstant_path:
      case YARVINSN_trace_getconstant:
      case YARVINSN_trace_setconstant:
      case YARVINSN_trace_getglobal:
      case YARVINSN_trace_setglobal:
      case YARVINSN_trace_putnil:
      case YARVINSN_trace_putself:
      case YARVINSN_trace_putobject:
      case YARVINSN_trace_putspecialobject:
      case YARVINSN_trace_putstring:
      case YARVINSN_trace_putchilledstring:
      case YARVINSN_trace_concatstrings:
      case YARVINSN_trace_anytostring:
      case YARVINSN_trace_toregexp:
      case YARVINSN_trace_intern:
      case YARVINSN_trace_newarray:
      case YARVINSN_trace_pushtoarraykwsplat:
      case YARVINSN_trace_duparray:
      case YARVINSN_trace_duphash:
      case YARVINSN_trace_expandarray:
      case YARVINSN_trace_concatarray:
      case YARVINSN_trace_concattoarray:
      case YARVINSN_trace_pushtoarray:
      case YARVINSN_trace_splatarray:
      case YARVINSN_trace_splatkw:
      case YARVINSN_trace_newhash:
      case YARVINSN_trace_newrange:
      case YARVINSN_trace_pop:
      case YARVINSN_trace_dup:
      case YARVINSN_trace_dupn:
      case YARVINSN_trace_swap:
      case YARVINSN_trace_opt_reverse:
      case YARVINSN_trace_topn:
      case YARVINSN_trace_setn:
      case YARVINSN_trace_adjuststack:
      case YARVINSN_trace_defined:
      case YARVINSN_trace_definedivar:
      case YARVINSN_trace_checkmatch:
      case YARVINSN_trace_checkkeyword:
      case YARVINSN_trace_checktype:
      case YARVINSN_trace_defineclass:
      case YARVINSN_trace_definemethod:
      case YARVINSN_trace_definesmethod:
      case YARVINSN_trace_send:
      case YARVINSN_trace_sendforward:
      case YARVINSN_trace_opt_send_without_block:
      case YARVINSN_trace_objtostring:
      case YARVINSN_trace_opt_ary_freeze:
      case YARVINSN_trace_opt_hash_freeze:
      case YARVINSN_trace_opt_str_freeze:
      case YARVINSN_trace_opt_nil_p:
      case YARVINSN_trace_opt_str_uminus:
      case YARVINSN_trace_opt_duparray_send:
      case YARVINSN_trace_opt_newarray_send:
      case YARVINSN_trace_invokesuper:
      case YARVINSN_trace_invokesuperforward:
      case YARVINSN_trace_invokeblock:
      case YARVINSN_trace_leave:
      case YARVINSN_trace_throw:
      case YARVINSN_trace_jump:
      case YARVINSN_trace_branchif:
      case YARVINSN_trace_branchunless:
      case YARVINSN_trace_branchnil:
      case YARVINSN_trace_once:
      case YARVINSN_trace_opt_case_dispatch:
      case YARVINSN_trace_opt_plus:
      case YARVINSN_trace_opt_minus:
      case YARVINSN_trace_opt_mult:
      case YARVINSN_trace_opt_div:
      case YARVINSN_trace_opt_mod:
      case YARVINSN_trace_opt_eq:
      case YARVINSN_trace_opt_neq:
      case YARVINSN_trace_opt_lt:
      case YARVINSN_trace_opt_le:
      case YARVINSN_trace_opt_gt:
      case YARVINSN_trace_opt_ge:
      case YARVINSN_trace_opt_ltlt:
      case YARVINSN_trace_opt_and:
      case YARVINSN_trace_opt_or:
      case YARVINSN_trace_opt_aref:
      case YARVINSN_trace_opt_aset:
      case YARVINSN_trace_opt_aset_with:
      case YARVINSN_trace_opt_aref_with:
      case YARVINSN_trace_opt_length:
      case YARVINSN_trace_opt_size:
      case YARVINSN_trace_opt_empty_p:
      case YARVINSN_trace_opt_succ:
      case YARVINSN_trace_opt_not:
      case YARVINSN_trace_opt_regexpmatch2:
      case YARVINSN_trace_invokebuiltin:
      case YARVINSN_trace_opt_invokebuiltin_delegate:
      case YARVINSN_trace_opt_invokebuiltin_delegate_leave:
      case YARVINSN_trace_getlocal_WC_0:
      case YARVINSN_trace_getlocal_WC_1:
      case YARVINSN_trace_setlocal_WC_0:
      case YARVINSN_trace_setlocal_WC_1:
      case YARVINSN_trace_putobject_INT2FIX_0_:
      case YARVINSN_trace_putobject_INT2FIX_1_:
        return 1;
      default:
        return 0;
    }
}
typedef struct iseq_link_element {
    enum {
        ISEQ_ELEMENT_ANCHOR,
        ISEQ_ELEMENT_LABEL,
        ISEQ_ELEMENT_INSN,
        ISEQ_ELEMENT_ADJUST,
        ISEQ_ELEMENT_TRACE,
    } type;
    struct iseq_link_element *next;
    struct iseq_link_element *prev;
} LINK_ELEMENT;
typedef struct iseq_link_anchor {
    LINK_ELEMENT anchor;
    LINK_ELEMENT *last;
} LINK_ANCHOR;
typedef enum {
    LABEL_RESCUE_NONE,
    LABEL_RESCUE_BEG,
    LABEL_RESCUE_END,
    LABEL_RESCUE_TYPE_MAX
} LABEL_RESCUE_TYPE;
typedef struct iseq_label_data {
    LINK_ELEMENT link;
    int label_no;
    int position;
    int sc_state;
    int sp;
    int refcnt;
    unsigned int set: 1;
    unsigned int rescued: 2;
    unsigned int unremovable: 1;
} LABEL;
typedef struct iseq_insn_data {
    LINK_ELEMENT link;
    enum ruby_vminsn_type insn_id;
    int operand_size;
    int sc_state;
    VALUE *operands;
    struct {
        int line_no;
        int node_id;
        rb_event_flag_t events;
    } insn_info;
} INSN;
typedef struct iseq_adjust_data {
    LINK_ELEMENT link;
    LABEL *label;
    int line_no;
} ADJUST;
typedef struct iseq_trace_data {
    LINK_ELEMENT link;
    rb_event_flag_t event;
    long data;
} TRACE;
struct ensure_range {
    LABEL *begin;
    LABEL *end;
    struct ensure_range *next;
};
struct iseq_compile_data_ensure_node_stack {
    const void *ensure_node;
    struct iseq_compile_data_ensure_node_stack *prev;
    struct ensure_range *erange;
};
const ID rb_iseq_shared_exc_local_tbl[] = {idERROR_INFO};
static void iseq_add_getlocal(rb_iseq_t *iseq, LINK_ANCHOR *const seq, const NODE *const line_node, int idx, int level);
static void iseq_add_setlocal(rb_iseq_t *iseq, LINK_ANCHOR *const seq, const NODE *const line_node, int idx, int level);
__attribute__((__format__(__printf__, 3, 4)))
static void
append_compile_error(const rb_iseq_t *iseq, int line, const char *fmt, ...)
{
    VALUE err_info = ISEQ_COMPILE_DATA(iseq)->err_info;
    VALUE file = rb_iseq_path(iseq);
    VALUE err = err_info == ((VALUE)RUBY_Qtrue) ? ((VALUE)RUBY_Qfalse) : err_info;
    va_list args;
    __builtin_va_start(args,fmt);
    err = rb_syntax_error_append(err, file, line, -1, ((void *)0), fmt, args);
    __builtin_va_end(args);
    if (RB_NIL_P(err_info)) {
        (rb_obj_write((VALUE)(iseq), (VALUE *)(&ISEQ_COMPILE_DATA(iseq)->err_info), (VALUE)(err), "compile.c", 376));
        rb_set_errinfo(err);
    }
    else if (!err_info) {
        (rb_obj_write((VALUE)(iseq), (VALUE *)(&ISEQ_COMPILE_DATA(iseq)->err_info), (VALUE)(((VALUE)RUBY_Qtrue)), "compile.c", 380));
    }
    if (0) {
        if (RB_SPECIAL_CONST_P(err)) err = rb_eSyntaxError;
        rb_exc_fatal(err);
    }
}
static inline VALUE
freeze_hide_obj(VALUE obj)
{
    rb_obj_freeze_inline(obj);
    RBASIC_CLEAR_CLASS(obj);
    return obj;
}
static INSN *
insn_operands_unification(INSN *iobj)
{
    VALUE *op = iobj->operands;
    switch (iobj->insn_id) {
    default:
                        ;
        break;
    case YARVINSN_getlocal:
        if ( op[1] == rb_long2num_inline(0) ) {
            iobj->insn_id = YARVINSN_getlocal_WC_0;
            iobj->operand_size = 1;
            break;
        }
        if ( op[1] == rb_long2num_inline(1) ) {
            iobj->insn_id = YARVINSN_getlocal_WC_1;
            iobj->operand_size = 1;
            break;
        }
        break;
    case YARVINSN_setlocal:
        if ( op[1] == rb_long2num_inline(0) ) {
            iobj->insn_id = YARVINSN_setlocal_WC_0;
            iobj->operand_size = 1;
            break;
        }
        if ( op[1] == rb_long2num_inline(1) ) {
            iobj->insn_id = YARVINSN_setlocal_WC_1;
            iobj->operand_size = 1;
            break;
        }
        break;
    case YARVINSN_putobject:
        if ( op[0] == __builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)) ) {
            iobj->insn_id = YARVINSN_putobject_INT2FIX_0_;
            iobj->operand_size = 0;
            break;
        }
        if ( op[0] == __builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)) ) {
            iobj->insn_id = YARVINSN_putobject_INT2FIX_1_;
            iobj->operand_size = 0;
            break;
        }
        break;
    }
    return iobj;
}
int
rb_insn_unified_local_var_level(VALUE insn)
{
    switch (insn) {
      default:
        return -1; ;
      case YARVINSN_getlocal_WC_0:
        return 0;
      case YARVINSN_getlocal_WC_1:
        return 1;
      case YARVINSN_setlocal_WC_0:
        return 0;
      case YARVINSN_setlocal_WC_1:
        return 1;
      case YARVINSN_putobject_INT2FIX_0_:
        return __builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0));
      case YARVINSN_putobject_INT2FIX_1_:
        return __builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1));
    }
    return -1;
}
static void dump_disasm_list_with_cursor(const LINK_ELEMENT *link, const LINK_ELEMENT *curr, const LABEL *dest);
static void dump_disasm_list(const LINK_ELEMENT *elem);
static int insn_data_length(INSN *iobj);
static int calc_sp_depth(int depth, INSN *iobj);
static INSN *new_insn_body(rb_iseq_t *iseq, int line_no, int node_id, enum ruby_vminsn_type insn_id, int argc, ...);
static LABEL *new_label_body(rb_iseq_t *iseq, long line);
static ADJUST *new_adjust_body(rb_iseq_t *iseq, LABEL *label, int line);
static TRACE *new_trace_body(rb_iseq_t *iseq, rb_event_flag_t event, long data);
static int iseq_compile_each(rb_iseq_t *iseq, LINK_ANCHOR *anchor, const NODE *n, int);
static int iseq_setup(rb_iseq_t *iseq, LINK_ANCHOR *const anchor);
static int iseq_setup_insn(rb_iseq_t *iseq, LINK_ANCHOR *const anchor);
static int iseq_optimize(rb_iseq_t *iseq, LINK_ANCHOR *const anchor);
static int iseq_insns_unification(rb_iseq_t *iseq, LINK_ANCHOR *const anchor);
static int iseq_set_local_table(rb_iseq_t *iseq, const rb_ast_id_table_t *tbl, const NODE *const node_args);
static int iseq_set_exception_local_table(rb_iseq_t *iseq);
static int iseq_set_arguments(rb_iseq_t *iseq, LINK_ANCHOR *const anchor, const NODE *const node);
static int iseq_set_sequence(rb_iseq_t *iseq, LINK_ANCHOR *const anchor);
static int iseq_set_exception_table(rb_iseq_t *iseq);
static int iseq_set_optargs_table(rb_iseq_t *iseq);
static int compile_defined_expr(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, VALUE needstr, _Bool ignore);
static int compile_hash(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *node, int method_call_keywords, int popped);
static void
verify_list( const char *info, LINK_ANCHOR *const anchor)
{
}
static void
verify_call_cache(rb_iseq_t *iseq)
{
}
static void
ADD_ELEM( LINK_ANCHOR *const anchor, LINK_ELEMENT *elem)
{
    elem->prev = anchor->last;
    anchor->last->next = elem;
    anchor->last = elem;
    verify_list("add", anchor);
}
static void
APPEND_ELEM( LINK_ANCHOR *const anchor, LINK_ELEMENT *before, LINK_ELEMENT *elem)
{
    elem->prev = before;
    elem->next = before->next;
    elem->next->prev = elem;
    before->next = elem;
    if (before == anchor->last) anchor->last = elem;
    verify_list("add", anchor);
}
static int
branch_coverage_valid_p(rb_iseq_t *iseq, int first_line)
{
    if (!((iseq)->body)->variable.coverage) return 0;
    if (!RARRAY_AREF(((iseq)->body)->variable.coverage, 1)) return 0;
    if (first_line <= 0) return 0;
    return 1;
}
static VALUE
setup_branch(const rb_code_location_t *loc, const char *type, VALUE structure, VALUE key)
{
    const int first_lineno = loc->beg_pos.lineno, first_column = loc->beg_pos.column;
    const int last_lineno = loc->end_pos.lineno, last_column = loc->end_pos.column;
    VALUE branch = rb_ary_hidden_new(6);
    rb_hash_aset(structure, key, branch);
    rb_ary_push(branch, rb_id2sym((__builtin_constant_p(type) ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, (type)); }) : (rb_intern)(type))));
    rb_ary_push(branch, __builtin_choose_expr( __builtin_constant_p(first_lineno), ((VALUE)(first_lineno)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(first_lineno)));
    rb_ary_push(branch, __builtin_choose_expr( __builtin_constant_p(first_column), ((VALUE)(first_column)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(first_column)));
    rb_ary_push(branch, __builtin_choose_expr( __builtin_constant_p(last_lineno), ((VALUE)(last_lineno)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(last_lineno)));
    rb_ary_push(branch, __builtin_choose_expr( __builtin_constant_p(last_column), ((VALUE)(last_column)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(last_column)));
    return branch;
}
static VALUE
decl_branch_base(rb_iseq_t *iseq, VALUE key, const rb_code_location_t *loc, const char *type)
{
    if (!branch_coverage_valid_p(iseq, loc->beg_pos.lineno)) return ((VALUE)RUBY_Qundef);
    VALUE structure = RARRAY_AREF(RARRAY_AREF(((iseq)->body)->variable.coverage, 1), 0);
    VALUE branch_base = rb_hash_aref(structure, key);
    VALUE branches;
    if (RB_NIL_P(branch_base)) {
        branch_base = setup_branch(loc, type, structure, key);
        branches = rb_hash_new();
        rb_obj_hide(branches);
        rb_ary_push(branch_base, branches);
    }
    else {
        branches = RARRAY_AREF(branch_base, 5);
    }
    return branches;
}
static NODE
generate_dummy_line_node(int lineno, int node_id)
{
    NODE dummy = { 0 };
    (&dummy)->flags=(((&dummy)->flags&~((VALUE)(-1)<<(8 +7)))|((VALUE)((lineno)&(((long)1<<(sizeof(VALUE)*8 -(8 +7)))-1))<<(8 +7)));
    (((NODE *)(&dummy))->node_id = (node_id));
    return dummy;
}
static void
add_trace_branch_coverage(rb_iseq_t *iseq, LINK_ANCHOR *const seq, const rb_code_location_t *loc, int node_id, int branch_id, const char *type, VALUE branches)
{
    if (!branch_coverage_valid_p(iseq, loc->beg_pos.lineno)) return;
    VALUE key = __builtin_choose_expr( __builtin_constant_p(branch_id), ((VALUE)(branch_id)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(branch_id));
    VALUE branch = rb_hash_aref(branches, key);
    long counter_idx;
    if (RB_NIL_P(branch)) {
        branch = setup_branch(loc, type, branches, key);
        VALUE counters = RARRAY_AREF(RARRAY_AREF(((iseq)->body)->variable.coverage, 1), 1);
        counter_idx = rb_array_len(counters);
        rb_ary_push(branch, RB_INT2FIX(counter_idx));
        rb_ary_push(counters, __builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)));
    }
    else {
        counter_idx = rb_fix2long(RARRAY_AREF(branch, 5));
    }
    ADD_ELEM((seq), (LINK_ELEMENT *)new_trace_body(iseq, (0x020000), (counter_idx)));
    ADD_ELEM((seq), (LINK_ELEMENT *) new_insn_body(iseq, (loc->end_pos.lineno), (node_id), YARVINSN_nop, 0));
}
static int
validate_label(st_data_t name, st_data_t label, st_data_t arg)
{
    rb_iseq_t *iseq = (rb_iseq_t *)arg;
    LABEL *lobj = (LABEL *)label;
    if (!lobj->link.next) {
        do {
            append_compile_error(iseq, lobj->position,
                          "%""l""i" "\v"": undefined label",
                          rb_sym2str((VALUE)name));
        } while (0);
    }
    return ST_CONTINUE;
}
static void
validate_labels(rb_iseq_t *iseq, st_table *labels_table)
{
    rb_st_foreach(labels_table, validate_label, (st_data_t)iseq);
    rb_st_free_table(labels_table);
}
static NODE *
get_nd_recv(const NODE *node)
{
    switch (((int) ((((NODE *)(node))->flags & (((VALUE)0x7f)<<8))>>8))) {
      case NODE_CALL:
        return ((rb_node_call_t *)(node))->nd_recv;
      case NODE_OPCALL:
        return ((rb_node_opcall_t *)(node))->nd_recv;
      case NODE_FCALL:
        return 0;
      case NODE_QCALL:
        return ((rb_node_qcall_t *)(node))->nd_recv;
      case NODE_VCALL:
        return 0;
      case NODE_ATTRASGN:
        return ((rb_node_attrasgn_t *)(node))->nd_recv;
      case NODE_OP_ASGN1:
        return ((rb_node_op_asgn1_t *)(node))->nd_recv;
      case NODE_OP_ASGN2:
        return ((rb_node_op_asgn2_t *)(node))->nd_recv;
      default:
        rb_bug("unexpected node: %s", ruby_node_name(((int) ((((NODE *)(node))->flags & (((VALUE)0x7f)<<8))>>8))));
    }
}
static ID
get_node_call_nd_mid(const NODE *node)
{
    switch (((int) ((((NODE *)(node))->flags & (((VALUE)0x7f)<<8))>>8))) {
      case NODE_CALL:
        return ((rb_node_call_t *)(node))->nd_mid;
      case NODE_OPCALL:
        return ((rb_node_opcall_t *)(node))->nd_mid;
      case NODE_FCALL:
        return ((rb_node_fcall_t *)(node))->nd_mid;
      case NODE_QCALL:
        return ((rb_node_qcall_t *)(node))->nd_mid;
      case NODE_VCALL:
        return ((rb_node_vcall_t *)(node))->nd_mid;
      case NODE_ATTRASGN:
        return ((rb_node_attrasgn_t *)(node))->nd_mid;
      default:
        rb_bug("unexpected node: %s", ruby_node_name(((int) ((((NODE *)(node))->flags & (((VALUE)0x7f)<<8))>>8))));
    }
}
static NODE *
get_nd_args(const NODE *node)
{
    switch (((int) ((((NODE *)(node))->flags & (((VALUE)0x7f)<<8))>>8))) {
      case NODE_CALL:
        return ((rb_node_call_t *)(node))->nd_args;
      case NODE_OPCALL:
        return ((rb_node_opcall_t *)(node))->nd_args;
      case NODE_FCALL:
        return ((rb_node_fcall_t *)(node))->nd_args;
      case NODE_QCALL:
        return ((rb_node_qcall_t *)(node))->nd_args;
      case NODE_VCALL:
        return 0;
      case NODE_ATTRASGN:
        return ((rb_node_attrasgn_t *)(node))->nd_args;
      default:
        rb_bug("unexpected node: %s", ruby_node_name(((int) ((((NODE *)(node))->flags & (((VALUE)0x7f)<<8))>>8))));
    }
}
static ID
get_node_colon_nd_mid(const NODE *node)
{
    switch (((int) ((((NODE *)(node))->flags & (((VALUE)0x7f)<<8))>>8))) {
      case NODE_COLON2:
        return ((rb_node_colon2_t *)(node))->nd_mid;
      case NODE_COLON3:
        return ((rb_node_colon3_t *)(node))->nd_mid;
      default:
        rb_bug("unexpected node: %s", ruby_node_name(((int) ((((NODE *)(node))->flags & (((VALUE)0x7f)<<8))>>8))));
    }
}
static ID
get_nd_vid(const NODE *node)
{
    switch (((int) ((((NODE *)(node))->flags & (((VALUE)0x7f)<<8))>>8))) {
      case NODE_LASGN:
        return ((rb_node_lasgn_t *)(node))->nd_vid;
      case NODE_DASGN:
        return ((rb_node_dasgn_t *)(node))->nd_vid;
      case NODE_IASGN:
        return ((rb_node_iasgn_t *)(node))->nd_vid;
      case NODE_CVASGN:
        return ((rb_node_cvasgn_t *)(node))->nd_vid;
      default:
        rb_bug("unexpected node: %s", ruby_node_name(((int) ((((NODE *)(node))->flags & (((VALUE)0x7f)<<8))>>8))));
    }
}
static NODE *
get_nd_value(const NODE *node)
{
    switch (((int) ((((NODE *)(node))->flags & (((VALUE)0x7f)<<8))>>8))) {
      case NODE_LASGN:
        return ((rb_node_lasgn_t *)(node))->nd_value;
      case NODE_DASGN:
        return ((rb_node_dasgn_t *)(node))->nd_value;
      default:
        rb_bug("unexpected node: %s", ruby_node_name(((int) ((((NODE *)(node))->flags & (((VALUE)0x7f)<<8))>>8))));
    }
}
static VALUE
get_string_value(const NODE *node)
{
    switch (((int) ((((NODE *)(node))->flags & (((VALUE)0x7f)<<8))>>8))) {
      case NODE_STR:
        return rb_node_str_string_val(node);
      case NODE_FILE:
        return rb_node_file_path_val(node);
      default:
        rb_bug("unexpected node: %s", ruby_node_name(((int) ((((NODE *)(node))->flags & (((VALUE)0x7f)<<8))>>8))));
    }
}
VALUE
rb_iseq_compile_callback(rb_iseq_t *iseq, const struct rb_iseq_new_with_callback_callback_func * ifunc)
{
    LINK_ANCHOR ret[1] = {{{ISEQ_ELEMENT_ANCHOR,},&ret[0].anchor}};
    ((ret->last = &ret->anchor)->next = ((void *)0));
    (*ifunc->func)(iseq, ret, ifunc->data);
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (ISEQ_COMPILE_DATA(iseq)->last_line), (-1), YARVINSN_leave, 0));
    if (!(iseq_setup_insn(iseq, ret))) {;return 0;};
    return iseq_setup(iseq, ret);
}
static _Bool drop_unreachable_return(LINK_ANCHOR *ret);
VALUE
rb_iseq_compile_node(rb_iseq_t *iseq, const NODE *node)
{
    LINK_ANCHOR ret[1] = {{{ISEQ_ELEMENT_ANCHOR,},&ret[0].anchor}};
    ((ret->last = &ret->anchor)->next = ((void *)0));
    if (node == 0) {
        (void)(((iseq_compile_each(iseq, (ret), (node), 0))));
        iseq_set_local_table(iseq, 0, 0);
    }
    else if (nd_type_p(node, NODE_SCOPE)) {
        iseq_set_local_table(iseq, ((rb_node_scope_t *)(node))->nd_tbl, (NODE *)((rb_node_scope_t *)(node))->nd_args);
        iseq_set_arguments(iseq, ret, (NODE *)((rb_node_scope_t *)(node))->nd_args);
        switch (((iseq)->body)->type) {
          case ISEQ_TYPE_BLOCK:
            {
                LABEL *start = ISEQ_COMPILE_DATA(iseq)->start_label = new_label_body(iseq, (0));
                LABEL *end = ISEQ_COMPILE_DATA(iseq)->end_label = new_label_body(iseq, (0));
                start->rescued = LABEL_RESCUE_BEG;
                end->rescued = LABEL_RESCUE_END;
                ADD_ELEM((ret), (LINK_ELEMENT *)new_trace_body(iseq, (0x0100), 0));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (((iseq)->body)->location.first_lineno), (-1), YARVINSN_nop, 0));
                ADD_ELEM((ret), (LINK_ELEMENT *) (start));
                if (!(((iseq_compile_each(iseq, (ret), (((rb_node_scope_t *)(node))->nd_body), 0))))) {;return 0;};
                ADD_ELEM((ret), (LINK_ELEMENT *) (end));
                ADD_ELEM((ret), (LINK_ELEMENT *)new_trace_body(iseq, (0x0200), 0));
                ISEQ_COMPILE_DATA(iseq)->last_line = ((iseq)->body)->location.code_location.end_pos.lineno;
                do { VALUE _e = __extension__ ({ const VALUE args_to_new_ary[] = {(CATCH_TYPE_REDO), (VALUE)(start) | 1, (VALUE)(end) | 1, (VALUE)(((void *)0)), (VALUE)(start) | 1}; if (__builtin_constant_p(5)) { __extension__ _Static_assert(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))) == (5), "rb_ary_new_from_args" ": " "numberof(args_to_new_ary) == (5)"); } rb_ary_new_from_values(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))), args_to_new_ary); }); ((start) ? (((start)->refcnt++), (start)->unremovable=1) : 0); ((end)->refcnt++); ((start)->refcnt++); if (RB_NIL_P(ISEQ_COMPILE_DATA(iseq)->catch_table_ary)) (rb_obj_write((VALUE)(iseq), (VALUE *)(&ISEQ_COMPILE_DATA(iseq)->catch_table_ary), (VALUE)(rb_ary_hidden_new(3)), "compile.c", 896)); rb_ary_push(ISEQ_COMPILE_DATA(iseq)->catch_table_ary, freeze_hide_obj(_e)); } while (0);
                do { VALUE _e = __extension__ ({ const VALUE args_to_new_ary[] = {(CATCH_TYPE_NEXT), (VALUE)(start) | 1, (VALUE)(end) | 1, (VALUE)(((void *)0)), (VALUE)(end) | 1}; if (__builtin_constant_p(5)) { __extension__ _Static_assert(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))) == (5), "rb_ary_new_from_args" ": " "numberof(args_to_new_ary) == (5)"); } rb_ary_new_from_values(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))), args_to_new_ary); }); ((start) ? (((start)->refcnt++), (start)->unremovable=1) : 0); ((end)->refcnt++); ((end)->refcnt++); if (RB_NIL_P(ISEQ_COMPILE_DATA(iseq)->catch_table_ary)) (rb_obj_write((VALUE)(iseq), (VALUE *)(&ISEQ_COMPILE_DATA(iseq)->catch_table_ary), (VALUE)(rb_ary_hidden_new(3)), "compile.c", 897)); rb_ary_push(ISEQ_COMPILE_DATA(iseq)->catch_table_ary, freeze_hide_obj(_e)); } while (0);
                break;
            }
          case ISEQ_TYPE_CLASS:
            {
                ADD_ELEM((ret), (LINK_ELEMENT *)new_trace_body(iseq, (0x0002), 0));
                if (!(((iseq_compile_each(iseq, (ret), (((rb_node_scope_t *)(node))->nd_body), 0))))) {;return 0;};
                ADD_ELEM((ret), (LINK_ELEMENT *)new_trace_body(iseq, (0x0004), 0));
                ISEQ_COMPILE_DATA(iseq)->last_line = (int)(((long)(node)->flags)>>(8 +7));
                break;
            }
          case ISEQ_TYPE_METHOD:
            {
                ISEQ_COMPILE_DATA(iseq)->root_node = ((rb_node_scope_t *)(node))->nd_body;
                ADD_ELEM((ret), (LINK_ELEMENT *)new_trace_body(iseq, (0x0008), 0));
                if (!(((iseq_compile_each(iseq, (ret), (((rb_node_scope_t *)(node))->nd_body), 0))))) {;return 0;};
                ISEQ_COMPILE_DATA(iseq)->root_node = ((rb_node_scope_t *)(node))->nd_body;
                ADD_ELEM((ret), (LINK_ELEMENT *)new_trace_body(iseq, (0x0010), 0));
                ISEQ_COMPILE_DATA(iseq)->last_line = (int)(((long)(node)->flags)>>(8 +7));
                break;
            }
          default: {
            if (!(((iseq_compile_each(iseq, (ret), (((rb_node_scope_t *)(node))->nd_body), 0))))) {;return 0;};
            break;
          }
        }
    }
    else {
        const char *m;
        switch (((iseq)->body)->type) {
          case ISEQ_TYPE_METHOD: m = "METHOD"; goto invalid_iseq_type;
          case ISEQ_TYPE_CLASS: m = "CLASS"; goto invalid_iseq_type;
          case ISEQ_TYPE_BLOCK: m = "BLOCK"; goto invalid_iseq_type;
          case ISEQ_TYPE_EVAL: m = "EVAL"; goto invalid_iseq_type;
          case ISEQ_TYPE_MAIN: m = "MAIN"; goto invalid_iseq_type;
          case ISEQ_TYPE_TOP: m = "TOP"; goto invalid_iseq_type;
          case ISEQ_TYPE_RESCUE:
            iseq_set_exception_local_table(iseq);
            if (!(((iseq_compile_each(iseq, (ret), (node), 0))))) {;return 0;};
            break;
          case ISEQ_TYPE_ENSURE:
            iseq_set_exception_local_table(iseq);
            if (!(((iseq_compile_each(iseq, (ret), (node), 1))))) {;return 0;};
            break;
          case ISEQ_TYPE_PLAIN:
            if (!(((iseq_compile_each(iseq, (ret), (node), 0))))) {;return 0;};
            break;
          default:
            append_compile_error(iseq, (int)(((long)(node)->flags)>>(8 +7)), "unknown scope: %d", ((iseq)->body)->type);
            return 0;
          invalid_iseq_type:
            append_compile_error(iseq, (int)(((long)(node)->flags)>>(8 +7)), "compile/ISEQ_TYPE_%s should not be reached", m);
            return 0;
        }
    }
    if (((iseq)->body)->type == ISEQ_TYPE_RESCUE || ((iseq)->body)->type == ISEQ_TYPE_ENSURE) {
        NODE dummy_line_node = generate_dummy_line_node(0, -1);
        iseq_add_getlocal(iseq, (ret), (&dummy_line_node), ((1)), (0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(&dummy_line_node)->flags)>>(8 +7)), (((NODE *)(&dummy_line_node))->node_id), YARVINSN_throw, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))));
    }
    else if (!drop_unreachable_return(ret)) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (ISEQ_COMPILE_DATA(iseq)->last_line), (-1), YARVINSN_leave, 0));
    }
    if (!(iseq_setup_insn(iseq, ret))) {;return 0;};
    return iseq_setup(iseq, ret);
}
static int
rb_iseq_translate_threaded_code(rb_iseq_t *iseq)
{
    const void * const *table = rb_vm_get_insns_address_table();
    unsigned int i;
    VALUE *encoded = (VALUE *)((iseq)->body)->iseq_encoded;
    for (i = 0; i < ((iseq)->body)->iseq_size; ) {
        int insn = (int)((iseq)->body)->iseq_encoded[i];
        int len = insn_len(insn);
        encoded[i] = (VALUE)table[insn];
        i += len;
    }
    RB_FL_SET((VALUE)iseq, ((VALUE)RUBY_FL_USER7));
    rb_yjit_live_iseq_count++;
    rb_yjit_iseq_alloc_count++;
    return 1;
}
VALUE *
rb_iseq_original_iseq(const rb_iseq_t *iseq)
{
    VALUE *original_code;
    if (ISEQ_ORIGINAL_ISEQ(iseq)) return ISEQ_ORIGINAL_ISEQ(iseq);
    original_code = ISEQ_ORIGINAL_ISEQ_ALLOC(iseq, ((iseq)->body)->iseq_size);
    ruby_nonempty_memcpy((original_code), (((iseq)->body)->iseq_encoded), rbimpl_size_mul_or_raise(sizeof(VALUE), (((iseq)->body)->iseq_size)));
    {
        unsigned int i;
        for (i = 0; i < ((iseq)->body)->iseq_size; ) {
            const void *addr = (const void *)original_code[i];
            const int insn = rb_vm_insn_addr2insn(addr);
            original_code[i] = insn;
            i += insn_len(insn);
        }
    }
    return original_code;
}
static void *
compile_data_alloc_with_arena(struct iseq_compile_data_storage **arena, size_t size)
{
    void *ptr = 0;
    struct iseq_compile_data_storage *storage = *arena;
    const size_t padding = 0;
    if (size >= 0x7fffffff - padding) rb_memerror();
    if (storage->pos + size + padding > storage->size) {
        unsigned int alloc_size = storage->size;
        while (alloc_size < size + 0) {
            if (alloc_size >= 0x7fffffff / 2) rb_memerror();
            alloc_size *= 2;
        }
        storage->next = (void *)((char *)ruby_xmalloc2((alloc_size + __builtin_offsetof (struct iseq_compile_data_storage, buff)), sizeof(char)));
        storage = *arena = storage->next;
        storage->next = 0;
        storage->pos = 0;
        storage->size = alloc_size;
    }
    ptr = (void *)&storage->buff[storage->pos];
    storage->pos += (int)size;
    return ptr;
}
static void *
compile_data_alloc(rb_iseq_t *iseq, size_t size)
{
    struct iseq_compile_data_storage ** arena = &ISEQ_COMPILE_DATA(iseq)->node.storage_current;
    return compile_data_alloc_with_arena(arena, size);
}
static inline void *
compile_data_alloc2(rb_iseq_t *iseq, size_t x, size_t y)
{
    size_t size = rb_size_mul_or_raise(x, y, rb_eRuntimeError);
    return compile_data_alloc(iseq, size);
}
static inline void *
compile_data_calloc2(rb_iseq_t *iseq, size_t x, size_t y)
{
    size_t size = rb_size_mul_or_raise(x, y, rb_eRuntimeError);
    void *p = compile_data_alloc(iseq, size);
    memset(p, 0, size);
    return p;
}
static INSN *
compile_data_alloc_insn(rb_iseq_t *iseq)
{
    struct iseq_compile_data_storage ** arena = &ISEQ_COMPILE_DATA(iseq)->insn.storage_current;
    return (INSN *)compile_data_alloc_with_arena(arena, sizeof(INSN));
}
static LABEL *
compile_data_alloc_label(rb_iseq_t *iseq)
{
    return (LABEL *)compile_data_alloc(iseq, sizeof(LABEL));
}
static ADJUST *
compile_data_alloc_adjust(rb_iseq_t *iseq)
{
    return (ADJUST *)compile_data_alloc(iseq, sizeof(ADJUST));
}
static TRACE *
compile_data_alloc_trace(rb_iseq_t *iseq)
{
    return (TRACE *)compile_data_alloc(iseq, sizeof(TRACE));
}
static void
ELEM_INSERT_NEXT(LINK_ELEMENT *elem1, LINK_ELEMENT *elem2)
{
    elem2->next = elem1->next;
    elem2->prev = elem1;
    elem1->next = elem2;
    if (elem2->next) {
        elem2->next->prev = elem2;
    }
}
static void
ELEM_INSERT_PREV(LINK_ELEMENT *elem1, LINK_ELEMENT *elem2)
{
    elem2->prev = elem1->prev;
    elem2->next = elem1;
    elem1->prev = elem2;
    if (elem2->prev) {
        elem2->prev->next = elem2;
    }
}
static void
ELEM_REPLACE(LINK_ELEMENT *elem1, LINK_ELEMENT *elem2)
{
    elem2->prev = elem1->prev;
    elem2->next = elem1->next;
    if (elem1->prev) {
        elem1->prev->next = elem2;
    }
    if (elem1->next) {
        elem1->next->prev = elem2;
    }
}
static void
ELEM_REMOVE(LINK_ELEMENT *elem)
{
    elem->prev->next = elem->next;
    if (elem->next) {
        elem->next->prev = elem->prev;
    }
}
static LINK_ELEMENT *
FIRST_ELEMENT(const LINK_ANCHOR *const anchor)
{
    return anchor->anchor.next;
}
static LINK_ELEMENT *
LAST_ELEMENT(LINK_ANCHOR *const anchor)
{
    return anchor->last;
}
static LINK_ELEMENT *
ELEM_FIRST_INSN(LINK_ELEMENT *elem)
{
    while (elem) {
        switch (elem->type) {
          case ISEQ_ELEMENT_INSN:
          case ISEQ_ELEMENT_ADJUST:
            return elem;
          default:
            elem = elem->next;
        }
    }
    return ((void *)0);
}
static int
LIST_INSN_SIZE_ONE(const LINK_ANCHOR *const anchor)
{
    LINK_ELEMENT *first_insn = ELEM_FIRST_INSN(FIRST_ELEMENT(anchor));
    if (first_insn != ((void *)0) &&
        ELEM_FIRST_INSN(first_insn->next) == ((void *)0)) {
        return 1;
    }
    else {
        return 0;
    }
}
static int
LIST_INSN_SIZE_ZERO(const LINK_ANCHOR *const anchor)
{
    if (ELEM_FIRST_INSN(FIRST_ELEMENT(anchor)) == ((void *)0)) {
        return 1;
    }
    else {
        return 0;
    }
}
static void
APPEND_LIST( LINK_ANCHOR *const anc1, LINK_ANCHOR *const anc2)
{
    if (anc2->anchor.next) {
        ((void)0);
        anc1->last->next = anc2->anchor.next;
        anc2->anchor.next->prev = anc1->last;
        anc1->last = anc2->last;
    }
    else {
        ((void)0);
    }
    verify_list("append", anc1);
}
static TRACE *
new_trace_body(rb_iseq_t *iseq, rb_event_flag_t event, long data)
{
    TRACE *trace = compile_data_alloc_trace(iseq);
    trace->link.type = ISEQ_ELEMENT_TRACE;
    trace->link.next = ((void *)0);
    trace->event = event;
    trace->data = data;
    return trace;
}
static LABEL *
new_label_body(rb_iseq_t *iseq, long line)
{
    LABEL *labelobj = compile_data_alloc_label(iseq);
    labelobj->link.type = ISEQ_ELEMENT_LABEL;
    labelobj->link.next = 0;
    labelobj->label_no = ISEQ_COMPILE_DATA(iseq)->label_no++;
    labelobj->sc_state = 0;
    labelobj->sp = -1;
    labelobj->refcnt = 0;
    labelobj->set = 0;
    labelobj->rescued = LABEL_RESCUE_NONE;
    labelobj->unremovable = 0;
    labelobj->position = -1;
    return labelobj;
}
static ADJUST *
new_adjust_body(rb_iseq_t *iseq, LABEL *label, int line)
{
    ADJUST *adjust = compile_data_alloc_adjust(iseq);
    adjust->link.type = ISEQ_ELEMENT_ADJUST;
    adjust->link.next = 0;
    adjust->label = label;
    adjust->line_no = line;
    ((label) ? (((label)->refcnt++), (label)->unremovable=1) : 0);
    return adjust;
}
static void
iseq_insn_each_markable_object(INSN *insn, void (*func)(VALUE, VALUE), VALUE data)
{
    const char *types = insn_op_types(insn->insn_id);
    for (int j = 0; types[j]; j++) {
        char type = types[j];
        switch (type) {
          case TS_CDHASH:
          case TS_ISEQ:
          case TS_VALUE:
          case TS_IC:
          case TS_CALLDATA:
            func((((INSN*)(insn))->operands[(j)]), data);
            break;
          default:
            break;
        }
    }
}
static void
iseq_insn_each_object_write_barrier(VALUE obj, VALUE iseq)
{
    (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(obj), "compile.c", 1398));
}
static INSN *
new_insn_core(rb_iseq_t *iseq, int line_no, int node_id, int insn_id, int argc, VALUE *argv)
{
    INSN *iobj = compile_data_alloc_insn(iseq);
    iobj->link.type = ISEQ_ELEMENT_INSN;
    iobj->link.next = 0;
    iobj->insn_id = insn_id;
    iobj->insn_info.line_no = line_no;
    iobj->insn_info.node_id = node_id;
    iobj->insn_info.events = 0;
    iobj->operands = argv;
    iobj->operand_size = argc;
    iobj->sc_state = 0;
    iseq_insn_each_markable_object(iobj, iseq_insn_each_object_write_barrier, (VALUE)iseq);
    return iobj;
}
static INSN *
new_insn_body(rb_iseq_t *iseq, int line_no, int node_id, enum ruby_vminsn_type insn_id, int argc, ...)
{
    VALUE *operands = 0;
    va_list argv;
    if (argc > 0) {
        int i;
        __builtin_va_start(argv,argc);
        operands = compile_data_alloc2(iseq, sizeof(VALUE), argc);
        for (i = 0; i < argc; i++) {
            VALUE v = __builtin_va_arg(argv,VALUE);
            operands[i] = v;
        }
        __builtin_va_end(argv);
    }
    return new_insn_core(iseq, line_no, node_id, insn_id, argc, operands);
}
static const struct rb_callinfo *
new_callinfo(rb_iseq_t *iseq, ID mid, int argc, unsigned int flag, struct rb_callinfo_kwarg *kw_arg, int has_blockiseq)
{
    ((void)0);
    if (kw_arg) {
        flag |= (0x01 << VM_CALL_KWARG_bit);
        argc += kw_arg->keyword_len;
    }
    if (!(flag & ((0x01 << VM_CALL_ARGS_SPLAT_bit) | (0x01 << VM_CALL_ARGS_BLOCKARG_bit) | (0x01 << VM_CALL_KWARG_bit) | (0x01 << VM_CALL_KW_SPLAT_bit) | (0x01 << VM_CALL_FORWARDING_bit)))
        && !has_blockiseq) {
        flag |= (0x01 << VM_CALL_ARGS_SIMPLE_bit);
    }
    ((iseq)->body)->ci_size++;
    const struct rb_callinfo *ci = vm_ci_new_(mid, flag, argc, kw_arg, "compile.c", 1457);
    (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(ci), "compile.c", 1458));
    return ci;
}
static INSN *
new_insn_send(rb_iseq_t *iseq, int line_no, int node_id, ID id, VALUE argc, const rb_iseq_t *blockiseq, VALUE flag, struct rb_callinfo_kwarg *keywords)
{
    VALUE *operands = compile_data_calloc2(iseq, sizeof(VALUE), 2);
    VALUE ci = (VALUE)new_callinfo(iseq, id, RB_FIX2INT(argc), RB_FIX2INT(flag), keywords, blockiseq != ((void *)0));
    operands[0] = ci;
    operands[1] = (VALUE)blockiseq;
    if (blockiseq) {
        (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(blockiseq), "compile.c", 1470));
    }
    INSN *insn;
    if (vm_ci_flag((struct rb_callinfo *)ci) & (0x01 << VM_CALL_FORWARDING_bit)) {
        insn = new_insn_core(iseq, line_no, node_id, YARVINSN_sendforward, 2, operands);
    }
    else {
        insn = new_insn_core(iseq, line_no, node_id, YARVINSN_send, 2, operands);
    }
    (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(ci), "compile.c", 1482));
    (*__extension__ ({ volatile VALUE *rb_gc_guarded_ptr = &(ci); __asm__("" : : "m"(rb_gc_guarded_ptr)); rb_gc_guarded_ptr; }));
    return insn;
}
static rb_iseq_t *
new_child_iseq(rb_iseq_t *iseq, const NODE *const node,
               VALUE name, const rb_iseq_t *parent, enum rb_iseq_type type, int line_no)
{
    rb_iseq_t *ret_iseq;
    VALUE ast_value = rb_ruby_ast_new(node);
    if(0)printf("[new_child_iseq]> ---------------------------------------\n");
    int isolated_depth = ISEQ_COMPILE_DATA(iseq)->isolated_depth;
    ret_iseq = rb_iseq_new_with_opt(ast_value, name,
                                    rb_iseq_path(iseq), rb_iseq_realpath(iseq),
                                    line_no, parent,
                                    isolated_depth ? isolated_depth + 1 : 0,
                                    type, ISEQ_COMPILE_DATA(iseq)->option,
                                    ((iseq)->body)->variable.script_lines);
    if(0)printf("[new_child_iseq]< ---------------------------------------\n");
    return ret_iseq;
}
static rb_iseq_t *
new_child_iseq_with_callback(rb_iseq_t *iseq, const struct rb_iseq_new_with_callback_callback_func *ifunc,
                     VALUE name, const rb_iseq_t *parent, enum rb_iseq_type type, int line_no)
{
    rb_iseq_t *ret_iseq;
    if(0)printf("[new_child_iseq_with_callback]> ---------------------------------------\n");
    ret_iseq = rb_iseq_new_with_callback(ifunc, name,
                                 rb_iseq_path(iseq), rb_iseq_realpath(iseq),
                                 line_no, parent, type, ISEQ_COMPILE_DATA(iseq)->option);
    if(0)printf("[new_child_iseq_with_callback]< ---------------------------------------\n");
    return ret_iseq;
}
static void
set_catch_except_p(rb_iseq_t *iseq)
{
    ((void)0);
    ISEQ_COMPILE_DATA(iseq)->catch_except_p = 1;
    if (((iseq)->body)->parent_iseq != ((void *)0)) {
        if (ISEQ_COMPILE_DATA(((iseq)->body)->parent_iseq)) {
          set_catch_except_p((rb_iseq_t *) ((iseq)->body)->parent_iseq);
        }
    }
}
static void
update_catch_except_flags(rb_iseq_t *iseq, struct rb_iseq_constant_body *body)
{
    unsigned int pos;
    size_t i;
    int insn;
    const struct iseq_catch_table *ct = body->catch_table;
    pos = 0;
    while (pos < body->iseq_size) {
        insn = rb_vm_insn_decode(body->iseq_encoded[pos]);
        if (insn == YARVINSN_throw) {
            set_catch_except_p(iseq);
            break;
        }
        pos += insn_len(insn);
    }
    if (ct == ((void *)0))
        return;
    for (i = 0; i < ct->size; i++) {
        const struct iseq_catch_table_entry *entry =
            __extension__({
#pragma GCC diagnostic push
           ;
#pragma GCC diagnostic ignored "-Waddress-of-packed-member"
           ; const volatile void *unaligned_member_ptr_result = &(ct)->entries[i];
#pragma GCC diagnostic pop
           ; (__typeof__((ct)->entries[i]) *)unaligned_member_ptr_result; });
        if (entry->type != CATCH_TYPE_BREAK
            && entry->type != CATCH_TYPE_NEXT
            && entry->type != CATCH_TYPE_REDO) {
            ((void)0);
            ISEQ_COMPILE_DATA(iseq)->catch_except_p = 1;
            break;
        }
    }
}
static void
iseq_insert_nop_between_end_and_cont(rb_iseq_t *iseq)
{
    VALUE catch_table_ary = ISEQ_COMPILE_DATA(iseq)->catch_table_ary;
    if (RB_NIL_P(catch_table_ary)) return;
    unsigned int i, tlen = (unsigned int)rb_array_len(catch_table_ary);
    const VALUE *tptr = rb_array_const_ptr(catch_table_ary);
    for (i = 0; i < tlen; i++) {
        const VALUE *ptr = rb_array_const_ptr(tptr[i]);
        LINK_ELEMENT *end = (LINK_ELEMENT *)(ptr[2] & ~1);
        LINK_ELEMENT *cont = (LINK_ELEMENT *)(ptr[4] & ~1);
        LINK_ELEMENT *e;
        enum rb_catch_type ct = (enum rb_catch_type)(ptr[0] & 0xffff);
        if (ct != CATCH_TYPE_BREAK
            && ct != CATCH_TYPE_NEXT
            && ct != CATCH_TYPE_REDO) {
            for (e = end; e && (((e)->type == ISEQ_ELEMENT_LABEL) || ((e)->type == ISEQ_ELEMENT_TRACE)); e = e->next) {
                if (e == cont) {
                    INSN *nop = new_insn_core(iseq, 0, -1, YARVINSN_nop, 0, 0);
                    ELEM_INSERT_NEXT(end, &nop->link);
                    break;
                }
            }
        }
    }
    (*__extension__ ({ volatile VALUE *rb_gc_guarded_ptr = &(catch_table_ary); __asm__("" : : "m"(rb_gc_guarded_ptr)); rb_gc_guarded_ptr; }));
}
static int
iseq_setup_insn(rb_iseq_t *iseq, LINK_ANCHOR *const anchor)
{
    if (RB_TEST(ISEQ_COMPILE_DATA(iseq)->err_info))
        return 0;
    if (0 > 5)
        dump_disasm_list(FIRST_ELEMENT(anchor));
    if(0)printf("[compile step 3.1 (iseq_optimize)]\n");
    iseq_optimize(iseq, anchor);
    if (0 > 5)
        dump_disasm_list(FIRST_ELEMENT(anchor));
    if (ISEQ_COMPILE_DATA(iseq)->option->instructions_unification) {
        if(0)printf("[compile step 3.2 (iseq_insns_unification)]\n");
        iseq_insns_unification(iseq, anchor);
        if (0 > 5)
            dump_disasm_list(FIRST_ELEMENT(anchor));
    }
    if(0)printf("[compile step 3.4 (iseq_insert_nop_between_end_and_cont)]\n");
    iseq_insert_nop_between_end_and_cont(iseq);
    if (0 > 5)
        dump_disasm_list(FIRST_ELEMENT(anchor));
    return 1;
}
static int
iseq_setup(rb_iseq_t *iseq, LINK_ANCHOR *const anchor)
{
    if (RB_TEST(ISEQ_COMPILE_DATA(iseq)->err_info))
        return 0;
    if(0)printf("[compile step 4.1 (iseq_set_sequence)]\n");
    if (!iseq_set_sequence(iseq, anchor)) return 0;
    if (0 > 5)
        dump_disasm_list(FIRST_ELEMENT(anchor));
    if(0)printf("[compile step 4.2 (iseq_set_exception_table)]\n");
    if (!iseq_set_exception_table(iseq)) return 0;
    if(0)printf("[compile step 4.3 (set_optargs_table)] \n");
    if (!iseq_set_optargs_table(iseq)) return 0;
    if(0)printf("[compile step 5 (iseq_translate_threaded_code)] \n");
    if (!rb_iseq_translate_threaded_code(iseq)) return 0;
    if(0)printf("[compile step 6 (update_catch_except_flags)] \n");
    ((void)0);
    update_catch_except_flags(iseq, ((iseq)->body));
    if(0)printf("[compile step 6.1 (remove unused catch tables)] \n");
    ((void)0);
    if (!ISEQ_COMPILE_DATA(iseq)->catch_except_p && ((iseq)->body)->catch_table) {
        ruby_xfree(((iseq)->body)->catch_table);
        ((iseq)->body)->catch_table = ((void *)0);
    }
    if (((iseq)->body)->insns_info.succ_index_table == ((void *)0)) {
        if(0)printf("[compile step 7 (rb_iseq_insns_info_encode_positions)] \n");
        rb_iseq_insns_info_encode_positions(iseq);
    }
    if (0 > 1) {
        VALUE str = rb_iseq_disasm(iseq);
        printf("%s\n", rb_string_value_cstr(&(str)));
    }
    verify_call_cache(iseq);
    if(0)printf("[compile step: finish]\n");
    return 1;
}
static int
iseq_set_exception_local_table(rb_iseq_t *iseq)
{
    ((iseq)->body)->local_table_size = ((int)(sizeof(rb_iseq_shared_exc_local_tbl) / sizeof((rb_iseq_shared_exc_local_tbl)[0])));
    ((iseq)->body)->local_table = rb_iseq_shared_exc_local_tbl;
    return 1;
}
static int
get_lvar_level(const rb_iseq_t *iseq)
{
    int lev = 0;
    while (iseq != ((iseq)->body)->local_iseq) {
        lev++;
        iseq = ((iseq)->body)->parent_iseq;
    }
    return lev;
}
static int
get_dyna_var_idx_at_raw(const rb_iseq_t *iseq, ID id)
{
    unsigned int i;
    for (i = 0; i < ((iseq)->body)->local_table_size; i++) {
        if (((iseq)->body)->local_table[i] == id) {
            return (int)i;
        }
    }
    return -1;
}
static int
get_local_var_idx(const rb_iseq_t *iseq, ID id)
{
    int idx = get_dyna_var_idx_at_raw(((iseq)->body)->local_iseq, id);
    if (idx < 0) {
        append_compile_error(iseq, (ISEQ_COMPILE_DATA(iseq)->last_line),
                      "get_local_var_idx: %d", idx);
    }
    return idx;
}
static int
get_dyna_var_idx(const rb_iseq_t *iseq, ID id, int *level, int *ls)
{
    int lv = 0, idx = -1;
    const rb_iseq_t *const topmost_iseq = iseq;
    while (iseq) {
        idx = get_dyna_var_idx_at_raw(iseq, id);
        if (idx >= 0) {
            break;
        }
        iseq = ((iseq)->body)->parent_iseq;
        lv++;
    }
    if (idx < 0) {
        append_compile_error(topmost_iseq, (ISEQ_COMPILE_DATA(topmost_iseq)->last_line),
                      "get_dyna_var_idx: -1");
    }
    *level = lv;
    *ls = ((iseq)->body)->local_table_size;
    return idx;
}
static int
iseq_local_block_param_p(const rb_iseq_t *iseq, unsigned int idx, unsigned int level)
{
    const struct rb_iseq_constant_body *body;
    while (level > 0) {
        iseq = ((iseq)->body)->parent_iseq;
        level--;
    }
    body = ((iseq)->body);
    if (body->local_iseq == iseq &&
        body->param.flags.has_block &&
        body->local_table_size - body->param.block_start == idx) {
        return 1;
    }
    else {
        return 0;
    }
}
static int
iseq_block_param_id_p(const rb_iseq_t *iseq, ID id, int *pidx, int *plevel)
{
    int level, ls;
    int idx = get_dyna_var_idx(iseq, id, &level, &ls);
    if (iseq_local_block_param_p(iseq, ls - idx, level)) {
        *pidx = ls - idx;
        *plevel = level;
        return 1;
    }
    else {
        return 0;
    }
}
static void
access_outer_variables(const rb_iseq_t *iseq, int level, ID id, _Bool write)
{
    int isolated_depth = ISEQ_COMPILE_DATA(iseq)->isolated_depth;
    if (isolated_depth && level >= isolated_depth) {
        if (id == (__builtin_constant_p("yield") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("yield")); }) : (rb_intern)("yield"))) {
            append_compile_error(iseq, (ISEQ_COMPILE_DATA(iseq)->last_line), "can not yield from isolated Proc");
        }
        else {
            append_compile_error(iseq, (ISEQ_COMPILE_DATA(iseq)->last_line), "can not access variable '%s' from isolated Proc", rb_id2name(id));
        }
    }
    for (int i=0; i<level; i++) {
        VALUE val;
        struct rb_id_table *ovs = ((iseq)->body)->outer_variables;
        if (!ovs) {
            ovs = ((iseq)->body)->outer_variables = rb_id_table_create(8);
        }
        if (rb_id_table_lookup(((iseq)->body)->outer_variables, id, &val)) {
            if (write && !val) {
                rb_id_table_insert(((iseq)->body)->outer_variables, id, ((VALUE)RUBY_Qtrue));
            }
        }
        else {
            rb_id_table_insert(((iseq)->body)->outer_variables, id, ((write) ? ((VALUE)RUBY_Qtrue) : ((VALUE)RUBY_Qfalse)));
        }
        iseq = ((iseq)->body)->parent_iseq;
    }
}
static ID
iseq_lvar_id(const rb_iseq_t *iseq, int idx, int level)
{
    for (int i=0; i<level; i++) {
        iseq = ((iseq)->body)->parent_iseq;
    }
    ID id = ((iseq)->body)->local_table[((iseq)->body)->local_table_size - idx];
    return id;
}
static void
iseq_add_getlocal(rb_iseq_t *iseq, LINK_ANCHOR *const seq, const NODE *const line_node, int idx, int level)
{
    if (iseq_local_block_param_p(iseq, idx, level)) {
        ADD_ELEM((seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_getblockparam, 2, (VALUE)(__builtin_choose_expr( __builtin_constant_p((idx) + ( 3) - 1), ((VALUE)((idx) + ( 3) - 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((idx) + ( 3) - 1))), (VALUE)(__builtin_choose_expr( __builtin_constant_p(level), ((VALUE)(level)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(level)))));
    }
    else {
        ADD_ELEM((seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_getlocal, 2, (VALUE)(__builtin_choose_expr( __builtin_constant_p((idx) + ( 3) - 1), ((VALUE)((idx) + ( 3) - 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((idx) + ( 3) - 1))), (VALUE)(__builtin_choose_expr( __builtin_constant_p(level), ((VALUE)(level)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(level)))));
    }
    if (level > 0) access_outer_variables(iseq, level, iseq_lvar_id(iseq, idx, level), ((VALUE)RUBY_Qfalse));
}
static void
iseq_add_setlocal(rb_iseq_t *iseq, LINK_ANCHOR *const seq, const NODE *const line_node, int idx, int level)
{
    if (iseq_local_block_param_p(iseq, idx, level)) {
        ADD_ELEM((seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_setblockparam, 2, (VALUE)(__builtin_choose_expr( __builtin_constant_p((idx) + ( 3) - 1), ((VALUE)((idx) + ( 3) - 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((idx) + ( 3) - 1))), (VALUE)(__builtin_choose_expr( __builtin_constant_p(level), ((VALUE)(level)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(level)))));
    }
    else {
        ADD_ELEM((seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_setlocal, 2, (VALUE)(__builtin_choose_expr( __builtin_constant_p((idx) + ( 3) - 1), ((VALUE)((idx) + ( 3) - 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((idx) + ( 3) - 1))), (VALUE)(__builtin_choose_expr( __builtin_constant_p(level), ((VALUE)(level)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(level)))));
    }
    if (level > 0) access_outer_variables(iseq, level, iseq_lvar_id(iseq, idx, level), ((VALUE)RUBY_Qtrue));
}
static void
iseq_calc_param_size(rb_iseq_t *iseq)
{
    struct rb_iseq_constant_body *const body = ((iseq)->body);
    if (body->param.flags.has_opt ||
        body->param.flags.has_post ||
        body->param.flags.has_rest ||
        body->param.flags.has_block ||
        body->param.flags.has_kw ||
        body->param.flags.has_kwrest) {
        if (body->param.flags.has_block) {
            body->param.size = body->param.block_start + 1;
        }
        else if (body->param.flags.has_kwrest) {
            body->param.size = body->param.keyword->rest_start + 1;
        }
        else if (body->param.flags.has_kw) {
            body->param.size = body->param.keyword->bits_start + 1;
        }
        else if (body->param.flags.has_post) {
            body->param.size = body->param.post_start + body->param.post_num;
        }
        else if (body->param.flags.has_rest) {
            body->param.size = body->param.rest_start + 1;
        }
        else if (body->param.flags.has_opt) {
            body->param.size = body->param.lead_num + body->param.opt_num;
        }
        else {
            __builtin_unreachable();
        }
    }
    else {
        body->param.size = body->param.lead_num;
    }
}
static int
iseq_set_arguments_keywords(rb_iseq_t *iseq, LINK_ANCHOR *const optargs,
                            const struct rb_args_info *args, int arg_size)
{
    const rb_node_kw_arg_t *node = args->kw_args;
    struct rb_iseq_constant_body *const body = ((iseq)->body);
    struct rb_iseq_param_keyword *keyword;
    const VALUE default_values = rb_ary_hidden_new(1);
    const VALUE complex_mark = rb_str_tmp_new(0);
    int kw = 0, rkw = 0, di = 0, i;
    body->param.flags.has_kw = 1;
    body->param.keyword = keyword = ((struct rb_iseq_param_keyword *)ruby_xcalloc((1), sizeof(struct rb_iseq_param_keyword)));
    while (node) {
        kw++;
        node = node->nd_next;
    }
    arg_size += kw;
    keyword->bits_start = arg_size++;
    node = args->kw_args;
    while (node) {
        const NODE *val_node = get_nd_value(node->nd_body);
        VALUE dv;
        if (val_node == ((NODE *)-1)) {
            ++rkw;
        }
        else {
            switch (((int) ((((NODE *)(val_node))->flags & (((VALUE)0x7f)<<8))>>8))) {
              case NODE_SYM:
                dv = rb_node_sym_string_val(val_node);
                break;
              case NODE_REGX:
                dv = rb_node_regx_string_val(val_node);
                break;
              case NODE_LINE:
                dv = rb_node_line_lineno_val(val_node);
                break;
              case NODE_INTEGER:
                dv = rb_node_integer_literal_val(val_node);
                break;
              case NODE_FLOAT:
                dv = rb_node_float_literal_val(val_node);
                break;
              case NODE_RATIONAL:
                dv = rb_node_rational_literal_val(val_node);
                break;
              case NODE_IMAGINARY:
                dv = rb_node_imaginary_literal_val(val_node);
                break;
              case NODE_ENCODING:
                dv = rb_node_encoding_val(val_node);
                break;
              case NODE_NIL:
                dv = ((VALUE)RUBY_Qnil);
                break;
              case NODE_TRUE:
                dv = ((VALUE)RUBY_Qtrue);
                break;
              case NODE_FALSE:
                dv = ((VALUE)RUBY_Qfalse);
                break;
              default:
                (void)(((iseq_compile_each(iseq, (optargs), (((NODE *)(node))), 1))));
                dv = complex_mark;
            }
            keyword->num = ++di;
            rb_ary_push(default_values, dv);
        }
        node = node->nd_next;
    }
    keyword->num = kw;
    if (((rb_node_dvar_t *)(args->kw_rest_arg))->nd_vid != 0) {
        ID kw_id = iseq->body->local_table[arg_size];
        keyword->rest_start = arg_size++;
        body->param.flags.has_kwrest = 1;
        if (kw_id == idPow) body->param.flags.anon_kwrest = 1;
    }
    keyword->required_num = rkw;
    keyword->table = &body->local_table[keyword->bits_start - keyword->num];
    if (rb_array_len(default_values)) {
        VALUE *dvs = ((VALUE *)ruby_xmalloc2((rb_array_len(default_values)), sizeof(VALUE)));
        for (i = 0; i < rb_array_len(default_values); i++) {
            VALUE dv = RARRAY_AREF(default_values, i);
            if (dv == complex_mark) dv = ((VALUE)RUBY_Qundef);
            (rb_obj_write((VALUE)(iseq), (VALUE *)(&dvs[i]), (VALUE)(dv), "compile.c", 1996));
        }
        keyword->default_values = dvs;
    }
    return arg_size;
}
static void
iseq_set_use_block(rb_iseq_t *iseq)
{
    struct rb_iseq_constant_body *const body = ((iseq)->body);
    if (!body->param.flags.use_block) {
        body->param.flags.use_block = 1;
        rb_vm_t *vm = rb_current_vm();
        if (!rb_warning_category_enabled_p(RB_WARN_CATEGORY_STRICT_UNUSED_BLOCK)) {
            st_data_t key = (st_data_t)rb_intern_str(body->location.label);
            rb_st_insert(vm->unused_block_warning_table, key, 1);
        }
    }
}
static int
iseq_set_arguments(rb_iseq_t *iseq, LINK_ANCHOR *const optargs, const NODE *const node_args)
{
    if(0)printf("iseq_set_arguments: %s\n", node_args ? "" : "0");
    if (node_args) {
        struct rb_iseq_constant_body *const body = ((iseq)->body);
        struct rb_args_info *args = &((rb_node_args_t *)(node_args))->nd_ainfo;
        ID rest_id = 0;
        int last_comma = 0;
        ID block_id = 0;
        int arg_size;
        do { const NODE *error_node = (node_args); enum node_type error_type = ((int) ((((NODE *)(error_node))->flags & (((VALUE)0x7f)<<8))>>8)); if (error_type != (NODE_ARGS)) { append_compile_error(iseq, (int)(((long)(error_node)->flags)>>(8 +7)), "iseq_set_arguments" ": " "NODE_ARGS" " is expected, but %s", ruby_node_name(error_type)); return 0; } } while (0);
        body->param.flags.ruby2_keywords = args->ruby2_keywords;
        body->param.lead_num = arg_size = (int)args->pre_args_num;
        if (body->param.lead_num > 0) body->param.flags.has_lead = 1;
        if(0)printf("  - argc: %d\n", body->param.lead_num);
        rest_id = args->rest_arg;
        if (rest_id == ((ID)1)) {
            last_comma = 1;
            rest_id = 0;
        }
        block_id = args->block_arg;
        _Bool optimized_forward = (args->forwarding && args->pre_args_num == 0 && !args->opt_args);
        if (optimized_forward) {
            rest_id = 0;
            block_id = 0;
        }
        if (args->opt_args) {
            const rb_node_opt_arg_t *node = args->opt_args;
            LABEL *label;
            VALUE labels = rb_ary_hidden_new(1);
            VALUE *opt_table;
            int i = 0, j;
            while (node) {
                label = new_label_body(iseq, ((int)(((long)(((NODE *)(node)))->flags)>>(8 +7))));
                rb_ary_push(labels, (VALUE)label | 1);
                ADD_ELEM((optargs), (LINK_ELEMENT *) (label));
                (void)(((iseq_compile_each(iseq, (optargs), (node->nd_body), 1))));
                node = node->nd_next;
                i += 1;
            }
            label = new_label_body(iseq, ((int)(((long)(node_args)->flags)>>(8 +7))));
            rb_ary_push(labels, (VALUE)label | 1);
            ADD_ELEM((optargs), (LINK_ELEMENT *) (label));
            opt_table = ((VALUE *)ruby_xmalloc2((i+1), sizeof(VALUE)));
            ruby_nonempty_memcpy((opt_table), (rb_array_const_ptr(labels)), rbimpl_size_mul_or_raise(sizeof(VALUE), (i+1)));
            for (j = 0; j < i+1; j++) {
                opt_table[j] &= ~1;
            }
            rb_ary_clear(labels);
            body->param.flags.has_opt = 1;
            body->param.opt_num = i;
            body->param.opt_table = opt_table;
            arg_size += i;
        }
        if (rest_id) {
            body->param.rest_start = arg_size++;
            body->param.flags.has_rest = 1;
            if (rest_id == '*') body->param.flags.anon_rest = 1;
            ((void)0);
        }
        if (args->first_post_arg) {
            body->param.post_start = arg_size;
            body->param.post_num = args->post_args_num;
            body->param.flags.has_post = 1;
            arg_size += args->post_args_num;
            if (body->param.flags.has_rest) {
                body->param.post_start = body->param.rest_start + 1;
            }
        }
        if (args->kw_args) {
            arg_size = iseq_set_arguments_keywords(iseq, optargs, args, arg_size);
        }
        else if (args->kw_rest_arg && !optimized_forward) {
            ID kw_id = iseq->body->local_table[arg_size];
            struct rb_iseq_param_keyword *keyword = ((struct rb_iseq_param_keyword *)ruby_xcalloc((1), sizeof(struct rb_iseq_param_keyword)));
            keyword->rest_start = arg_size++;
            body->param.keyword = keyword;
            body->param.flags.has_kwrest = 1;
            static ID anon_kwrest = 0;
            if (!anon_kwrest) anon_kwrest = (__builtin_constant_p("**") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("**")); }) : (rb_intern)("**"));
            if (kw_id == anon_kwrest) body->param.flags.anon_kwrest = 1;
        }
        else if (args->no_kwarg) {
            body->param.flags.accepts_no_kwarg = 1;
        }
        if (block_id) {
            body->param.block_start = arg_size++;
            body->param.flags.has_block = 1;
            iseq_set_use_block(iseq);
        }
        if (optimized_forward) {
            body->param.flags.use_block = 1;
            body->param.flags.forwardable = 1;
            arg_size = 1;
        }
        iseq_calc_param_size(iseq);
        body->param.size = arg_size;
        if (args->pre_init) {
            (void)(((iseq_compile_each(iseq, (optargs), (args->pre_init), 1))));
        }
        if (args->post_init) {
            (void)(((iseq_compile_each(iseq, (optargs), (args->post_init), 1))));
        }
        if (body->type == ISEQ_TYPE_BLOCK) {
            if (body->param.flags.has_opt == 0 &&
                body->param.flags.has_post == 0 &&
                body->param.flags.has_rest == 0 &&
                body->param.flags.has_kw == 0 &&
                body->param.flags.has_kwrest == 0) {
                if (body->param.lead_num == 1 && last_comma == 0) {
                    body->param.flags.ambiguous_param0 = 1;
                }
            }
        }
    }
    return 1;
}
static int
iseq_set_local_table(rb_iseq_t *iseq, const rb_ast_id_table_t *tbl, const NODE *const node_args)
{
    unsigned int size = tbl ? tbl->size : 0;
    unsigned int offset = 0;
    if (node_args) {
        struct rb_args_info *args = &((rb_node_args_t *)(node_args))->nd_ainfo;
        if (args->forwarding && args->pre_args_num == 0 && !args->opt_args) {
            size -= 3;
            offset += 3;
        }
    }
    if (size > 0) {
        ID *ids = (ID *)((ID *)ruby_xmalloc2((size), sizeof(ID)));
        ruby_nonempty_memcpy((ids), (tbl->ids + offset), rbimpl_size_mul_or_raise(sizeof(ID), (size)));
        ((iseq)->body)->local_table = ids;
    }
    ((iseq)->body)->local_table_size = size;
    if(0)printf("iseq_set_local_table: %u\n", ((iseq)->body)->local_table_size);
    return 1;
}
int
rb_iseq_cdhash_cmp(VALUE val, VALUE lit)
{
    int tval, tlit;
    if (val == lit) {
        return 0;
    }
    else if ((tlit = __extension__({ VALUE arg_obj = (lit); RB_SPECIAL_CONST_P(arg_obj) ? -1 : (int)RB_BUILTIN_TYPE(arg_obj); })) == -1) {
        return val != lit;
    }
    else if ((tval = __extension__({ VALUE arg_obj = (val); RB_SPECIAL_CONST_P(arg_obj) ? -1 : (int)RB_BUILTIN_TYPE(arg_obj); })) == -1) {
        return -1;
    }
    else if (tlit != tval) {
        return -1;
    }
    else if (tlit == RUBY_T_SYMBOL) {
        return val != lit;
    }
    else if (tlit == RUBY_T_STRING) {
        return rb_str_hash_cmp(lit, val);
    }
    else if (tlit == RUBY_T_BIGNUM) {
        long x = rb_fix2long(rb_big_cmp(lit, val));
        ((void)0);
        return (int)x;
    }
    else if (tlit == RUBY_T_FLOAT) {
        return rb_float_cmp(lit, val);
    }
    else if (tlit == RUBY_T_RATIONAL) {
        const struct RRational *rat1 = ((struct RRational *)(val));
        const struct RRational *rat2 = ((struct RRational *)(lit));
        return rb_iseq_cdhash_cmp(rat1->num, rat2->num) || rb_iseq_cdhash_cmp(rat1->den, rat2->den);
    }
    else if (tlit == RUBY_T_COMPLEX) {
        const struct RComplex *comp1 = ((struct RComplex *)(val));
        const struct RComplex *comp2 = ((struct RComplex *)(lit));
        return rb_iseq_cdhash_cmp(comp1->real, comp2->real) || rb_iseq_cdhash_cmp(comp1->imag, comp2->imag);
    }
    else if (tlit == RUBY_T_REGEXP) {
        return rb_reg_equal(val, lit) ? 0 : -1;
    }
    else {
        __builtin_unreachable();
    }
}
st_index_t
rb_iseq_cdhash_hash(VALUE a)
{
    switch (__extension__({ VALUE arg_obj = (a); RB_SPECIAL_CONST_P(arg_obj) ? -1 : (int)RB_BUILTIN_TYPE(arg_obj); })) {
      case -1:
      case RUBY_T_SYMBOL:
        return (st_index_t)a;
      case RUBY_T_STRING:
        return rb_str_hash(a);
      case RUBY_T_BIGNUM:
        return rb_fix2long(rb_big_hash(a));
      case RUBY_T_FLOAT:
        return rb_dbl_long_hash(rb_float_value_inline(a));
      case RUBY_T_RATIONAL:
        return rb_rational_hash(a);
      case RUBY_T_COMPLEX:
        return rb_complex_hash(a);
      case RUBY_T_REGEXP:
        return rb_num2long_inline(rb_reg_hash(a));
      default:
        __builtin_unreachable();
    }
}
static const struct st_hash_type cdhash_type = {
    rb_iseq_cdhash_cmp,
    rb_iseq_cdhash_hash,
};
struct cdhash_set_label_struct {
    VALUE hash;
    int pos;
    int len;
};
static int
cdhash_set_label_i(VALUE key, VALUE val, VALUE ptr)
{
    struct cdhash_set_label_struct *data = (struct cdhash_set_label_struct *)ptr;
    LABEL *lobj = (LABEL *)(val & ~1);
    rb_hash_aset(data->hash, key, __builtin_choose_expr( __builtin_constant_p(lobj->position - (data->pos+data->len)), ((VALUE)(lobj->position - (data->pos+data->len))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(lobj->position - (data->pos+data->len))));
    return ST_CONTINUE;
}
static inline VALUE
get_ivar_ic_value(rb_iseq_t *iseq,ID id)
{
    return __builtin_choose_expr( __builtin_constant_p(((iseq)->body)->ivc_size++), ((VALUE)(((iseq)->body)->ivc_size++)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(((iseq)->body)->ivc_size++));
}
static inline VALUE
get_cvar_ic_value(rb_iseq_t *iseq,ID id)
{
    VALUE val;
    struct rb_id_table *tbl = ISEQ_COMPILE_DATA(iseq)->ivar_cache_table;
    if (tbl) {
        if (rb_id_table_lookup(tbl,id,&val)) {
            return val;
        }
    }
    else {
        tbl = rb_id_table_create(1);
        ISEQ_COMPILE_DATA(iseq)->ivar_cache_table = tbl;
    }
    val = __builtin_choose_expr( __builtin_constant_p(((iseq)->body)->icvarc_size++), ((VALUE)(((iseq)->body)->icvarc_size++)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(((iseq)->body)->icvarc_size++));
    rb_id_table_insert(tbl,id,val);
    return val;
}
static int
fix_sp_depth(rb_iseq_t *iseq, LINK_ANCHOR *const anchor)
{
    int stack_max = 0, sp = 0, line = 0;
    LINK_ELEMENT *list;
    for (list = FIRST_ELEMENT(anchor); list; list = list->next) {
        if (((list)->type == ISEQ_ELEMENT_LABEL)) {
            LABEL *lobj = (LABEL *)list;
            lobj->set = 1;
        }
    }
    for (list = FIRST_ELEMENT(anchor); list; list = list->next) {
        switch (list->type) {
          case ISEQ_ELEMENT_INSN:
            {
                int j, len, insn;
                const char *types;
                VALUE *operands;
                INSN *iobj = (INSN *)list;
                sp = calc_sp_depth(sp, iobj);
                if (sp < 0) {
                    dump_disasm_list_with_cursor(FIRST_ELEMENT(anchor), list, ((void *)0));
                    append_compile_error(iseq, iobj->insn_info.line_no,
                                  "argument stack underflow (%d)", sp);
                    return -1;
                }
                if (sp > stack_max) {
                    stack_max = sp;
                }
                line = iobj->insn_info.line_no;
                operands = iobj->operands;
                insn = iobj->insn_id;
                types = insn_op_types(insn);
                len = insn_len(insn);
                if (iobj->operand_size != len - 1) {
                    dump_disasm_list_with_cursor(FIRST_ELEMENT(anchor), list, ((void *)0));
                    append_compile_error(iseq, iobj->insn_info.line_no,
                                  "operand size miss! (%d for %d)",
                                  iobj->operand_size, len - 1);
                    return -1;
                }
                for (j = 0; types[j]; j++) {
                    if (types[j] == TS_OFFSET) {
                        LABEL *lobj = (LABEL *)operands[j];
                        if (!lobj->set) {
                            dump_disasm_list_with_cursor(FIRST_ELEMENT(anchor), list, ((void *)0));
                            append_compile_error(iseq, iobj->insn_info.line_no,
                                          "unknown label: ""<L%03d>", lobj->label_no);
                            return -1;
                        }
                        if (lobj->sp == -1) {
                            lobj->sp = sp;
                        }
                        else if (lobj->sp != sp) {
                            if(0)printf("%s:%d: sp inconsistency found but ignored (" "<L%03d>" " sp: %d, calculated sp: %d)\n",
                                   RSTRING_PTR(rb_iseq_path(iseq)), line,
                                   lobj->label_no, lobj->sp, sp);
                        }
                    }
                }
                break;
            }
          case ISEQ_ELEMENT_LABEL:
            {
                LABEL *lobj = (LABEL *)list;
                if (lobj->sp == -1) {
                    lobj->sp = sp;
                }
                else {
                    if (lobj->sp != sp) {
                        if(0)printf("%s:%d: sp inconsistency found but ignored (" "<L%03d>" " sp: %d, calculated sp: %d)\n",
                                RSTRING_PTR(rb_iseq_path(iseq)), line,
                                lobj->label_no, lobj->sp, sp);
                    }
                    sp = lobj->sp;
                }
                break;
            }
          case ISEQ_ELEMENT_TRACE:
            {
                break;
            }
          case ISEQ_ELEMENT_ADJUST:
            {
                ADJUST *adjust = (ADJUST *)list;
                int orig_sp = sp;
                sp = adjust->label ? adjust->label->sp : 0;
                if (adjust->line_no != -1 && orig_sp - sp < 0) {
                    dump_disasm_list_with_cursor(FIRST_ELEMENT(anchor), list, ((void *)0));
                    append_compile_error(iseq, adjust->line_no,
                                  "iseq_set_sequence: adjust bug %d < %d",
                                  orig_sp, sp);
                    return -1;
                }
                break;
            }
          default:
            dump_disasm_list_with_cursor(FIRST_ELEMENT(anchor), list, ((void *)0));
            append_compile_error(iseq, line, "unknown list type: %d", list->type);
            return -1;
        }
    }
    return stack_max;
}
static int
add_insn_info(struct iseq_insn_info_entry *insns_info, unsigned int *positions,
              int insns_info_index, int code_index, const INSN *iobj)
{
    if (insns_info_index == 0 ||
        insns_info[insns_info_index-1].line_no != iobj->insn_info.line_no ||
        insns_info[insns_info_index-1].node_id != iobj->insn_info.node_id ||
        insns_info[insns_info_index-1].events != iobj->insn_info.events) {
        insns_info[insns_info_index].line_no = iobj->insn_info.line_no;
        insns_info[insns_info_index].node_id = iobj->insn_info.node_id;
        insns_info[insns_info_index].events = iobj->insn_info.events;
        positions[insns_info_index] = code_index;
        return 1;
    }
    return 0;
}
static int
add_adjust_info(struct iseq_insn_info_entry *insns_info, unsigned int *positions,
                int insns_info_index, int code_index, const ADJUST *adjust)
{
    insns_info[insns_info_index].line_no = adjust->line_no;
    insns_info[insns_info_index].node_id = -1;
    insns_info[insns_info_index].events = 0;
    positions[insns_info_index] = code_index;
    return 1;
}
static ID *
array_to_idlist(VALUE arr)
{
    ((void)0);
    long size = rb_array_len(arr);
    ID *ids = (ID *)((ID *)ruby_xmalloc2((size + 1), sizeof(ID)));
    for (int i = 0; i < size; i++) {
        VALUE sym = RARRAY_AREF(arr, i);
        ids[i] = rb_sym2id(sym);
    }
    ids[size] = 0;
    return ids;
}
static VALUE
idlist_to_array(const ID *ids)
{
    VALUE arr = rb_ary_new();
    while (*ids) {
        rb_ary_push(arr, rb_id2sym(*ids++));
    }
    return arr;
}
static int
iseq_set_sequence(rb_iseq_t *iseq, LINK_ANCHOR *const anchor)
{
    struct iseq_insn_info_entry *insns_info;
    struct rb_iseq_constant_body *const body = ((iseq)->body);
    unsigned int *positions;
    LINK_ELEMENT *list;
    VALUE *generated_iseq;
    rb_event_flag_t events = 0;
    long data = 0;
    int insn_num, code_index, insns_info_index, sp = 0;
    int stack_max = fix_sp_depth(iseq, anchor);
    if (stack_max < 0) return 0;
    insn_num = code_index = 0;
    for (list = FIRST_ELEMENT(anchor); list; list = list->next) {
        switch (list->type) {
          case ISEQ_ELEMENT_INSN:
            {
                INSN *iobj = (INSN *)list;
                sp = calc_sp_depth(sp, iobj);
                insn_num++;
                events = iobj->insn_info.events |= events;
                if (((iseq)->body)->variable.coverage) {
                    if (RARRAY_AREF(((iseq)->body)->variable.coverage, 0) && (events & 0x010000) &&
                        !(rb_get_coverage_mode() & 8)) {
                        int line = iobj->insn_info.line_no - 1;
                        if (line >= 0 && line < rb_array_len(RARRAY_AREF(((iseq)->body)->variable.coverage, 0))) {
                            RARRAY_ASET(RARRAY_AREF(((iseq)->body)->variable.coverage, 0), line, __builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)));
                        }
                    }
                    if (RARRAY_AREF(((iseq)->body)->variable.coverage, 1) && (events & 0x020000)) {
                        while (rb_array_len(((iseq)->body)->variable.pc2branchindex) <= code_index) {
                            rb_ary_push(((iseq)->body)->variable.pc2branchindex, ((VALUE)RUBY_Qnil));
                        }
                        RARRAY_ASET(((iseq)->body)->variable.pc2branchindex, code_index, __builtin_choose_expr( __builtin_constant_p(data), ((VALUE)(data)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(data)));
                    }
                }
                code_index += insn_data_length(iobj);
                events = 0;
                data = 0;
                break;
            }
          case ISEQ_ELEMENT_LABEL:
            {
                LABEL *lobj = (LABEL *)list;
                lobj->position = code_index;
                if (lobj->sp != sp) {
                    if(0)printf("%s: sp inconsistency found but ignored (" "<L%03d>" " sp: %d, calculated sp: %d)\n",
                           RSTRING_PTR(rb_iseq_path(iseq)),
                           lobj->label_no, lobj->sp, sp);
                }
                sp = lobj->sp;
                break;
            }
          case ISEQ_ELEMENT_TRACE:
            {
                TRACE *trace = (TRACE *)list;
                events |= trace->event;
                if (trace->event & 0x020000) data = trace->data;
                break;
            }
          case ISEQ_ELEMENT_ADJUST:
            {
                ADJUST *adjust = (ADJUST *)list;
                if (adjust->line_no != -1) {
                    int orig_sp = sp;
                    sp = adjust->label ? adjust->label->sp : 0;
                    if (orig_sp - sp > 0) {
                        if (orig_sp - sp > 1) code_index++;
                        code_index++;
                        insn_num++;
                    }
                }
                break;
            }
          default: break;
        }
    }
    generated_iseq = ((VALUE *)ruby_xmalloc2((code_index), sizeof(VALUE)));
    insns_info = ((struct iseq_insn_info_entry *)ruby_xmalloc2((insn_num), sizeof(struct iseq_insn_info_entry)));
    positions = ((unsigned int *)ruby_xmalloc2((insn_num), sizeof(unsigned int)));
    if ((body->ic_size + body->ivc_size + body->ise_size + body->icvarc_size)) {
        body->is_entries = ((union iseq_inline_storage_entry *)ruby_xcalloc(((body->ic_size + body->ivc_size + body->ise_size + body->icvarc_size)), sizeof(union iseq_inline_storage_entry)));
    }
    else {
        body->is_entries = ((void *)0);
    }
    body->call_data = ((struct rb_call_data *)ruby_xcalloc((body->ci_size), sizeof(struct rb_call_data)));
    ISEQ_COMPILE_DATA(iseq)->ci_index = 0;
    iseq_bits_t * mark_offset_bits;
    int code_size = code_index;
    iseq_bits_t tmp[1] = {0};
    _Bool needs_bitmap = 0;
    if ((((code_index) + ((sizeof(iseq_bits_t) * 8)) - 1) / ((sizeof(iseq_bits_t) * 8))) == 1) {
        mark_offset_bits = tmp;
    }
    else {
        mark_offset_bits = ((iseq_bits_t *)ruby_xcalloc(((((code_index) + ((sizeof(iseq_bits_t) * 8)) - 1) / ((sizeof(iseq_bits_t) * 8)))), sizeof(iseq_bits_t)));
    }
    list = FIRST_ELEMENT(anchor);
    insns_info_index = code_index = sp = 0;
    while (list) {
        switch (list->type) {
          case ISEQ_ELEMENT_INSN:
            {
                int j, len, insn;
                const char *types;
                VALUE *operands;
                INSN *iobj = (INSN *)list;
                sp = calc_sp_depth(sp, iobj);
                operands = iobj->operands;
                insn = iobj->insn_id;
                generated_iseq[code_index] = insn;
                types = insn_op_types(insn);
                len = insn_len(insn);
                for (j = 0; types[j]; j++) {
                    char type = types[j];
                    switch (type) {
                      case TS_OFFSET:
                        {
                            LABEL *lobj = (LABEL *)operands[j];
                            generated_iseq[code_index + 1 + j] = lobj->position - (code_index + len);
                            break;
                        }
                      case TS_CDHASH:
                        {
                            VALUE map = operands[j];
                            struct cdhash_set_label_struct data;
                            data.hash = map;
                            data.pos = code_index;
                            data.len = len;
                            rb_hash_foreach(map, cdhash_set_label_i, (VALUE)&data);
                            rb_hash_rehash(map);
                            freeze_hide_obj(map);
                            generated_iseq[code_index + 1 + j] = map;
                            (mark_offset_bits[(code_index + 1 + j) / (sizeof(iseq_bits_t) * 8)] |= ((iseq_bits_t)1 << ((code_index + 1 + j) % (sizeof(iseq_bits_t) * 8))));
                            (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(map), "compile.c", 2664));
                            needs_bitmap = 1;
                            break;
                        }
                      case TS_LINDEX:
                      case TS_NUM:
                        generated_iseq[code_index + 1 + j] = RB_FIX2INT(operands[j]);
                        break;
                      case TS_ISEQ:
                      case TS_VALUE:
                        {
                            VALUE v = operands[j];
                            generated_iseq[code_index + 1 + j] = v;
                            if (!RB_SPECIAL_CONST_P(v)) {
                                (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(v), "compile.c", 2679));
                                (mark_offset_bits[(code_index + 1 + j) / (sizeof(iseq_bits_t) * 8)] |= ((iseq_bits_t)1 << ((code_index + 1 + j) % (sizeof(iseq_bits_t) * 8))));
                                needs_bitmap = 1;
                            }
                            break;
                        }
                      case TS_IC:
                        {
                            unsigned int ic_index = ISEQ_COMPILE_DATA(iseq)->ic_index++;
                            IC ic = &ISEQ_IS_ENTRY_START(body, type)[ic_index].ic_cache;
                            if ((__builtin_expect(!!(ic_index >= body->ic_size), 0))) {
                                dump_disasm_list_with_cursor(FIRST_ELEMENT(anchor), &iobj->link, 0);
                                append_compile_error(iseq, iobj->insn_info.line_no,
                                              "iseq_set_sequence: ic_index overflow: index: %d, size: %d",
                                              ic_index, (body->ic_size + body->ivc_size + body->ise_size + body->icvarc_size));
                            }
                            ic->segments = array_to_idlist(operands[j]);
                            generated_iseq[code_index + 1 + j] = (VALUE)ic;
                        }
                        break;
                      case TS_IVC:
                        {
                            unsigned int ic_index = RB_FIX2UINT(operands[j]);
                            IVC cache = ((IVC)&body->is_entries[ic_index]);
                            if (insn == YARVINSN_setinstancevariable) {
                                cache->iv_set_name = rb_sym2id(operands[j - 1]);
                            }
                            else {
                                cache->iv_set_name = 0;
                            }
                            vm_ic_attr_index_initialize(cache, (((uintptr_t)1 << 32) - 1));
                        }
                      case TS_ISE:
                      case TS_ICVARC:
                        {
                            unsigned int ic_index = RB_FIX2UINT(operands[j]);
                            IC ic = &ISEQ_IS_ENTRY_START(body, type)[ic_index].ic_cache;
                            if ((__builtin_expect(!!(ic_index >= (body->ic_size + body->ivc_size + body->ise_size + body->icvarc_size)), 0))) {
                                dump_disasm_list_with_cursor(FIRST_ELEMENT(anchor), &iobj->link, 0);
                                append_compile_error(iseq, iobj->insn_info.line_no,
                                              "iseq_set_sequence: ic_index overflow: index: %d, size: %d",
                                              ic_index, (body->ic_size + body->ivc_size + body->ise_size + body->icvarc_size));
                            }
                            generated_iseq[code_index + 1 + j] = (VALUE)ic;
                            break;
                        }
                      case TS_CALLDATA:
                        {
                            const struct rb_callinfo *source_ci = (const struct rb_callinfo *)operands[j];
                            ((void)0);
                            struct rb_call_data *cd = &body->call_data[ISEQ_COMPILE_DATA(iseq)->ci_index++];
                            cd->ci = source_ci;
                            cd->cc = rb_vm_empty_cc();
                            generated_iseq[code_index + 1 + j] = (VALUE)cd;
                            break;
                        }
                      case TS_ID:
                        generated_iseq[code_index + 1 + j] = rb_sym2id(operands[j]);
                        break;
                      case TS_FUNCPTR:
                        generated_iseq[code_index + 1 + j] = operands[j];
                        break;
                      case TS_BUILTIN:
                        generated_iseq[code_index + 1 + j] = operands[j];
                        break;
                      default:
                        (ruby_xfree(generated_iseq), ruby_xfree(insns_info), dump_disasm_list_with_cursor(FIRST_ELEMENT(anchor), list, ((void *)0)), append_compile_error)(iseq, iobj->insn_info.line_no,
                                      "unknown operand type: %c", type);
                        return 0;
                    }
                }
                if (add_insn_info(insns_info, positions, insns_info_index, code_index, iobj)) insns_info_index++;
                code_index += len;
                break;
            }
          case ISEQ_ELEMENT_LABEL:
            {
                LABEL *lobj = (LABEL *)list;
                if (lobj->sp != sp) {
                    if(0)printf("%s: sp inconsistency found but ignored (" "<L%03d>" " sp: %d, calculated sp: %d)\n",
                           RSTRING_PTR(rb_iseq_path(iseq)),
                           lobj->label_no, lobj->sp, sp);
                }
                sp = lobj->sp;
                break;
            }
          case ISEQ_ELEMENT_ADJUST:
            {
                ADJUST *adjust = (ADJUST *)list;
                int orig_sp = sp;
                if (adjust->label) {
                    sp = adjust->label->sp;
                }
                else {
                    sp = 0;
                }
                if (adjust->line_no != -1) {
                    const int diff = orig_sp - sp;
                    if (diff > 0) {
                        if (insns_info_index == 0) {
                            append_compile_error(iseq, adjust->line_no,
                                          "iseq_set_sequence: adjust bug (ISEQ_ELEMENT_ADJUST must not be the first in iseq)");
                        }
                        if (add_adjust_info(insns_info, positions, insns_info_index, code_index, adjust)) insns_info_index++;
                    }
                    if (diff > 1) {
                        generated_iseq[code_index++] = YARVINSN_adjuststack;
                        generated_iseq[code_index++] = orig_sp - sp;
                    }
                    else if (diff == 1) {
                        generated_iseq[code_index++] = YARVINSN_pop;
                    }
                    else if (diff < 0) {
                        int label_no = adjust->label ? adjust->label->label_no : -1;
                        ruby_xfree(generated_iseq);
                        ruby_xfree(insns_info);
                        ruby_xfree(positions);
                        if ((((code_size) + ((sizeof(iseq_bits_t) * 8)) - 1) / ((sizeof(iseq_bits_t) * 8))) > 1) {
                            ruby_xfree(mark_offset_bits);
                        }
                        ((void)0);
                        append_compile_error(iseq, adjust->line_no,
                                      "iseq_set_sequence: adjust bug to %d %d < %d",
                                      label_no, orig_sp, sp);
                        return 0;
                    }
                }
                break;
            }
          default:
            break;
        }
        list = list->next;
    }
    body->iseq_encoded = (void *)generated_iseq;
    body->iseq_size = code_index;
    body->stack_max = stack_max;
    if ((((body->iseq_size) + ((sizeof(iseq_bits_t) * 8)) - 1) / ((sizeof(iseq_bits_t) * 8))) == 1) {
        body->mark_bits.single = mark_offset_bits[0];
    }
    else {
        if (needs_bitmap) {
            body->mark_bits.list = mark_offset_bits;
        }
        else {
            body->mark_bits.list = 0;
            ruby_xfree(mark_offset_bits);
        }
    }
    body->insns_info.body = insns_info;
    body->insns_info.positions = positions;
    ((insns_info) = ((struct iseq_insn_info_entry *)ruby_xrealloc2((void *)(insns_info), (insns_info_index), sizeof(struct iseq_insn_info_entry))));
    body->insns_info.body = insns_info;
    ((positions) = ((unsigned int *)ruby_xrealloc2((void *)(positions), (insns_info_index), sizeof(unsigned int))));
    body->insns_info.positions = positions;
    body->insns_info.size = insns_info_index;
    return 1;
}
static int
label_get_position(LABEL *lobj)
{
    return lobj->position;
}
static int
label_get_sp(LABEL *lobj)
{
    return lobj->sp;
}
static int
iseq_set_exception_table(rb_iseq_t *iseq)
{
    const VALUE *tptr, *ptr;
    unsigned int tlen, i;
    struct iseq_catch_table_entry *entry;
    ((iseq)->body)->catch_table = ((void *)0);
    VALUE catch_table_ary = ISEQ_COMPILE_DATA(iseq)->catch_table_ary;
    if (RB_NIL_P(catch_table_ary)) return 1;
    tlen = (int)rb_array_len(catch_table_ary);
    tptr = rb_array_const_ptr(catch_table_ary);
    if (tlen > 0) {
        struct iseq_catch_table *table = ruby_xmalloc(iseq_catch_table_bytes(tlen));
        table->size = tlen;
        for (i = 0; i < table->size; i++) {
            int pos;
            ptr = rb_array_const_ptr(tptr[i]);
            entry = __extension__({
#pragma GCC diagnostic push
           ;
#pragma GCC diagnostic ignored "-Waddress-of-packed-member"
           ; const volatile void *unaligned_member_ptr_result = &(table)->entries[i];
#pragma GCC diagnostic pop
           ; (__typeof__((table)->entries[i]) *)unaligned_member_ptr_result; });
            entry->type = (enum rb_catch_type)(ptr[0] & 0xffff);
            pos = label_get_position((LABEL *)(ptr[1] & ~1));
            ((void)0);
            entry->start = (unsigned int)pos;
            pos = label_get_position((LABEL *)(ptr[2] & ~1));
            ((void)0);
            entry->end = (unsigned int)pos;
            entry->iseq = (rb_iseq_t *)ptr[3];
            (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(entry->iseq), "compile.c", 2896));
            if (ptr[4]) {
                LABEL *lobj = (LABEL *)(ptr[4] & ~1);
                entry->cont = label_get_position(lobj);
                entry->sp = label_get_sp(lobj);
                if (entry->type == CATCH_TYPE_RESCUE ||
                    entry->type == CATCH_TYPE_BREAK ||
                    entry->type == CATCH_TYPE_NEXT) {
                    ((void)0);
                    entry->sp--;
                }
            }
            else {
                entry->cont = 0;
            }
        }
        ((iseq)->body)->catch_table = table;
        (rb_obj_write((VALUE)(iseq), (VALUE *)(&ISEQ_COMPILE_DATA(iseq)->catch_table_ary), (VALUE)(0), "compile.c", 2917));
    }
    (*__extension__ ({ volatile VALUE *rb_gc_guarded_ptr = &(catch_table_ary); __asm__("" : : "m"(rb_gc_guarded_ptr)); rb_gc_guarded_ptr; }));
    return 1;
}
static int
iseq_set_optargs_table(rb_iseq_t *iseq)
{
    int i;
    VALUE *opt_table = (VALUE *)((iseq)->body)->param.opt_table;
    if (((iseq)->body)->param.flags.has_opt) {
        for (i = 0; i < ((iseq)->body)->param.opt_num + 1; i++) {
            opt_table[i] = label_get_position((LABEL *)opt_table[i]);
        }
    }
    return 1;
}
static LINK_ELEMENT *
get_destination_insn(INSN *iobj)
{
    LABEL *lobj = (LABEL *)(((INSN*)(iobj))->operands[(0)]);
    LINK_ELEMENT *list;
    rb_event_flag_t events = 0;
    list = lobj->link.next;
    while (list) {
        switch (list->type) {
          case ISEQ_ELEMENT_INSN:
          case ISEQ_ELEMENT_ADJUST:
            goto found;
          case ISEQ_ELEMENT_LABEL:
            break;
          case ISEQ_ELEMENT_TRACE:
            {
                TRACE *trace = (TRACE *)list;
                events |= trace->event;
            }
            break;
          default: break;
        }
        list = list->next;
    }
  found:
    if (list && ((list)->type == ISEQ_ELEMENT_INSN)) {
        INSN *iobj = (INSN *)list;
        iobj->insn_info.events |= events;
    }
    return list;
}
static LINK_ELEMENT *
get_next_insn(INSN *iobj)
{
    LINK_ELEMENT *list = iobj->link.next;
    while (list) {
        if (((list)->type == ISEQ_ELEMENT_INSN) || ((list)->type == ISEQ_ELEMENT_ADJUST)) {
            return list;
        }
        list = list->next;
    }
    return 0;
}
static LINK_ELEMENT *
get_prev_insn(INSN *iobj)
{
    LINK_ELEMENT *list = iobj->link.prev;
    while (list) {
        if (((list)->type == ISEQ_ELEMENT_INSN) || ((list)->type == ISEQ_ELEMENT_ADJUST)) {
            return list;
        }
        list = list->prev;
    }
    return 0;
}
static void
unref_destination(INSN *iobj, int pos)
{
    LABEL *lobj = (LABEL *)(((INSN*)(iobj))->operands[(pos)]);
    --lobj->refcnt;
    if (!lobj->refcnt) ELEM_REMOVE(&lobj->link);
}
static _Bool
replace_destination(INSN *dobj, INSN *nobj)
{
    VALUE n = (((INSN*)(nobj))->operands[(0)]);
    LABEL *dl = (LABEL *)(((INSN*)(dobj))->operands[(0)]);
    LABEL *nl = (LABEL *)n;
    if (dl == nl) return 0;
    --dl->refcnt;
    ++nl->refcnt;
    (((INSN*)(dobj))->operands[(0)]) = n;
    if (!dl->refcnt) ELEM_REMOVE(&dl->link);
    return 1;
}
static LABEL*
find_destination(INSN *i)
{
    int pos, len = insn_len(i->insn_id);
    for (pos = 0; pos < len; ++pos) {
        if (insn_op_types(i->insn_id)[pos] == TS_OFFSET) {
            return (LABEL *)(((INSN*)(i))->operands[(pos)]);
        }
    }
    return 0;
}
static int
remove_unreachable_chunk(rb_iseq_t *iseq, LINK_ELEMENT *i)
{
    LINK_ELEMENT *first = i, *end;
    int *unref_counts = 0, nlabels = ISEQ_COMPILE_DATA(iseq)->label_no;
    if (!i) return 0;
    unref_counts = ((int *)__builtin_alloca (rbimpl_size_mul_or_raise(sizeof(int), (nlabels))));
    memset((unref_counts), 0, rbimpl_size_mul_or_raise(sizeof(int), (nlabels)));
    end = i;
    do {
        LABEL *lab;
        if (((i)->type == ISEQ_ELEMENT_INSN)) {
            if (((((INSN*)(i))->insn_id) == YARVINSN_leave)) {
                end = i;
                break;
            }
            else if ((lab = find_destination((INSN *)i)) != 0) {
                unref_counts[lab->label_no]++;
            }
        }
        else if (((i)->type == ISEQ_ELEMENT_LABEL)) {
            lab = (LABEL *)i;
            if (lab->unremovable) return 0;
            if (lab->refcnt > unref_counts[lab->label_no]) {
                if (i == first) return 0;
                break;
            }
            continue;
        }
        else if (((i)->type == ISEQ_ELEMENT_TRACE)) {
        }
        else if (((i)->type == ISEQ_ELEMENT_ADJUST)) {
            return 0;
        }
        end = i;
    } while ((i = i->next) != 0);
    i = first;
    do {
        if (((i)->type == ISEQ_ELEMENT_INSN)) {
            struct rb_iseq_constant_body *body = ((iseq)->body);
            VALUE insn = (((INSN*)(i))->insn_id);
            int pos, len = insn_len(insn);
            for (pos = 0; pos < len; ++pos) {
                switch (insn_op_types(insn)[pos]) {
                  case TS_OFFSET:
                    unref_destination((INSN *)i, pos);
                    break;
                  case TS_CALLDATA:
                    --(body->ci_size);
                    break;
                }
            }
        }
        ELEM_REMOVE(i);
    } while ((i != end) && (i = i->next) != 0);
    return 1;
}
static int
iseq_pop_newarray(rb_iseq_t *iseq, INSN *iobj)
{
    switch ((((INSN*)(iobj))->operands[(0)])) {
      case __builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)):
        ELEM_REMOVE(&iobj->link);
        return 1;
      case __builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)):
        ELEM_REMOVE(&iobj->link);
        return 0;
      default:
        iobj->insn_id = YARVINSN_adjuststack;
        return 1;
    }
}
static int
is_frozen_putstring(INSN *insn, VALUE *op)
{
    if (((((INSN*)(insn))->insn_id) == YARVINSN_putstring) || ((((INSN*)(insn))->insn_id) == YARVINSN_putchilledstring)) {
        *op = (((INSN*)(insn))->operands[(0)]);
        return 1;
    }
    else if (((((INSN*)(insn))->insn_id) == YARVINSN_putobject)) {
        *op = (((INSN*)(insn))->operands[(0)]);
        return RB_TYPE_P(*op, RUBY_T_STRING);
    }
    return 0;
}
static int
optimize_checktype(rb_iseq_t *iseq, INSN *iobj)
{
    int line, node_id;
    INSN *niobj, *ciobj, *dup = 0;
    LABEL *dest = 0;
    VALUE type;
    switch ((((INSN*)(iobj))->insn_id)) {
      case YARVINSN_putstring:
      case YARVINSN_putchilledstring:
        type = __builtin_choose_expr( __builtin_constant_p(RUBY_T_STRING), ((VALUE)(RUBY_T_STRING)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(RUBY_T_STRING));
        break;
      case YARVINSN_putnil:
        type = __builtin_choose_expr( __builtin_constant_p(RUBY_T_NIL), ((VALUE)(RUBY_T_NIL)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(RUBY_T_NIL));
        break;
      case YARVINSN_putobject:
        type = __builtin_choose_expr( __builtin_constant_p(((int)rb_type((((INSN*)(iobj))->operands[(0)])))), ((VALUE)(((int)rb_type((((INSN*)(iobj))->operands[(0)]))))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(((int)rb_type((((INSN*)(iobj))->operands[(0)])))));
        break;
      default: return 0;
    }
    ciobj = (INSN *)get_next_insn(iobj);
    if (((((INSN*)(ciobj))->insn_id) == YARVINSN_jump)) {
        ciobj = (INSN *)get_next_insn((INSN*)(((INSN*)(ciobj))->operands[(0)]));
    }
    if (((((INSN*)(ciobj))->insn_id) == YARVINSN_dup)) {
        ciobj = (INSN *)get_next_insn(dup = ciobj);
    }
    if (!ciobj || !((((INSN*)(ciobj))->insn_id) == YARVINSN_checktype)) return 0;
    niobj = (INSN *)get_next_insn(ciobj);
    if (!niobj) {
        return 0;
    }
    switch ((((INSN*)(niobj))->insn_id)) {
      case YARVINSN_branchif:
        if ((((INSN*)(ciobj))->operands[(0)]) == type) {
            dest = (LABEL *)(((INSN*)(niobj))->operands[(0)]);
        }
        break;
      case YARVINSN_branchunless:
        if ((((INSN*)(ciobj))->operands[(0)]) != type) {
            dest = (LABEL *)(((INSN*)(niobj))->operands[(0)]);
        }
        break;
      default:
        return 0;
    }
    line = ciobj->insn_info.line_no;
    node_id = ciobj->insn_info.node_id;
    if (!dest) {
        if (niobj->link.next && ((niobj->link.next)->type == ISEQ_ELEMENT_LABEL)) {
            dest = (LABEL *)niobj->link.next;
        }
        else {
            dest = new_label_body(iseq, (line));
            ELEM_INSERT_NEXT(&niobj->link, &dest->link);
        }
    }
    ELEM_INSERT_NEXT(&(iobj)->link, (LINK_ELEMENT *) new_insn_body(iseq, line, node_id, YARVINSN_jump, 1, (VALUE)(dest)));
    ((dest)->refcnt++);
    if (!dup) ELEM_INSERT_NEXT(&(iobj)->link, (LINK_ELEMENT *) new_insn_body(iseq, line, node_id, YARVINSN_pop, 0));
    return 1;
}
static const struct rb_callinfo *
ci_flag_set(const rb_iseq_t *iseq, const struct rb_callinfo *ci, unsigned int add)
{
    const struct rb_callinfo *nci = vm_ci_new_(vm_ci_mid(ci), vm_ci_flag(ci) | add, vm_ci_argc(ci), vm_ci_kwarg(ci), "compile.c", 3224);
    (rb_obj_written((VALUE)(iseq), (VALUE)(ci), (VALUE)(nci), "compile.c", 3228));
    return nci;
}
static const struct rb_callinfo *
ci_argc_set(const rb_iseq_t *iseq, const struct rb_callinfo *ci, int argc)
{
    const struct rb_callinfo *nci = vm_ci_new_(vm_ci_mid(ci), vm_ci_flag(ci), argc, vm_ci_kwarg(ci), "compile.c", 3235);
    (rb_obj_written((VALUE)(iseq), (VALUE)(ci), (VALUE)(nci), "compile.c", 3239));
    return nci;
}
static int
iseq_peephole_optimize(rb_iseq_t *iseq, LINK_ELEMENT *list, const int do_tailcallopt)
{
    INSN *const iobj = (INSN *)list;
  again:
    optimize_checktype(iseq, iobj);
    if (((((INSN*)(iobj))->insn_id) == YARVINSN_jump)) {
        INSN *niobj, *diobj, *piobj;
        diobj = (INSN *)get_destination_insn(iobj);
        niobj = (INSN *)get_next_insn(iobj);
        if (diobj == niobj) {
            unref_destination(iobj, 0);
            ELEM_REMOVE(&iobj->link);
            return 1;
        }
        else if (iobj != diobj && ((&diobj->link)->type == ISEQ_ELEMENT_INSN) &&
                 ((((INSN*)(diobj))->insn_id) == YARVINSN_jump) &&
                 (((INSN*)(iobj))->operands[(0)]) != (((INSN*)(diobj))->operands[(0)]) &&
                 diobj->insn_info.events == 0) {
            if (replace_destination(iobj, diobj)) {
                remove_unreachable_chunk(iseq, iobj->link.next);
                goto again;
            }
        }
        else if (((((INSN*)(diobj))->insn_id) == YARVINSN_leave)) {
            unref_destination(iobj, 0);
            iobj->insn_id = YARVINSN_leave;
            iobj->operand_size = 0;
            iobj->insn_info = diobj->insn_info;
            goto again;
        }
        else if (((iobj->link.prev)->type == ISEQ_ELEMENT_INSN) &&
                 (piobj = (INSN *)iobj->link.prev) &&
                 (((((INSN*)(piobj))->insn_id) == YARVINSN_branchif) ||
                  ((((INSN*)(piobj))->insn_id) == YARVINSN_branchunless))) {
            INSN *pdiobj = (INSN *)get_destination_insn(piobj);
            if (niobj == pdiobj) {
                int refcnt = ((piobj->link.next)->type == ISEQ_ELEMENT_LABEL) ?
                    ((LABEL *)piobj->link.next)->refcnt : 0;
                piobj->insn_id = (((((INSN*)(piobj))->insn_id) == YARVINSN_branchif))
                  ? YARVINSN_branchunless : YARVINSN_branchif;
                if (replace_destination(piobj, iobj) && refcnt <= 1) {
                    ELEM_REMOVE(&iobj->link);
                }
                else {
                }
                return 1;
            }
            else if (diobj == pdiobj) {
                INSN *popiobj = new_insn_core(iseq, iobj->insn_info.line_no, iobj->insn_info.node_id, YARVINSN_pop, 0, 0);
                ELEM_REPLACE(&piobj->link, &popiobj->link);
            }
        }
        if (remove_unreachable_chunk(iseq, iobj->link.next)) {
            goto again;
        }
    }
    if (((((INSN*)(iobj))->insn_id) == YARVINSN_newrange)) {
        INSN *const range = iobj;
        INSN *beg, *end;
        VALUE str_beg, str_end;
        if ((end = (INSN *)get_prev_insn(range)) != 0 &&
                is_frozen_putstring(end, &str_end) &&
                (beg = (INSN *)get_prev_insn(end)) != 0 &&
                is_frozen_putstring(beg, &str_beg)) {
            int excl = RB_FIX2INT((((INSN*)(range))->operands[(0)]));
            VALUE lit_range = rb_range_new(str_beg, str_end, excl);
            ELEM_REMOVE(&beg->link);
            ELEM_REMOVE(&end->link);
            range->insn_id = YARVINSN_putobject;
            (((INSN*)(range))->operands[(0)]) = lit_range;
            (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(lit_range), "compile.c", 3387));
        }
    }
    if (((((INSN*)(iobj))->insn_id) == YARVINSN_leave)) {
        remove_unreachable_chunk(iseq, iobj->link.next);
    }
    if (((((INSN*)(iobj))->insn_id) == YARVINSN_duparray)) {
        LINK_ELEMENT *next = iobj->link.next;
        if (((next)->type == ISEQ_ELEMENT_INSN) && (((((INSN*)(next))->insn_id) == YARVINSN_concatarray) || ((((INSN*)(next))->insn_id) == YARVINSN_concattoarray))) {
            iobj->insn_id = YARVINSN_putobject;
        }
    }
    if (((((INSN*)(iobj))->insn_id) == YARVINSN_duparray)) {
        LINK_ELEMENT *next = iobj->link.next;
        if (((next)->type == ISEQ_ELEMENT_INSN) && (((((INSN*)(next))->insn_id) == YARVINSN_send))) {
            const struct rb_callinfo *ci = (struct rb_callinfo *)(((INSN*)(next))->operands[(0)]);
            const rb_iseq_t *blockiseq = (rb_iseq_t *)(((INSN*)(next))->operands[(1)]);
            if ((vm_ci_flag(ci) & (0x01 << VM_CALL_ARGS_SIMPLE_bit)) && vm_ci_argc(ci) == 0 && blockiseq == ((void *)0) && vm_ci_mid(ci) == idFreeze) {
                VALUE ary = iobj->operands[0];
                rb_obj_reveal(ary, rb_cArray);
                iobj->insn_id = YARVINSN_opt_ary_freeze;
                iobj->operand_size = 2;
                iobj->operands = compile_data_calloc2(iseq, iobj->operand_size, sizeof(VALUE));
                iobj->operands[0] = ary;
                iobj->operands[1] = (VALUE)ci;
                ELEM_REMOVE(next);
            }
        }
    }
    if (((((INSN*)(iobj))->insn_id) == YARVINSN_duphash)) {
        LINK_ELEMENT *next = iobj->link.next;
        if (((next)->type == ISEQ_ELEMENT_INSN) && (((((INSN*)(next))->insn_id) == YARVINSN_send))) {
            const struct rb_callinfo *ci = (struct rb_callinfo *)(((INSN*)(next))->operands[(0)]);
            const rb_iseq_t *blockiseq = (rb_iseq_t *)(((INSN*)(next))->operands[(1)]);
            if ((vm_ci_flag(ci) & (0x01 << VM_CALL_ARGS_SIMPLE_bit)) && vm_ci_argc(ci) == 0 && blockiseq == ((void *)0) && vm_ci_mid(ci) == idFreeze) {
                VALUE hash = iobj->operands[0];
                rb_obj_reveal(hash, rb_cHash);
                iobj->insn_id = YARVINSN_opt_hash_freeze;
                iobj->operand_size = 2;
                iobj->operands = compile_data_calloc2(iseq, iobj->operand_size, sizeof(VALUE));
                iobj->operands[0] = hash;
                iobj->operands[1] = (VALUE)ci;
                ELEM_REMOVE(next);
            }
        }
    }
    if (((((INSN*)(iobj))->insn_id) == YARVINSN_newarray) && iobj->operands[0] == __builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))) {
        LINK_ELEMENT *next = iobj->link.next;
        if (((next)->type == ISEQ_ELEMENT_INSN) && (((((INSN*)(next))->insn_id) == YARVINSN_send))) {
            const struct rb_callinfo *ci = (struct rb_callinfo *)(((INSN*)(next))->operands[(0)]);
            const rb_iseq_t *blockiseq = (rb_iseq_t *)(((INSN*)(next))->operands[(1)]);
            if ((vm_ci_flag(ci) & (0x01 << VM_CALL_ARGS_SIMPLE_bit)) && vm_ci_argc(ci) == 0 && blockiseq == ((void *)0) && vm_ci_mid(ci) == idFreeze) {
                iobj->insn_id = YARVINSN_opt_ary_freeze;
                iobj->operand_size = 2;
                iobj->operands = compile_data_calloc2(iseq, iobj->operand_size, sizeof(VALUE));
                iobj->operands[0] = rb_cArray_empty_frozen;
                iobj->operands[1] = (VALUE)ci;
                ELEM_REMOVE(next);
            }
        }
    }
    if (((((INSN*)(iobj))->insn_id) == YARVINSN_newhash) && iobj->operands[0] == __builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))) {
        LINK_ELEMENT *next = iobj->link.next;
        if (((next)->type == ISEQ_ELEMENT_INSN) && (((((INSN*)(next))->insn_id) == YARVINSN_send))) {
            const struct rb_callinfo *ci = (struct rb_callinfo *)(((INSN*)(next))->operands[(0)]);
            const rb_iseq_t *blockiseq = (rb_iseq_t *)(((INSN*)(next))->operands[(1)]);
            if ((vm_ci_flag(ci) & (0x01 << VM_CALL_ARGS_SIMPLE_bit)) && vm_ci_argc(ci) == 0 && blockiseq == ((void *)0) && vm_ci_mid(ci) == idFreeze) {
                iobj->insn_id = YARVINSN_opt_hash_freeze;
                iobj->operand_size = 2;
                iobj->operands = compile_data_calloc2(iseq, iobj->operand_size, sizeof(VALUE));
                iobj->operands[0] = rb_cHash_empty_frozen;
                iobj->operands[1] = (VALUE)ci;
                ELEM_REMOVE(next);
            }
        }
    }
    if (((((INSN*)(iobj))->insn_id) == YARVINSN_branchif) ||
        ((((INSN*)(iobj))->insn_id) == YARVINSN_branchnil) ||
        ((((INSN*)(iobj))->insn_id) == YARVINSN_branchunless)) {
        INSN *nobj = (INSN *)get_destination_insn(iobj);
        int stop_optimization =
            ((iseq)->body)->variable.coverage && RARRAY_AREF(((iseq)->body)->variable.coverage, 0) &&
            nobj->link.type == ISEQ_ELEMENT_INSN &&
            nobj->insn_info.events;
        if (!stop_optimization) {
            INSN *pobj = (INSN *)iobj->link.prev;
            int prev_dup = 0;
            if (pobj) {
                if (!((&pobj->link)->type == ISEQ_ELEMENT_INSN))
                    pobj = 0;
                else if (((((INSN*)(pobj))->insn_id) == YARVINSN_dup))
                    prev_dup = 1;
            }
            for (;;) {
                if (((&nobj->link)->type == ISEQ_ELEMENT_INSN) && ((((INSN*)(nobj))->insn_id) == YARVINSN_jump)) {
                    if (!replace_destination(iobj, nobj)) break;
                }
                else if (prev_dup && ((((INSN*)(nobj))->insn_id) == YARVINSN_dup) &&
                         !!(nobj = (INSN *)nobj->link.next) &&
                         nobj->insn_id == iobj->insn_id) {
                    if (!replace_destination(iobj, nobj)) break;
                }
                else if (pobj) {
                    int cond;
                    if (prev_dup && ((pobj->link.prev)->type == ISEQ_ELEMENT_INSN)) {
                        pobj = (INSN *)pobj->link.prev;
                    }
                    if (((((INSN*)(pobj))->insn_id) == YARVINSN_putobject)) {
                        cond = (((((INSN*)(iobj))->insn_id) == YARVINSN_branchif) ?
                                (((INSN*)(pobj))->operands[(0)]) != ((VALUE)RUBY_Qfalse) :
                                ((((INSN*)(iobj))->insn_id) == YARVINSN_branchunless) ?
                                (((INSN*)(pobj))->operands[(0)]) == ((VALUE)RUBY_Qfalse) :
                                0);
                    }
                    else if (((((INSN*)(pobj))->insn_id) == YARVINSN_putstring) ||
                             ((((INSN*)(pobj))->insn_id) == YARVINSN_duparray) ||
                             ((((INSN*)(pobj))->insn_id) == YARVINSN_newarray)) {
                        cond = ((((INSN*)(iobj))->insn_id) == YARVINSN_branchif);
                    }
                    else if (((((INSN*)(pobj))->insn_id) == YARVINSN_putnil)) {
                        cond = !((((INSN*)(iobj))->insn_id) == YARVINSN_branchif);
                    }
                    else break;
                    if (prev_dup || !((((INSN*)(pobj))->insn_id) == YARVINSN_newarray)) {
                        ELEM_REMOVE(iobj->link.prev);
                    }
                    else if (!iseq_pop_newarray(iseq, pobj)) {
                        pobj = new_insn_core(iseq, pobj->insn_info.line_no, pobj->insn_info.node_id, YARVINSN_pop, 0, ((void *)0));
                        ELEM_INSERT_PREV(&iobj->link, &pobj->link);
                    }
                    if (cond) {
                        if (prev_dup) {
                            pobj = new_insn_core(iseq, pobj->insn_info.line_no, pobj->insn_info.node_id, YARVINSN_putnil, 0, ((void *)0));
                            ELEM_INSERT_NEXT(&iobj->link, &pobj->link);
                        }
                        iobj->insn_id = YARVINSN_jump;
                        goto again;
                    }
                    else {
                        unref_destination(iobj, 0);
                        ELEM_REMOVE(&iobj->link);
                    }
                    break;
                }
                else break;
                nobj = (INSN *)get_destination_insn(nobj);
            }
        }
    }
    if (((((INSN*)(iobj))->insn_id) == YARVINSN_pop)) {
        LINK_ELEMENT *prev = iobj->link.prev;
        if (((prev)->type == ISEQ_ELEMENT_INSN)) {
            enum ruby_vminsn_type previ = ((INSN *)prev)->insn_id;
            if (previ == YARVINSN_putobject || previ == YARVINSN_putnil ||
                previ == YARVINSN_putself || previ == YARVINSN_putstring ||
                previ == YARVINSN_putchilledstring ||
                previ == YARVINSN_dup ||
                previ == YARVINSN_getlocal ||
                previ == YARVINSN_getblockparam ||
                previ == YARVINSN_getblockparamproxy ||
                previ == YARVINSN_getinstancevariable ||
                previ == YARVINSN_duparray) {
                ELEM_REMOVE(prev);
                ELEM_REMOVE(&iobj->link);
            }
            else if (previ == YARVINSN_newarray && iseq_pop_newarray(iseq, (INSN*)prev)) {
                ELEM_REMOVE(&iobj->link);
            }
            else if (previ == YARVINSN_concatarray) {
                INSN *piobj = (INSN *)prev;
                ELEM_INSERT_PREV(&(piobj)->link, (LINK_ELEMENT *) new_insn_body(iseq, piobj->insn_info.line_no, piobj->insn_info.node_id, YARVINSN_splatarray, 1, (VALUE)(((VALUE)RUBY_Qfalse))));
                (((INSN*)(piobj))->insn_id) = YARVINSN_pop;
            }
            else if (previ == YARVINSN_concatstrings) {
                if ((((INSN*)(prev))->operands[(0)]) == __builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1))) {
                    ELEM_REMOVE(prev);
                }
                else {
                    ELEM_REMOVE(&iobj->link);
                    (((INSN*)(prev))->insn_id) = YARVINSN_adjuststack;
                }
            }
        }
    }
    if (((((INSN*)(iobj))->insn_id) == YARVINSN_newarray) ||
        ((((INSN*)(iobj))->insn_id) == YARVINSN_duparray) ||
        ((((INSN*)(iobj))->insn_id) == YARVINSN_concatarray) ||
        ((((INSN*)(iobj))->insn_id) == YARVINSN_splatarray) ||
        0) {
        LINK_ELEMENT *next = iobj->link.next;
        if (((next)->type == ISEQ_ELEMENT_INSN) && ((((INSN*)(next))->insn_id) == YARVINSN_splatarray)) {
            ELEM_REMOVE(next);
        }
    }
    if (((((INSN*)(iobj))->insn_id) == YARVINSN_newarray)) {
        LINK_ELEMENT *next = iobj->link.next;
        if (((next)->type == ISEQ_ELEMENT_INSN) && ((((INSN*)(next))->insn_id) == YARVINSN_expandarray) &&
            (((INSN*)(next))->operands[(1)]) == __builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))) {
            VALUE op1, op2;
            op1 = (((INSN*)(iobj))->operands[(0)]);
            op2 = (((INSN*)(next))->operands[(0)]);
            ELEM_REMOVE(next);
            if (op1 == op2) {
                if (op1 == __builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2))) {
                    (((INSN*)(iobj))->insn_id) = YARVINSN_swap;
                    iobj->operand_size = 0;
                }
                else {
                    (((INSN*)(iobj))->insn_id) = YARVINSN_opt_reverse;
                }
            }
            else {
                long diff = rb_fix2long(op1) - rb_fix2long(op2);
                (((INSN*)(iobj))->insn_id) = YARVINSN_opt_reverse;
                (((INSN*)(iobj))->operands[(0)]) = (((INSN*)(next))->operands[(0)]);
                if (op1 > op2) {
                    for (; diff > 0; diff--) {
                        ELEM_INSERT_PREV(&(iobj)->link, (LINK_ELEMENT *) new_insn_body(iseq, iobj->insn_info.line_no, iobj->insn_info.node_id, YARVINSN_pop, 0));
                    }
                }
                else {
                    for (; diff < 0; diff++) {
                        ELEM_INSERT_PREV(&(iobj)->link, (LINK_ELEMENT *) new_insn_body(iseq, iobj->insn_info.line_no, iobj->insn_info.node_id, YARVINSN_putnil, 0));
                    }
                }
            }
        }
    }
    if (((((INSN*)(iobj))->insn_id) == YARVINSN_duparray)) {
        LINK_ELEMENT *next = iobj->link.next;
        if (((next)->type == ISEQ_ELEMENT_INSN) && ((((INSN*)(next))->insn_id) == YARVINSN_expandarray)) {
            (((INSN*)(iobj))->insn_id) = YARVINSN_putobject;
        }
    }
    if (((((INSN*)(iobj))->insn_id) == YARVINSN_anytostring)) {
        LINK_ELEMENT *next = iobj->link.next;
        if (((next)->type == ISEQ_ELEMENT_INSN) && ((((INSN*)(next))->insn_id) == YARVINSN_concatstrings) &&
            (((INSN*)(next))->operands[(0)]) == __builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1))) {
            ELEM_REMOVE(next);
        }
    }
    if (((((INSN*)(iobj))->insn_id) == YARVINSN_putstring) || ((((INSN*)(iobj))->insn_id) == YARVINSN_putchilledstring) ||
        (((((INSN*)(iobj))->insn_id) == YARVINSN_putobject) && RB_TYPE_P((((INSN*)(iobj))->operands[(0)]), RUBY_T_STRING))) {
        if (((&iobj->link)->next && (((&iobj->link)->next)->type == ISEQ_ELEMENT_INSN) && ((((INSN*)((&iobj->link)->next))->insn_id) == YARVINSN_concatstrings)) &&
            RSTRING_LEN((((INSN*)(iobj))->operands[(0)])) == 0) {
            INSN *next = (INSN *)iobj->link.next;
            if (((((INSN*)(next))->operands[(0)]) = (((((INSN*)(next))->operands[(0)]))+(__builtin_choose_expr( __builtin_constant_p(-1), ((VALUE)(-1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(-1))&~RUBY_FIXNUM_FLAG))) == __builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1))) {
                ELEM_REMOVE(&next->link);
            }
            ELEM_REMOVE(&iobj->link);
        }
    }
    if (((((INSN*)(iobj))->insn_id) == YARVINSN_concatstrings)) {
        LINK_ELEMENT *next = iobj->link.next;
        INSN *jump = 0;
        if (((next)->type == ISEQ_ELEMENT_INSN) && ((((INSN*)(next))->insn_id) == YARVINSN_jump))
            next = get_destination_insn(jump = (INSN *)next);
        if (((next)->type == ISEQ_ELEMENT_INSN) && ((((INSN*)(next))->insn_id) == YARVINSN_concatstrings)) {
            int n = RB_FIX2INT((((INSN*)(iobj))->operands[(0)])) + RB_FIX2INT((((INSN*)(next))->operands[(0)])) - 1;
            (((INSN*)(iobj))->operands[(0)]) = __builtin_choose_expr( __builtin_constant_p(n), ((VALUE)(n)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(n));
            if (jump) {
                LABEL *label = ((LABEL *)(((INSN*)(jump))->operands[(0)]));
                if (!--label->refcnt) {
                    ELEM_REMOVE(&label->link);
                }
                else {
                    label = new_label_body(iseq, (0));
                    (((INSN*)(jump))->operands[(0)]) = (VALUE)label;
                }
                label->refcnt++;
                ELEM_INSERT_NEXT(next, &label->link);
                if (!(iseq_peephole_optimize(iseq, get_next_insn(jump), do_tailcallopt))) {;return 0;};
            }
            else {
                ELEM_REMOVE(next);
            }
        }
    }
    if (do_tailcallopt &&
        (((((INSN*)(iobj))->insn_id) == YARVINSN_send) ||
         ((((INSN*)(iobj))->insn_id) == YARVINSN_opt_aref_with) ||
         ((((INSN*)(iobj))->insn_id) == YARVINSN_opt_aset_with) ||
         ((((INSN*)(iobj))->insn_id) == YARVINSN_invokesuper))) {
        INSN *piobj = ((void *)0);
        if (iobj->link.next) {
            LINK_ELEMENT *next = iobj->link.next;
            do {
                if (!((next)->type == ISEQ_ELEMENT_INSN)) {
                    next = next->next;
                    continue;
                }
                switch ((((INSN*)(next))->insn_id)) {
                  case YARVINSN_nop:
                    next = next->next;
                    break;
                  case YARVINSN_jump:
                    next = get_destination_insn((INSN *)next);
                    break;
                  case YARVINSN_leave:
                    piobj = iobj;
                  default:
                    next = ((void *)0);
                    break;
                }
            } while (next);
        }
        if (piobj) {
            const struct rb_callinfo *ci = (struct rb_callinfo *)(((INSN*)(piobj))->operands[(0)]);
            if (((((INSN*)(piobj))->insn_id) == YARVINSN_send) ||
                ((((INSN*)(piobj))->insn_id) == YARVINSN_invokesuper)) {
                if ((((INSN*)(piobj))->operands[(1)]) == 0) {
                    ci = ci_flag_set(iseq, ci, (0x01 << VM_CALL_TAILCALL_bit));
                    (((INSN*)(piobj))->operands[(0)]) = (VALUE)ci;
                    (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(ci), "compile.c", 3906));
                }
            }
            else {
                ci = ci_flag_set(iseq, ci, (0x01 << VM_CALL_TAILCALL_bit));
                (((INSN*)(piobj))->operands[(0)]) = (VALUE)ci;
                (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(ci), "compile.c", 3912));
            }
        }
    }
    if (((((INSN*)(iobj))->insn_id) == YARVINSN_dup)) {
        if (((&iobj->link)->next && (((&iobj->link)->next)->type == ISEQ_ELEMENT_INSN) && ((((INSN*)((&iobj->link)->next))->insn_id) == YARVINSN_setlocal))) {
            LINK_ELEMENT *set1 = iobj->link.next, *set2 = ((void *)0);
            if (((set1)->next && (((set1)->next)->type == ISEQ_ELEMENT_INSN) && ((((INSN*)((set1)->next))->insn_id) == YARVINSN_setlocal))) {
                set2 = set1->next;
                if ((((INSN*)(set1))->operands[(0)]) == (((INSN*)(set2))->operands[(0)]) &&
                    (((INSN*)(set1))->operands[(1)]) == (((INSN*)(set2))->operands[(1)])) {
                    ELEM_REMOVE(set1);
                    ELEM_REMOVE(&iobj->link);
                }
            }
            else if (((set1)->next && (((set1)->next)->type == ISEQ_ELEMENT_INSN) && ((((INSN*)((set1)->next))->insn_id) == YARVINSN_dup)) &&
                     ((set1->next)->next && (((set1->next)->next)->type == ISEQ_ELEMENT_INSN) && ((((INSN*)((set1->next)->next))->insn_id) == YARVINSN_setlocal))) {
                set2 = set1->next->next;
                if ((((INSN*)(set1))->operands[(0)]) == (((INSN*)(set2))->operands[(0)]) &&
                    (((INSN*)(set1))->operands[(1)]) == (((INSN*)(set2))->operands[(1)])) {
                    ELEM_REMOVE(set1->next);
                    ELEM_REMOVE(set2);
                }
            }
        }
    }
    if (((((INSN*)(iobj))->insn_id) == YARVINSN_getlocal)) {
        LINK_ELEMENT *niobj = &iobj->link;
        if (((niobj)->next && (((niobj)->next)->type == ISEQ_ELEMENT_INSN) && ((((INSN*)((niobj)->next))->insn_id) == YARVINSN_dup))) {
            niobj = niobj->next;
        }
        if (((niobj)->next && (((niobj)->next)->type == ISEQ_ELEMENT_INSN) && ((((INSN*)((niobj)->next))->insn_id) == YARVINSN_setlocal))) {
            LINK_ELEMENT *set1 = niobj->next;
            if ((((INSN*)(iobj))->operands[(0)]) == (((INSN*)(set1))->operands[(0)]) &&
                (((INSN*)(iobj))->operands[(1)]) == (((INSN*)(set1))->operands[(1)])) {
                ELEM_REMOVE(set1);
                ELEM_REMOVE(niobj);
            }
        }
    }
    if (((((INSN*)(iobj))->insn_id) == YARVINSN_opt_invokebuiltin_delegate)) {
        if (((iobj->link.next)->type == ISEQ_ELEMENT_TRACE)) {
            if (((iobj->link.next)->next && (((iobj->link.next)->next)->type == ISEQ_ELEMENT_INSN) && ((((INSN*)((iobj->link.next)->next))->insn_id) == YARVINSN_leave))) {
                iobj->insn_id = YARVINSN_opt_invokebuiltin_delegate_leave;
                const struct rb_builtin_function *bf = (const struct rb_builtin_function *)iobj->operands[0];
                if (iobj == (INSN *)list && bf->argc == 0 && (iseq->body->builtin_attrs & BUILTIN_ATTR_LEAF)) {
                    iseq->body->builtin_attrs |= BUILTIN_ATTR_SINGLE_NOARG_LEAF;
                }
            }
        }
    }
    if (((((INSN*)(iobj))->insn_id) == YARVINSN_getblockparam)) {
        if (((&iobj->link)->next && (((&iobj->link)->next)->type == ISEQ_ELEMENT_INSN) && ((((INSN*)((&iobj->link)->next))->insn_id) == YARVINSN_branchif)) || ((&iobj->link)->next && (((&iobj->link)->next)->type == ISEQ_ELEMENT_INSN) && ((((INSN*)((&iobj->link)->next))->insn_id) == YARVINSN_branchunless))) {
            iobj->insn_id = YARVINSN_getblockparamproxy;
        }
    }
    if (((((INSN*)(iobj))->insn_id) == YARVINSN_splatarray) && (((INSN*)(iobj))->operands[(0)]) == 0) {
        LINK_ELEMENT *niobj = &iobj->link;
        if (((niobj)->next && (((niobj)->next)->type == ISEQ_ELEMENT_INSN) && ((((INSN*)((niobj)->next))->insn_id) == YARVINSN_duphash))) {
            niobj = niobj->next;
            LINK_ELEMENT *siobj;
            unsigned int set_flags = 0, unset_flags = 0;
            if (((niobj)->next && (((niobj)->next)->type == ISEQ_ELEMENT_INSN) && ((((INSN*)((niobj)->next))->insn_id) == YARVINSN_send))) {
                siobj = niobj->next;
                set_flags = (0x01 << VM_CALL_ARGS_SPLAT_bit)|(0x01 << VM_CALL_KW_SPLAT_bit)|(0x01 << VM_CALL_KW_SPLAT_MUT_bit);
                unset_flags = (0x01 << VM_CALL_ARGS_BLOCKARG_bit);
            }
            else if ((((niobj)->next && (((niobj)->next)->type == ISEQ_ELEMENT_INSN) && ((((INSN*)((niobj)->next))->insn_id) == YARVINSN_getlocal)) || ((niobj)->next && (((niobj)->next)->type == ISEQ_ELEMENT_INSN) && ((((INSN*)((niobj)->next))->insn_id) == YARVINSN_getinstancevariable)) ||
                        ((niobj)->next && (((niobj)->next)->type == ISEQ_ELEMENT_INSN) && ((((INSN*)((niobj)->next))->insn_id) == YARVINSN_getblockparamproxy))) && (((niobj->next)->next && (((niobj->next)->next)->type == ISEQ_ELEMENT_INSN) && ((((INSN*)((niobj->next)->next))->insn_id) == YARVINSN_send)))) {
                siobj = niobj->next->next;
                set_flags = (0x01 << VM_CALL_ARGS_SPLAT_bit)|(0x01 << VM_CALL_KW_SPLAT_bit)|(0x01 << VM_CALL_KW_SPLAT_MUT_bit)|(0x01 << VM_CALL_ARGS_BLOCKARG_bit);
            }
            if (set_flags) {
                const struct rb_callinfo *ci = (const struct rb_callinfo *)(((INSN*)(siobj))->operands[(0)]);
                unsigned int flags = vm_ci_flag(ci);
                if ((flags & set_flags) == set_flags && !(flags & unset_flags)) {
                    ((INSN*)niobj)->insn_id = YARVINSN_putobject;
                    (((INSN*)(niobj))->operands[(0)]) = rb_hash_freeze(rb_hash_resurrect((((INSN*)(niobj))->operands[(0)])));
                    const struct rb_callinfo *nci = vm_ci_new_(vm_ci_mid(ci), flags & ~(0x01 << VM_CALL_KW_SPLAT_MUT_bit), vm_ci_argc(ci), vm_ci_kwarg(ci), "compile.c", 4064);
                    (rb_obj_written((VALUE)(iseq), (VALUE)(ci), (VALUE)(nci), "compile.c", 4066));
                    (((INSN*)(siobj))->operands[(0)]) = (VALUE)nci;
                }
            }
        }
    }
    return 1;
}
static int
insn_set_specialized_instruction(rb_iseq_t *iseq, INSN *iobj, int insn_id)
{
    iobj->insn_id = insn_id;
    iobj->operand_size = insn_len(insn_id) - 1;
    iobj->insn_info.events |= 0x0020 | 0x0040;
    if (insn_id == YARVINSN_opt_neq) {
        VALUE original_ci = iobj->operands[0];
        iobj->operand_size = 2;
        iobj->operands = compile_data_calloc2(iseq, iobj->operand_size, sizeof(VALUE));
        iobj->operands[0] = (VALUE)new_callinfo(iseq, idEq, 1, 0, ((void *)0), 0);
        iobj->operands[1] = original_ci;
    }
    return 1;
}
static int
iseq_specialized_instruction(rb_iseq_t *iseq, INSN *iobj)
{
    if (((((INSN*)(iobj))->insn_id) == YARVINSN_newarray) && iobj->link.next &&
        ((iobj->link.next)->type == ISEQ_ELEMENT_INSN)) {
        INSN *niobj = (INSN *)iobj->link.next;
        if (((((INSN*)(niobj))->insn_id) == YARVINSN_send)) {
            const struct rb_callinfo *ci = (struct rb_callinfo *)(((INSN*)(niobj))->operands[(0)]);
            if ((vm_ci_flag(ci) & (0x01 << VM_CALL_ARGS_SIMPLE_bit)) && vm_ci_argc(ci) == 0) {
                VALUE method = __builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0));
                switch (vm_ci_mid(ci)) {
                  case idMax:
                      method = __builtin_choose_expr( __builtin_constant_p(VM_OPT_NEWARRAY_SEND_MAX), ((VALUE)(VM_OPT_NEWARRAY_SEND_MAX)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_OPT_NEWARRAY_SEND_MAX));
                      break;
                  case idMin:
                      method = __builtin_choose_expr( __builtin_constant_p(VM_OPT_NEWARRAY_SEND_MIN), ((VALUE)(VM_OPT_NEWARRAY_SEND_MIN)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_OPT_NEWARRAY_SEND_MIN));
                      break;
                  case idHash:
                      method = __builtin_choose_expr( __builtin_constant_p(VM_OPT_NEWARRAY_SEND_HASH), ((VALUE)(VM_OPT_NEWARRAY_SEND_HASH)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_OPT_NEWARRAY_SEND_HASH));
                      break;
                }
                if (method != __builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))) {
                    VALUE num = iobj->operands[0];
                    int operand_len = insn_len(YARVINSN_opt_newarray_send) - 1;
                    iobj->insn_id = YARVINSN_opt_newarray_send;
                    iobj->operands = compile_data_calloc2(iseq, operand_len, sizeof(VALUE));
                    iobj->operands[0] = num;
                    iobj->operands[1] = method;
                    iobj->operand_size = operand_len;
                    ELEM_REMOVE(&niobj->link);
                    return 1;
                }
            }
        }
        else if ((((((INSN*)(niobj))->insn_id) == YARVINSN_putstring) || ((((INSN*)(niobj))->insn_id) == YARVINSN_putchilledstring) ||
                  (((((INSN*)(niobj))->insn_id) == YARVINSN_putobject) && RB_TYPE_P((((INSN*)(niobj))->operands[(0)]), RUBY_T_STRING))) &&
                 ((&niobj->link)->next && (((&niobj->link)->next)->type == ISEQ_ELEMENT_INSN) && ((((INSN*)((&niobj->link)->next))->insn_id) == YARVINSN_send))) {
            const struct rb_callinfo *ci = (struct rb_callinfo *)(((INSN*)((INSN *)niobj->link.next))->operands[(0)]);
            if ((vm_ci_flag(ci) & (0x01 << VM_CALL_ARGS_SIMPLE_bit)) && vm_ci_argc(ci) == 1 && vm_ci_mid(ci) == idPack) {
                VALUE num = iobj->operands[0];
                int operand_len = insn_len(YARVINSN_opt_newarray_send) - 1;
                iobj->insn_id = YARVINSN_opt_newarray_send;
                iobj->operands = compile_data_calloc2(iseq, operand_len, sizeof(VALUE));
                iobj->operands[0] = ((num)+(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1))&~RUBY_FIXNUM_FLAG));
                iobj->operands[1] = __builtin_choose_expr( __builtin_constant_p(VM_OPT_NEWARRAY_SEND_PACK), ((VALUE)(VM_OPT_NEWARRAY_SEND_PACK)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_OPT_NEWARRAY_SEND_PACK));
                iobj->operand_size = operand_len;
                ELEM_REMOVE(&iobj->link);
                ELEM_REMOVE(niobj->link.next);
                ELEM_INSERT_NEXT(&niobj->link, &iobj->link);
                return 1;
            }
        }
        else if ((((((INSN*)(niobj))->insn_id) == YARVINSN_putstring) || ((((INSN*)(niobj))->insn_id) == YARVINSN_putchilledstring) ||
                  (((((INSN*)(niobj))->insn_id) == YARVINSN_putobject) && RB_TYPE_P((((INSN*)(niobj))->operands[(0)]), RUBY_T_STRING))) &&
                 ((&niobj->link)->next && (((&niobj->link)->next)->type == ISEQ_ELEMENT_INSN) && ((((INSN*)((&niobj->link)->next))->insn_id) == YARVINSN_getlocal)) &&
                 (niobj->link.next && ((niobj->link.next)->next && (((niobj->link.next)->next)->type == ISEQ_ELEMENT_INSN) && ((((INSN*)((niobj->link.next)->next))->insn_id) == YARVINSN_send)))) {
            const struct rb_callinfo *ci = (struct rb_callinfo *)(((INSN*)((INSN *)(niobj->link.next)->next))->operands[(0)]);
            const struct rb_callinfo_kwarg *kwarg = vm_ci_kwarg(ci);
            if (vm_ci_mid(ci) == idPack && vm_ci_argc(ci) == 2 &&
                    (kwarg && kwarg->keyword_len == 1 && kwarg->keywords[0] == rb_id2sym(idBuffer))) {
                VALUE num = iobj->operands[0];
                int operand_len = insn_len(YARVINSN_opt_newarray_send) - 1;
                iobj->insn_id = YARVINSN_opt_newarray_send;
                iobj->operands = compile_data_calloc2(iseq, operand_len, sizeof(VALUE));
                iobj->operands[0] = ((num)+(__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2))&~RUBY_FIXNUM_FLAG));
                iobj->operands[1] = __builtin_choose_expr( __builtin_constant_p(VM_OPT_NEWARRAY_SEND_PACK_BUFFER), ((VALUE)(VM_OPT_NEWARRAY_SEND_PACK_BUFFER)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_OPT_NEWARRAY_SEND_PACK_BUFFER));
                iobj->operand_size = operand_len;
                ELEM_REMOVE((niobj->link.next)->next);
                ELEM_REMOVE(&iobj->link);
                ELEM_INSERT_NEXT(niobj->link.next, &iobj->link);
                return 1;
            }
        }
        if ((((((INSN*)(niobj))->insn_id) == YARVINSN_putstring) || ((((INSN*)(niobj))->insn_id) == YARVINSN_putchilledstring) ||
                  ((((INSN*)(niobj))->insn_id) == YARVINSN_putobject) ||
                  ((((INSN*)(niobj))->insn_id) == YARVINSN_putself) ||
                  ((((INSN*)(niobj))->insn_id) == YARVINSN_getlocal) ||
                  ((((INSN*)(niobj))->insn_id) == YARVINSN_getinstancevariable)) &&
                 ((&niobj->link)->next && (((&niobj->link)->next)->type == ISEQ_ELEMENT_INSN) && ((((INSN*)((&niobj->link)->next))->insn_id) == YARVINSN_send))) {
            LINK_ELEMENT *sendobj = &(niobj->link);
            const struct rb_callinfo *ci;
            do {
                sendobj = sendobj->next;
                ci = (struct rb_callinfo *)(((INSN*)(sendobj))->operands[(0)]);
            } while ((vm_ci_flag(ci) & (0x01 << VM_CALL_ARGS_SIMPLE_bit)) && vm_ci_argc(ci) == 0 && ((sendobj)->next && (((sendobj)->next)->type == ISEQ_ELEMENT_INSN) && ((((INSN*)((sendobj)->next))->insn_id) == YARVINSN_send)));
            if ((vm_ci_flag(ci) & (0x01 << VM_CALL_ARGS_SIMPLE_bit)) && vm_ci_argc(ci) == 1 && vm_ci_mid(ci) == idIncludeP) {
                VALUE num = iobj->operands[0];
                INSN *sendins = (INSN *)sendobj;
                sendins->insn_id = YARVINSN_opt_newarray_send;
                sendins->operand_size = insn_len(sendins->insn_id) - 1;
                sendins->operands = compile_data_calloc2(iseq, sendins->operand_size, sizeof(VALUE));
                sendins->operands[0] = ((num)+(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1))&~RUBY_FIXNUM_FLAG));
                sendins->operands[1] = __builtin_choose_expr( __builtin_constant_p(VM_OPT_NEWARRAY_SEND_INCLUDE_P), ((VALUE)(VM_OPT_NEWARRAY_SEND_INCLUDE_P)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_OPT_NEWARRAY_SEND_INCLUDE_P));
                ELEM_REMOVE(&iobj->link);
                return 1;
            }
        }
    }
    if (((((INSN*)(iobj))->insn_id) == YARVINSN_duparray) && iobj->link.next && ((iobj->link.next)->type == ISEQ_ELEMENT_INSN)) {
        INSN *niobj = (INSN *)iobj->link.next;
        if ((((((INSN*)(niobj))->insn_id) == YARVINSN_getlocal) ||
             ((((INSN*)(niobj))->insn_id) == YARVINSN_getinstancevariable) ||
             ((((INSN*)(niobj))->insn_id) == YARVINSN_putself)) &&
            ((&niobj->link)->next && (((&niobj->link)->next)->type == ISEQ_ELEMENT_INSN) && ((((INSN*)((&niobj->link)->next))->insn_id) == YARVINSN_send))) {
            LINK_ELEMENT *sendobj = &(niobj->link);
            const struct rb_callinfo *ci;
            do {
                sendobj = sendobj->next;
                ci = (struct rb_callinfo *)(((INSN*)(sendobj))->operands[(0)]);
            } while ((vm_ci_flag(ci) & (0x01 << VM_CALL_ARGS_SIMPLE_bit)) && vm_ci_argc(ci) == 0 && ((sendobj)->next && (((sendobj)->next)->type == ISEQ_ELEMENT_INSN) && ((((INSN*)((sendobj)->next))->insn_id) == YARVINSN_send)));
            if ((vm_ci_flag(ci) & (0x01 << VM_CALL_ARGS_SIMPLE_bit)) && vm_ci_argc(ci) == 1 && vm_ci_mid(ci) == idIncludeP) {
                VALUE ary = iobj->operands[0];
                rb_obj_reveal(ary, rb_cArray);
                INSN *sendins = (INSN *)sendobj;
                sendins->insn_id = YARVINSN_opt_duparray_send;
                sendins->operand_size = insn_len(sendins->insn_id) - 1;;
                sendins->operands = compile_data_calloc2(iseq, sendins->operand_size, sizeof(VALUE));
                sendins->operands[0] = ary;
                sendins->operands[1] = rb_id2sym(idIncludeP);
                sendins->operands[2] = __builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1));
                ELEM_REMOVE(&iobj->link);
                return 1;
            }
        }
    }
    if (((((INSN*)(iobj))->insn_id) == YARVINSN_send)) {
        const struct rb_callinfo *ci = (struct rb_callinfo *)(((INSN*)(iobj))->operands[(0)]);
        const rb_iseq_t *blockiseq = (rb_iseq_t *)(((INSN*)(iobj))->operands[(1)]);
        if ((vm_ci_flag(ci) & (0x01 << VM_CALL_ARGS_SIMPLE_bit))) {
            switch (vm_ci_argc(ci)) {
              case 0:
                switch (vm_ci_mid(ci)) {
                  case idLength: insn_set_specialized_instruction(iseq, iobj, YARVINSN_opt_length); return 1;
                  case idSize: insn_set_specialized_instruction(iseq, iobj, YARVINSN_opt_size); return 1;
                  case idEmptyP: insn_set_specialized_instruction(iseq, iobj, YARVINSN_opt_empty_p);return 1;
                  case idNilP: insn_set_specialized_instruction(iseq, iobj, YARVINSN_opt_nil_p); return 1;
                  case idSucc: insn_set_specialized_instruction(iseq, iobj, YARVINSN_opt_succ); return 1;
                  case idNot: insn_set_specialized_instruction(iseq, iobj, YARVINSN_opt_not); return 1;
                }
                break;
              case 1:
                switch (vm_ci_mid(ci)) {
                  case idPLUS: insn_set_specialized_instruction(iseq, iobj, YARVINSN_opt_plus); return 1;
                  case idMINUS: insn_set_specialized_instruction(iseq, iobj, YARVINSN_opt_minus); return 1;
                  case idMULT: insn_set_specialized_instruction(iseq, iobj, YARVINSN_opt_mult); return 1;
                  case idDIV: insn_set_specialized_instruction(iseq, iobj, YARVINSN_opt_div); return 1;
                  case idMOD: insn_set_specialized_instruction(iseq, iobj, YARVINSN_opt_mod); return 1;
                  case idEq: insn_set_specialized_instruction(iseq, iobj, YARVINSN_opt_eq); return 1;
                  case idNeq: insn_set_specialized_instruction(iseq, iobj, YARVINSN_opt_neq); return 1;
                  case idEqTilde:insn_set_specialized_instruction(iseq, iobj, YARVINSN_opt_regexpmatch2);return 1;
                  case idLT: insn_set_specialized_instruction(iseq, iobj, YARVINSN_opt_lt); return 1;
                  case idLE: insn_set_specialized_instruction(iseq, iobj, YARVINSN_opt_le); return 1;
                  case idGT: insn_set_specialized_instruction(iseq, iobj, YARVINSN_opt_gt); return 1;
                  case idGE: insn_set_specialized_instruction(iseq, iobj, YARVINSN_opt_ge); return 1;
                  case idLTLT: insn_set_specialized_instruction(iseq, iobj, YARVINSN_opt_ltlt); return 1;
                  case idAREF: insn_set_specialized_instruction(iseq, iobj, YARVINSN_opt_aref); return 1;
                  case idAnd: insn_set_specialized_instruction(iseq, iobj, YARVINSN_opt_and); return 1;
                  case idOr: insn_set_specialized_instruction(iseq, iobj, YARVINSN_opt_or); return 1;
                }
                break;
              case 2:
                switch (vm_ci_mid(ci)) {
                  case idASET: insn_set_specialized_instruction(iseq, iobj, YARVINSN_opt_aset); return 1;
                }
                break;
            }
        }
        if ((vm_ci_flag(ci) & ((0x01 << VM_CALL_ARGS_BLOCKARG_bit) | (0x01 << VM_CALL_FORWARDING_bit))) == 0 && blockiseq == ((void *)0)) {
            iobj->insn_id = YARVINSN_opt_send_without_block;
            iobj->operand_size = insn_len(iobj->insn_id) - 1;
        }
    }
    return 1;
}
static inline int
tailcallable_p(rb_iseq_t *iseq)
{
    switch (((iseq)->body)->type) {
      case ISEQ_TYPE_TOP:
      case ISEQ_TYPE_EVAL:
      case ISEQ_TYPE_MAIN:
      case ISEQ_TYPE_RESCUE:
      case ISEQ_TYPE_ENSURE:
        return 0;
      default:
        return 1;
    }
}
static int
iseq_optimize(rb_iseq_t *iseq, LINK_ANCHOR *const anchor)
{
    LINK_ELEMENT *list;
    const int do_peepholeopt = ISEQ_COMPILE_DATA(iseq)->option->peephole_optimization;
    const int do_tailcallopt = tailcallable_p(iseq) &&
        ISEQ_COMPILE_DATA(iseq)->option->tailcall_optimization;
    const int do_si = ISEQ_COMPILE_DATA(iseq)->option->specialized_instruction;
    const int do_ou = ISEQ_COMPILE_DATA(iseq)->option->operands_unification;
    int rescue_level = 0;
    int tailcallopt = do_tailcallopt;
    list = FIRST_ELEMENT(anchor);
    int do_block_optimization = 0;
    if (((iseq)->body)->type == ISEQ_TYPE_BLOCK && !ISEQ_COMPILE_DATA(iseq)->catch_except_p) {
        do_block_optimization = 1;
    }
    while (list) {
        if (((list)->type == ISEQ_ELEMENT_INSN)) {
            if (do_peepholeopt) {
                iseq_peephole_optimize(iseq, list, tailcallopt);
            }
            if (do_si) {
                iseq_specialized_instruction(iseq, (INSN *)list);
            }
            if (do_ou) {
                insn_operands_unification((INSN *)list);
            }
            if (do_block_optimization) {
                INSN * item = (INSN *)list;
                if (((((INSN*)(item))->insn_id) == YARVINSN_jump)) {
                    do_block_optimization = 0;
                }
            }
        }
        if (((list)->type == ISEQ_ELEMENT_LABEL)) {
            switch (((LABEL *)list)->rescued) {
              case LABEL_RESCUE_BEG:
                rescue_level++;
                tailcallopt = 0;
                break;
              case LABEL_RESCUE_END:
                if (!--rescue_level) tailcallopt = do_tailcallopt;
                break;
            }
        }
        list = list->next;
    }
    if (do_block_optimization) {
        LINK_ELEMENT * le = FIRST_ELEMENT(anchor)->next;
        if (((le)->type == ISEQ_ELEMENT_INSN) && ((((INSN*)((INSN *)le))->insn_id) == YARVINSN_nop)) {
            ELEM_REMOVE(le);
        }
    }
    return 1;
}
static int
iseq_insns_unification(rb_iseq_t *iseq, LINK_ANCHOR *const anchor)
{
    return 1;
}
static int
all_string_result_p(const NODE *node)
{
    if (!node) return 0;
    switch (((int) ((((NODE *)(node))->flags & (((VALUE)0x7f)<<8))>>8))) {
      case NODE_STR: case NODE_DSTR: case NODE_FILE:
        return 1;
      case NODE_IF: case NODE_UNLESS:
        if (!((rb_node_if_t *)(node))->nd_body || !((rb_node_if_t *)(node))->nd_else) return 0;
        if (all_string_result_p(((rb_node_if_t *)(node))->nd_body))
            return all_string_result_p(((rb_node_if_t *)(node))->nd_else);
        return 0;
      case NODE_AND: case NODE_OR:
        if (!((rb_node_and_t *)(node))->nd_2nd)
            return all_string_result_p(((rb_node_and_t *)(node))->nd_1st);
        if (!all_string_result_p(((rb_node_and_t *)(node))->nd_1st))
            return 0;
        return all_string_result_p(((rb_node_and_t *)(node))->nd_2nd);
      default:
        return 0;
    }
}
static int
compile_dstr_fragments(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, int *cntp)
{
    const struct RNode_LIST *list = ((rb_node_dstr_t *)(node))->nd_next;
    VALUE lit = rb_node_dstr_string_val(node);
    LINK_ELEMENT *first_lit = 0;
    int cnt = 0;
    ((void)0);
    if (!RB_NIL_P(lit)) {
        cnt++;
        if (!RB_TYPE_P(lit, RUBY_T_STRING)) {
            append_compile_error(iseq, (int)(((long)(node)->flags)>>(8 +7)), "dstr: must be string: %s",
                          rb_builtin_type_name(((int)rb_type(lit))));
            return 0;
        }
        lit = rb_fstring(lit);
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putobject, 1, (VALUE)(lit)));
        (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(lit), "compile.c", 4523));
        if (RSTRING_LEN(lit) == 0) first_lit = LAST_ELEMENT(ret);
    }
    while (list) {
        const NODE *const head = list->nd_head;
        if (nd_type_p(head, NODE_STR)) {
            lit = rb_node_str_string_val(head);
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(head)->flags)>>(8 +7)), (((NODE *)(head))->node_id), YARVINSN_putobject, 1, (VALUE)(lit)));
            (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(lit), "compile.c", 4532));
            lit = ((VALUE)RUBY_Qnil);
        }
        else {
            if (!(((iseq_compile_each(iseq, (ret), (head), 0))))) {;return 0;};
        }
        cnt++;
        list = (struct RNode_LIST *)list->nd_next;
    }
    if (RB_NIL_P(lit) && first_lit) {
        ELEM_REMOVE(first_lit);
        --cnt;
    }
    *cntp = cnt;
    return 1;
}
static int
compile_block(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *node, int popped)
{
    while (node && nd_type_p(node, NODE_BLOCK)) {
        if (!(((iseq_compile_each(iseq, (ret), (((rb_node_block_t *)(node))->nd_head), ((((rb_node_block_t *)(node))->nd_next ? 1 : popped))))))) {;return 0;};
        node = ((rb_node_block_t *)(node))->nd_next;
    }
    if (node) {
        if (!(((iseq_compile_each(iseq, (ret), (((rb_node_block_t *)(node))->nd_next), (popped)))))) {;return 0;};
    }
    return 1;
}
static int
compile_dstr(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node)
{
    int cnt;
    if (!((rb_node_dstr_t *)(node))->nd_next) {
        VALUE lit = rb_node_dstr_string_val(node);
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putstring, 1, (VALUE)(lit)));
        (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(lit), "compile.c", 4571));
    }
    else {
        if (!(compile_dstr_fragments(iseq, ret, node, &cnt))) {;return 0;};
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_concatstrings, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(cnt), ((VALUE)(cnt)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(cnt)))));
    }
    return 1;
}
static int
compile_dregx(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, int popped)
{
    int cnt;
    int cflag = (int)((rb_node_dregx_t *)(node))->as.nd_cflag;
    if (!((rb_node_dregx_t *)(node))->nd_next) {
        if (!popped) {
            VALUE src = rb_node_dregx_string_val(node);
            VALUE match = rb_reg_compile(src, cflag, ((void *)0), 0);
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putobject, 1, (VALUE)(match)));
            (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(match), "compile.c", 4591));
        }
        return 1;
    }
    if (!(compile_dstr_fragments(iseq, ret, node, &cnt))) {;return 0;};
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_toregexp, 2, (VALUE)(__builtin_choose_expr( __builtin_constant_p(cflag), ((VALUE)(cflag)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(cflag))), (VALUE)(__builtin_choose_expr( __builtin_constant_p(cnt), ((VALUE)(cnt)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(cnt)))));
    if (popped) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pop, 0));
    }
    return 1;
}
static int
compile_flip_flop(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, int again,
                  LABEL *then_label, LABEL *else_label)
{
    const int line = (int)(((long)(node)->flags)>>(8 +7));
    LABEL *lend = new_label_body(iseq, (line));
    rb_num_t cnt = ISEQ_FLIP_CNT_INCREMENT(((iseq)->body)->local_iseq)
        + VM_SVAR_FLIPFLOP_START;
    VALUE key = __builtin_choose_expr( __builtin_constant_p(cnt), ((VALUE)(cnt)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(cnt));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_getspecial, 2, (VALUE)(key), (VALUE)(__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))));
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_branchif, 1, (VALUE)(lend))), ((lend)->refcnt++));
    if (!(((iseq_compile_each(iseq, (ret), (((rb_node_flip2_t *)(node))->nd_beg), 0))))) {;return 0;};
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_branchunless, 1, (VALUE)(else_label))), ((else_label)->refcnt++));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qtrue))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_setspecial, 1, (VALUE)(key)));
    if (!again) {
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_jump, 1, (VALUE)(then_label))), ((then_label)->refcnt++));
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) (lend));
    if (!(((iseq_compile_each(iseq, (ret), (((rb_node_flip2_t *)(node))->nd_end), 0))))) {;return 0;};
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_branchunless, 1, (VALUE)(then_label))), ((then_label)->refcnt++));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qfalse))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_setspecial, 1, (VALUE)(key)));
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_jump, 1, (VALUE)(then_label))), ((then_label)->refcnt++));
    return 1;
}
static int
compile_branch_condition(rb_iseq_t *iseq, LINK_ANCHOR *ret, const NODE *cond,
                         LABEL *then_label, LABEL *else_label);
static int
compile_logical(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *cond,
                LABEL *then_label, LABEL *else_label)
{
    LINK_ANCHOR seq[1] = {{{ISEQ_ELEMENT_ANCHOR,},&seq[0].anchor}};
    ((seq->last = &seq->anchor)->next = ((void *)0));
    LABEL *label = new_label_body(iseq, ((int)(((long)(cond)->flags)>>(8 +7))));
    if (!then_label) then_label = label;
    else if (!else_label) else_label = label;
    if (!(compile_branch_condition(iseq, seq, cond, then_label, else_label))) {;return 0;};
    if (LIST_INSN_SIZE_ONE(seq)) {
        INSN *insn = (INSN *)ELEM_FIRST_INSN(FIRST_ELEMENT(seq));
        if (insn->insn_id == YARVINSN_jump && (LABEL *)(insn->operands[0]) == label)
            return 1;
    }
    if (!label->refcnt) {
        return 2;
    }
    ADD_ELEM((seq), (LINK_ELEMENT *) (label));
    APPEND_LIST((ret), (seq));
    return 1;
}
static int
compile_branch_condition(rb_iseq_t *iseq, LINK_ANCHOR *ret, const NODE *cond,
                         LABEL *then_label, LABEL *else_label)
{
    int ok;
    LINK_ANCHOR ignore[1] = {{{ISEQ_ELEMENT_ANCHOR,},&ignore[0].anchor}};
  again:
    switch (((int) ((((NODE *)(cond))->flags & (((VALUE)0x7f)<<8))>>8))) {
      case NODE_AND:
        if (!(ok = compile_logical(iseq, ret, ((rb_node_and_t *)(cond))->nd_1st, ((void *)0), else_label))) {;return 0;};
        cond = ((rb_node_and_t *)(cond))->nd_2nd;
        if (ok == 2) {
            ((ignore->last = &ignore->anchor)->next = ((void *)0));
            ret = ignore;
            then_label = new_label_body(iseq, ((int)(((long)(cond)->flags)>>(8 +7))));
        }
        goto again;
      case NODE_OR:
        if (!(ok = compile_logical(iseq, ret, ((rb_node_or_t *)(cond))->nd_1st, then_label, ((void *)0)))) {;return 0;};
        cond = ((rb_node_or_t *)(cond))->nd_2nd;
        if (ok == 2) {
            ((ignore->last = &ignore->anchor)->next = ((void *)0));
            ret = ignore;
            else_label = new_label_body(iseq, ((int)(((long)(cond)->flags)>>(8 +7))));
        }
        goto again;
      case NODE_SYM:
      case NODE_LINE:
      case NODE_FILE:
      case NODE_ENCODING:
      case NODE_INTEGER:
      case NODE_FLOAT:
      case NODE_RATIONAL:
      case NODE_IMAGINARY:
      case NODE_TRUE:
      case NODE_STR:
      case NODE_REGX:
      case NODE_ZLIST:
      case NODE_LAMBDA:
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(cond)->flags)>>(8 +7)), (((NODE *)(cond))->node_id), YARVINSN_jump, 1, (VALUE)(then_label))), ((then_label)->refcnt++));
        return 1;
      case NODE_FALSE:
      case NODE_NIL:
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(cond)->flags)>>(8 +7)), (((NODE *)(cond))->node_id), YARVINSN_jump, 1, (VALUE)(else_label))), ((else_label)->refcnt++));
        return 1;
      case NODE_LIST:
      case NODE_ARGSCAT:
      case NODE_DREGX:
      case NODE_DSTR:
        if (!(((iseq_compile_each(iseq, (ret), (cond), 1))))) {;return 0;};
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(cond)->flags)>>(8 +7)), (((NODE *)(cond))->node_id), YARVINSN_jump, 1, (VALUE)(then_label))), ((then_label)->refcnt++));
        return 1;
      case NODE_FLIP2:
        if (!(compile_flip_flop(iseq, ret, cond, 1, then_label, else_label))) {;return 0;};
        return 1;
      case NODE_FLIP3:
        if (!(compile_flip_flop(iseq, ret, cond, 0, then_label, else_label))) {;return 0;};
        return 1;
      case NODE_DEFINED:
        if (!(compile_defined_expr(iseq, ret, cond, ((VALUE)RUBY_Qfalse), ret == ignore))) {;return 0;};
        break;
      default:
        {
            LINK_ANCHOR cond_seq[1] = {{{ISEQ_ELEMENT_ANCHOR,},&cond_seq[0].anchor}};
            ((cond_seq->last = &cond_seq->anchor)->next = ((void *)0));
            if (!(((iseq_compile_each(iseq, (cond_seq), (cond), 0))))) {;return 0;};
            if (LIST_INSN_SIZE_ONE(cond_seq)) {
                INSN *insn = (INSN *)ELEM_FIRST_INSN(FIRST_ELEMENT(cond_seq));
                if (insn->insn_id == YARVINSN_putobject) {
                    if (RB_TEST(insn->operands[0])) {
                        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(cond)->flags)>>(8 +7)), (((NODE *)(cond))->node_id), YARVINSN_jump, 1, (VALUE)(then_label))), ((then_label)->refcnt++));
                        return 1;
                    }
                    else {
                        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(cond)->flags)>>(8 +7)), (((NODE *)(cond))->node_id), YARVINSN_jump, 1, (VALUE)(else_label))), ((else_label)->refcnt++));
                        return 1;
                    }
                }
            }
            APPEND_LIST((ret), (cond_seq));
        }
        break;
    }
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(cond)->flags)>>(8 +7)), (((NODE *)(cond))->node_id), YARVINSN_branchunless, 1, (VALUE)(else_label))), ((else_label)->refcnt++));
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(cond)->flags)>>(8 +7)), (((NODE *)(cond))->node_id), YARVINSN_jump, 1, (VALUE)(then_label))), ((then_label)->refcnt++));
    return 1;
}
static int
keyword_node_p(const NODE *const node)
{
    return nd_type_p(node, NODE_HASH) && (((rb_node_hash_t *)(node))->nd_brace & 1) != 1;
}
static VALUE
get_symbol_value(rb_iseq_t *iseq, const NODE *node)
{
    switch (((int) ((((NODE *)(node))->flags & (((VALUE)0x7f)<<8))>>8))) {
      case NODE_SYM:
        return rb_node_sym_string_val(node);
      default:
        do { const NODE *error_node = (node); append_compile_error(iseq, (int)(((long)(error_node)->flags)>>(8 +7)), "get_symbol_value" ": unknown node (%s)", ruby_node_name(((int) ((((NODE *)(error_node))->flags & (((VALUE)0x7f)<<8))>>8)))); return ((VALUE)RUBY_Qnil); } while (0);
    }
}
static VALUE
node_hash_unique_key_index(rb_iseq_t *iseq, rb_node_hash_t *node_hash, int *count_ptr)
{
    NODE *node = node_hash->nd_head;
    VALUE hash = rb_hash_new();
    VALUE ary = rb_ary_new();
    for (int i = 0; node != ((void *)0); i++, node = ((rb_node_list_t *)(((rb_node_list_t *)(node))->nd_next))->nd_next) {
        VALUE key = get_symbol_value(iseq, ((rb_node_list_t *)(node))->nd_head);
        VALUE idx = rb_hash_aref(hash, key);
        if (!RB_NIL_P(idx)) {
            rb_ary_store(ary, RB_FIX2INT(idx), ((VALUE)RUBY_Qfalse));
            (*count_ptr)--;
        }
        rb_hash_aset(hash, key, __builtin_choose_expr( __builtin_constant_p(i), ((VALUE)(i)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(i)));
        rb_ary_store(ary, i, ((VALUE)RUBY_Qtrue));
        (*count_ptr)++;
    }
    return ary;
}
static int
compile_keyword_arg(rb_iseq_t *iseq, LINK_ANCHOR *const ret,
                    const NODE *const root_node,
                    struct rb_callinfo_kwarg **const kw_arg_ptr,
                    unsigned int *flag)
{
    ((void)0);
    ((void)0);
    ((void)0);
    if (((rb_node_hash_t *)(root_node))->nd_head && nd_type_p(((rb_node_hash_t *)(root_node))->nd_head, NODE_LIST)) {
        const NODE *node = ((rb_node_hash_t *)(root_node))->nd_head;
        int seen_nodes = 0;
        while (node) {
            const NODE *key_node = ((rb_node_list_t *)(node))->nd_head;
            seen_nodes++;
            ((void)0);
            if (key_node && nd_type_p(key_node, NODE_SYM)) {
            }
            else {
                if (flag) {
                    *flag |= (0x01 << VM_CALL_KW_SPLAT_bit);
                    if (seen_nodes > 1 || ((rb_node_list_t *)(((rb_node_list_t *)(node))->nd_next))->nd_next) {
                        *flag |= (0x01 << VM_CALL_KW_SPLAT_MUT_bit);
                    }
                }
                return 0;
            }
            node = ((rb_node_list_t *)(node))->nd_next;
            node = ((rb_node_list_t *)(node))->nd_next;
        }
        node = ((rb_node_hash_t *)(root_node))->nd_head;
        {
            int len = 0;
            VALUE key_index = node_hash_unique_key_index(iseq, ((rb_node_hash_t *)(root_node)), &len);
            struct rb_callinfo_kwarg *kw_arg =
                rb_xmalloc_mul_add(len, sizeof(VALUE), sizeof(struct rb_callinfo_kwarg));
            VALUE *keywords = kw_arg->keywords;
            int i = 0;
            int j = 0;
            kw_arg->references = 0;
            kw_arg->keyword_len = len;
            *kw_arg_ptr = kw_arg;
            for (i=0; node != ((void *)0); i++, node = ((rb_node_list_t *)(((rb_node_list_t *)(node))->nd_next))->nd_next) {
                const NODE *key_node = ((rb_node_list_t *)(node))->nd_head;
                const NODE *val_node = ((rb_node_list_t *)(((rb_node_list_t *)(node))->nd_next))->nd_head;
                int popped = 1;
                if (rb_ary_entry(key_index, i)) {
                    keywords[j] = get_symbol_value(iseq, key_node);
                    j++;
                    popped = 0;
                }
                (void)(((iseq_compile_each(iseq, (ret), (val_node), (popped)))));
            }
            ((void)0);
            return 1;
        }
    }
    return 0;
}
static int
compile_args(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *node, NODE **kwnode_ptr)
{
    int len = 0;
    for (; node; len++, node = ((rb_node_list_t *)(node))->nd_next) {
        if (0 > 0) {
            do { const NODE *error_node = (node); enum node_type error_type = ((int) ((((NODE *)(error_node))->flags & (((VALUE)0x7f)<<8))>>8)); if (error_type != (NODE_LIST)) { append_compile_error(iseq, (int)(((long)(error_node)->flags)>>(8 +7)), "compile_args" ": " "NODE_LIST" " is expected, but %s", ruby_node_name(error_type)); return -1; } } while (0);
        }
        if (((rb_node_list_t *)(node))->nd_next == ((void *)0) && keyword_node_p(((rb_node_list_t *)(node))->nd_head)) {
            *kwnode_ptr = ((rb_node_list_t *)(node))->nd_head;
        }
        else {
            ((void)0);
            (void)(((iseq_compile_each(iseq, (ret), (((rb_node_list_t *)(node))->nd_head), (0)))));
        }
    }
    return len;
}
static inline _Bool
frozen_string_literal_p(const rb_iseq_t *iseq)
{
    return ISEQ_COMPILE_DATA(iseq)->option->frozen_string_literal > 0;
}
static inline _Bool
static_literal_node_p(const NODE *node, const rb_iseq_t *iseq, _Bool hash_key)
{
    switch (((int) ((((NODE *)(node))->flags & (((VALUE)0x7f)<<8))>>8))) {
      case NODE_SYM:
      case NODE_REGX:
      case NODE_LINE:
      case NODE_ENCODING:
      case NODE_INTEGER:
      case NODE_FLOAT:
      case NODE_RATIONAL:
      case NODE_IMAGINARY:
      case NODE_NIL:
      case NODE_TRUE:
      case NODE_FALSE:
        return 1;
      case NODE_STR:
      case NODE_FILE:
        return hash_key || frozen_string_literal_p(iseq);
      default:
        return 0;
    }
}
static inline VALUE
static_literal_value(const NODE *node, rb_iseq_t *iseq)
{
    switch (((int) ((((NODE *)(node))->flags & (((VALUE)0x7f)<<8))>>8))) {
      case NODE_INTEGER:
        return rb_node_integer_literal_val(node);
      case NODE_FLOAT:
        return rb_node_float_literal_val(node);
      case NODE_RATIONAL:
        return rb_node_rational_literal_val(node);
      case NODE_IMAGINARY:
        return rb_node_imaginary_literal_val(node);
      case NODE_NIL:
        return ((VALUE)RUBY_Qnil);
      case NODE_TRUE:
        return ((VALUE)RUBY_Qtrue);
      case NODE_FALSE:
        return ((VALUE)RUBY_Qfalse);
      case NODE_SYM:
        return rb_node_sym_string_val(node);
      case NODE_REGX:
        return rb_node_regx_string_val(node);
      case NODE_LINE:
        return rb_node_line_lineno_val(node);
      case NODE_ENCODING:
        return rb_node_encoding_val(node);
      case NODE_FILE:
      case NODE_STR:
        if (ISEQ_COMPILE_DATA(iseq)->option->debug_frozen_string_literal || RB_TEST((*rb_ruby_debug_ptr()))) {
            VALUE lit = get_string_value(node);
            return rb_str_with_debug_created_info(lit, rb_iseq_path(iseq), (int)(int)(((long)(node)->flags)>>(8 +7)));
        }
        else {
            return get_string_value(node);
        }
      default:
        rb_bug("unexpected node: %s", ruby_node_name(((int) ((((NODE *)(node))->flags & (((VALUE)0x7f)<<8))>>8))));
    }
}
static int
compile_array(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *node, int popped, _Bool first_chunk)
{
    const NODE *line_node = node;
    if (nd_type_p(node, NODE_ZLIST)) {
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_newarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))));
        }
        return 0;
    }
    do { const NODE *error_node = (node); enum node_type error_type = ((int) ((((NODE *)(error_node))->flags & (((VALUE)0x7f)<<8))>>8)); if (error_type != (NODE_LIST)) { append_compile_error(iseq, (int)(((long)(error_node)->flags)>>(8 +7)), "compile_array" ": " "NODE_LIST" " is expected, but %s", ruby_node_name(error_type)); return -1; } } while (0);
    if (popped) {
        for (; node; node = ((rb_node_list_t *)(node))->nd_next) {
            (void)(((iseq_compile_each(iseq, (ret), (((rb_node_list_t *)(node))->nd_head), (popped)))));
        }
        return 1;
    }
    const int max_stack_len = 0x100;
    const int min_tmp_ary_len = 0x40;
    int stack_len = 0;
    while (node) {
        int count = 1;
        if (static_literal_node_p(((rb_node_list_t *)(node))->nd_head, iseq, 0)) {
            const NODE *node_tmp = ((rb_node_list_t *)(node))->nd_next;
            for (; node_tmp && static_literal_node_p(((rb_node_list_t *)(node_tmp))->nd_head, iseq, 0); node_tmp = ((rb_node_list_t *)(node_tmp))->nd_next)
                count++;
            if ((first_chunk && stack_len == 0 && !node_tmp) || count >= min_tmp_ary_len) {
                VALUE ary = rb_ary_hidden_new(count);
                for (; count; count--, node = ((rb_node_list_t *)(node))->nd_next)
                    rb_ary_push(ary, static_literal_value(((rb_node_list_t *)(node))->nd_head, iseq));
                rb_obj_freeze_inline(ary);
                if (stack_len) { if (first_chunk) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_newarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(stack_len), ((VALUE)(stack_len)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(stack_len))))); else ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pushtoarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(stack_len), ((VALUE)(stack_len)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(stack_len))))); first_chunk = 0; stack_len = 0; };
                if (first_chunk) {
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_duparray, 1, (VALUE)(ary)));
                    first_chunk = 0;
                }
                else {
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(ary)));
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_concattoarray, 0));
                }
                (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(ary), "compile.c", 5069));
            }
        }
        for (; count; count--, node = ((rb_node_list_t *)(node))->nd_next) {
            if (0 > 0) {
                do { const NODE *error_node = (node); enum node_type error_type = ((int) ((((NODE *)(error_node))->flags & (((VALUE)0x7f)<<8))>>8)); if (error_type != (NODE_LIST)) { append_compile_error(iseq, (int)(((long)(error_node)->flags)>>(8 +7)), "compile_array" ": " "NODE_LIST" " is expected, but %s", ruby_node_name(error_type)); return -1; } } while (0);
            }
            if (!((rb_node_list_t *)(node))->nd_next && keyword_node_p(((rb_node_list_t *)(node))->nd_head)) {
                if (stack_len == 0 && first_chunk) {
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_newarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))));
                }
                else {
                    if (stack_len) { if (first_chunk) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_newarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(stack_len), ((VALUE)(stack_len)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(stack_len))))); else ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pushtoarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(stack_len), ((VALUE)(stack_len)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(stack_len))))); first_chunk = 0; stack_len = 0; };
                }
                (void)(((iseq_compile_each(iseq, (ret), (((rb_node_list_t *)(node))->nd_head), (0)))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pushtoarraykwsplat, 0));
                return 1;
            }
            else {
                (void)(((iseq_compile_each(iseq, (ret), (((rb_node_list_t *)(node))->nd_head), (0)))));
                stack_len++;
            }
            if (stack_len >= max_stack_len) if (stack_len) { if (first_chunk) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_newarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(stack_len), ((VALUE)(stack_len)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(stack_len))))); else ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pushtoarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(stack_len), ((VALUE)(stack_len)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(stack_len))))); first_chunk = 0; stack_len = 0; };
        }
    }
    if (stack_len) { if (first_chunk) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_newarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(stack_len), ((VALUE)(stack_len)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(stack_len))))); else ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pushtoarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(stack_len), ((VALUE)(stack_len)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(stack_len))))); first_chunk = 0; stack_len = 0; };
    return 1;
}
static inline int
static_literal_node_pair_p(const NODE *node, const rb_iseq_t *iseq)
{
    return ((rb_node_list_t *)(node))->nd_head && static_literal_node_p(((rb_node_list_t *)(node))->nd_head, iseq, 1) && static_literal_node_p(((rb_node_list_t *)(((rb_node_list_t *)(node))->nd_next))->nd_head, iseq, 0);
}
static int
compile_hash(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *node, int method_call_keywords, int popped)
{
    const NODE *line_node = node;
    node = ((rb_node_hash_t *)(node))->nd_head;
    if (!node || nd_type_p(node, NODE_ZLIST)) {
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_newhash, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))));
        }
        return 0;
    }
    do { const NODE *error_node = (node); enum node_type error_type = ((int) ((((NODE *)(error_node))->flags & (((VALUE)0x7f)<<8))>>8)); if (error_type != (NODE_LIST)) { append_compile_error(iseq, (int)(((long)(error_node)->flags)>>(8 +7)), "compile_hash" ": " "NODE_LIST" " is expected, but %s", ruby_node_name(error_type)); return -1; } } while (0);
    if (popped) {
        for (; node; node = ((rb_node_list_t *)(node))->nd_next) {
            (void)(((iseq_compile_each(iseq, (ret), (((rb_node_list_t *)(node))->nd_head), (popped)))));
        }
        return 1;
    }
    const int max_stack_len = 0x100;
    const int min_tmp_hash_len = 0x800;
    int stack_len = 0;
    int first_chunk = 1;
    LINK_ANCHOR anchor[1] = {{{ISEQ_ELEMENT_ANCHOR,},&anchor[0].anchor}};
    ((anchor->last = &anchor->anchor)->next = ((void *)0));
    while (node) {
        int count = 1;
        if (static_literal_node_pair_p(node, iseq)) {
            const NODE *node_tmp = ((rb_node_list_t *)(((rb_node_list_t *)(node))->nd_next))->nd_next;
            for (; node_tmp && static_literal_node_pair_p(node_tmp, iseq); node_tmp = ((rb_node_list_t *)(((rb_node_list_t *)(node_tmp))->nd_next))->nd_next)
                count++;
            if ((first_chunk && stack_len == 0 && !node_tmp) || count >= min_tmp_hash_len) {
                VALUE ary = rb_ary_hidden_new(count);
                for (; count; count--, node = ((rb_node_list_t *)(((rb_node_list_t *)(node))->nd_next))->nd_next) {
                    VALUE elem[2];
                    elem[0] = static_literal_value(((rb_node_list_t *)(node))->nd_head, iseq);
                    elem[1] = static_literal_value(((rb_node_list_t *)(((rb_node_list_t *)(node))->nd_next))->nd_head, iseq);
                    rb_ary_cat(ary, elem, 2);
                }
                VALUE hash = rb_hash_new_with_size(rb_array_len(ary) / 2);
                rb_hash_bulk_insert(rb_array_len(ary), rb_array_const_ptr(ary), hash);
                hash = rb_obj_hide(hash);
                rb_obj_freeze_inline(hash);
                if (stack_len) { if (first_chunk) { APPEND_LIST(ret, anchor); ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_newhash, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(stack_len), ((VALUE)(stack_len)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(stack_len))))); } else { ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE))))); ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_swap, 0)); APPEND_LIST(ret, anchor); ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((id_core_hash_merge_ptr)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(stack_len + 1), ((VALUE)(stack_len + 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(stack_len + 1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0)))); } ((anchor->last = &anchor->anchor)->next = ((void *)0)); first_chunk = stack_len = 0; };
                if (first_chunk) {
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_duphash, 1, (VALUE)(hash)));
                    first_chunk = 0;
                }
                else {
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_swap, 0));
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(hash)));
                    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((id_core_hash_merge_kwd)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
                }
                (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(hash), "compile.c", 5217));
            }
        }
        for (; count; count--, node = ((rb_node_list_t *)(((rb_node_list_t *)(node))->nd_next))->nd_next) {
            if (0 > 0) {
                do { const NODE *error_node = (node); enum node_type error_type = ((int) ((((NODE *)(error_node))->flags & (((VALUE)0x7f)<<8))>>8)); if (error_type != (NODE_LIST)) { append_compile_error(iseq, (int)(((long)(error_node)->flags)>>(8 +7)), "compile_hash" ": " "NODE_LIST" " is expected, but %s", ruby_node_name(error_type)); return -1; } } while (0);
            }
            if (((rb_node_list_t *)(node))->nd_head) {
                (void)(((iseq_compile_each(iseq, (anchor), (((rb_node_list_t *)(node))->nd_head), (0)))));
                (void)(((iseq_compile_each(iseq, (anchor), (((rb_node_list_t *)(((rb_node_list_t *)(node))->nd_next))->nd_head), (0)))));
                stack_len += 2;
                if (stack_len >= max_stack_len) if (stack_len) { if (first_chunk) { APPEND_LIST(ret, anchor); ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_newhash, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(stack_len), ((VALUE)(stack_len)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(stack_len))))); } else { ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE))))); ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_swap, 0)); APPEND_LIST(ret, anchor); ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((id_core_hash_merge_ptr)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(stack_len + 1), ((VALUE)(stack_len + 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(stack_len + 1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0)))); } ((anchor->last = &anchor->anchor)->next = ((void *)0)); first_chunk = stack_len = 0; };
            }
            else {
                if (stack_len) { if (first_chunk) { APPEND_LIST(ret, anchor); ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_newhash, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(stack_len), ((VALUE)(stack_len)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(stack_len))))); } else { ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE))))); ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_swap, 0)); APPEND_LIST(ret, anchor); ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((id_core_hash_merge_ptr)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(stack_len + 1), ((VALUE)(stack_len + 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(stack_len + 1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0)))); } ((anchor->last = &anchor->anchor)->next = ((void *)0)); first_chunk = stack_len = 0; };
                const NODE *kw = ((rb_node_list_t *)(((rb_node_list_t *)(node))->nd_next))->nd_head;
                int empty_kw = nd_type_p(kw, NODE_HASH) && (!((rb_node_hash_t *)(kw))->nd_head);
                int first_kw = first_chunk && stack_len == 0;
                int last_kw = !((rb_node_list_t *)(((rb_node_list_t *)(node))->nd_next))->nd_next;
                int only_kw = last_kw && first_kw;
                empty_kw = empty_kw || nd_type_p(kw, NODE_NIL);
                if (empty_kw) {
                    if (only_kw && method_call_keywords) {
                        (void)(((iseq_compile_each(iseq, (ret), (kw), 0))));
                    }
                    else if (first_kw) {
                        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_newhash, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))));
                    }
                }
                else {
                    if (only_kw && method_call_keywords) {
                        (void)(((iseq_compile_each(iseq, (ret), (kw), 0))));
                    }
                    else {
                        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
                        if (first_kw) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_newhash, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))));
                        else ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_swap, 0));
                        (void)(((iseq_compile_each(iseq, (ret), (kw), 0))));
                        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((id_core_hash_merge_kwd)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
                    }
                }
                first_chunk = 0;
            }
        }
    }
    if (stack_len) { if (first_chunk) { APPEND_LIST(ret, anchor); ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_newhash, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(stack_len), ((VALUE)(stack_len)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(stack_len))))); } else { ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE))))); ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_swap, 0)); APPEND_LIST(ret, anchor); ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((id_core_hash_merge_ptr)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(stack_len + 1), ((VALUE)(stack_len + 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(stack_len + 1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0)))); } ((anchor->last = &anchor->anchor)->next = ((void *)0)); first_chunk = stack_len = 0; };
    return 1;
}
VALUE
rb_node_case_when_optimizable_literal(const NODE *const node)
{
    switch (((int) ((((NODE *)(node))->flags & (((VALUE)0x7f)<<8))>>8))) {
      case NODE_INTEGER:
        return rb_node_integer_literal_val(node);
      case NODE_FLOAT: {
        VALUE v = rb_node_float_literal_val(node);
        double ival;
        if (modf(rb_float_value_inline(v), &ival) == 0.0) {
            return (((ival) < (0x7fffffffffffffffL / 2) + 1) && ((ival) >= ((-0x7fffffffffffffffL - 1L) / 2))) ? RB_INT2FIX((long)ival) : rb_dbl2big(ival);
        }
        return v;
      }
      case NODE_RATIONAL:
      case NODE_IMAGINARY:
        return ((VALUE)RUBY_Qundef);
      case NODE_NIL:
        return ((VALUE)RUBY_Qnil);
      case NODE_TRUE:
        return ((VALUE)RUBY_Qtrue);
      case NODE_FALSE:
        return ((VALUE)RUBY_Qfalse);
      case NODE_SYM:
        return rb_node_sym_string_val(node);
      case NODE_LINE:
        return rb_node_line_lineno_val(node);
      case NODE_STR:
        return rb_node_str_string_val(node);
      case NODE_FILE:
        return rb_node_file_path_val(node);
    }
    return ((VALUE)RUBY_Qundef);
}
static int
when_vals(rb_iseq_t *iseq, LINK_ANCHOR *const cond_seq, const NODE *vals,
          LABEL *l1, int only_special_literals, VALUE literals)
{
    while (vals) {
        const NODE *val = ((rb_node_list_t *)(vals))->nd_head;
        VALUE lit = rb_node_case_when_optimizable_literal(val);
        if (RB_UNDEF_P(lit)) {
            only_special_literals = 0;
        }
        else if (RB_NIL_P(rb_hash_lookup(literals, lit))) {
            rb_hash_aset(literals, lit, (VALUE)(l1) | 1);
        }
        if (nd_type_p(val, NODE_STR) || nd_type_p(val, NODE_FILE)) {
            ((void)0);
            lit = get_string_value(val);
            ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(val)->flags)>>(8 +7)), (((NODE *)(val))->node_id), YARVINSN_putobject, 1, (VALUE)(lit)));
            (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(lit), "compile.c", 5358));
        }
        else {
            if (!((iseq_compile_each(iseq, (cond_seq), (val), 0)))) return -1;
        }
        ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(vals)->flags)>>(8 +7)), (((NODE *)(vals))->node_id), YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
        ADD_ELEM(((cond_seq)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((vals))->flags)>>(8 +7)), (((NODE *)((vals)))->node_id), ((idEqq)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p((0x01 << VM_CALL_FCALL_bit)), ((VALUE)((0x01 << VM_CALL_FCALL_bit))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((0x01 << VM_CALL_FCALL_bit)))), (((void *)0))));
        (ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(val)->flags)>>(8 +7)), (((NODE *)(val))->node_id), YARVINSN_branchif, 1, (VALUE)(l1))), ((l1)->refcnt++));
        vals = ((rb_node_list_t *)(vals))->nd_next;
    }
    return only_special_literals;
}
static int
when_splat_vals(rb_iseq_t *iseq, LINK_ANCHOR *const cond_seq, const NODE *vals,
                LABEL *l1, int only_special_literals, VALUE literals)
{
    const NODE *line_node = vals;
    switch (((int) ((((NODE *)(vals))->flags & (((VALUE)0x7f)<<8))>>8))) {
      case NODE_LIST:
        if (when_vals(iseq, cond_seq, vals, l1, only_special_literals, literals) < 0)
            return 0;
        break;
      case NODE_SPLAT:
        ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dup, 0));
        if (!(((iseq_compile_each(iseq, (cond_seq), (((rb_node_splat_t *)(vals))->nd_head), 0))))) {;return 0;};
        ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_splatarray, 1, (VALUE)(((VALUE)RUBY_Qfalse))));
        ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_checkmatch, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_CHECKMATCH_TYPE_CASE | 0x04), ((VALUE)(VM_CHECKMATCH_TYPE_CASE | 0x04)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_CHECKMATCH_TYPE_CASE | 0x04)))));
        (ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_branchif, 1, (VALUE)(l1))), ((l1)->refcnt++));
        break;
      case NODE_ARGSCAT:
        if (!(when_splat_vals(iseq, cond_seq, ((rb_node_argscat_t *)(vals))->nd_head, l1, only_special_literals, literals))) {;return 0;};
        if (!(when_splat_vals(iseq, cond_seq, ((rb_node_argscat_t *)(vals))->nd_body, l1, only_special_literals, literals))) {;return 0;};
        break;
      case NODE_ARGSPUSH:
        if (!(when_splat_vals(iseq, cond_seq, ((rb_node_argspush_t *)(vals))->nd_head, l1, only_special_literals, literals))) {;return 0;};
        ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dup, 0));
        if (!(((iseq_compile_each(iseq, (cond_seq), (((rb_node_argspush_t *)(vals))->nd_body), 0))))) {;return 0;};
        ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_checkmatch, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_CHECKMATCH_TYPE_CASE), ((VALUE)(VM_CHECKMATCH_TYPE_CASE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_CHECKMATCH_TYPE_CASE)))));
        (ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_branchif, 1, (VALUE)(l1))), ((l1)->refcnt++));
        break;
      default:
        ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dup, 0));
        if (!(((iseq_compile_each(iseq, (cond_seq), (vals), 0))))) {;return 0;};
        ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_splatarray, 1, (VALUE)(((VALUE)RUBY_Qfalse))));
        ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_checkmatch, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_CHECKMATCH_TYPE_CASE | 0x04), ((VALUE)(VM_CHECKMATCH_TYPE_CASE | 0x04)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_CHECKMATCH_TYPE_CASE | 0x04)))));
        (ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_branchif, 1, (VALUE)(l1))), ((l1)->refcnt++));
        break;
    }
    return 1;
}
struct masgn_lhs_node {
  INSN *before_insn;
  struct masgn_lhs_node *next;
  const NODE *line_node;
  int argn;
  int num_args;
  int lhs_pos;
};
struct masgn_state {
    struct masgn_lhs_node *first_memo;
    struct masgn_lhs_node *last_memo;
    int lhs_level;
    int num_args;
    _Bool nested;
};
static int
add_masgn_lhs_node(struct masgn_state *state, int lhs_pos, const NODE *line_node, int argc, INSN *before_insn)
{
    if (!state) {
        rb_bug("no masgn_state");
    }
    struct masgn_lhs_node *memo;
    memo = malloc(sizeof(struct masgn_lhs_node));
    if (!memo) {
        return 0;
    }
    memo->before_insn = before_insn;
    memo->line_node = line_node;
    memo->argn = state->num_args + 1;
    memo->num_args = argc;
    state->num_args += argc;
    memo->lhs_pos = lhs_pos;
    memo->next = ((void *)0);
    if (!state->first_memo) {
        state->first_memo = memo;
    }
    else {
        state->last_memo->next = memo;
    }
    state->last_memo = memo;
    return 1;
}
static int compile_massign0(rb_iseq_t *iseq, LINK_ANCHOR *const pre, LINK_ANCHOR *const rhs, LINK_ANCHOR *const lhs, LINK_ANCHOR *const post, const NODE *const node, struct masgn_state *state, int popped);
static int
compile_massign_lhs(rb_iseq_t *iseq, LINK_ANCHOR *const pre, LINK_ANCHOR *const rhs, LINK_ANCHOR *const lhs, LINK_ANCHOR *const post, const NODE *const node, struct masgn_state *state, int lhs_pos)
{
    switch (((int) ((((NODE *)(node))->flags & (((VALUE)0x7f)<<8))>>8))) {
      case NODE_ATTRASGN: {
        INSN *iobj;
        const NODE *line_node = node;
        if (!(((iseq_compile_each(iseq, (pre), (node), 1))))) {;return 0;};
        _Bool safenav_call = 0;
        LINK_ELEMENT *insn_element = LAST_ELEMENT(pre);
        iobj = (INSN *)get_prev_insn((INSN *)insn_element);
        ((__builtin_expect(!!(!!(iobj)), 1)) ? ((void)0) : __builtin_unreachable());
        ELEM_REMOVE(insn_element);
        if (!((((INSN*)(iobj))->insn_id) == YARVINSN_send)) {
            safenav_call = 1;
            iobj = (INSN *)get_prev_insn(iobj);
            ELEM_INSERT_NEXT(&iobj->link, insn_element);
        }
        (pre->last = iobj->link.prev)->next = 0;
        const struct rb_callinfo *ci = (struct rb_callinfo *)(((INSN*)(iobj))->operands[(0)]);
        int argc = vm_ci_argc(ci) + 1;
        ci = ci_argc_set(iseq, ci, argc);
        (((INSN*)(iobj))->operands[(0)]) = (VALUE)ci;
        (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(ci), "compile.c", 5573));
        if (argc == 1) {
            ADD_ELEM((lhs), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_swap, 0));
        }
        else {
            ADD_ELEM((lhs), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(argc), ((VALUE)(argc)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(argc)))));
        }
        if (!add_masgn_lhs_node(state, lhs_pos, line_node, argc, (INSN *)LAST_ELEMENT(lhs))) {
            return 0;
        }
        iobj->link.prev = lhs->last;
        lhs->last->next = &iobj->link;
        for (lhs->last = &iobj->link; lhs->last->next; lhs->last = lhs->last->next);
        if (vm_ci_flag(ci) & (0x01 << VM_CALL_ARGS_SPLAT_bit)) {
            int argc = vm_ci_argc(ci);
            _Bool dupsplat = 0;
            ci = ci_argc_set(iseq, ci, argc - 1);
            if (!(vm_ci_flag(ci) & (0x01 << VM_CALL_ARGS_SPLAT_MUT_bit))) {
                dupsplat = 1;
                ci = ci_flag_set(iseq, ci, (0x01 << VM_CALL_ARGS_SPLAT_MUT_bit));
            }
            (((INSN*)(iobj))->operands[(0)]) = (VALUE)ci;
            (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(iobj), "compile.c", 5603));
            int line_no = (int)(((long)(line_node)->flags)>>(8 +7));
            int node_id = (((NODE *)(line_node))->node_id);
            if (dupsplat) {
                ELEM_INSERT_PREV(&(iobj)->link, (LINK_ELEMENT *) new_insn_body(iseq, line_no, node_id, YARVINSN_swap, 0));
                ELEM_INSERT_PREV(&(iobj)->link, (LINK_ELEMENT *) new_insn_body(iseq, line_no, node_id, YARVINSN_splatarray, 1, (VALUE)(((VALUE)RUBY_Qtrue))));
                ELEM_INSERT_PREV(&(iobj)->link, (LINK_ELEMENT *) new_insn_body(iseq, line_no, node_id, YARVINSN_swap, 0));
            }
            ELEM_INSERT_PREV(&(iobj)->link, (LINK_ELEMENT *) new_insn_body(iseq, line_no, node_id, YARVINSN_pushtoarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
        }
        if (!safenav_call) {
            ADD_ELEM((lhs), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
            if (argc != 1) {
                ADD_ELEM((lhs), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
            }
        }
        for (int i=0; i < argc; i++) {
            ADD_ELEM((post), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
        }
        break;
      }
      case NODE_MASGN: {
        LINK_ANCHOR nest_rhs[1] = {{{ISEQ_ELEMENT_ANCHOR,},&nest_rhs[0].anchor}};
        ((nest_rhs->last = &nest_rhs->anchor)->next = ((void *)0));
        LINK_ANCHOR nest_lhs[1] = {{{ISEQ_ELEMENT_ANCHOR,},&nest_lhs[0].anchor}};
        ((nest_lhs->last = &nest_lhs->anchor)->next = ((void *)0));
        int prev_level = state->lhs_level;
        _Bool prev_nested = state->nested;
        state->nested = 1;
        state->lhs_level = lhs_pos - 1;
        if (!(compile_massign0(iseq, pre, nest_rhs, nest_lhs, post, node, state, 1))) {;return 0;};
        state->lhs_level = prev_level;
        state->nested = prev_nested;
        APPEND_LIST((lhs), (nest_rhs));
        APPEND_LIST((lhs), (nest_lhs));
        break;
      }
      case NODE_CDECL:
        if (!((rb_node_cdecl_t *)(node))->nd_vid) {
            INSN *iobj;
            if (!(((iseq_compile_each(iseq, (pre), (node), 1))))) {;return 0;};
            LINK_ELEMENT *insn_element = LAST_ELEMENT(pre);
            iobj = (INSN *)insn_element;
            ELEM_REMOVE((LINK_ELEMENT *)get_prev_insn((INSN *)get_prev_insn(iobj)));
            ELEM_REMOVE((LINK_ELEMENT *)get_prev_insn(iobj));
            ELEM_REMOVE(insn_element);
            pre->last = iobj->link.prev;
            ADD_ELEM(lhs, (LINK_ELEMENT *)iobj);
            if (!add_masgn_lhs_node(state, lhs_pos, node, 1, (INSN *)LAST_ELEMENT(lhs))) {
                return 0;
            }
            ADD_ELEM((post), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pop, 0));
            break;
        }
      default: {
        LINK_ANCHOR anchor[1] = {{{ISEQ_ELEMENT_ANCHOR,},&anchor[0].anchor}};
        ((anchor->last = &anchor->anchor)->next = ((void *)0));
        if (!(((iseq_compile_each(iseq, (anchor), (node), 1))))) {;return 0;};
        ELEM_REMOVE(FIRST_ELEMENT(anchor));
        APPEND_LIST((lhs), (anchor));
      }
    }
    return 1;
}
static int
compile_massign_opt_lhs(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *lhsn)
{
    if (lhsn) {
        if (!(compile_massign_opt_lhs(iseq, ret, ((rb_node_list_t *)(lhsn))->nd_next))) {;return 0;};
        if (!(compile_massign_lhs(iseq, ret, ret, ret, ret, ((rb_node_list_t *)(lhsn))->nd_head, ((void *)0), 0))) {;return 0;};
    }
    return 1;
}
static int
compile_massign_opt(rb_iseq_t *iseq, LINK_ANCHOR *const ret,
                    const NODE *rhsn, const NODE *orig_lhsn)
{
    VALUE mem[64];
    const int memsize = ((int)(sizeof(mem) / sizeof((mem)[0])));
    int memindex = 0;
    int llen = 0, rlen = 0;
    int i;
    const NODE *lhsn = orig_lhsn;
    if (rhsn == 0 || !nd_type_p(rhsn, NODE_LIST)) {
        return 0;
    }
    while (lhsn) {
        const NODE *ln = ((rb_node_list_t *)(lhsn))->nd_head;
        switch (((int) ((((NODE *)(ln))->flags & (((VALUE)0x7f)<<8))>>8))) {
          case NODE_LASGN:
          case NODE_DASGN:
          case NODE_IASGN:
          case NODE_CVASGN:
            { int i; if (memindex == memsize) return 0; for (i=0; i<memindex; i++) { if (mem[i] == (get_nd_vid(ln))) return 0; } mem[memindex++] = (get_nd_vid(ln)); };
            break;
          default:
            return 0;
        }
        lhsn = ((rb_node_list_t *)(lhsn))->nd_next;
        llen++;
    }
    while (rhsn) {
        if (llen <= rlen) {
            (void)(((iseq_compile_each(iseq, (ret), (((rb_node_list_t *)(rhsn))->nd_head), 1))));
        }
        else {
            (void)(((iseq_compile_each(iseq, (ret), (((rb_node_list_t *)(rhsn))->nd_head), 0))));
        }
        rhsn = ((rb_node_list_t *)(rhsn))->nd_next;
        rlen++;
    }
    if (llen > rlen) {
        for (i=0; i<llen-rlen; i++) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(orig_lhsn)->flags)>>(8 +7)), (((NODE *)(orig_lhsn))->node_id), YARVINSN_putnil, 0));
        }
    }
    compile_massign_opt_lhs(iseq, ret, orig_lhsn);
    return 1;
}
static int
compile_massign0(rb_iseq_t *iseq, LINK_ANCHOR *const pre, LINK_ANCHOR *const rhs, LINK_ANCHOR *const lhs, LINK_ANCHOR *const post, const NODE *const node, struct masgn_state *state, int popped)
{
    const NODE *rhsn = ((rb_node_masgn_t *)(node))->nd_value;
    const NODE *splatn = ((rb_node_masgn_t *)(node))->nd_args;
    const NODE *lhsn = ((rb_node_masgn_t *)(node))->nd_head;
    const NODE *lhsn_count = lhsn;
    int lhs_splat = (splatn && ((splatn) != ((NODE *)-1))) ? 1 : 0;
    int llen = 0;
    int lpos = 0;
    while (lhsn_count) {
        llen++;
        lhsn_count = ((rb_node_list_t *)(lhsn_count))->nd_next;
    }
    while (lhsn) {
        if (!(compile_massign_lhs(iseq, pre, rhs, lhs, post, ((rb_node_list_t *)(lhsn))->nd_head, state, (llen - lpos) + lhs_splat + state->lhs_level))) {;return 0;};
        lpos++;
        lhsn = ((rb_node_list_t *)(lhsn))->nd_next;
    }
    if (lhs_splat) {
        if (nd_type_p(splatn, NODE_POSTARG)) {
            const NODE *postn = ((rb_node_postarg_t *)(splatn))->nd_2nd;
            const NODE *restn = ((rb_node_postarg_t *)(splatn))->nd_1st;
            int plen = (int)((rb_node_list_t *)(postn))->as.nd_alen;
            int ppos = 0;
            int flag = 0x02 | (((restn) != ((NODE *)-1)) ? 0x01 : 0x00);
            ADD_ELEM((lhs), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(splatn)->flags)>>(8 +7)), (((NODE *)(splatn))->node_id), YARVINSN_expandarray, 2, (VALUE)(__builtin_choose_expr( __builtin_constant_p(plen), ((VALUE)(plen)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(plen))), (VALUE)(__builtin_choose_expr( __builtin_constant_p(flag), ((VALUE)(flag)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(flag)))));
            if (((restn) != ((NODE *)-1))) {
                if (!(compile_massign_lhs(iseq, pre, rhs, lhs, post, restn, state, 1 + plen + state->lhs_level))) {;return 0;};
            }
            while (postn) {
                if (!(compile_massign_lhs(iseq, pre, rhs, lhs, post, ((rb_node_list_t *)(postn))->nd_head, state, (plen - ppos) + state->lhs_level))) {;return 0;};
                ppos++;
                postn = ((rb_node_list_t *)(postn))->nd_next;
            }
        }
        else {
            if (!(compile_massign_lhs(iseq, pre, rhs, lhs, post, splatn, state, 1 + state->lhs_level))) {;return 0;};
        }
    }
    if (!state->nested) {
        (void)(((iseq_compile_each(iseq, (rhs), (rhsn), 0))));
    }
    if (!popped) {
        ADD_ELEM((rhs), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_dup, 0));
    }
    ADD_ELEM((rhs), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_expandarray, 2, (VALUE)(__builtin_choose_expr( __builtin_constant_p(llen), ((VALUE)(llen)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(llen))), (VALUE)(__builtin_choose_expr( __builtin_constant_p(lhs_splat), ((VALUE)(lhs_splat)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(lhs_splat)))));
    return 1;
}
static int
compile_massign(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, int popped)
{
    if (!popped || ((rb_node_masgn_t *)(node))->nd_args || !compile_massign_opt(iseq, ret, ((rb_node_masgn_t *)(node))->nd_value, ((rb_node_masgn_t *)(node))->nd_head)) {
        struct masgn_state state;
        state.lhs_level = popped ? 0 : 1;
        state.nested = 0;
        state.num_args = 0;
        state.first_memo = ((void *)0);
        state.last_memo = ((void *)0);
        LINK_ANCHOR pre[1] = {{{ISEQ_ELEMENT_ANCHOR,},&pre[0].anchor}};
        ((pre->last = &pre->anchor)->next = ((void *)0));
        LINK_ANCHOR rhs[1] = {{{ISEQ_ELEMENT_ANCHOR,},&rhs[0].anchor}};
        ((rhs->last = &rhs->anchor)->next = ((void *)0));
        LINK_ANCHOR lhs[1] = {{{ISEQ_ELEMENT_ANCHOR,},&lhs[0].anchor}};
        ((lhs->last = &lhs->anchor)->next = ((void *)0));
        LINK_ANCHOR post[1] = {{{ISEQ_ELEMENT_ANCHOR,},&post[0].anchor}};
        ((post->last = &post->anchor)->next = ((void *)0));
        int ok = compile_massign0(iseq, pre, rhs, lhs, post, node, &state, popped);
        struct masgn_lhs_node *memo = state.first_memo, *tmp_memo;
        while (memo) {
            VALUE topn_arg = __builtin_choose_expr( __builtin_constant_p((state.num_args - memo->argn) + memo->lhs_pos), ((VALUE)((state.num_args - memo->argn) + memo->lhs_pos)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((state.num_args - memo->argn) + memo->lhs_pos));
            for (int i = 0; i < memo->num_args; i++) {
                ELEM_INSERT_PREV(&(memo->before_insn)->link, (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(memo->line_node)->flags)>>(8 +7)), (((NODE *)(memo->line_node))->node_id), YARVINSN_topn, 1, (VALUE)(topn_arg)));
            }
            tmp_memo = memo->next;
            free(memo);
            memo = tmp_memo;
        }
        if (!(ok)) {;return 0;};
        APPEND_LIST((ret), (pre));
        APPEND_LIST((ret), (rhs));
        APPEND_LIST((ret), (lhs));
        if (!popped && state.num_args >= 1) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(state.num_args), ((VALUE)(state.num_args)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(state.num_args)))));
        }
        APPEND_LIST((ret), (post));
    }
    return 1;
}
static VALUE
collect_const_segments(rb_iseq_t *iseq, const NODE *node)
{
    VALUE arr = rb_ary_new();
    for (;;) {
        switch (((int) ((((NODE *)(node))->flags & (((VALUE)0x7f)<<8))>>8))) {
          case NODE_CONST:
            rb_ary_unshift(arr, rb_id2sym(((rb_node_const_t *)(node))->nd_vid));
            return arr;
          case NODE_COLON3:
            rb_ary_unshift(arr, rb_id2sym(((rb_node_colon3_t *)(node))->nd_mid));
            rb_ary_unshift(arr, rb_id2sym(idNULL));
            return arr;
          case NODE_COLON2:
            rb_ary_unshift(arr, rb_id2sym(((rb_node_colon2_t *)(node))->nd_mid));
            node = ((rb_node_colon2_t *)(node))->nd_head;
            break;
          default:
            return ((VALUE)RUBY_Qfalse);
        }
    }
}
static int
compile_const_prefix(rb_iseq_t *iseq, const NODE *const node,
                     LINK_ANCHOR *const pref, LINK_ANCHOR *const body)
{
    switch (((int) ((((NODE *)(node))->flags & (((VALUE)0x7f)<<8))>>8))) {
      case NODE_CONST:
        ((void)0);
        ADD_ELEM((body), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qtrue))));
        ADD_ELEM((body), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_getconstant, 1, (VALUE)(rb_id2sym(((rb_node_const_t *)(node))->nd_vid))));
        break;
      case NODE_COLON3:
        ((void)0);
        ADD_ELEM((body), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pop, 0));
        ADD_ELEM((body), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putobject, 1, (VALUE)(rb_cObject)));
        ADD_ELEM((body), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qtrue))));
        ADD_ELEM((body), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_getconstant, 1, (VALUE)(rb_id2sym(((rb_node_colon3_t *)(node))->nd_mid))));
        break;
      case NODE_COLON2:
        if (!(compile_const_prefix(iseq, ((rb_node_colon2_t *)(node))->nd_head, pref, body))) {;return 0;};
        ((void)0);
        ADD_ELEM((body), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qfalse))));
        ADD_ELEM((body), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_getconstant, 1, (VALUE)(rb_id2sym(((rb_node_colon2_t *)(node))->nd_mid))));
        break;
      default:
        if (!(((iseq_compile_each(iseq, (pref), (node), 0))))) {;return 0;};
        break;
    }
    return 1;
}
static int
compile_cpath(LINK_ANCHOR *const ret, rb_iseq_t *iseq, const NODE *cpath)
{
    if (nd_type_p(cpath, NODE_COLON3)) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(cpath)->flags)>>(8 +7)), (((NODE *)(cpath))->node_id), YARVINSN_putobject, 1, (VALUE)(rb_cObject)));
        return 0x08;
    }
    else if (nd_type_p(cpath, NODE_COLON2) && ((rb_node_colon2_t *)(cpath))->nd_head) {
        (void)(((iseq_compile_each(iseq, (ret), (((rb_node_colon2_t *)(cpath))->nd_head), 0))));
        return 0x08;
    }
    else {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(cpath)->flags)>>(8 +7)), (((NODE *)(cpath))->node_id), YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_CONST_BASE), ((VALUE)(VM_SPECIAL_OBJECT_CONST_BASE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_CONST_BASE)))));
        return 0;
    }
}
static inline int
private_recv_p(const NODE *node)
{
    NODE *recv = get_nd_recv(node);
    if (recv && nd_type_p(recv, NODE_SELF)) {
        return ((rb_node_self_t *)(recv))->nd_state != 0;
    }
    return 0;
}
static void
defined_expr(rb_iseq_t *iseq, LINK_ANCHOR *const ret,
             const NODE *const node, LABEL **lfinish, VALUE needstr, _Bool ignore);
static int
compile_call(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, const enum node_type type, const NODE *const line_node, int popped, _Bool assume_receiver);
static void
defined_expr0(rb_iseq_t *iseq, LINK_ANCHOR *const ret,
              const NODE *const node, LABEL **lfinish, VALUE needstr,
              _Bool keep_result)
{
    enum defined_type expr_type = DEFINED_NOT_DEFINED;
    enum node_type type;
    const int line = (int)(((long)(node)->flags)>>(8 +7));
    const NODE *line_node = node;
    switch (type = ((int) ((((NODE *)(node))->flags & (((VALUE)0x7f)<<8))>>8))) {
      case NODE_NIL:
        expr_type = DEFINED_NIL;
        break;
      case NODE_SELF:
        expr_type = DEFINED_SELF;
        break;
      case NODE_TRUE:
        expr_type = DEFINED_TRUE;
        break;
      case NODE_FALSE:
        expr_type = DEFINED_FALSE;
        break;
      case NODE_HASH:
      case NODE_LIST:{
        const NODE *vals = (((int) ((((NODE *)(node))->flags & (((VALUE)0x7f)<<8))>>8)) == NODE_HASH) ? ((rb_node_hash_t *)(node))->nd_head : node;
        if (vals) {
            do {
                if (((rb_node_list_t *)(vals))->nd_head) {
                    defined_expr0(iseq, ret, ((rb_node_list_t *)(vals))->nd_head, lfinish, ((VALUE)RUBY_Qfalse), 0);
                    if (!lfinish[1]) {
                        lfinish[1] = new_label_body(iseq, (line));
                    }
                    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_branchunless, 1, (VALUE)(lfinish[1]))), ((lfinish[1])->refcnt++));
                }
            } while ((vals = ((rb_node_list_t *)(vals))->nd_next) != ((void *)0));
        }
      }
      case NODE_STR:
      case NODE_SYM:
      case NODE_REGX:
      case NODE_LINE:
      case NODE_FILE:
      case NODE_ENCODING:
      case NODE_INTEGER:
      case NODE_FLOAT:
      case NODE_RATIONAL:
      case NODE_IMAGINARY:
      case NODE_ZLIST:
      case NODE_AND:
      case NODE_OR:
      default:
        expr_type = DEFINED_EXPR;
        break;
      case NODE_SPLAT:
        defined_expr0(iseq, ret, ((rb_node_list_t *)(node))->nd_head, lfinish, ((VALUE)RUBY_Qfalse), 0);
        if (!lfinish[1]) {
            lfinish[1] = new_label_body(iseq, (line));
        }
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_branchunless, 1, (VALUE)(lfinish[1]))), ((lfinish[1])->refcnt++));
        expr_type = DEFINED_EXPR;
        break;
      case NODE_LVAR:
      case NODE_DVAR:
        expr_type = DEFINED_LVAR;
        break;
      case NODE_IVAR:
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_definedivar, 3, (VALUE)(rb_id2sym(((rb_node_ivar_t *)(node))->nd_vid)), (VALUE)(get_ivar_ic_value(iseq,((rb_node_ivar_t *)(node))->nd_vid)), (VALUE)((needstr == ((VALUE)RUBY_Qfalse) ? ((VALUE)RUBY_Qtrue) : rb_iseq_defined_string(DEFINED_IVAR)))));
        return;
      case NODE_GVAR:
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putnil, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_defined, 3, (VALUE)(__builtin_choose_expr( __builtin_constant_p(DEFINED_GVAR), ((VALUE)(DEFINED_GVAR)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(DEFINED_GVAR))), (VALUE)(rb_id2sym(((rb_node_gvar_t *)(node))->nd_vid)), (VALUE)((needstr == ((VALUE)RUBY_Qfalse) ? ((VALUE)RUBY_Qtrue) : rb_iseq_defined_string(DEFINED_GVAR)))));
        return;
      case NODE_CVAR:
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putnil, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_defined, 3, (VALUE)(__builtin_choose_expr( __builtin_constant_p(DEFINED_CVAR), ((VALUE)(DEFINED_CVAR)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(DEFINED_CVAR))), (VALUE)(rb_id2sym(((rb_node_cvar_t *)(node))->nd_vid)), (VALUE)((needstr == ((VALUE)RUBY_Qfalse) ? ((VALUE)RUBY_Qtrue) : rb_iseq_defined_string(DEFINED_CVAR)))));
        return;
      case NODE_CONST:
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putnil, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_defined, 3, (VALUE)(__builtin_choose_expr( __builtin_constant_p(DEFINED_CONST), ((VALUE)(DEFINED_CONST)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(DEFINED_CONST))), (VALUE)(rb_id2sym(((rb_node_const_t *)(node))->nd_vid)), (VALUE)((needstr == ((VALUE)RUBY_Qfalse) ? ((VALUE)RUBY_Qtrue) : rb_iseq_defined_string(DEFINED_CONST)))));
        return;
      case NODE_COLON2:
        if (!lfinish[1]) {
            lfinish[1] = new_label_body(iseq, (line));
        }
        defined_expr0(iseq, ret, ((rb_node_colon2_t *)(node))->nd_head, lfinish, ((VALUE)RUBY_Qfalse), 0);
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_branchunless, 1, (VALUE)(lfinish[1]))), ((lfinish[1])->refcnt++));
        (void)(((iseq_compile_each(iseq, (ret), (((rb_node_colon2_t *)(node))->nd_head), 0))));
        if (rb_is_const_id(((rb_node_colon2_t *)(node))->nd_mid)) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_defined, 3, (VALUE)(__builtin_choose_expr( __builtin_constant_p(DEFINED_CONST_FROM), ((VALUE)(DEFINED_CONST_FROM)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(DEFINED_CONST_FROM))), (VALUE)(rb_id2sym(((rb_node_colon2_t *)(node))->nd_mid)), (VALUE)((needstr == ((VALUE)RUBY_Qfalse) ? ((VALUE)RUBY_Qtrue) : rb_iseq_defined_string(DEFINED_CONST)))));
        }
        else {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_defined, 3, (VALUE)(__builtin_choose_expr( __builtin_constant_p(DEFINED_METHOD), ((VALUE)(DEFINED_METHOD)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(DEFINED_METHOD))), (VALUE)(rb_id2sym(((rb_node_colon2_t *)(node))->nd_mid)), (VALUE)((needstr == ((VALUE)RUBY_Qfalse) ? ((VALUE)RUBY_Qtrue) : rb_iseq_defined_string(DEFINED_METHOD)))));
        }
        return;
      case NODE_COLON3:
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(rb_cObject)));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_defined, 3, (VALUE)(__builtin_choose_expr( __builtin_constant_p(DEFINED_CONST_FROM), ((VALUE)(DEFINED_CONST_FROM)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(DEFINED_CONST_FROM))), (VALUE)(rb_id2sym(((rb_node_colon3_t *)(node))->nd_mid)), (VALUE)((needstr == ((VALUE)RUBY_Qfalse) ? ((VALUE)RUBY_Qtrue) : rb_iseq_defined_string(DEFINED_CONST)))));
        return;
      case NODE_CALL:
      case NODE_OPCALL:
      case NODE_VCALL:
      case NODE_FCALL:
      case NODE_ATTRASGN:{
        const int explicit_receiver =
            (type == NODE_CALL || type == NODE_OPCALL ||
             (type == NODE_ATTRASGN && !private_recv_p(node)));
        if (get_nd_args(node) || explicit_receiver) {
            if (!lfinish[1]) {
                lfinish[1] = new_label_body(iseq, (line));
            }
            if (!lfinish[2]) {
                lfinish[2] = new_label_body(iseq, (line));
            }
        }
        if (get_nd_args(node)) {
            defined_expr0(iseq, ret, get_nd_args(node), lfinish, ((VALUE)RUBY_Qfalse), 0);
            (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_branchunless, 1, (VALUE)(lfinish[1]))), ((lfinish[1])->refcnt++));
        }
        if (explicit_receiver) {
            defined_expr0(iseq, ret, get_nd_recv(node), lfinish, ((VALUE)RUBY_Qfalse), 1);
            switch (((int) ((((NODE *)(get_nd_recv(node)))->flags & (((VALUE)0x7f)<<8))>>8))) {
              case NODE_CALL:
              case NODE_OPCALL:
              case NODE_VCALL:
              case NODE_FCALL:
              case NODE_ATTRASGN:
                (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_branchunless, 1, (VALUE)(lfinish[2]))), ((lfinish[2])->refcnt++));
                compile_call(iseq, ret, get_nd_recv(node), ((int) ((((NODE *)(get_nd_recv(node)))->flags & (((VALUE)0x7f)<<8))>>8)), line_node, 0, 1);
                break;
              default:
                (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_branchunless, 1, (VALUE)(lfinish[1]))), ((lfinish[1])->refcnt++));
                (void)(((iseq_compile_each(iseq, (ret), (get_nd_recv(node)), 0))));
                break;
            }
            if (keep_result) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dup, 0));
            }
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_defined, 3, (VALUE)(__builtin_choose_expr( __builtin_constant_p(DEFINED_METHOD), ((VALUE)(DEFINED_METHOD)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(DEFINED_METHOD))), (VALUE)(rb_id2sym(get_node_call_nd_mid(node))), (VALUE)((needstr == ((VALUE)RUBY_Qfalse) ? ((VALUE)RUBY_Qtrue) : rb_iseq_defined_string(DEFINED_METHOD)))));
        }
        else {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putself, 0));
            if (keep_result) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dup, 0));
            }
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_defined, 3, (VALUE)(__builtin_choose_expr( __builtin_constant_p(DEFINED_FUNC), ((VALUE)(DEFINED_FUNC)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(DEFINED_FUNC))), (VALUE)(rb_id2sym(get_node_call_nd_mid(node))), (VALUE)((needstr == ((VALUE)RUBY_Qfalse) ? ((VALUE)RUBY_Qtrue) : rb_iseq_defined_string(DEFINED_METHOD)))));
        }
        return;
      }
      case NODE_YIELD:
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putnil, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_defined, 3, (VALUE)(__builtin_choose_expr( __builtin_constant_p(DEFINED_YIELD), ((VALUE)(DEFINED_YIELD)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(DEFINED_YIELD))), (VALUE)(0), (VALUE)((needstr == ((VALUE)RUBY_Qfalse) ? ((VALUE)RUBY_Qtrue) : rb_iseq_defined_string(DEFINED_YIELD)))));
        iseq_set_use_block(((iseq)->body)->local_iseq);
        return;
      case NODE_BACK_REF:
      case NODE_NTH_REF:
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putnil, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_defined, 3, (VALUE)(__builtin_choose_expr( __builtin_constant_p(DEFINED_REF), ((VALUE)(DEFINED_REF)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(DEFINED_REF))), (VALUE)(__builtin_choose_expr( __builtin_constant_p((((rb_node_back_ref_t *)(node))->nd_nth << 1) | (type == NODE_BACK_REF)), ((VALUE)((((rb_node_back_ref_t *)(node))->nd_nth << 1) | (type == NODE_BACK_REF))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((((rb_node_back_ref_t *)(node))->nd_nth << 1) | (type == NODE_BACK_REF)))), (VALUE)((needstr == ((VALUE)RUBY_Qfalse) ? ((VALUE)RUBY_Qtrue) : rb_iseq_defined_string(DEFINED_GVAR)))));
        return;
      case NODE_SUPER:
      case NODE_ZSUPER:
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putnil, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_defined, 3, (VALUE)(__builtin_choose_expr( __builtin_constant_p(DEFINED_ZSUPER), ((VALUE)(DEFINED_ZSUPER)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(DEFINED_ZSUPER))), (VALUE)(0), (VALUE)((needstr == ((VALUE)RUBY_Qfalse) ? ((VALUE)RUBY_Qtrue) : rb_iseq_defined_string(DEFINED_ZSUPER)))));
        return;
      case NODE_OP_ASGN1:
      case NODE_OP_ASGN2:
      case NODE_OP_ASGN_OR:
      case NODE_OP_ASGN_AND:
      case NODE_MASGN:
      case NODE_LASGN:
      case NODE_DASGN:
      case NODE_GASGN:
      case NODE_IASGN:
      case NODE_CDECL:
      case NODE_CVASGN:
      case NODE_OP_CDECL:
        expr_type = DEFINED_ASGN;
        break;
    }
    ((void)0);
    if (needstr != ((VALUE)RUBY_Qfalse)) {
        VALUE str = rb_iseq_defined_string(expr_type);
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(str)));
    }
    else {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qtrue))));
    }
}
static void
build_defined_rescue_iseq(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const void *unused)
{
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (0), (-1), YARVINSN_putnil, 0));
    iseq_set_exception_local_table(iseq);
}
static void
defined_expr(rb_iseq_t *iseq, LINK_ANCHOR *const ret,
             const NODE *const node, LABEL **lfinish, VALUE needstr, _Bool ignore)
{
    LINK_ELEMENT *lcur = ret->last;
    defined_expr0(iseq, ret, node, lfinish, needstr, 0);
    if (lfinish[1]) {
        int line = (int)(((long)(node)->flags)>>(8 +7));
        LABEL *lstart = new_label_body(iseq, (line));
        LABEL *lend = new_label_body(iseq, (line));
        const rb_iseq_t *rescue;
        struct rb_iseq_new_with_callback_callback_func *ifunc =
            rb_iseq_new_with_callback_new_callback(build_defined_rescue_iseq, ((void *)0));
        rescue = new_child_iseq_with_callback(iseq, ifunc,
                                              rb_str_concat(((__builtin_constant_p("defined guard in ") ? rbimpl_str_new_cstr : rb_str_new_cstr) ("defined guard in ")),
                                                            ((iseq)->body)->location.label),
                                              iseq, ISEQ_TYPE_RESCUE, 0);
        lstart->rescued = LABEL_RESCUE_BEG;
        lend->rescued = LABEL_RESCUE_END;
        APPEND_ELEM((ret), (lcur), (LINK_ELEMENT *) (lstart));
        ADD_ELEM((ret), (LINK_ELEMENT *) (lend));
        if (!ignore) {
            do { VALUE _e = __extension__ ({ const VALUE args_to_new_ary[] = {(CATCH_TYPE_RESCUE), (VALUE)(lstart) | 1, (VALUE)(lend) | 1, (VALUE)(rescue), (VALUE)(lfinish[1]) | 1}; if (__builtin_constant_p(5)) { __extension__ _Static_assert(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))) == (5), "rb_ary_new_from_args" ": " "numberof(args_to_new_ary) == (5)"); } rb_ary_new_from_values(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))), args_to_new_ary); }); ((lstart) ? (((lstart)->refcnt++), (lstart)->unremovable=1) : 0); ((lend)->refcnt++); ((lfinish[1])->refcnt++); if (RB_NIL_P(ISEQ_COMPILE_DATA(iseq)->catch_table_ary)) (rb_obj_write((VALUE)(iseq), (VALUE *)(&ISEQ_COMPILE_DATA(iseq)->catch_table_ary), (VALUE)(rb_ary_hidden_new(3)), "compile.c", 6207)); rb_ary_push(ISEQ_COMPILE_DATA(iseq)->catch_table_ary, freeze_hide_obj(_e)); } while (0);
        }
    }
}
static int
compile_defined_expr(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, VALUE needstr, _Bool ignore)
{
    const int line = (int)(((long)(node)->flags)>>(8 +7));
    const NODE *line_node = node;
    if (!((rb_node_defined_t *)(node))->nd_head) {
        VALUE str = rb_iseq_defined_string(DEFINED_NIL);
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(str)));
    }
    else {
        LABEL *lfinish[3];
        LINK_ELEMENT *last = ret->last;
        lfinish[0] = new_label_body(iseq, (line));
        lfinish[1] = 0;
        lfinish[2] = 0;
        defined_expr(iseq, ret, ((rb_node_defined_t *)(node))->nd_head, lfinish, needstr, ignore);
        if (lfinish[1]) {
            ELEM_INSERT_NEXT(last, &new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putnil, 0)->link);
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_swap, 0));
            if (lfinish[2]) {
                ADD_ELEM((ret), (LINK_ELEMENT *) (lfinish[2]));
            }
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
            ADD_ELEM((ret), (LINK_ELEMENT *) (lfinish[1]));
        }
        ADD_ELEM((ret), (LINK_ELEMENT *) (lfinish[0]));
    }
    return 1;
}
static VALUE
make_name_for_block(const rb_iseq_t *orig_iseq)
{
    int level = 1;
    const rb_iseq_t *iseq = orig_iseq;
    if (((orig_iseq)->body)->parent_iseq != 0) {
        while (((orig_iseq)->body)->local_iseq != iseq) {
            if (((iseq)->body)->type == ISEQ_TYPE_BLOCK) {
                level++;
            }
            iseq = ((iseq)->body)->parent_iseq;
        }
    }
    if (level == 1) {
        return rb_sprintf("block in %""l""i" "\v", ((iseq)->body)->location.label);
    }
    else {
        return rb_sprintf("block (%d levels) in %""l""i" "\v", level, ((iseq)->body)->location.label);
    }
}
static void
push_ensure_entry(rb_iseq_t *iseq,
                  struct iseq_compile_data_ensure_node_stack *enl,
                  struct ensure_range *er, const void *const node)
{
    enl->ensure_node = node;
    enl->prev = ISEQ_COMPILE_DATA(iseq)->ensure_node_stack;
    enl->erange = er;
    ISEQ_COMPILE_DATA(iseq)->ensure_node_stack = enl;
}
static void
add_ensure_range(rb_iseq_t *iseq, struct ensure_range *erange,
                 LABEL *lstart, LABEL *lend)
{
    struct ensure_range *ne =
        compile_data_alloc(iseq, sizeof(struct ensure_range));
    while (erange->next != 0) {
        erange = erange->next;
    }
    ne->next = 0;
    ne->begin = lend;
    ne->end = erange->end;
    erange->end = lstart;
    erange->next = ne;
}
static _Bool
can_add_ensure_iseq(const rb_iseq_t *iseq)
{
    struct iseq_compile_data_ensure_node_stack *e;
    if (ISEQ_COMPILE_DATA(iseq)->in_rescue && (e = ISEQ_COMPILE_DATA(iseq)->ensure_node_stack) != ((void *)0)) {
        while (e) {
            if (e->ensure_node) return 0;
            e = e->prev;
        }
    }
    return 1;
}
static void
add_ensure_iseq(LINK_ANCHOR *const ret, rb_iseq_t *iseq, int is_return)
{
    ((void)0);
    struct iseq_compile_data_ensure_node_stack *enlp =
        ISEQ_COMPILE_DATA(iseq)->ensure_node_stack;
    struct iseq_compile_data_ensure_node_stack *prev_enlp = enlp;
    LINK_ANCHOR ensure[1] = {{{ISEQ_ELEMENT_ANCHOR,},&ensure[0].anchor}};
    ((ensure->last = &ensure->anchor)->next = ((void *)0));
    while (enlp) {
        if (enlp->erange != ((void *)0)) {
            LINK_ANCHOR ensure_part[1] = {{{ISEQ_ELEMENT_ANCHOR,},&ensure_part[0].anchor}};
            LABEL *lstart = new_label_body(iseq, (0));
            LABEL *lend = new_label_body(iseq, (0));
            ((ensure_part->last = &ensure_part->anchor)->next = ((void *)0));
            add_ensure_range(iseq, enlp->erange, lstart, lend);
            ISEQ_COMPILE_DATA(iseq)->ensure_node_stack = enlp->prev;
            ADD_ELEM((ensure_part), (LINK_ELEMENT *) (lstart));
            (void)(((iseq_compile_each(iseq, (ensure_part), (enlp->ensure_node), 1))));
            ADD_ELEM((ensure_part), (LINK_ELEMENT *) (lend));
            APPEND_LIST((ensure), (ensure_part));
        }
        else {
            if (!is_return) {
                break;
            }
        }
        enlp = enlp->prev;
    }
    ISEQ_COMPILE_DATA(iseq)->ensure_node_stack = prev_enlp;
    APPEND_LIST((ret), (ensure));
}
static _Bool
keyword_node_single_splat_p(NODE *kwnode)
{
    ((void)0);
    NODE *node = ((rb_node_hash_t *)(kwnode))->nd_head;
    return ((rb_node_list_t *)(node))->nd_head == ((void *)0) &&
           ((rb_node_list_t *)(((rb_node_list_t *)(node))->nd_next))->nd_next == ((void *)0);
}
static void
compile_single_keyword_splat_mutable(rb_iseq_t *iseq, LINK_ANCHOR *const args, const NODE *argn,
                                     NODE *kwnode, unsigned int *flag_ptr)
{
    *flag_ptr |= (0x01 << VM_CALL_KW_SPLAT_MUT_bit);
    ADD_ELEM((args), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(argn)->flags)>>(8 +7)), (((NODE *)(argn))->node_id), YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
    ADD_ELEM((args), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(argn)->flags)>>(8 +7)), (((NODE *)(argn))->node_id), YARVINSN_newhash, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))));
    compile_hash(iseq, args, kwnode, 1, 0);
    ADD_ELEM(((args)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((argn))->flags)>>(8 +7)), (((NODE *)((argn)))->node_id), ((id_core_hash_merge_kwd)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
}
static int
setup_args_core(rb_iseq_t *iseq, LINK_ANCHOR *const args, const NODE *argn,
                unsigned int *dup_rest, unsigned int *flag_ptr, struct rb_callinfo_kwarg **kwarg_ptr)
{
    if (!argn) return 0;
    NODE *kwnode = ((void *)0);
    switch (((int) ((((NODE *)(argn))->flags & (((VALUE)0x7f)<<8))>>8))) {
      case NODE_LIST: {
        int len = compile_args(iseq, args, argn, &kwnode);
        ((void)0);
        if (kwnode) {
            if (compile_keyword_arg(iseq, args, kwnode, kwarg_ptr, flag_ptr)) {
                len -= 1;
            }
            else {
                if (keyword_node_single_splat_p(kwnode) && (*dup_rest & 2)) {
                    compile_single_keyword_splat_mutable(iseq, args, argn, kwnode, flag_ptr);
                }
                else {
                    compile_hash(iseq, args, kwnode, 1, 0);
                }
            }
        }
        return len;
      }
      case NODE_SPLAT: {
        (void)(((iseq_compile_each(iseq, (args), (((rb_node_splat_t *)(argn))->nd_head), 0))));
        ADD_ELEM((args), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(argn)->flags)>>(8 +7)), (((NODE *)(argn))->node_id), YARVINSN_splatarray, 1, (VALUE)(((*dup_rest & 1) ? ((VALUE)RUBY_Qtrue) : ((VALUE)RUBY_Qfalse)))));
        if (*dup_rest & 1) *dup_rest &= ~1;
        if (flag_ptr) *flag_ptr |= (0x01 << VM_CALL_ARGS_SPLAT_bit);
        ((void)0);
        return 1;
      }
      case NODE_ARGSCAT: {
        if (flag_ptr) *flag_ptr |= (0x01 << VM_CALL_ARGS_SPLAT_bit);
        int argc = setup_args_core(iseq, args, ((rb_node_argscat_t *)(argn))->nd_head, dup_rest, ((void *)0), ((void *)0));
        _Bool args_pushed = 0;
        if (nd_type_p(((rb_node_argscat_t *)(argn))->nd_body, NODE_LIST)) {
            int rest_len = compile_args(iseq, args, ((rb_node_argscat_t *)(argn))->nd_body, &kwnode);
            if (kwnode) rest_len--;
            ADD_ELEM((args), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(argn)->flags)>>(8 +7)), (((NODE *)(argn))->node_id), YARVINSN_pushtoarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(rest_len), ((VALUE)(rest_len)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(rest_len)))));
            args_pushed = 1;
        }
        else {
            ((void)0);
            (void)(((iseq_compile_each(iseq, (args), (((rb_node_argscat_t *)(argn))->nd_body), 0))));
        }
        if (nd_type_p(((rb_node_argscat_t *)(argn))->nd_head, NODE_LIST)) {
            ADD_ELEM((args), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(argn)->flags)>>(8 +7)), (((NODE *)(argn))->node_id), YARVINSN_splatarray, 1, (VALUE)(((*dup_rest & 1) ? ((VALUE)RUBY_Qtrue) : ((VALUE)RUBY_Qfalse)))));
            if (*dup_rest & 1) *dup_rest &= ~1;
            argc += 1;
        }
        else if (!args_pushed) {
            ADD_ELEM((args), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(argn)->flags)>>(8 +7)), (((NODE *)(argn))->node_id), YARVINSN_concattoarray, 0));
        }
        if (kwnode) {
            *flag_ptr |= (0x01 << VM_CALL_KW_SPLAT_bit);
            compile_hash(iseq, args, kwnode, 1, 0);
            argc += 1;
        }
        return argc;
      }
      case NODE_ARGSPUSH: {
        if (flag_ptr) *flag_ptr |= (0x01 << VM_CALL_ARGS_SPLAT_bit);
        int argc = setup_args_core(iseq, args, ((rb_node_argspush_t *)(argn))->nd_head, dup_rest, ((void *)0), ((void *)0));
        if (nd_type_p(((rb_node_argspush_t *)(argn))->nd_body, NODE_LIST)) {
            int rest_len = compile_args(iseq, args, ((rb_node_argspush_t *)(argn))->nd_body, &kwnode);
            if (kwnode) rest_len--;
            ADD_ELEM((args), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(argn)->flags)>>(8 +7)), (((NODE *)(argn))->node_id), YARVINSN_newarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(rest_len), ((VALUE)(rest_len)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(rest_len)))));
            ADD_ELEM((args), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(argn)->flags)>>(8 +7)), (((NODE *)(argn))->node_id), YARVINSN_pushtoarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
        }
        else {
            if (keyword_node_p(((rb_node_argspush_t *)(argn))->nd_body)) {
                kwnode = ((rb_node_argspush_t *)(argn))->nd_body;
            }
            else {
                (void)(((iseq_compile_each(iseq, (args), (((rb_node_argspush_t *)(argn))->nd_body), 0))));
                ADD_ELEM((args), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(argn)->flags)>>(8 +7)), (((NODE *)(argn))->node_id), YARVINSN_pushtoarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
            }
        }
        if (kwnode) {
            *flag_ptr |= (0x01 << VM_CALL_KW_SPLAT_bit);
            if (!keyword_node_single_splat_p(kwnode)) {
                *flag_ptr |= (0x01 << VM_CALL_KW_SPLAT_MUT_bit);
                compile_hash(iseq, args, kwnode, 1, 0);
            }
            else if (*dup_rest & 2) {
                compile_single_keyword_splat_mutable(iseq, args, argn, kwnode, flag_ptr);
            }
            else {
                compile_hash(iseq, args, kwnode, 1, 0);
            }
            argc += 1;
        }
        return argc;
      }
      default: {
        do { const NODE *error_node = (argn); append_compile_error(iseq, (int)(((long)(error_node)->flags)>>(8 +7)), "setup_arg" ": unknown node (%s)", ruby_node_name(((int) ((((NODE *)(error_node))->flags & (((VALUE)0x7f)<<8))>>8)))); return ((VALUE)RUBY_Qnil); } while (0);
      }
    }
}
static void
setup_args_splat_mut(unsigned int *flag, int dup_rest, int initial_dup_rest)
{
    if ((*flag & (0x01 << VM_CALL_ARGS_SPLAT_bit)) && dup_rest != initial_dup_rest) {
        *flag |= (0x01 << VM_CALL_ARGS_SPLAT_MUT_bit);
    }
}
static _Bool
setup_args_dup_rest_p(const NODE *argn)
{
    switch(((int) ((((NODE *)(argn))->flags & (((VALUE)0x7f)<<8))>>8))) {
      case NODE_LVAR:
      case NODE_DVAR:
      case NODE_GVAR:
      case NODE_IVAR:
      case NODE_CVAR:
      case NODE_CONST:
      case NODE_COLON3:
      case NODE_INTEGER:
      case NODE_FLOAT:
      case NODE_RATIONAL:
      case NODE_IMAGINARY:
      case NODE_STR:
      case NODE_SYM:
      case NODE_REGX:
      case NODE_SELF:
      case NODE_NIL:
      case NODE_TRUE:
      case NODE_FALSE:
      case NODE_LAMBDA:
      case NODE_NTH_REF:
      case NODE_BACK_REF:
        return 0;
      case NODE_COLON2:
        return setup_args_dup_rest_p(((rb_node_colon2_t *)(argn))->nd_head);
      default:
        return 1;
    }
}
static VALUE
setup_args(rb_iseq_t *iseq, LINK_ANCHOR *const args, const NODE *argn,
           unsigned int *flag, struct rb_callinfo_kwarg **keywords)
{
    VALUE ret;
    unsigned int dup_rest = 1, initial_dup_rest;
    if (argn) {
        const NODE *check_arg = nd_type_p(argn, NODE_BLOCK_PASS) ?
            ((rb_node_block_pass_t *)(argn))->nd_head : argn;
        if (check_arg) {
            switch(((int) ((((NODE *)(check_arg))->flags & (((VALUE)0x7f)<<8))>>8))) {
              case(NODE_SPLAT):
                dup_rest = 0;
                break;
              case(NODE_ARGSCAT):
                dup_rest = !nd_type_p(((rb_node_argscat_t *)(check_arg))->nd_head, NODE_LIST);
                break;
              case(NODE_ARGSPUSH):
                dup_rest = !((nd_type_p(((rb_node_argspush_t *)(check_arg))->nd_head, NODE_SPLAT) ||
                    (nd_type_p(((rb_node_argspush_t *)(check_arg))->nd_head, NODE_ARGSCAT) &&
                     nd_type_p(((rb_node_argscat_t *)(((rb_node_argspush_t *)(check_arg))->nd_head))->nd_head, NODE_LIST))) &&
                    nd_type_p(((rb_node_argspush_t *)(check_arg))->nd_body, NODE_HASH) &&
                    !((rb_node_hash_t *)(((rb_node_argspush_t *)(check_arg))->nd_body))->nd_brace);
                if (dup_rest == 0) {
                    NODE *node = ((rb_node_hash_t *)(((rb_node_argspush_t *)(check_arg))->nd_body))->nd_head;
                    while (node) {
                        NODE *key_node = ((rb_node_list_t *)(node))->nd_head;
                        if (key_node && setup_args_dup_rest_p(key_node)) {
                            dup_rest = 1;
                            break;
                        }
                        node = ((rb_node_list_t *)(node))->nd_next;
                        NODE *value_node = ((rb_node_list_t *)(node))->nd_head;
                        if (setup_args_dup_rest_p(value_node)) {
                            dup_rest = 1;
                            break;
                        }
                        node = ((rb_node_list_t *)(node))->nd_next;
                    }
                }
                break;
              default:
                break;
            }
        }
        if (check_arg != argn && setup_args_dup_rest_p(((rb_node_block_pass_t *)(argn))->nd_body)) {
            dup_rest = 1 | 2;
        }
    }
    initial_dup_rest = dup_rest;
    if (argn && nd_type_p(argn, NODE_BLOCK_PASS)) {
        LINK_ANCHOR arg_block[1] = {{{ISEQ_ELEMENT_ANCHOR,},&arg_block[0].anchor}};
        ((arg_block->last = &arg_block->anchor)->next = ((void *)0));
        if (((rb_node_block_pass_t *)(argn))->forwarding && ((((iseq)->body)->local_iseq)->body)->param.flags.forwardable) {
            int idx = ((((iseq)->body)->local_iseq)->body)->local_table_size;
            ((void)0);
            const NODE * arg_node =
                ((rb_node_argspush_t *)(((rb_node_block_pass_t *)(argn))->nd_head))->nd_head;
            int argc = 0;
            if (nd_type_p(arg_node, NODE_ARGSCAT)) {
                argc += setup_args_core(iseq, args, ((rb_node_argscat_t *)(arg_node))->nd_head, &dup_rest, flag, keywords);
            }
            *flag |= (0x01 << VM_CALL_FORWARDING_bit);
            iseq_add_getlocal(iseq, (args), (argn), (idx), (get_lvar_level(iseq)));
            setup_args_splat_mut(flag, dup_rest, initial_dup_rest);
            return __builtin_choose_expr( __builtin_constant_p(argc), ((VALUE)(argc)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(argc));
        }
        else {
            *flag |= (0x01 << VM_CALL_ARGS_BLOCKARG_bit);
            (void)(((iseq_compile_each(iseq, (arg_block), (((rb_node_block_pass_t *)(argn))->nd_body), 0))));
        }
        if (LIST_INSN_SIZE_ONE(arg_block)) {
            LINK_ELEMENT *elem = FIRST_ELEMENT(arg_block);
            if (((elem)->type == ISEQ_ELEMENT_INSN)) {
                INSN *iobj = (INSN *)elem;
                if (iobj->insn_id == YARVINSN_getblockparam) {
                    iobj->insn_id = YARVINSN_getblockparamproxy;
                }
            }
        }
        ret = __builtin_choose_expr( __builtin_constant_p(setup_args_core(iseq, args, ((rb_node_block_pass_t *)(argn))->nd_head, &dup_rest, flag, keywords)), ((VALUE)(setup_args_core(iseq, args, ((rb_node_block_pass_t *)(argn))->nd_head, &dup_rest, flag, keywords))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(setup_args_core(iseq, args, ((rb_node_block_pass_t *)(argn))->nd_head, &dup_rest, flag, keywords)));
        APPEND_LIST((args), (arg_block));
    }
    else {
        ret = __builtin_choose_expr( __builtin_constant_p(setup_args_core(iseq, args, argn, &dup_rest, flag, keywords)), ((VALUE)(setup_args_core(iseq, args, argn, &dup_rest, flag, keywords))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(setup_args_core(iseq, args, argn, &dup_rest, flag, keywords)));
    }
    setup_args_splat_mut(flag, dup_rest, initial_dup_rest);
    return ret;
}
static void
build_postexe_iseq(rb_iseq_t *iseq, LINK_ANCHOR *ret, const void *ptr)
{
    const NODE *body = ptr;
    int line = (int)(((long)(body)->flags)>>(8 +7));
    VALUE argc = __builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0));
    const rb_iseq_t *block = new_child_iseq(iseq, (body), rb_fstring(make_name_for_block(((iseq)->body)->parent_iseq)), iseq, (ISEQ_TYPE_BLOCK), (line));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(body)->flags)>>(8 +7)), (((NODE *)(body))->node_id), YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((body))->flags)>>(8 +7)), (((NODE *)((body)))->node_id), ((id_core_set_postexe)), (VALUE)((argc)), ((block)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p((0x01 << VM_CALL_FCALL_bit)), ((VALUE)((0x01 << VM_CALL_FCALL_bit))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((0x01 << VM_CALL_FCALL_bit)))), (((void *)0))));
    (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)((VALUE)block), "compile.c", 6668));
    iseq_set_local_table(iseq, 0, 0);
}
static void
compile_named_capture_assign(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node)
{
    const NODE *vars;
    LINK_ELEMENT *last;
    int line = (int)(((long)(node)->flags)>>(8 +7));
    const NODE *line_node = node;
    LABEL *fail_label = new_label_body(iseq, (line)), *end_label = new_label_body(iseq, (line));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_getglobal, 1, (VALUE)(rb_id2sym(idBACKREF))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dup, 0));
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_branchunless, 1, (VALUE)(fail_label))), ((fail_label)->refcnt++));
    for (vars = node; vars; vars = ((rb_node_block_t *)(vars))->nd_next) {
        INSN *cap;
        if (((rb_node_block_t *)(vars))->nd_next) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dup, 0));
        }
        last = ret->last;
        (void)(((iseq_compile_each(iseq, (ret), (((rb_node_block_t *)(vars))->nd_head), 1))));
        last = last->next;
        cap = new_insn_send(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), idAREF, __builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)),
                            ((void *)0), __builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)), ((void *)0));
        ELEM_INSERT_PREV(last->next, (LINK_ELEMENT *)cap);
        if (!((rb_node_block_t *)(vars))->nd_next && vars == node) {
            LINK_ANCHOR nom[1] = {{{ISEQ_ELEMENT_ANCHOR,},&nom[0].anchor}};
            ((nom->last = &nom->anchor)->next = ((void *)0));
            (ADD_ELEM((nom), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_jump, 1, (VALUE)(end_label))), ((end_label)->refcnt++));
            ADD_ELEM((nom), (LINK_ELEMENT *) (fail_label));
            ADD_ELEM((nom), (LINK_ELEMENT *) (end_label));
            (nom->last->next = cap->link.next)->prev = nom->last;
            (cap->link.next = nom->anchor.next)->prev = &cap->link;
            return;
        }
    }
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_jump, 1, (VALUE)(end_label))), ((end_label)->refcnt++));
    ADD_ELEM((ret), (LINK_ELEMENT *) (fail_label));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
    for (vars = node; vars; vars = ((rb_node_block_t *)(vars))->nd_next) {
        last = ret->last;
        (void)(((iseq_compile_each(iseq, (ret), (((rb_node_block_t *)(vars))->nd_head), 1))));
        last = last->next;
        ((INSN*)last)->insn_id = YARVINSN_putnil;
        ((INSN*)last)->operand_size = 0;
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) (end_label));
}
static int
optimizable_range_item_p(const NODE *n)
{
    if (!n) return 0;
    switch (((int) ((((NODE *)(n))->flags & (((VALUE)0x7f)<<8))>>8))) {
      case NODE_LINE:
        return 1;
      case NODE_INTEGER:
        return 1;
      case NODE_NIL:
        return 1;
      default:
        return 0;
    }
}
static VALUE
optimized_range_item(const NODE *n)
{
    switch (((int) ((((NODE *)(n))->flags & (((VALUE)0x7f)<<8))>>8))) {
      case NODE_LINE:
        return rb_node_line_lineno_val(n);
      case NODE_INTEGER:
        return rb_node_integer_literal_val(n);
      case NODE_FLOAT:
        return rb_node_float_literal_val(n);
      case NODE_RATIONAL:
        return rb_node_rational_literal_val(n);
      case NODE_IMAGINARY:
        return rb_node_imaginary_literal_val(n);
      case NODE_NIL:
        return ((VALUE)RUBY_Qnil);
      default:
        rb_bug("unexpected node: %s", ruby_node_name(((int) ((((NODE *)(n))->flags & (((VALUE)0x7f)<<8))>>8))));
    }
}
static int
compile_if(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, int popped, const enum node_type type)
{
    const NODE *const node_body = type == NODE_IF ? ((rb_node_if_t *)(node))->nd_body : ((rb_node_unless_t *)(node))->nd_else;
    const NODE *const node_else = type == NODE_IF ? ((rb_node_if_t *)(node))->nd_else : ((rb_node_unless_t *)(node))->nd_body;
    const int line = (int)(((long)(node)->flags)>>(8 +7));
    const NODE *line_node = node;
    LINK_ANCHOR cond_seq[1] = {{{ISEQ_ELEMENT_ANCHOR,},&cond_seq[0].anchor}};
    LABEL *then_label, *else_label, *end_label;
    VALUE branches = ((VALUE)RUBY_Qfalse);
    ((cond_seq->last = &cond_seq->anchor)->next = ((void *)0));
    then_label = new_label_body(iseq, (line));
    else_label = new_label_body(iseq, (line));
    end_label = 0;
    NODE *cond = ((rb_node_if_t *)(node))->nd_cond;
    if (((int) ((((NODE *)(cond))->flags & (((VALUE)0x7f)<<8))>>8)) == NODE_BLOCK) {
        cond = ((rb_node_block_t *)(cond))->nd_head;
    }
    if (!(compile_branch_condition(iseq, cond_seq, cond, then_label, else_label))) {;return 0;};
    APPEND_LIST((ret), (cond_seq));
    if (then_label->refcnt && else_label->refcnt) {
        branches = decl_branch_base(iseq, (rb_int2inum((intptr_t)(void *)(node))), (&((NODE *)(node))->nd_loc), type == NODE_IF ? "if" : "unless");
    }
    if (then_label->refcnt) {
        ADD_ELEM((ret), (LINK_ELEMENT *) (then_label));
        LINK_ANCHOR then_seq[1] = {{{ISEQ_ELEMENT_ANCHOR,},&then_seq[0].anchor}};
        ((then_seq->last = &then_seq->anchor)->next = ((void *)0));
        if (!(((iseq_compile_each(iseq, (then_seq), (node_body), (popped)))))) {;return 0;};
        if (else_label->refcnt) {
            const NODE *const coverage_node = node_body ? node_body : node;
            add_trace_branch_coverage(
                iseq,
                ret,
                (&((NODE *)(coverage_node))->nd_loc),
                (((NODE *)(coverage_node))->node_id),
                0,
                type == NODE_IF ? "then" : "else",
                branches);
            end_label = new_label_body(iseq, (line));
            (ADD_ELEM((then_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_jump, 1, (VALUE)(end_label))), ((end_label)->refcnt++));
            if (!popped) {
                ADD_ELEM((then_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
            }
        }
        APPEND_LIST((ret), (then_seq));
    }
    if (else_label->refcnt) {
        ADD_ELEM((ret), (LINK_ELEMENT *) (else_label));
        LINK_ANCHOR else_seq[1] = {{{ISEQ_ELEMENT_ANCHOR,},&else_seq[0].anchor}};
        ((else_seq->last = &else_seq->anchor)->next = ((void *)0));
        if (!(((iseq_compile_each(iseq, (else_seq), (node_else), (popped)))))) {;return 0;};
        if (then_label->refcnt) {
            const NODE *const coverage_node = node_else ? node_else : node;
            add_trace_branch_coverage(
                iseq,
                ret,
                (&((NODE *)(coverage_node))->nd_loc),
                (((NODE *)(coverage_node))->node_id),
                1,
                type == NODE_IF ? "else" : "then",
                branches);
        }
        APPEND_LIST((ret), (else_seq));
    }
    if (end_label) {
        ADD_ELEM((ret), (LINK_ELEMENT *) (end_label));
    }
    return 1;
}
static int
compile_case(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const orig_node, int popped)
{
    const NODE *vals;
    const NODE *node = orig_node;
    LABEL *endlabel, *elselabel;
    LINK_ANCHOR head[1] = {{{ISEQ_ELEMENT_ANCHOR,},&head[0].anchor}};
    LINK_ANCHOR body_seq[1] = {{{ISEQ_ELEMENT_ANCHOR,},&body_seq[0].anchor}};
    LINK_ANCHOR cond_seq[1] = {{{ISEQ_ELEMENT_ANCHOR,},&cond_seq[0].anchor}};
    int only_special_literals = 1;
    VALUE literals = rb_hash_new();
    int line;
    enum node_type type;
    const NODE *line_node;
    VALUE branches = ((VALUE)RUBY_Qfalse);
    int branch_id = 0;
    ((head->last = &head->anchor)->next = ((void *)0));
    ((body_seq->last = &body_seq->anchor)->next = ((void *)0));
    ((cond_seq->last = &cond_seq->anchor)->next = ((void *)0));
    rb_hash_tbl_raw(literals, "compile.c", 6873)->type = &cdhash_type;
    if (!(((iseq_compile_each(iseq, (head), (((rb_node_case_t *)(node))->nd_head), 0))))) {;return 0;};
    branches = decl_branch_base(iseq, (rb_int2inum((intptr_t)(void *)(node))), (&((NODE *)(node))->nd_loc), "case");
    node = ((rb_node_case_t *)(node))->nd_body;
    do { const NODE *error_node = (node); enum node_type error_type = ((int) ((((NODE *)(error_node))->flags & (((VALUE)0x7f)<<8))>>8)); if (error_type != (NODE_WHEN)) { append_compile_error(iseq, (int)(((long)(error_node)->flags)>>(8 +7)), "NODE_CASE" ": " "NODE_WHEN" " is expected, but %s", ruby_node_name(error_type)); return 0; } } while (0);
    type = ((int) ((((NODE *)(node))->flags & (((VALUE)0x7f)<<8))>>8));
    line = (int)(((long)(node)->flags)>>(8 +7));
    line_node = node;
    endlabel = new_label_body(iseq, (line));
    elselabel = new_label_body(iseq, (line));
    APPEND_LIST((ret), (head));
    while (type == NODE_WHEN) {
        LABEL *l1;
        l1 = new_label_body(iseq, (line));
        ADD_ELEM((body_seq), (LINK_ELEMENT *) (l1));
        ADD_ELEM((body_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
        const NODE *const coverage_node = ((rb_node_when_t *)(node))->nd_body ? ((rb_node_when_t *)(node))->nd_body : node;
        add_trace_branch_coverage(
                iseq,
                body_seq,
                (&((NODE *)(coverage_node))->nd_loc),
                (((NODE *)(coverage_node))->node_id),
                branch_id++,
                "when",
                branches);
        if (!(((iseq_compile_each(iseq, (body_seq), (((rb_node_when_t *)(node))->nd_body), (popped)))))) {;return 0;};
        (ADD_ELEM((body_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_jump, 1, (VALUE)(endlabel))), ((endlabel)->refcnt++));
        vals = ((rb_node_when_t *)(node))->nd_head;
        if (vals) {
            switch (((int) ((((NODE *)(vals))->flags & (((VALUE)0x7f)<<8))>>8))) {
              case NODE_LIST:
                only_special_literals = when_vals(iseq, cond_seq, vals, l1, only_special_literals, literals);
                if (only_special_literals < 0) return 0;
                break;
              case NODE_SPLAT:
              case NODE_ARGSCAT:
              case NODE_ARGSPUSH:
                only_special_literals = 0;
                if (!(when_splat_vals(iseq, cond_seq, vals, l1, only_special_literals, literals))) {;return 0;};
                break;
              default:
                do { const NODE *error_node = (vals); append_compile_error(iseq, (int)(((long)(error_node)->flags)>>(8 +7)), "NODE_CASE" ": unknown node (%s)", ruby_node_name(((int) ((((NODE *)(error_node))->flags & (((VALUE)0x7f)<<8))>>8)))); return 0; } while (0);
            }
        }
        else {
            do { append_compile_error(iseq, (int)(((long)(node)->flags)>>(8 +7)), "NODE_CASE" ": must be " "NODE_LIST" ", but 0"); return 0; } while (0);
        }
        node = ((rb_node_when_t *)(node))->nd_next;
        if (!node) {
            break;
        }
        type = ((int) ((((NODE *)(node))->flags & (((VALUE)0x7f)<<8))>>8));
        line = (int)(((long)(node)->flags)>>(8 +7));
        line_node = node;
    }
    if (node) {
        ADD_ELEM((cond_seq), (LINK_ELEMENT *) (elselabel));
        ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
        add_trace_branch_coverage(iseq, cond_seq, (&((NODE *)(node))->nd_loc), (((NODE *)(node))->node_id), branch_id, "else", branches);
        if (!(((iseq_compile_each(iseq, (cond_seq), (node), (popped)))))) {;return 0;};
        (ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_jump, 1, (VALUE)(endlabel))), ((endlabel)->refcnt++));
    }
    else {
        if(0)printf("== else (implicit)\n");
        ADD_ELEM((cond_seq), (LINK_ELEMENT *) (elselabel));
        ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(orig_node)->flags)>>(8 +7)), (((NODE *)(orig_node))->node_id), YARVINSN_pop, 0));
        add_trace_branch_coverage(iseq, cond_seq, (&((NODE *)(orig_node))->nd_loc), (((NODE *)(orig_node))->node_id), branch_id, "else", branches);
        if (!popped) {
            ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(orig_node)->flags)>>(8 +7)), (((NODE *)(orig_node))->node_id), YARVINSN_putnil, 0));
        }
        (ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(orig_node)->flags)>>(8 +7)), (((NODE *)(orig_node))->node_id), YARVINSN_jump, 1, (VALUE)(endlabel))), ((endlabel)->refcnt++));
    }
    if (only_special_literals && ISEQ_COMPILE_DATA(iseq)->option->specialized_instruction) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(orig_node)->flags)>>(8 +7)), (((NODE *)(orig_node))->node_id), YARVINSN_dup, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(orig_node)->flags)>>(8 +7)), (((NODE *)(orig_node))->node_id), YARVINSN_opt_case_dispatch, 2, (VALUE)(literals), (VALUE)(elselabel)));
        (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(literals), "compile.c", 6961));
        ((elselabel)->refcnt++);
    }
    APPEND_LIST((ret), (cond_seq));
    APPEND_LIST((ret), (body_seq));
    ADD_ELEM((ret), (LINK_ELEMENT *) (endlabel));
    return 1;
}
static int
compile_case2(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const orig_node, int popped)
{
    const NODE *vals;
    const NODE *val;
    const NODE *node = ((rb_node_case2_t *)(orig_node))->nd_body;
    LABEL *endlabel;
    LINK_ANCHOR body_seq[1] = {{{ISEQ_ELEMENT_ANCHOR,},&body_seq[0].anchor}};
    VALUE branches = ((VALUE)RUBY_Qfalse);
    int branch_id = 0;
    branches = decl_branch_base(iseq, (rb_int2inum((intptr_t)(void *)(orig_node))), (&((NODE *)(orig_node))->nd_loc), "case");
    ((body_seq->last = &body_seq->anchor)->next = ((void *)0));
    endlabel = new_label_body(iseq, ((int)(((long)(node)->flags)>>(8 +7))));
    while (node && nd_type_p(node, NODE_WHEN)) {
        const int line = (int)(((long)(node)->flags)>>(8 +7));
        LABEL *l1 = new_label_body(iseq, (line));
        ADD_ELEM((body_seq), (LINK_ELEMENT *) (l1));
        const NODE *const coverage_node = ((rb_node_when_t *)(node))->nd_body ? ((rb_node_when_t *)(node))->nd_body : node;
        add_trace_branch_coverage(
                iseq,
                body_seq,
                (&((NODE *)(coverage_node))->nd_loc),
                (((NODE *)(coverage_node))->node_id),
                branch_id++,
                "when",
                branches);
        if (!(((iseq_compile_each(iseq, (body_seq), (((rb_node_when_t *)(node))->nd_body), (popped)))))) {;return 0;};
        (ADD_ELEM((body_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_jump, 1, (VALUE)(endlabel))), ((endlabel)->refcnt++));
        vals = ((rb_node_when_t *)(node))->nd_head;
        if (!vals) {
            do { append_compile_error(iseq, (int)(((long)(node)->flags)>>(8 +7)), "NODE_WHEN" ": must be " "NODE_LIST" ", but 0"); return 0; } while (0);
        }
        switch (((int) ((((NODE *)(vals))->flags & (((VALUE)0x7f)<<8))>>8))) {
          case NODE_LIST:
            while (vals) {
                LABEL *lnext;
                val = ((rb_node_list_t *)(vals))->nd_head;
                lnext = new_label_body(iseq, ((int)(((long)(val)->flags)>>(8 +7))));
                ((void)0);
                if (!(compile_branch_condition(iseq, ret, val, l1, lnext))) {;return 0;};
                ADD_ELEM((ret), (LINK_ELEMENT *) (lnext));
                vals = ((rb_node_list_t *)(vals))->nd_next;
            }
            break;
          case NODE_SPLAT:
          case NODE_ARGSCAT:
          case NODE_ARGSPUSH:
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(vals)->flags)>>(8 +7)), (((NODE *)(vals))->node_id), YARVINSN_putnil, 0));
            if (!(((iseq_compile_each(iseq, (ret), (vals), 0))))) {;return 0;};
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(vals)->flags)>>(8 +7)), (((NODE *)(vals))->node_id), YARVINSN_checkmatch, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_CHECKMATCH_TYPE_WHEN | 0x04), ((VALUE)(VM_CHECKMATCH_TYPE_WHEN | 0x04)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_CHECKMATCH_TYPE_WHEN | 0x04)))));
            (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(vals)->flags)>>(8 +7)), (((NODE *)(vals))->node_id), YARVINSN_branchif, 1, (VALUE)(l1))), ((l1)->refcnt++));
            break;
          default:
            do { const NODE *error_node = (vals); append_compile_error(iseq, (int)(((long)(error_node)->flags)>>(8 +7)), "NODE_WHEN" ": unknown node (%s)", ruby_node_name(((int) ((((NODE *)(error_node))->flags & (((VALUE)0x7f)<<8))>>8)))); return 0; } while (0);
        }
        node = ((rb_node_when_t *)(node))->nd_next;
    }
    const NODE *const coverage_node = node ? node : orig_node;
    add_trace_branch_coverage(
        iseq,
        ret,
        (&((NODE *)(coverage_node))->nd_loc),
        (((NODE *)(coverage_node))->node_id),
        branch_id,
        "else",
        branches);
    if (!(((iseq_compile_each(iseq, (ret), (node), (popped)))))) {;return 0;};
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(orig_node)->flags)>>(8 +7)), (((NODE *)(orig_node))->node_id), YARVINSN_jump, 1, (VALUE)(endlabel))), ((endlabel)->refcnt++));
    APPEND_LIST((ret), (body_seq));
    ADD_ELEM((ret), (LINK_ELEMENT *) (endlabel));
    return 1;
}
static int iseq_compile_pattern_match(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, LABEL *unmatched, _Bool in_single_pattern, _Bool in_alt_pattern, int base_index, _Bool use_deconstructed_cache);
static int iseq_compile_pattern_constant(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, LABEL *match_failed, _Bool in_single_pattern, int base_index);
static int iseq_compile_array_deconstruct(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, LABEL *deconstruct, LABEL *deconstructed, LABEL *match_failed, LABEL *type_error, _Bool in_single_pattern, int base_index, _Bool use_deconstructed_cache);
static int iseq_compile_pattern_set_general_errmsg(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, VALUE errmsg, int base_index);
static int iseq_compile_pattern_set_length_errmsg(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, VALUE errmsg, VALUE pattern_length, int base_index);
static int iseq_compile_pattern_set_eqq_errmsg(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, int base_index);
static int
iseq_compile_pattern_each(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, LABEL *matched, LABEL *unmatched, _Bool in_single_pattern, _Bool in_alt_pattern, int base_index, _Bool use_deconstructed_cache)
{
    const int line = (int)(((long)(node)->flags)>>(8 +7));
    const NODE *line_node = node;
    switch (((int) ((((NODE *)(node))->flags & (((VALUE)0x7f)<<8))>>8))) {
      case NODE_ARYPTN: {
        const NODE *args = ((rb_node_aryptn_t *)(node))->pre_args;
        const int pre_args_num = ((rb_node_aryptn_t *)(node))->pre_args ? rb_long2int_inline(((rb_node_list_t *)(((rb_node_aryptn_t *)(node))->pre_args))->as.nd_alen) : 0;
        const int post_args_num = ((rb_node_aryptn_t *)(node))->post_args ? rb_long2int_inline(((rb_node_list_t *)(((rb_node_aryptn_t *)(node))->post_args))->as.nd_alen) : 0;
        const int min_argc = pre_args_num + post_args_num;
        const int use_rest_num = ((rb_node_aryptn_t *)(node))->rest_arg && (((((rb_node_aryptn_t *)(node))->rest_arg) != ((NODE *)-1)) ||
                                                      (!((((rb_node_aryptn_t *)(node))->rest_arg) != ((NODE *)-1)) && post_args_num > 0));
        LABEL *match_failed, *type_error, *deconstruct, *deconstructed;
        int i;
        match_failed = new_label_body(iseq, (line));
        type_error = new_label_body(iseq, (line));
        deconstruct = new_label_body(iseq, (line));
        deconstructed = new_label_body(iseq, (line));
        if (use_rest_num) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_swap, 0));
            if (base_index) {
                base_index++;
            }
        }
        if (!(iseq_compile_pattern_constant(iseq, ret, node, match_failed, in_single_pattern, base_index))) {;return 0;};
        if (!(iseq_compile_array_deconstruct(iseq, ret, node, deconstruct, deconstructed, match_failed, type_error, in_single_pattern, base_index, use_deconstructed_cache))) {;return 0;};
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dup, 0));
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((idLength)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(min_argc), ((VALUE)(min_argc)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(min_argc)))));
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((((rb_node_aryptn_t *)(node))->rest_arg ? idGE : idEq)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
        if (in_single_pattern) {
            if (!(iseq_compile_pattern_set_length_errmsg(iseq, ret, node, ((rb_node_aryptn_t *)(node))->rest_arg ? rb_fstring_new(("%p length mismatch (given %p, expected %p+)"), ((sizeof("%p length mismatch (given %p, expected %p+)" "") / sizeof("%p length mismatch (given %p, expected %p+)" ""[0])) - 1)) : rb_fstring_new(("%p length mismatch (given %p, expected %p)"), ((sizeof("%p length mismatch (given %p, expected %p)" "") / sizeof("%p length mismatch (given %p, expected %p)" ""[0])) - 1)), __builtin_choose_expr( __builtin_constant_p(min_argc), ((VALUE)(min_argc)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(min_argc)), base_index + 1 ))) {;return 0;};
        }
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_branchunless, 1, (VALUE)(match_failed))), ((match_failed)->refcnt++));
        for (i = 0; i < pre_args_num; i++) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dup, 0));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(i), ((VALUE)(i)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(i)))));
            ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((idAREF)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
            if (!(iseq_compile_pattern_match(iseq, ret, ((rb_node_list_t *)(args))->nd_head, match_failed, in_single_pattern, in_alt_pattern, base_index + 1 , 0))) {;return 0;};
            args = ((rb_node_list_t *)(args))->nd_next;
        }
        if (((rb_node_aryptn_t *)(node))->rest_arg) {
            if (((((rb_node_aryptn_t *)(node))->rest_arg) != ((NODE *)-1))) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dup, 0));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(pre_args_num), ((VALUE)(pre_args_num)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(pre_args_num)))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
                ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((idLength)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(min_argc), ((VALUE)(min_argc)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(min_argc)))));
                ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((idMINUS)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(4), ((VALUE)(4)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(4)))));
                ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((idAREF)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
                if (!(iseq_compile_pattern_match(iseq, ret, ((rb_node_aryptn_t *)(node))->rest_arg, match_failed, in_single_pattern, in_alt_pattern, base_index + 1 , 0))) {;return 0;};
            }
            else {
                if (post_args_num > 0) {
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dup, 0));
                    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((idLength)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(min_argc), ((VALUE)(min_argc)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(min_argc)))));
                    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((idMINUS)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))));
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
                }
            }
        }
        args = ((rb_node_aryptn_t *)(node))->post_args;
        for (i = 0; i < post_args_num; i++) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dup, 0));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(pre_args_num + i), ((VALUE)(pre_args_num + i)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(pre_args_num + i)))));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)))));
            ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((idPLUS)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
            ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((idAREF)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
            if (!(iseq_compile_pattern_match(iseq, ret, ((rb_node_list_t *)(args))->nd_head, match_failed, in_single_pattern, in_alt_pattern, base_index + 1 , 0))) {;return 0;};
            args = ((rb_node_list_t *)(args))->nd_next;
        }
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
        if (use_rest_num) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
        }
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_jump, 1, (VALUE)(matched))), ((matched)->refcnt++));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putnil, 0));
        if (use_rest_num) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putnil, 0));
        }
        ADD_ELEM((ret), (LINK_ELEMENT *) (type_error));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(rb_eTypeError)));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(rb_fstring_new(("deconstruct must return Array"), ((sizeof("deconstruct must return Array" "") / sizeof("deconstruct must return Array" ""[0])) - 1)))));
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((id_core_raise)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) (match_failed));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
        if (use_rest_num) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
        }
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_jump, 1, (VALUE)(unmatched))), ((unmatched)->refcnt++));
        break;
      }
      case NODE_FNDPTN: {
        const NODE *args = ((rb_node_fndptn_t *)(node))->args;
        const int args_num = ((rb_node_fndptn_t *)(node))->args ? rb_long2int_inline(((rb_node_list_t *)(((rb_node_fndptn_t *)(node))->args))->as.nd_alen) : 0;
        LABEL *match_failed, *type_error, *deconstruct, *deconstructed;
        match_failed = new_label_body(iseq, (line));
        type_error = new_label_body(iseq, (line));
        deconstruct = new_label_body(iseq, (line));
        deconstructed = new_label_body(iseq, (line));
        if (!(iseq_compile_pattern_constant(iseq, ret, node, match_failed, in_single_pattern, base_index))) {;return 0;};
        if (!(iseq_compile_array_deconstruct(iseq, ret, node, deconstruct, deconstructed, match_failed, type_error, in_single_pattern, base_index, use_deconstructed_cache))) {;return 0;};
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dup, 0));
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((idLength)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(args_num), ((VALUE)(args_num)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(args_num)))));
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((idGE)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
        if (in_single_pattern) {
            if (!(iseq_compile_pattern_set_length_errmsg(iseq, ret, node, rb_fstring_new(("%p length mismatch (given %p, expected %p+)"), ((sizeof("%p length mismatch (given %p, expected %p+)" "") / sizeof("%p length mismatch (given %p, expected %p+)" ""[0])) - 1)), __builtin_choose_expr( __builtin_constant_p(args_num), ((VALUE)(args_num)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(args_num)), base_index + 1 ))) {;return 0;};
        }
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_branchunless, 1, (VALUE)(match_failed))), ((match_failed)->refcnt++));
        {
            LABEL *while_begin = new_label_body(iseq, ((int)(((long)(node)->flags)>>(8 +7))));
            LABEL *next_loop = new_label_body(iseq, ((int)(((long)(node)->flags)>>(8 +7))));
            LABEL *find_succeeded = new_label_body(iseq, (line));
            LABEL *find_failed = new_label_body(iseq, ((int)(((long)(node)->flags)>>(8 +7))));
            int j;
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dup, 0));
            ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((idLength)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dup, 0));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(args_num), ((VALUE)(args_num)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(args_num)))));
            ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((idMINUS)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))));
            ADD_ELEM((ret), (LINK_ELEMENT *) (while_begin));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dup, 0));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))));
            ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((idLE)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
            (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_branchunless, 1, (VALUE)(find_failed))), ((find_failed)->refcnt++));
            for (j = 0; j < args_num; j++) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
                if (j != 0) {
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(j), ((VALUE)(j)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(j)))));
                    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((idPLUS)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
                }
                ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((idAREF)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
                if (!(iseq_compile_pattern_match(iseq, ret, ((rb_node_list_t *)(args))->nd_head, next_loop, in_single_pattern, in_alt_pattern, base_index + 4 , 0))) {;return 0;};
                args = ((rb_node_list_t *)(args))->nd_next;
            }
            if (((((rb_node_fndptn_t *)(node))->pre_rest_arg) != ((NODE *)-1))) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))));
                ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((idAREF)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
                if (!(iseq_compile_pattern_match(iseq, ret, ((rb_node_fndptn_t *)(node))->pre_rest_arg, find_failed, in_single_pattern, in_alt_pattern, base_index + 4 , 0))) {;return 0;};
            }
            if (((((rb_node_fndptn_t *)(node))->post_rest_arg) != ((NODE *)-1))) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(args_num), ((VALUE)(args_num)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(args_num)))));
                ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((idPLUS)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)))));
                ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((idAREF)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
                if (!(iseq_compile_pattern_match(iseq, ret, ((rb_node_fndptn_t *)(node))->post_rest_arg, find_failed, in_single_pattern, in_alt_pattern, base_index + 4 , 0))) {;return 0;};
            }
            (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_jump, 1, (VALUE)(find_succeeded))), ((find_succeeded)->refcnt++));
            ADD_ELEM((ret), (LINK_ELEMENT *) (next_loop));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
            ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((idPLUS)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
            (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_jump, 1, (VALUE)(while_begin))), ((while_begin)->refcnt++));
            ADD_ELEM((ret), (LINK_ELEMENT *) (find_failed));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_adjuststack, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)))));
            if (in_single_pattern) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(rb_fstring_new(("%p does not match to find pattern"), ((sizeof("%p does not match to find pattern" "") / sizeof("%p does not match to find pattern" ""[0])) - 1)))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))));
                ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((id_core_sprintf)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(base_index + 1 + 1), ((VALUE)(base_index + 1 + 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(base_index + 1 + 1)))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qfalse))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(base_index + 2 + 2), ((VALUE)(base_index + 2 + 2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(base_index + 2 + 2)))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
            }
            (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_jump, 1, (VALUE)(match_failed))), ((match_failed)->refcnt++));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dupn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)))));
            ADD_ELEM((ret), (LINK_ELEMENT *) (find_succeeded));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_adjuststack, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)))));
        }
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_jump, 1, (VALUE)(matched))), ((matched)->refcnt++));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putnil, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) (type_error));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(rb_eTypeError)));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(rb_fstring_new(("deconstruct must return Array"), ((sizeof("deconstruct must return Array" "") / sizeof("deconstruct must return Array" ""[0])) - 1)))));
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((id_core_raise)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) (match_failed));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_jump, 1, (VALUE)(unmatched))), ((unmatched)->refcnt++));
        break;
      }
      case NODE_HSHPTN: {
        LABEL *match_failed, *type_error;
        VALUE keys = ((VALUE)RUBY_Qnil);
        match_failed = new_label_body(iseq, (line));
        type_error = new_label_body(iseq, (line));
        if (((rb_node_hshptn_t *)(node))->nd_pkwargs && !((rb_node_hshptn_t *)(node))->nd_pkwrestarg) {
            const NODE *kw_args = ((rb_node_hash_t *)(((rb_node_hshptn_t *)(node))->nd_pkwargs))->nd_head;
            keys = rb_ary_new_capa(kw_args ? ((rb_node_list_t *)(kw_args))->as.nd_alen/2 : 0);
            while (kw_args) {
                rb_ary_push(keys, get_symbol_value(iseq, ((rb_node_list_t *)(kw_args))->nd_head));
                kw_args = ((rb_node_list_t *)(((rb_node_list_t *)(kw_args))->nd_next))->nd_next;
            }
        }
        if (!(iseq_compile_pattern_constant(iseq, ret, node, match_failed, in_single_pattern, base_index))) {;return 0;};
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dup, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(rb_id2sym((__builtin_constant_p("deconstruct_keys") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("deconstruct_keys")); }) : (rb_intern)("deconstruct_keys"))))));
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((idRespond_to)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
        if (in_single_pattern) {
            if (!(iseq_compile_pattern_set_general_errmsg(iseq, ret, node, rb_fstring_new(("%p does not respond to #deconstruct_keys"), ((sizeof("%p does not respond to #deconstruct_keys" "") / sizeof("%p does not respond to #deconstruct_keys" ""[0])) - 1)), base_index + 1 ))) {;return 0;};
        }
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_branchunless, 1, (VALUE)(match_failed))), ((match_failed)->refcnt++));
        if (RB_NIL_P(keys)) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putnil, 0));
        }
        else {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_duparray, 1, (VALUE)(keys)));
            (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(rb_obj_hide(keys)), "compile.c", 7496));
        }
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), (((__builtin_constant_p("deconstruct_keys") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("deconstruct_keys")); }) : (rb_intern)("deconstruct_keys")))), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dup, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_checktype, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(RUBY_T_HASH), ((VALUE)(RUBY_T_HASH)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(RUBY_T_HASH)))));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_branchunless, 1, (VALUE)(type_error))), ((type_error)->refcnt++));
        if (((rb_node_hshptn_t *)(node))->nd_pkwrestarg) {
            ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), (((__builtin_constant_p("dup") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("dup")); }) : (rb_intern)("dup")))), (VALUE)((__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
        }
        if (((rb_node_hshptn_t *)(node))->nd_pkwargs) {
            int i;
            int keys_num;
            const NODE *args;
            args = ((rb_node_hash_t *)(((rb_node_hshptn_t *)(node))->nd_pkwargs))->nd_head;
            if (args) {
                LINK_ANCHOR match_values[1] = {{{ISEQ_ELEMENT_ANCHOR,},&match_values[0].anchor}};
                ((match_values->last = &match_values->anchor)->next = ((void *)0));
                keys_num = rb_long2int_inline(((rb_node_list_t *)(args))->as.nd_alen) / 2;
                for (i = 0; i < keys_num; i++) {
                    NODE *key_node = ((rb_node_list_t *)(args))->nd_head;
                    NODE *value_node = ((rb_node_list_t *)(((rb_node_list_t *)(args))->nd_next))->nd_head;
                    VALUE key = get_symbol_value(iseq, key_node);
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dup, 0));
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(key)));
                    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), (((__builtin_constant_p("key?") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("key?")); }) : (rb_intern)("key?")))), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
                    if (in_single_pattern) {
                        LABEL *match_succeeded;
                        match_succeeded = new_label_body(iseq, (line));
                        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dup, 0));
                        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_branchif, 1, (VALUE)(match_succeeded))), ((match_succeeded)->refcnt++));
                        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(rb_str_freeze(rb_sprintf("key not found: %+""l""i" "\v", key)))));
                        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(base_index + 1 + 2), ((VALUE)(base_index + 1 + 2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(base_index + 1 + 2)))));
                        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qtrue))));
                        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(base_index + 2 + 3), ((VALUE)(base_index + 2 + 3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(base_index + 2 + 3)))));
                        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)))));
                        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(base_index + 3 + 4), ((VALUE)(base_index + 3 + 4)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(base_index + 3 + 4)))));
                        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(key)));
                        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(base_index + 4 + 5), ((VALUE)(base_index + 4 + 5)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(base_index + 4 + 5)))));
                        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_adjuststack, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(4), ((VALUE)(4)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(4)))));
                        ADD_ELEM((ret), (LINK_ELEMENT *) (match_succeeded));
                    }
                    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_branchunless, 1, (VALUE)(match_failed))), ((match_failed)->refcnt++));
                    ADD_ELEM((match_values), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dup, 0));
                    ADD_ELEM((match_values), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(key)));
                    ADD_ELEM(((match_values)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((((rb_node_hshptn_t *)(node))->nd_pkwrestarg ? (__builtin_constant_p("delete") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("delete")); }) : (rb_intern)("delete")) : idAREF)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
                    if (!(iseq_compile_pattern_match(iseq, match_values, value_node, match_failed, in_single_pattern, in_alt_pattern, base_index + 1 , 0))) {;return 0;};
                    args = ((rb_node_list_t *)(((rb_node_list_t *)(args))->nd_next))->nd_next;
                }
                APPEND_LIST((ret), (match_values));
            }
        }
        else {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dup, 0));
            ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((idEmptyP)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
            if (in_single_pattern) {
                if (!(iseq_compile_pattern_set_general_errmsg(iseq, ret, node, rb_fstring_new(("%p is not empty"), ((sizeof("%p is not empty" "") / sizeof("%p is not empty" ""[0])) - 1)), base_index + 1 ))) {;return 0;};
            }
            (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_branchunless, 1, (VALUE)(match_failed))), ((match_failed)->refcnt++));
        }
        if (((rb_node_hshptn_t *)(node))->nd_pkwrestarg) {
            if (((rb_node_hshptn_t *)(node))->nd_pkwrestarg == ((NODE *)-1)) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dup, 0));
                ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((idEmptyP)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
                if (in_single_pattern) {
                    if (!(iseq_compile_pattern_set_general_errmsg(iseq, ret, node, rb_fstring_new(("rest of %p is not empty"), ((sizeof("rest of %p is not empty" "") / sizeof("rest of %p is not empty" ""[0])) - 1)), base_index + 1 ))) {;return 0;};
                }
                (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_branchunless, 1, (VALUE)(match_failed))), ((match_failed)->refcnt++));
            }
            else {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dup, 0));
                if (!(iseq_compile_pattern_match(iseq, ret, ((rb_node_hshptn_t *)(node))->nd_pkwrestarg, match_failed, in_single_pattern, in_alt_pattern, base_index + 1 , 0))) {;return 0;};
            }
        }
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_jump, 1, (VALUE)(matched))), ((matched)->refcnt++));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putnil, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) (type_error));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(rb_eTypeError)));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(rb_fstring_new(("deconstruct_keys must return Hash"), ((sizeof("deconstruct_keys must return Hash" "") / sizeof("deconstruct_keys must return Hash" ""[0])) - 1)))));
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((id_core_raise)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) (match_failed));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_jump, 1, (VALUE)(unmatched))), ((unmatched)->refcnt++));
        break;
      }
      case NODE_SYM:
      case NODE_REGX:
      case NODE_LINE:
      case NODE_INTEGER:
      case NODE_FLOAT:
      case NODE_RATIONAL:
      case NODE_IMAGINARY:
      case NODE_FILE:
      case NODE_ENCODING:
      case NODE_STR:
      case NODE_XSTR:
      case NODE_DSTR:
      case NODE_DSYM:
      case NODE_DREGX:
      case NODE_LIST:
      case NODE_ZLIST:
      case NODE_LAMBDA:
      case NODE_DOT2:
      case NODE_DOT3:
      case NODE_CONST:
      case NODE_LVAR:
      case NODE_DVAR:
      case NODE_IVAR:
      case NODE_CVAR:
      case NODE_GVAR:
      case NODE_TRUE:
      case NODE_FALSE:
      case NODE_SELF:
      case NODE_NIL:
      case NODE_COLON2:
      case NODE_COLON3:
      case NODE_BEGIN:
      case NODE_BLOCK:
      case NODE_ONCE:
        if (!(((iseq_compile_each(iseq, (ret), (node), 0))))) {;return 0;};
        if (in_single_pattern) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dupn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))));
        }
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_checkmatch, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_CHECKMATCH_TYPE_CASE), ((VALUE)(VM_CHECKMATCH_TYPE_CASE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_CHECKMATCH_TYPE_CASE)))));
        if (in_single_pattern) {
            if (!(iseq_compile_pattern_set_eqq_errmsg(iseq, ret, node, base_index + 2 ))) {;return 0;};
        }
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_branchif, 1, (VALUE)(matched))), ((matched)->refcnt++));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_jump, 1, (VALUE)(unmatched))), ((unmatched)->refcnt++));
        break;
      case NODE_LASGN: {
        struct rb_iseq_constant_body *const body = ((iseq)->body);
        ID id = ((rb_node_lasgn_t *)(node))->nd_vid;
        int idx = ((body->local_iseq)->body)->local_table_size - get_local_var_idx(iseq, id);
        if (in_alt_pattern) {
            const char *name = rb_id2name(id);
            if (name && strlen(name) > 0 && name[0] != '_') {
                append_compile_error(iseq, (int)(((long)(node)->flags)>>(8 +7)), "illegal variable in alternative pattern (%""l""i" "\v"")",
                              rb_id2str(id));
                return 0;
            }
        }
        iseq_add_setlocal(iseq, (ret), (line_node), (idx), (get_lvar_level(iseq)));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_jump, 1, (VALUE)(matched))), ((matched)->refcnt++));
        break;
      }
      case NODE_DASGN: {
        int idx, lv, ls;
        ID id = ((rb_node_dasgn_t *)(node))->nd_vid;
        idx = get_dyna_var_idx(iseq, id, &lv, &ls);
        if (in_alt_pattern) {
            const char *name = rb_id2name(id);
            if (name && strlen(name) > 0 && name[0] != '_') {
                append_compile_error(iseq, (int)(((long)(node)->flags)>>(8 +7)), "illegal variable in alternative pattern (%""l""i" "\v"")",
                              rb_id2str(id));
                return 0;
            }
        }
        if (idx < 0) {
            append_compile_error(iseq, (int)(((long)(node)->flags)>>(8 +7)), "NODE_DASGN: unknown id (%""l""i" "\v"")",
                          rb_id2str(id));
            return 0;
        }
        iseq_add_setlocal(iseq, (ret), (line_node), (ls - idx), (lv));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_jump, 1, (VALUE)(matched))), ((matched)->refcnt++));
        break;
      }
      case NODE_IF:
      case NODE_UNLESS: {
        LABEL *match_failed;
        match_failed = unmatched;
        if (!(iseq_compile_pattern_match(iseq, ret, ((rb_node_if_t *)(node))->nd_body, unmatched, in_single_pattern, in_alt_pattern, base_index, use_deconstructed_cache))) {;return 0;};
        if (!(((iseq_compile_each(iseq, (ret), (((rb_node_if_t *)(node))->nd_cond), 0))))) {;return 0;};
        if (in_single_pattern) {
            LABEL *match_succeeded;
            match_succeeded = new_label_body(iseq, (line));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dup, 0));
            if (nd_type_p(node, NODE_IF)) {
                (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_branchif, 1, (VALUE)(match_succeeded))), ((match_succeeded)->refcnt++));
            }
            else {
                (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_branchunless, 1, (VALUE)(match_succeeded))), ((match_succeeded)->refcnt++));
            }
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(rb_fstring_new(("guard clause does not return true"), ((sizeof("guard clause does not return true" "") / sizeof("guard clause does not return true" ""[0])) - 1)))));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(base_index + 1 + 1), ((VALUE)(base_index + 1 + 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(base_index + 1 + 1)))));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qfalse))));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(base_index + 2 + 2), ((VALUE)(base_index + 2 + 2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(base_index + 2 + 2)))));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
            ADD_ELEM((ret), (LINK_ELEMENT *) (match_succeeded));
        }
        if (nd_type_p(node, NODE_IF)) {
            (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_branchunless, 1, (VALUE)(match_failed))), ((match_failed)->refcnt++));
        }
        else {
            (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_branchif, 1, (VALUE)(match_failed))), ((match_failed)->refcnt++));
        }
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_jump, 1, (VALUE)(matched))), ((matched)->refcnt++));
        break;
      }
      case NODE_HASH: {
        NODE *n;
        LABEL *match_failed;
        match_failed = new_label_body(iseq, (line));
        n = ((rb_node_hash_t *)(node))->nd_head;
        if (! (nd_type_p(n, NODE_LIST) && ((rb_node_list_t *)(n))->as.nd_alen == 2)) {
            append_compile_error(iseq, (int)(((long)(node)->flags)>>(8 +7)), "unexpected node");
            return 0;
        }
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dup, 0));
        if (!(iseq_compile_pattern_match(iseq, ret, ((rb_node_list_t *)(n))->nd_head, match_failed, in_single_pattern, in_alt_pattern, base_index + 1 , use_deconstructed_cache))) {;return 0;};
        if (!(iseq_compile_pattern_each(iseq, ret, ((rb_node_list_t *)(((rb_node_list_t *)(n))->nd_next))->nd_head, matched, match_failed, in_single_pattern, in_alt_pattern, base_index, 0))) {;return 0;};
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putnil, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) (match_failed));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_jump, 1, (VALUE)(unmatched))), ((unmatched)->refcnt++));
        break;
      }
      case NODE_OR: {
        LABEL *match_succeeded, *fin;
        match_succeeded = new_label_body(iseq, (line));
        fin = new_label_body(iseq, (line));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dup, 0));
        if (!(iseq_compile_pattern_each(iseq, ret, ((rb_node_or_t *)(node))->nd_1st, match_succeeded, fin, in_single_pattern, 1, base_index + 1 , use_deconstructed_cache))) {;return 0;};
        ADD_ELEM((ret), (LINK_ELEMENT *) (match_succeeded));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_jump, 1, (VALUE)(matched))), ((matched)->refcnt++));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putnil, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) (fin));
        if (!(iseq_compile_pattern_each(iseq, ret, ((rb_node_or_t *)(node))->nd_2nd, matched, unmatched, in_single_pattern, 1, base_index, use_deconstructed_cache))) {;return 0;};
        break;
      }
      default:
        do { const NODE *error_node = (node); append_compile_error(iseq, (int)(((long)(error_node)->flags)>>(8 +7)), "NODE_IN" ": unknown node (%s)", ruby_node_name(((int) ((((NODE *)(error_node))->flags & (((VALUE)0x7f)<<8))>>8)))); return 0; } while (0);
    }
    return 1;
}
static int
iseq_compile_pattern_match(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, LABEL *unmatched, _Bool in_single_pattern, _Bool in_alt_pattern, int base_index, _Bool use_deconstructed_cache)
{
    LABEL *fin = new_label_body(iseq, ((int)(((long)(node)->flags)>>(8 +7))));
    if (!(iseq_compile_pattern_each(iseq, ret, node, fin, unmatched, in_single_pattern, in_alt_pattern, base_index, use_deconstructed_cache))) {;return 0;};
    ADD_ELEM((ret), (LINK_ELEMENT *) (fin));
    return 1;
}
static int
iseq_compile_pattern_constant(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, LABEL *match_failed, _Bool in_single_pattern, int base_index)
{
    const NODE *line_node = node;
    if (((rb_node_aryptn_t *)(node))->nd_pconst) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dup, 0));
        if (!(((iseq_compile_each(iseq, (ret), (((rb_node_aryptn_t *)(node))->nd_pconst), 0))))) {;return 0;};
        if (in_single_pattern) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dupn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))));
        }
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_checkmatch, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_CHECKMATCH_TYPE_CASE), ((VALUE)(VM_CHECKMATCH_TYPE_CASE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_CHECKMATCH_TYPE_CASE)))));
        if (in_single_pattern) {
            if (!(iseq_compile_pattern_set_eqq_errmsg(iseq, ret, node, base_index + 3 ))) {;return 0;};
        }
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_branchunless, 1, (VALUE)(match_failed))), ((match_failed)->refcnt++));
    }
    return 1;
}
static int
iseq_compile_array_deconstruct(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, LABEL *deconstruct, LABEL *deconstructed, LABEL *match_failed, LABEL *type_error, _Bool in_single_pattern, int base_index, _Bool use_deconstructed_cache)
{
    const NODE *line_node = node;
    if (use_deconstructed_cache) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(base_index + 0), ((VALUE)(base_index + 0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(base_index + 0)))));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_branchnil, 1, (VALUE)(deconstruct))), ((deconstruct)->refcnt++));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(base_index + 0), ((VALUE)(base_index + 0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(base_index + 0)))));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_branchunless, 1, (VALUE)(match_failed))), ((match_failed)->refcnt++));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(base_index + 0 - 1), ((VALUE)(base_index + 0 - 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(base_index + 0 - 1)))));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_jump, 1, (VALUE)(deconstructed))), ((deconstructed)->refcnt++));
    }
    else {
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_jump, 1, (VALUE)(deconstruct))), ((deconstruct)->refcnt++));
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) (deconstruct));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dup, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(rb_id2sym((__builtin_constant_p("deconstruct") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("deconstruct")); }) : (rb_intern)("deconstruct"))))));
    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((idRespond_to)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
    if (use_deconstructed_cache) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(base_index + 0 + 1), ((VALUE)(base_index + 0 + 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(base_index + 0 + 1)))));
    }
    if (in_single_pattern) {
        if (!(iseq_compile_pattern_set_general_errmsg(iseq, ret, node, rb_fstring_new(("%p does not respond to #deconstruct"), ((sizeof("%p does not respond to #deconstruct" "") / sizeof("%p does not respond to #deconstruct" ""[0])) - 1)), base_index + 1 ))) {;return 0;};
    }
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_branchunless, 1, (VALUE)(match_failed))), ((match_failed)->refcnt++));
    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), (((__builtin_constant_p("deconstruct") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("deconstruct")); }) : (rb_intern)("deconstruct")))), (VALUE)((__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
    if (use_deconstructed_cache) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(base_index + 0), ((VALUE)(base_index + 0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(base_index + 0)))));
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dup, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_checktype, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(RUBY_T_ARRAY), ((VALUE)(RUBY_T_ARRAY)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(RUBY_T_ARRAY)))));
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_branchunless, 1, (VALUE)(type_error))), ((type_error)->refcnt++));
    ADD_ELEM((ret), (LINK_ELEMENT *) (deconstructed));
    return 1;
}
static int
iseq_compile_pattern_set_general_errmsg(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, VALUE errmsg, int base_index)
{
    const int line = (int)(((long)(node)->flags)>>(8 +7));
    const NODE *line_node = node;
    LABEL *match_succeeded = new_label_body(iseq, (line));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dup, 0));
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_branchif, 1, (VALUE)(match_succeeded))), ((match_succeeded)->refcnt++));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(errmsg)));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)))));
    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((id_core_sprintf)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(base_index + 1 + 1), ((VALUE)(base_index + 1 + 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(base_index + 1 + 1)))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qfalse))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(base_index + 2 + 2), ((VALUE)(base_index + 2 + 2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(base_index + 2 + 2)))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) (match_succeeded));
    return 1;
}
static int
iseq_compile_pattern_set_length_errmsg(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, VALUE errmsg, VALUE pattern_length, int base_index)
{
    const int line = (int)(((long)(node)->flags)>>(8 +7));
    const NODE *line_node = node;
    LABEL *match_succeeded = new_label_body(iseq, (line));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dup, 0));
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_branchif, 1, (VALUE)(match_succeeded))), ((match_succeeded)->refcnt++));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(errmsg)));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dup, 0));
    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((idLength)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(pattern_length)));
    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((id_core_sprintf)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(4), ((VALUE)(4)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(4)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(base_index + 1 + 1), ((VALUE)(base_index + 1 + 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(base_index + 1 + 1)))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qfalse))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(base_index + 2 + 2), ((VALUE)(base_index + 2 + 2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(base_index + 2 + 2)))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) (match_succeeded));
    return 1;
}
static int
iseq_compile_pattern_set_eqq_errmsg(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, int base_index)
{
    const int line = (int)(((long)(node)->flags)>>(8 +7));
    const NODE *line_node = node;
    LABEL *match_succeeded = new_label_body(iseq, (line));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dup, 0));
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_branchif, 1, (VALUE)(match_succeeded))), ((match_succeeded)->refcnt++));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(rb_fstring_new(("%p === %p does not return true"), ((sizeof("%p === %p does not return true" "") / sizeof("%p === %p does not return true" ""[0])) - 1)))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(5), ((VALUE)(5)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(5)))));
    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((id_core_sprintf)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(base_index + 1 + 1), ((VALUE)(base_index + 1 + 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(base_index + 1 + 1)))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qfalse))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(base_index + 2 + 2), ((VALUE)(base_index + 2 + 2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(base_index + 2 + 2)))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) (match_succeeded));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
    return 1;
}
static int
compile_case3(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const orig_node, int popped)
{
    const NODE *pattern;
    const NODE *node = orig_node;
    LABEL *endlabel, *elselabel;
    LINK_ANCHOR head[1] = {{{ISEQ_ELEMENT_ANCHOR,},&head[0].anchor}};
    LINK_ANCHOR body_seq[1] = {{{ISEQ_ELEMENT_ANCHOR,},&body_seq[0].anchor}};
    LINK_ANCHOR cond_seq[1] = {{{ISEQ_ELEMENT_ANCHOR,},&cond_seq[0].anchor}};
    int line;
    enum node_type type;
    const NODE *line_node;
    VALUE branches = 0;
    int branch_id = 0;
    _Bool single_pattern;
    ((head->last = &head->anchor)->next = ((void *)0));
    ((body_seq->last = &body_seq->anchor)->next = ((void *)0));
    ((cond_seq->last = &cond_seq->anchor)->next = ((void *)0));
    branches = decl_branch_base(iseq, (rb_int2inum((intptr_t)(void *)(node))), (&((NODE *)(node))->nd_loc), "case");
    node = ((rb_node_case3_t *)(node))->nd_body;
    do { const NODE *error_node = (node); enum node_type error_type = ((int) ((((NODE *)(error_node))->flags & (((VALUE)0x7f)<<8))>>8)); if (error_type != (NODE_IN)) { append_compile_error(iseq, (int)(((long)(error_node)->flags)>>(8 +7)), "NODE_CASE3" ": " "NODE_IN" " is expected, but %s", ruby_node_name(error_type)); return 0; } } while (0);
    type = ((int) ((((NODE *)(node))->flags & (((VALUE)0x7f)<<8))>>8));
    line = (int)(((long)(node)->flags)>>(8 +7));
    line_node = node;
    single_pattern = !((rb_node_in_t *)(node))->nd_next;
    endlabel = new_label_body(iseq, (line));
    elselabel = new_label_body(iseq, (line));
    if (single_pattern) {
        ADD_ELEM((head), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putnil, 0));
        ADD_ELEM((head), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putnil, 0));
        ADD_ELEM((head), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qfalse))));
        ADD_ELEM((head), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putnil, 0));
    }
    ADD_ELEM((head), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putnil, 0));
    if (!(((iseq_compile_each(iseq, (head), (((rb_node_case3_t *)(orig_node))->nd_head), 0))))) {;return 0;};
    APPEND_LIST((ret), (head));
    while (type == NODE_IN) {
        LABEL *l1;
        if (branch_id) {
            ADD_ELEM((body_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putnil, 0));
        }
        l1 = new_label_body(iseq, (line));
        ADD_ELEM((body_seq), (LINK_ELEMENT *) (l1));
        ADD_ELEM((body_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_adjuststack, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(single_pattern ? 6 : 2), ((VALUE)(single_pattern ? 6 : 2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(single_pattern ? 6 : 2)))));
        const NODE *const coverage_node = ((rb_node_in_t *)(node))->nd_body ? ((rb_node_in_t *)(node))->nd_body : node;
        add_trace_branch_coverage(
            iseq,
            body_seq,
            (&((NODE *)(coverage_node))->nd_loc),
            (((NODE *)(coverage_node))->node_id),
            branch_id++,
            "in",
            branches);
        if (!(((iseq_compile_each(iseq, (body_seq), (((rb_node_in_t *)(node))->nd_body), (popped)))))) {;return 0;};
        (ADD_ELEM((body_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_jump, 1, (VALUE)(endlabel))), ((endlabel)->refcnt++));
        pattern = ((rb_node_in_t *)(node))->nd_head;
        if (pattern) {
            int pat_line = (int)(((long)(pattern)->flags)>>(8 +7));
            LABEL *next_pat = new_label_body(iseq, (pat_line));
            ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(pattern)->flags)>>(8 +7)), (((NODE *)(pattern))->node_id), YARVINSN_dup, 0));
            if (!(iseq_compile_pattern_each(iseq, cond_seq, pattern, l1, next_pat, single_pattern, 0, 2, 1))) {;return 0;};
            ADD_ELEM((cond_seq), (LINK_ELEMENT *) (next_pat));
            ((next_pat) ? (((next_pat)->refcnt++), (next_pat)->unremovable=1) : 0);
        }
        else {
            append_compile_error(iseq, (int)(((long)(node)->flags)>>(8 +7)), "unexpected node");
            return 0;
        }
        node = ((rb_node_in_t *)(node))->nd_next;
        if (!node) {
            break;
        }
        type = ((int) ((((NODE *)(node))->flags & (((VALUE)0x7f)<<8))>>8));
        line = (int)(((long)(node)->flags)>>(8 +7));
        line_node = node;
    }
    if (node) {
        ADD_ELEM((cond_seq), (LINK_ELEMENT *) (elselabel));
        ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
        ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
        add_trace_branch_coverage(iseq, cond_seq, (&((NODE *)(node))->nd_loc), (((NODE *)(node))->node_id), branch_id, "else", branches);
        if (!(((iseq_compile_each(iseq, (cond_seq), (node), (popped)))))) {;return 0;};
        (ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_jump, 1, (VALUE)(endlabel))), ((endlabel)->refcnt++));
        ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putnil, 0));
        if (popped) {
            ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putnil, 0));
        }
    }
    else {
        if(0)printf("== else (implicit)\n");
        ADD_ELEM((cond_seq), (LINK_ELEMENT *) (elselabel));
        add_trace_branch_coverage(iseq, cond_seq, (&((NODE *)(orig_node))->nd_loc), (((NODE *)(orig_node))->node_id), branch_id, "else", branches);
        ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(orig_node)->flags)>>(8 +7)), (((NODE *)(orig_node))->node_id), YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
        if (single_pattern) {
            LABEL *key_error, *fin;
            struct rb_callinfo_kwarg *kw_arg;
            key_error = new_label_body(iseq, (line));
            fin = new_label_body(iseq, (line));
            kw_arg = rb_xmalloc_mul_add(2, sizeof(VALUE), sizeof(struct rb_callinfo_kwarg));
            kw_arg->references = 0;
            kw_arg->keyword_len = 2;
            kw_arg->keywords[0] = rb_id2sym((__builtin_constant_p("matchee") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("matchee")); }) : (rb_intern)("matchee")));
            kw_arg->keywords[1] = rb_id2sym((__builtin_constant_p("key") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("key")); }) : (rb_intern)("key")));
            ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(orig_node)->flags)>>(8 +7)), (((NODE *)(orig_node))->node_id), YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(2 + 2), ((VALUE)(2 + 2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2 + 2)))));
            (ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(orig_node)->flags)>>(8 +7)), (((NODE *)(orig_node))->node_id), YARVINSN_branchif, 1, (VALUE)(key_error))), ((key_error)->refcnt++));
            ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(orig_node)->flags)>>(8 +7)), (((NODE *)(orig_node))->node_id), YARVINSN_putobject, 1, (VALUE)(rb_eNoMatchingPatternError)));
            ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(orig_node)->flags)>>(8 +7)), (((NODE *)(orig_node))->node_id), YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
            ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(orig_node)->flags)>>(8 +7)), (((NODE *)(orig_node))->node_id), YARVINSN_putobject, 1, (VALUE)(rb_fstring_new(("%p: %s"), ((sizeof("%p: %s" "") / sizeof("%p: %s" ""[0])) - 1)))));
            ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(orig_node)->flags)>>(8 +7)), (((NODE *)(orig_node))->node_id), YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(4), ((VALUE)(4)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(4)))));
            ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(orig_node)->flags)>>(8 +7)), (((NODE *)(orig_node))->node_id), YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1 + 6), ((VALUE)(1 + 6)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1 + 6)))));
            ADD_ELEM(((cond_seq)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((orig_node))->flags)>>(8 +7)), (((NODE *)((orig_node)))->node_id), ((id_core_sprintf)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
            ADD_ELEM(((cond_seq)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((orig_node))->flags)>>(8 +7)), (((NODE *)((orig_node)))->node_id), ((id_core_raise)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
            (ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(orig_node)->flags)>>(8 +7)), (((NODE *)(orig_node))->node_id), YARVINSN_jump, 1, (VALUE)(fin))), ((fin)->refcnt++));
            ADD_ELEM((cond_seq), (LINK_ELEMENT *) (key_error));
            ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(orig_node)->flags)>>(8 +7)), (((NODE *)(orig_node))->node_id), YARVINSN_putobject, 1, (VALUE)(rb_eNoMatchingPatternKeyError)));
            ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(orig_node)->flags)>>(8 +7)), (((NODE *)(orig_node))->node_id), YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
            ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(orig_node)->flags)>>(8 +7)), (((NODE *)(orig_node))->node_id), YARVINSN_putobject, 1, (VALUE)(rb_fstring_new(("%p: %s"), ((sizeof("%p: %s" "") / sizeof("%p: %s" ""[0])) - 1)))));
            ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(orig_node)->flags)>>(8 +7)), (((NODE *)(orig_node))->node_id), YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(4), ((VALUE)(4)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(4)))));
            ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(orig_node)->flags)>>(8 +7)), (((NODE *)(orig_node))->node_id), YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1 + 6), ((VALUE)(1 + 6)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1 + 6)))));
            ADD_ELEM(((cond_seq)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((orig_node))->flags)>>(8 +7)), (((NODE *)((orig_node)))->node_id), ((id_core_sprintf)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
            ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(orig_node)->flags)>>(8 +7)), (((NODE *)(orig_node))->node_id), YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(3 + 4), ((VALUE)(3 + 4)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3 + 4)))));
            ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(orig_node)->flags)>>(8 +7)), (((NODE *)(orig_node))->node_id), YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(4 + 5), ((VALUE)(4 + 5)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(4 + 5)))));
            ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)(orig_node)->flags)>>(8 +7)), (((NODE *)(orig_node))->node_id), ((__builtin_constant_p("new") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("new")); }) : (rb_intern)("new"))), (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1))), (((void *)0)), (VALUE)(__builtin_choose_expr( __builtin_constant_p((0x01 << VM_CALL_KWARG_bit)), ((VALUE)((0x01 << VM_CALL_KWARG_bit))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((0x01 << VM_CALL_KWARG_bit)))), (kw_arg)));
            ADD_ELEM(((cond_seq)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((orig_node))->flags)>>(8 +7)), (((NODE *)((orig_node)))->node_id), ((id_core_raise)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
            ADD_ELEM((cond_seq), (LINK_ELEMENT *) (fin));
        }
        else {
            ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(orig_node)->flags)>>(8 +7)), (((NODE *)(orig_node))->node_id), YARVINSN_putobject, 1, (VALUE)(rb_eNoMatchingPatternError)));
            ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(orig_node)->flags)>>(8 +7)), (((NODE *)(orig_node))->node_id), YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))));
            ADD_ELEM(((cond_seq)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((orig_node))->flags)>>(8 +7)), (((NODE *)((orig_node)))->node_id), ((id_core_raise)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
        }
        ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(orig_node)->flags)>>(8 +7)), (((NODE *)(orig_node))->node_id), YARVINSN_adjuststack, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(single_pattern ? 7 : 3), ((VALUE)(single_pattern ? 7 : 3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(single_pattern ? 7 : 3)))));
        if (!popped) {
            ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(orig_node)->flags)>>(8 +7)), (((NODE *)(orig_node))->node_id), YARVINSN_putnil, 0));
        }
        (ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(orig_node)->flags)>>(8 +7)), (((NODE *)(orig_node))->node_id), YARVINSN_jump, 1, (VALUE)(endlabel))), ((endlabel)->refcnt++));
        ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(orig_node)->flags)>>(8 +7)), (((NODE *)(orig_node))->node_id), YARVINSN_dupn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(single_pattern ? 5 : 1), ((VALUE)(single_pattern ? 5 : 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(single_pattern ? 5 : 1)))));
        if (popped) {
            ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putnil, 0));
        }
    }
    APPEND_LIST((ret), (cond_seq));
    APPEND_LIST((ret), (body_seq));
    ADD_ELEM((ret), (LINK_ELEMENT *) (endlabel));
    return 1;
}
static int
compile_loop(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, int popped, const enum node_type type)
{
    const int line = (int)(int)(((long)(node)->flags)>>(8 +7));
    const NODE *line_node = node;
    LABEL *prev_start_label = ISEQ_COMPILE_DATA(iseq)->start_label;
    LABEL *prev_end_label = ISEQ_COMPILE_DATA(iseq)->end_label;
    LABEL *prev_redo_label = ISEQ_COMPILE_DATA(iseq)->redo_label;
    int prev_loopval_popped = ISEQ_COMPILE_DATA(iseq)->loopval_popped;
    VALUE branches = ((VALUE)RUBY_Qfalse);
    struct iseq_compile_data_ensure_node_stack enl;
    LABEL *next_label = ISEQ_COMPILE_DATA(iseq)->start_label = new_label_body(iseq, (line));
    LABEL *redo_label = ISEQ_COMPILE_DATA(iseq)->redo_label = new_label_body(iseq, (line));
    LABEL *break_label = ISEQ_COMPILE_DATA(iseq)->end_label = new_label_body(iseq, (line));
    LABEL *end_label = new_label_body(iseq, (line));
    LABEL *adjust_label = new_label_body(iseq, (line));
    LABEL *next_catch_label = new_label_body(iseq, (line));
    LABEL *tmp_label = ((void *)0);
    ISEQ_COMPILE_DATA(iseq)->loopval_popped = 0;
    push_ensure_entry(iseq, &enl, ((void *)0), ((void *)0));
    if (((rb_node_while_t *)(node))->nd_state == 1) {
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_jump, 1, (VALUE)(next_label))), ((next_label)->refcnt++));
    }
    else {
        tmp_label = new_label_body(iseq, (line));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_jump, 1, (VALUE)(tmp_label))), ((tmp_label)->refcnt++));
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) (adjust_label));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putnil, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) (next_catch_label));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_jump, 1, (VALUE)(next_label))), ((next_label)->refcnt++));
    if (tmp_label) ADD_ELEM((ret), (LINK_ELEMENT *) (tmp_label));
    ADD_ELEM((ret), (LINK_ELEMENT *) (redo_label));
    branches = decl_branch_base(iseq, (rb_int2inum((intptr_t)(void *)(node))), (&((NODE *)(node))->nd_loc), type == NODE_WHILE ? "while" : "until");
    const NODE *const coverage_node = ((rb_node_while_t *)(node))->nd_body ? ((rb_node_while_t *)(node))->nd_body : node;
    add_trace_branch_coverage(
        iseq,
        ret,
        (&((NODE *)(coverage_node))->nd_loc),
        (((NODE *)(coverage_node))->node_id),
        0,
        "body",
        branches);
    if (!(((iseq_compile_each(iseq, (ret), (((rb_node_while_t *)(node))->nd_body), 1))))) {;return 0;};
    ADD_ELEM((ret), (LINK_ELEMENT *) (next_label));
    if (type == NODE_WHILE) {
        if (!(compile_branch_condition(iseq, ret, ((rb_node_while_t *)(node))->nd_cond, redo_label, end_label))) {;return 0;};
    }
    else {
        if (!(compile_branch_condition(iseq, ret, ((rb_node_while_t *)(node))->nd_cond, end_label, redo_label))) {;return 0;};
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) (end_label));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_adjust_body(iseq, (adjust_label), -1));
    if (RB_UNDEF_P(((rb_node_while_t *)(node))->nd_state)) {
        append_compile_error(iseq, (int)(((long)(node)->flags)>>(8 +7)), "unsupported: putundef");
        return 0;
    }
    else {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putnil, 0));
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) (break_label));
    if (popped) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
    }
    do { VALUE _e = __extension__ ({ const VALUE args_to_new_ary[] = {(CATCH_TYPE_BREAK), (VALUE)(redo_label) | 1, (VALUE)(break_label) | 1, (VALUE)(((void *)0)), (VALUE)(break_label) | 1}; if (__builtin_constant_p(5)) { __extension__ _Static_assert(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))) == (5), "rb_ary_new_from_args" ": " "numberof(args_to_new_ary) == (5)"); } rb_ary_new_from_values(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))), args_to_new_ary); }); ((redo_label) ? (((redo_label)->refcnt++), (redo_label)->unremovable=1) : 0); ((break_label)->refcnt++); ((break_label)->refcnt++); if (RB_NIL_P(ISEQ_COMPILE_DATA(iseq)->catch_table_ary)) (rb_obj_write((VALUE)(iseq), (VALUE *)(&ISEQ_COMPILE_DATA(iseq)->catch_table_ary), (VALUE)(rb_ary_hidden_new(3)), "compile.c", 8226)); rb_ary_push(ISEQ_COMPILE_DATA(iseq)->catch_table_ary, freeze_hide_obj(_e)); } while (0);
    do { VALUE _e = __extension__ ({ const VALUE args_to_new_ary[] = {(CATCH_TYPE_NEXT), (VALUE)(redo_label) | 1, (VALUE)(break_label) | 1, (VALUE)(((void *)0)), (VALUE)(next_catch_label) | 1}; if (__builtin_constant_p(5)) { __extension__ _Static_assert(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))) == (5), "rb_ary_new_from_args" ": " "numberof(args_to_new_ary) == (5)"); } rb_ary_new_from_values(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))), args_to_new_ary); }); ((redo_label) ? (((redo_label)->refcnt++), (redo_label)->unremovable=1) : 0); ((break_label)->refcnt++); ((next_catch_label)->refcnt++); if (RB_NIL_P(ISEQ_COMPILE_DATA(iseq)->catch_table_ary)) (rb_obj_write((VALUE)(iseq), (VALUE *)(&ISEQ_COMPILE_DATA(iseq)->catch_table_ary), (VALUE)(rb_ary_hidden_new(3)), "compile.c", 8228)); rb_ary_push(ISEQ_COMPILE_DATA(iseq)->catch_table_ary, freeze_hide_obj(_e)); } while (0);
    do { VALUE _e = __extension__ ({ const VALUE args_to_new_ary[] = {(CATCH_TYPE_REDO), (VALUE)(redo_label) | 1, (VALUE)(break_label) | 1, (VALUE)(((void *)0)), (VALUE)(ISEQ_COMPILE_DATA(iseq)->redo_label) | 1}; if (__builtin_constant_p(5)) { __extension__ _Static_assert(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))) == (5), "rb_ary_new_from_args" ": " "numberof(args_to_new_ary) == (5)"); } rb_ary_new_from_values(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))), args_to_new_ary); }); ((redo_label) ? (((redo_label)->refcnt++), (redo_label)->unremovable=1) : 0); ((break_label)->refcnt++); ((ISEQ_COMPILE_DATA(iseq)->redo_label)->refcnt++); if (RB_NIL_P(ISEQ_COMPILE_DATA(iseq)->catch_table_ary)) (rb_obj_write((VALUE)(iseq), (VALUE *)(&ISEQ_COMPILE_DATA(iseq)->catch_table_ary), (VALUE)(rb_ary_hidden_new(3)), "compile.c", 8230)); rb_ary_push(ISEQ_COMPILE_DATA(iseq)->catch_table_ary, freeze_hide_obj(_e)); } while (0);
    ISEQ_COMPILE_DATA(iseq)->start_label = prev_start_label;
    ISEQ_COMPILE_DATA(iseq)->end_label = prev_end_label;
    ISEQ_COMPILE_DATA(iseq)->redo_label = prev_redo_label;
    ISEQ_COMPILE_DATA(iseq)->loopval_popped = prev_loopval_popped;
    ISEQ_COMPILE_DATA(iseq)->ensure_node_stack = ISEQ_COMPILE_DATA(iseq)->ensure_node_stack->prev;
    return 1;
}
static int
compile_iter(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, int popped)
{
    const int line = (int)(((long)(node)->flags)>>(8 +7));
    const NODE *line_node = node;
    const rb_iseq_t *prevblock = ISEQ_COMPILE_DATA(iseq)->current_block;
    LABEL *retry_label = new_label_body(iseq, (line));
    LABEL *retry_end_l = new_label_body(iseq, (line));
    const rb_iseq_t *child_iseq;
    ADD_ELEM((ret), (LINK_ELEMENT *) (retry_label));
    if (nd_type_p(node, NODE_FOR)) {
        if (!(((iseq_compile_each(iseq, (ret), (((rb_node_for_t *)(node))->nd_iter), 0))))) {;return 0;};
        ISEQ_COMPILE_DATA(iseq)->current_block = child_iseq =
            new_child_iseq(iseq, (((rb_node_for_t *)(node))->nd_body), rb_fstring(make_name_for_block(iseq)), iseq, (ISEQ_TYPE_BLOCK), (line));
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((idEach)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))), ((child_iseq)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
    }
    else {
        ISEQ_COMPILE_DATA(iseq)->current_block = child_iseq =
            new_child_iseq(iseq, (((rb_node_iter_t *)(node))->nd_body), rb_fstring(make_name_for_block(iseq)), iseq, (ISEQ_TYPE_BLOCK), (line));
        if (!(((iseq_compile_each(iseq, (ret), (((rb_node_iter_t *)(node))->nd_iter), 0))))) {;return 0;};
    }
    {
        INSN *iobj;
        LINK_ELEMENT *last_elem = LAST_ELEMENT(ret);
        iobj = ((last_elem)->type == ISEQ_ELEMENT_INSN) ? (INSN*) last_elem : (INSN*) get_prev_insn((INSN*) last_elem);
        while (!((((INSN*)(iobj))->insn_id) == YARVINSN_send) && !((((INSN*)(iobj))->insn_id) == YARVINSN_invokesuper) && !((((INSN*)(iobj))->insn_id) == YARVINSN_sendforward) && !((((INSN*)(iobj))->insn_id) == YARVINSN_invokesuperforward)) {
            iobj = (INSN*) get_prev_insn(iobj);
        }
        ELEM_INSERT_NEXT(&iobj->link, (LINK_ELEMENT*) retry_end_l);
        if (&iobj->link == LAST_ELEMENT(ret)) {
            ret->last = (LINK_ELEMENT*) retry_end_l;
        }
    }
    if (popped) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
    }
    ISEQ_COMPILE_DATA(iseq)->current_block = prevblock;
    do { VALUE _e = __extension__ ({ const VALUE args_to_new_ary[] = {(CATCH_TYPE_BREAK), (VALUE)(retry_label) | 1, (VALUE)(retry_end_l) | 1, (VALUE)(child_iseq), (VALUE)(retry_end_l) | 1}; if (__builtin_constant_p(5)) { __extension__ _Static_assert(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))) == (5), "rb_ary_new_from_args" ": " "numberof(args_to_new_ary) == (5)"); } rb_ary_new_from_values(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))), args_to_new_ary); }); ((retry_label) ? (((retry_label)->refcnt++), (retry_label)->unremovable=1) : 0); ((retry_end_l)->refcnt++); ((retry_end_l)->refcnt++); if (RB_NIL_P(ISEQ_COMPILE_DATA(iseq)->catch_table_ary)) (rb_obj_write((VALUE)(iseq), (VALUE *)(&ISEQ_COMPILE_DATA(iseq)->catch_table_ary), (VALUE)(rb_ary_hidden_new(3)), "compile.c", 8297)); rb_ary_push(ISEQ_COMPILE_DATA(iseq)->catch_table_ary, freeze_hide_obj(_e)); } while (0);
    return 1;
}
static int
compile_for_masgn(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, int popped)
{
    const NODE *line_node = node;
    const NODE *var = ((rb_node_for_masgn_t *)(node))->nd_var;
    LABEL *not_single = new_label_body(iseq, ((int)(((long)(var)->flags)>>(8 +7))));
    LABEL *not_ary = new_label_body(iseq, ((int)(((long)(var)->flags)>>(8 +7))));
    if (!(((iseq_compile_each(iseq, (ret), (var), 0))))) {;return 0;};
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dup, 0));
    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((idLength)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p((0x01 << VM_CALL_FCALL_bit)), ((VALUE)((0x01 << VM_CALL_FCALL_bit))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((0x01 << VM_CALL_FCALL_bit)))), (((void *)0))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((idEq)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p((0x01 << VM_CALL_FCALL_bit)), ((VALUE)((0x01 << VM_CALL_FCALL_bit))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((0x01 << VM_CALL_FCALL_bit)))), (((void *)0))));
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_branchunless, 1, (VALUE)(not_single))), ((not_single)->refcnt++));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dup, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))));
    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), ((idAREF)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p((0x01 << VM_CALL_FCALL_bit)), ((VALUE)((0x01 << VM_CALL_FCALL_bit))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((0x01 << VM_CALL_FCALL_bit)))), (((void *)0))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(rb_cArray)));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_swap, 0));
    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), (((__builtin_constant_p("try_convert") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("try_convert")); }) : (rb_intern)("try_convert")))), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p((0x01 << VM_CALL_FCALL_bit)), ((VALUE)((0x01 << VM_CALL_FCALL_bit))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((0x01 << VM_CALL_FCALL_bit)))), (((void *)0))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dup, 0));
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_branchunless, 1, (VALUE)(not_ary))), ((not_ary)->refcnt++));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_swap, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) (not_ary));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) (not_single));
    return 1;
}
static int
compile_break(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, int popped)
{
    const NODE *line_node = node;
    unsigned long throw_flag = 0;
    if (ISEQ_COMPILE_DATA(iseq)->redo_label != 0 && can_add_ensure_iseq(iseq)) {
        LABEL *splabel = new_label_body(iseq, (0));
        ADD_ELEM((ret), (LINK_ELEMENT *) (splabel));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_adjust_body(iseq, (ISEQ_COMPILE_DATA(iseq)->redo_label), (int)(((long)(line_node)->flags)>>(8 +7))));
        if (!(((iseq_compile_each(iseq, (ret), (((rb_node_break_t *)(node))->nd_stts), (ISEQ_COMPILE_DATA(iseq)->loopval_popped)))))) {;return 0;};
        add_ensure_iseq(ret, iseq, 0);
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_jump, 1, (VALUE)(ISEQ_COMPILE_DATA(iseq)->end_label))), ((ISEQ_COMPILE_DATA(iseq)->end_label)->refcnt++));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_adjust_body(iseq, (splabel), -1));
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putnil, 0));
        }
    }
    else {
        const rb_iseq_t *ip = iseq;
        while (ip) {
            if (!ISEQ_COMPILE_DATA(ip)) {
                ip = 0;
                break;
            }
            if (ISEQ_COMPILE_DATA(ip)->redo_label != 0) {
                throw_flag = VM_THROW_NO_ESCAPE_FLAG;
            }
            else if (((ip)->body)->type == ISEQ_TYPE_BLOCK) {
                throw_flag = 0;
            }
            else if (((ip)->body)->type == ISEQ_TYPE_EVAL) {
                append_compile_error(iseq, (int)(((long)(node)->flags)>>(8 +7)), "Can't escape from eval with break");
                return 0;
            }
            else {
                ip = ((ip)->body)->parent_iseq;
                continue;
            }
            if (!(((iseq_compile_each(iseq, (ret), (((rb_node_break_t *)(node))->nd_stts), 0))))) {;return 0;};
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_throw, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(throw_flag | RUBY_TAG_BREAK), ((VALUE)(throw_flag | RUBY_TAG_BREAK)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(throw_flag | RUBY_TAG_BREAK)))));
            if (popped) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
            }
            return 1;
        }
        append_compile_error(iseq, (int)(((long)(node)->flags)>>(8 +7)), "Invalid break");
        return 0;
    }
    return 1;
}
static int
compile_next(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, int popped)
{
    const NODE *line_node = node;
    unsigned long throw_flag = 0;
    if (ISEQ_COMPILE_DATA(iseq)->redo_label != 0 && can_add_ensure_iseq(iseq)) {
        LABEL *splabel = new_label_body(iseq, (0));
        if(0)printf("next in while loop\n");
        ADD_ELEM((ret), (LINK_ELEMENT *) (splabel));
        if (!(((iseq_compile_each(iseq, (ret), (((rb_node_next_t *)(node))->nd_stts), 0))))) {;return 0;};
        add_ensure_iseq(ret, iseq, 0);
        ADD_ELEM((ret), (LINK_ELEMENT *) new_adjust_body(iseq, (ISEQ_COMPILE_DATA(iseq)->redo_label), (int)(((long)(line_node)->flags)>>(8 +7))));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_jump, 1, (VALUE)(ISEQ_COMPILE_DATA(iseq)->start_label))), ((ISEQ_COMPILE_DATA(iseq)->start_label)->refcnt++));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_adjust_body(iseq, (splabel), -1));
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putnil, 0));
        }
    }
    else if (ISEQ_COMPILE_DATA(iseq)->end_label && can_add_ensure_iseq(iseq)) {
        LABEL *splabel = new_label_body(iseq, (0));
        if(0)printf("next in block\n");
        ADD_ELEM((ret), (LINK_ELEMENT *) (splabel));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_adjust_body(iseq, (ISEQ_COMPILE_DATA(iseq)->start_label), (int)(((long)(line_node)->flags)>>(8 +7))));
        if (!(((iseq_compile_each(iseq, (ret), (((rb_node_next_t *)(node))->nd_stts), 0))))) {;return 0;};
        add_ensure_iseq(ret, iseq, 0);
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_jump, 1, (VALUE)(ISEQ_COMPILE_DATA(iseq)->end_label))), ((ISEQ_COMPILE_DATA(iseq)->end_label)->refcnt++));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_adjust_body(iseq, (splabel), -1));
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putnil, 0));
        }
    }
    else {
        const rb_iseq_t *ip = iseq;
        while (ip) {
            if (!ISEQ_COMPILE_DATA(ip)) {
                ip = 0;
                break;
            }
            throw_flag = VM_THROW_NO_ESCAPE_FLAG;
            if (ISEQ_COMPILE_DATA(ip)->redo_label != 0) {
                break;
            }
            else if (((ip)->body)->type == ISEQ_TYPE_BLOCK) {
                break;
            }
            else if (((ip)->body)->type == ISEQ_TYPE_EVAL) {
                append_compile_error(iseq, (int)(((long)(node)->flags)>>(8 +7)), "Can't escape from eval with next");
                return 0;
            }
            ip = ((ip)->body)->parent_iseq;
        }
        if (ip != 0) {
            if (!(((iseq_compile_each(iseq, (ret), (((rb_node_next_t *)(node))->nd_stts), 0))))) {;return 0;};
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_throw, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(throw_flag | RUBY_TAG_NEXT), ((VALUE)(throw_flag | RUBY_TAG_NEXT)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(throw_flag | RUBY_TAG_NEXT)))));
            if (popped) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
            }
        }
        else {
            append_compile_error(iseq, (int)(((long)(node)->flags)>>(8 +7)), "Invalid next");
            return 0;
        }
    }
    return 1;
}
static int
compile_redo(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, int popped)
{
    const NODE *line_node = node;
    if (ISEQ_COMPILE_DATA(iseq)->redo_label && can_add_ensure_iseq(iseq)) {
        LABEL *splabel = new_label_body(iseq, (0));
        if(0)printf("redo in while");
        ADD_ELEM((ret), (LINK_ELEMENT *) (splabel));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_adjust_body(iseq, (ISEQ_COMPILE_DATA(iseq)->redo_label), (int)(((long)(line_node)->flags)>>(8 +7))));
        add_ensure_iseq(ret, iseq, 0);
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_jump, 1, (VALUE)(ISEQ_COMPILE_DATA(iseq)->redo_label))), ((ISEQ_COMPILE_DATA(iseq)->redo_label)->refcnt++));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_adjust_body(iseq, (splabel), -1));
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putnil, 0));
        }
    }
    else if (((iseq)->body)->type != ISEQ_TYPE_EVAL && ISEQ_COMPILE_DATA(iseq)->start_label && can_add_ensure_iseq(iseq)) {
        LABEL *splabel = new_label_body(iseq, (0));
        if(0)printf("redo in block");
        ADD_ELEM((ret), (LINK_ELEMENT *) (splabel));
        add_ensure_iseq(ret, iseq, 0);
        ADD_ELEM((ret), (LINK_ELEMENT *) new_adjust_body(iseq, (ISEQ_COMPILE_DATA(iseq)->start_label), (int)(((long)(line_node)->flags)>>(8 +7))));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_jump, 1, (VALUE)(ISEQ_COMPILE_DATA(iseq)->start_label))), ((ISEQ_COMPILE_DATA(iseq)->start_label)->refcnt++));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_adjust_body(iseq, (splabel), -1));
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putnil, 0));
        }
    }
    else {
        const rb_iseq_t *ip = iseq;
        while (ip) {
            if (!ISEQ_COMPILE_DATA(ip)) {
                ip = 0;
                break;
            }
            if (ISEQ_COMPILE_DATA(ip)->redo_label != 0) {
                break;
            }
            else if (((ip)->body)->type == ISEQ_TYPE_BLOCK) {
                break;
            }
            else if (((ip)->body)->type == ISEQ_TYPE_EVAL) {
                append_compile_error(iseq, (int)(((long)(node)->flags)>>(8 +7)), "Can't escape from eval with redo");
                return 0;
            }
            ip = ((ip)->body)->parent_iseq;
        }
        if (ip != 0) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putnil, 0));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_throw, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_THROW_NO_ESCAPE_FLAG | RUBY_TAG_REDO), ((VALUE)(VM_THROW_NO_ESCAPE_FLAG | RUBY_TAG_REDO)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_THROW_NO_ESCAPE_FLAG | RUBY_TAG_REDO)))));
            if (popped) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
            }
        }
        else {
            append_compile_error(iseq, (int)(((long)(node)->flags)>>(8 +7)), "Invalid redo");
            return 0;
        }
    }
    return 1;
}
static int
compile_retry(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, int popped)
{
    const NODE *line_node = node;
    if (((iseq)->body)->type == ISEQ_TYPE_RESCUE) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putnil, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_throw, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(RUBY_TAG_RETRY), ((VALUE)(RUBY_TAG_RETRY)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(RUBY_TAG_RETRY)))));
        if (popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
        }
    }
    else {
        append_compile_error(iseq, (int)(((long)(node)->flags)>>(8 +7)), "Invalid retry");
        return 0;
    }
    return 1;
}
static int
compile_rescue(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, int popped)
{
    const int line = (int)(((long)(node)->flags)>>(8 +7));
    const NODE *line_node = node;
    LABEL *lstart = new_label_body(iseq, (line));
    LABEL *lend = new_label_body(iseq, (line));
    LABEL *lcont = new_label_body(iseq, (line));
    const rb_iseq_t *rescue = new_child_iseq(iseq, (((rb_node_rescue_t *)(node))->nd_resq), rb_fstring(rb_str_concat(((__builtin_constant_p("rescue in ") ? rbimpl_str_new_cstr : rb_str_new_cstr) ("rescue in ")), ((iseq)->body)->location.label)), iseq, (ISEQ_TYPE_RESCUE), (line));
    lstart->rescued = LABEL_RESCUE_BEG;
    lend->rescued = LABEL_RESCUE_END;
    ADD_ELEM((ret), (LINK_ELEMENT *) (lstart));
    _Bool prev_in_rescue = ISEQ_COMPILE_DATA(iseq)->in_rescue;
    ISEQ_COMPILE_DATA(iseq)->in_rescue = 1;
    {
        if (!(((iseq_compile_each(iseq, (ret), (((rb_node_rescue_t *)(node))->nd_head), 0))))) {;return 0;};
    }
    ISEQ_COMPILE_DATA(iseq)->in_rescue = prev_in_rescue;
    ADD_ELEM((ret), (LINK_ELEMENT *) (lend));
    if (((rb_node_rescue_t *)(node))->nd_else) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
        if (!(((iseq_compile_each(iseq, (ret), (((rb_node_rescue_t *)(node))->nd_else), 0))))) {;return 0;};
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_nop, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) (lcont));
    if (popped) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
    }
    do { VALUE _e = __extension__ ({ const VALUE args_to_new_ary[] = {(CATCH_TYPE_RESCUE), (VALUE)(lstart) | 1, (VALUE)(lend) | 1, (VALUE)(rescue), (VALUE)(lcont) | 1}; if (__builtin_constant_p(5)) { __extension__ _Static_assert(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))) == (5), "rb_ary_new_from_args" ": " "numberof(args_to_new_ary) == (5)"); } rb_ary_new_from_values(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))), args_to_new_ary); }); ((lstart) ? (((lstart)->refcnt++), (lstart)->unremovable=1) : 0); ((lend)->refcnt++); ((lcont)->refcnt++); if (RB_NIL_P(ISEQ_COMPILE_DATA(iseq)->catch_table_ary)) (rb_obj_write((VALUE)(iseq), (VALUE *)(&ISEQ_COMPILE_DATA(iseq)->catch_table_ary), (VALUE)(rb_ary_hidden_new(3)), "compile.c", 8590)); rb_ary_push(ISEQ_COMPILE_DATA(iseq)->catch_table_ary, freeze_hide_obj(_e)); } while (0);
    do { VALUE _e = __extension__ ({ const VALUE args_to_new_ary[] = {(CATCH_TYPE_RETRY), (VALUE)(lend) | 1, (VALUE)(lcont) | 1, (VALUE)(((void *)0)), (VALUE)(lstart) | 1}; if (__builtin_constant_p(5)) { __extension__ _Static_assert(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))) == (5), "rb_ary_new_from_args" ": " "numberof(args_to_new_ary) == (5)"); } rb_ary_new_from_values(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))), args_to_new_ary); }); ((lend) ? (((lend)->refcnt++), (lend)->unremovable=1) : 0); ((lcont)->refcnt++); ((lstart)->refcnt++); if (RB_NIL_P(ISEQ_COMPILE_DATA(iseq)->catch_table_ary)) (rb_obj_write((VALUE)(iseq), (VALUE *)(&ISEQ_COMPILE_DATA(iseq)->catch_table_ary), (VALUE)(rb_ary_hidden_new(3)), "compile.c", 8591)); rb_ary_push(ISEQ_COMPILE_DATA(iseq)->catch_table_ary, freeze_hide_obj(_e)); } while (0);
    return 1;
}
static int
compile_resbody(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, int popped)
{
    const int line = (int)(((long)(node)->flags)>>(8 +7));
    const NODE *line_node = node;
    const NODE *resq = node;
    const NODE *narg;
    LABEL *label_miss, *label_hit;
    while (resq) {
        label_miss = new_label_body(iseq, (line));
        label_hit = new_label_body(iseq, (line));
        narg = ((rb_node_resbody_t *)(resq))->nd_args;
        if (narg) {
            switch (((int) ((((NODE *)(narg))->flags & (((VALUE)0x7f)<<8))>>8))) {
              case NODE_LIST:
                while (narg) {
                    iseq_add_getlocal(iseq, (ret), (line_node), ((1)), (0));
                    if (!(((iseq_compile_each(iseq, (ret), (((rb_node_list_t *)(narg))->nd_head), 0))))) {;return 0;};
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_checkmatch, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_CHECKMATCH_TYPE_RESCUE), ((VALUE)(VM_CHECKMATCH_TYPE_RESCUE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_CHECKMATCH_TYPE_RESCUE)))));
                    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_branchif, 1, (VALUE)(label_hit))), ((label_hit)->refcnt++));
                    narg = ((rb_node_list_t *)(narg))->nd_next;
                }
                break;
              case NODE_SPLAT:
              case NODE_ARGSCAT:
              case NODE_ARGSPUSH:
                iseq_add_getlocal(iseq, (ret), (line_node), ((1)), (0));
                if (!(((iseq_compile_each(iseq, (ret), (narg), 0))))) {;return 0;};
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_checkmatch, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_CHECKMATCH_TYPE_RESCUE | 0x04), ((VALUE)(VM_CHECKMATCH_TYPE_RESCUE | 0x04)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_CHECKMATCH_TYPE_RESCUE | 0x04)))));
                (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_branchif, 1, (VALUE)(label_hit))), ((label_hit)->refcnt++));
                break;
              default:
                do { const NODE *error_node = (narg); append_compile_error(iseq, (int)(((long)(error_node)->flags)>>(8 +7)), "NODE_RESBODY" ": unknown node (%s)", ruby_node_name(((int) ((((NODE *)(error_node))->flags & (((VALUE)0x7f)<<8))>>8)))); return 0; } while (0);
            }
        }
        else {
            iseq_add_getlocal(iseq, (ret), (line_node), ((1)), (0));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(rb_eStandardError)));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_checkmatch, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_CHECKMATCH_TYPE_RESCUE), ((VALUE)(VM_CHECKMATCH_TYPE_RESCUE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_CHECKMATCH_TYPE_RESCUE)))));
            (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_branchif, 1, (VALUE)(label_hit))), ((label_hit)->refcnt++));
        }
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_jump, 1, (VALUE)(label_miss))), ((label_miss)->refcnt++));
        ADD_ELEM((ret), (LINK_ELEMENT *) (label_hit));
        ADD_ELEM((ret), (LINK_ELEMENT *)new_trace_body(iseq, (0x4000), 0));
        if (((rb_node_resbody_t *)(resq))->nd_exc_var) {
            if (!(((iseq_compile_each(iseq, (ret), (((rb_node_resbody_t *)(resq))->nd_exc_var), 1))))) {;return 0;};
        }
        if (((int) ((((NODE *)(((rb_node_resbody_t *)(resq))->nd_body))->flags & (((VALUE)0x7f)<<8))>>8)) == NODE_BEGIN && ((rb_node_begin_t *)(((rb_node_resbody_t *)(resq))->nd_body))->nd_body == ((void *)0) && !((rb_node_resbody_t *)(resq))->nd_exc_var) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, ((int)(((long)(((rb_node_resbody_t *)(resq))->nd_body)->flags)>>(8 +7))), (-1), YARVINSN_putnil, 0));
        }
        else {
            if (!(((iseq_compile_each(iseq, (ret), (((rb_node_resbody_t *)(resq))->nd_body), 0))))) {;return 0;};
        }
        if (ISEQ_COMPILE_DATA(iseq)->option->tailcall_optimization) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_nop, 0));
        }
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_leave, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) (label_miss));
        resq = ((rb_node_resbody_t *)(resq))->nd_next;
    }
    return 1;
}
static int
compile_ensure(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, int popped)
{
    const int line = (int)(((long)(((rb_node_ensure_t *)(node))->nd_ensr)->flags)>>(8 +7));
    const NODE *line_node = node;
    LINK_ANCHOR ensr[1] = {{{ISEQ_ELEMENT_ANCHOR,},&ensr[0].anchor}};
    const rb_iseq_t *ensure = new_child_iseq(iseq, (((rb_node_ensure_t *)(node))->nd_ensr), rb_fstring(rb_str_concat(((__builtin_constant_p("ensure in ") ? rbimpl_str_new_cstr : rb_str_new_cstr) ("ensure in ")), ((iseq)->body)->location.label)), iseq, (ISEQ_TYPE_ENSURE), (line));
    LABEL *lstart = new_label_body(iseq, (line));
    LABEL *lend = new_label_body(iseq, (line));
    LABEL *lcont = new_label_body(iseq, (line));
    LINK_ELEMENT *last;
    int last_leave = 0;
    struct ensure_range er;
    struct iseq_compile_data_ensure_node_stack enl;
    struct ensure_range *erange;
    ((ensr->last = &ensr->anchor)->next = ((void *)0));
    if (!(((iseq_compile_each(iseq, (ensr), (((rb_node_ensure_t *)(node))->nd_ensr), 1))))) {;return 0;};
    last = ensr->last;
    last_leave = last && ((last)->type == ISEQ_ELEMENT_INSN) && ((((INSN*)(last))->insn_id) == YARVINSN_leave);
    er.begin = lstart;
    er.end = lend;
    er.next = 0;
    push_ensure_entry(iseq, &enl, &er, ((rb_node_ensure_t *)(node))->nd_ensr);
    ADD_ELEM((ret), (LINK_ELEMENT *) (lstart));
    if (!(((iseq_compile_each(iseq, (ret), (((rb_node_ensure_t *)(node))->nd_head), ((popped | last_leave))))))) {;return 0;};
    ADD_ELEM((ret), (LINK_ELEMENT *) (lend));
    APPEND_LIST((ret), (ensr));
    if (!popped && last_leave) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putnil, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) (lcont));
    if (last_leave) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
    erange = ISEQ_COMPILE_DATA(iseq)->ensure_node_stack->erange;
    if (lstart->link.next != &lend->link) {
        while (erange) {
            do { VALUE _e = __extension__ ({ const VALUE args_to_new_ary[] = {(CATCH_TYPE_ENSURE), (VALUE)(erange->begin) | 1, (VALUE)(erange->end) | 1, (VALUE)(ensure), (VALUE)(lcont) | 1}; if (__builtin_constant_p(5)) { __extension__ _Static_assert(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))) == (5), "rb_ary_new_from_args" ": " "numberof(args_to_new_ary) == (5)"); } rb_ary_new_from_values(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))), args_to_new_ary); }); ((erange->begin) ? (((erange->begin)->refcnt++), (erange->begin)->unremovable=1) : 0); ((erange->end)->refcnt++); ((lcont)->refcnt++); if (RB_NIL_P(ISEQ_COMPILE_DATA(iseq)->catch_table_ary)) (rb_obj_write((VALUE)(iseq), (VALUE *)(&ISEQ_COMPILE_DATA(iseq)->catch_table_ary), (VALUE)(rb_ary_hidden_new(3)), "compile.c", 8703)); rb_ary_push(ISEQ_COMPILE_DATA(iseq)->catch_table_ary, freeze_hide_obj(_e)); } while (0);
            erange = erange->next;
        }
    }
    ISEQ_COMPILE_DATA(iseq)->ensure_node_stack = enl.prev;
    return 1;
}
static int
compile_return(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, int popped)
{
    const NODE *line_node = node;
    if (iseq) {
        enum rb_iseq_type type = ((iseq)->body)->type;
        const rb_iseq_t *is = iseq;
        enum rb_iseq_type t = type;
        const NODE *retval = ((rb_node_return_t *)(node))->nd_stts;
        LABEL *splabel = 0;
        while (t == ISEQ_TYPE_RESCUE || t == ISEQ_TYPE_ENSURE) {
            if (!(is = ((is)->body)->parent_iseq)) break;
            t = ((is)->body)->type;
        }
        switch (t) {
          case ISEQ_TYPE_TOP:
          case ISEQ_TYPE_MAIN:
            if (retval) {
                rb_warn("argument of top-level return is ignored");
            }
            if (is == iseq) {
                type = ISEQ_TYPE_METHOD;
            }
            break;
          default:
            break;
        }
        if (type == ISEQ_TYPE_METHOD) {
            splabel = new_label_body(iseq, (0));
            ADD_ELEM((ret), (LINK_ELEMENT *) (splabel));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_adjust_body(iseq, (0), (int)(((long)(line_node)->flags)>>(8 +7))));
        }
        if (!(((iseq_compile_each(iseq, (ret), (retval), 0))))) {;return 0;};
        if (type == ISEQ_TYPE_METHOD && can_add_ensure_iseq(iseq)) {
            add_ensure_iseq(ret, iseq, 1);
            ADD_ELEM((ret), (LINK_ELEMENT *)new_trace_body(iseq, (0x0010), 0));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_leave, 0));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_adjust_body(iseq, (splabel), -1));
            if (!popped) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putnil, 0));
            }
        }
        else {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_throw, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(RUBY_TAG_RETURN), ((VALUE)(RUBY_TAG_RETURN)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(RUBY_TAG_RETURN)))));
            if (popped) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
            }
        }
    }
    return 1;
}
static _Bool
drop_unreachable_return(LINK_ANCHOR *ret)
{
    LINK_ELEMENT *i = ret->last, *last;
    if (!i) return 0;
    if (((i)->type == ISEQ_ELEMENT_TRACE)) i = i->prev;
    if (!((i)->type == ISEQ_ELEMENT_INSN) || !((((INSN*)(i))->insn_id) == YARVINSN_putnil)) return 0;
    last = i = i->prev;
    if (((i)->type == ISEQ_ELEMENT_ADJUST)) i = i->prev;
    if (!((i)->type == ISEQ_ELEMENT_INSN)) return 0;
    switch ((((INSN*)(i))->insn_id)) {
      case YARVINSN_leave:
      case YARVINSN_jump:
        break;
      default:
        return 0;
    }
    (ret->last = last->prev)->next = ((void *)0);
    return 1;
}
static int
compile_evstr(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, int popped)
{
    if (!(((iseq_compile_each(iseq, (ret), (node), (popped)))))) {;return 0;};
    if (!popped && !all_string_result_p(node)) {
        const NODE *line_node = node;
        const unsigned int flag = (0x01 << VM_CALL_FCALL_bit);
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dup, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_objtostring, 1, (VALUE)(new_callinfo(iseq, idTo_s, 0, flag, ((void *)0), 0))));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_anytostring, 0));
    }
    return 1;
}
static void
compile_lvar(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *line_node, ID id)
{
    int idx = ((((iseq)->body)->local_iseq)->body)->local_table_size - get_local_var_idx(iseq, id);
    if(0)printf("id: %s idx: %d\n", rb_id2name(id), idx);
    iseq_add_getlocal(iseq, (ret), (line_node), (idx), (get_lvar_level(iseq)));
}
static LABEL *
qcall_branch_start(rb_iseq_t *iseq, LINK_ANCHOR *const recv, VALUE *branches, const NODE *node, const NODE *line_node)
{
    LABEL *else_label = new_label_body(iseq, ((int)(((long)(line_node)->flags)>>(8 +7))));
    VALUE br = 0;
    br = decl_branch_base(iseq, (rb_int2inum((intptr_t)(void *)(node))), (&((NODE *)(node))->nd_loc), "&.");
    *branches = br;
    ADD_ELEM((recv), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_dup, 0));
    (ADD_ELEM((recv), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_branchnil, 1, (VALUE)(else_label))), ((else_label)->refcnt++));
    add_trace_branch_coverage(iseq, recv, (&((NODE *)(node))->nd_loc), (((NODE *)(node))->node_id), 0, "then", br);
    return else_label;
}
static void
qcall_branch_end(rb_iseq_t *iseq, LINK_ANCHOR *const ret, LABEL *else_label, VALUE branches, const NODE *node, const NODE *line_node)
{
    LABEL *end_label;
    if (!else_label) return;
    end_label = new_label_body(iseq, ((int)(((long)(line_node)->flags)>>(8 +7))));
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_jump, 1, (VALUE)(end_label))), ((end_label)->refcnt++));
    ADD_ELEM((ret), (LINK_ELEMENT *) (else_label));
    add_trace_branch_coverage(iseq, ret, (&((NODE *)(node))->nd_loc), (((NODE *)(node))->node_id), 1, "else", branches);
    ADD_ELEM((ret), (LINK_ELEMENT *) (end_label));
}
static int
compile_call_precheck_freeze(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, const NODE *line_node, int popped)
{
    if (get_nd_recv(node) &&
        (nd_type_p(get_nd_recv(node), NODE_STR) || nd_type_p(get_nd_recv(node), NODE_FILE)) &&
        (get_node_call_nd_mid(node) == idFreeze || get_node_call_nd_mid(node) == idUMinus) &&
        get_nd_args(node) == ((void *)0) &&
        ISEQ_COMPILE_DATA(iseq)->current_block == ((void *)0) &&
        ISEQ_COMPILE_DATA(iseq)->option->specialized_instruction) {
        VALUE str = get_string_value(get_nd_recv(node));
        if (get_node_call_nd_mid(node) == idUMinus) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_opt_str_uminus, 2, (VALUE)(str), (VALUE)(new_callinfo(iseq, idUMinus, 0, 0, ((void *)0), 0))));
        }
        else {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_opt_str_freeze, 2, (VALUE)(str), (VALUE)(new_callinfo(iseq, idFreeze, 0, 0, ((void *)0), 0))));
        }
        (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(str), "compile.c", 8867));
        if (popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
        }
        return 1;
    }
    if (get_node_call_nd_mid(node) == idAREF && !private_recv_p(node) && get_nd_args(node) &&
        nd_type_p(get_nd_args(node), NODE_LIST) && ((rb_node_list_t *)(get_nd_args(node)))->as.nd_alen == 1 &&
        (nd_type_p(((rb_node_list_t *)(get_nd_args(node)))->nd_head, NODE_STR) || nd_type_p(((rb_node_list_t *)(get_nd_args(node)))->nd_head, NODE_FILE)) &&
        ISEQ_COMPILE_DATA(iseq)->current_block == ((void *)0) &&
        !frozen_string_literal_p(iseq) &&
        ISEQ_COMPILE_DATA(iseq)->option->specialized_instruction) {
        VALUE str = get_string_value(((rb_node_list_t *)(get_nd_args(node)))->nd_head);
        if (!(((iseq_compile_each(iseq, (ret), (get_nd_recv(node)), 0))))) {;return 0;};
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_opt_aref_with, 2, (VALUE)(str), (VALUE)(new_callinfo(iseq, idAREF, 1, 0, ((void *)0), 0))));
        (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(str), "compile.c", 8886));
        if (popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
        }
        return 1;
    }
    return 0;
}
static int
iseq_has_builtin_function_table(const rb_iseq_t *iseq)
{
    return ISEQ_COMPILE_DATA(iseq)->builtin_function_table != ((void *)0);
}
static const struct rb_builtin_function *
iseq_builtin_function_lookup(const rb_iseq_t *iseq, const char *name)
{
    int i;
    const struct rb_builtin_function *table = ISEQ_COMPILE_DATA(iseq)->builtin_function_table;
    for (i=0; table[i].index != -1; i++) {
        if (strcmp(table[i].name, name) == 0) {
            return &table[i];
        }
    }
    return ((void *)0);
}
static const char *
iseq_builtin_function_name(const enum node_type type, const NODE *recv, ID mid)
{
    const char *name = rb_id2name(mid);
    static const char prefix[] = "__builtin_";
    const size_t prefix_len = sizeof(prefix) - 1;
    switch (type) {
      case NODE_CALL:
        if (recv) {
            switch (((int) ((((NODE *)(recv))->flags & (((VALUE)0x7f)<<8))>>8))) {
              case NODE_VCALL:
                if (((rb_node_vcall_t *)(recv))->nd_mid == (__builtin_constant_p("__builtin") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("__builtin")); }) : (rb_intern)("__builtin"))) {
                    return name;
                }
                break;
              case NODE_CONST:
                if (((rb_node_const_t *)(recv))->nd_vid == (__builtin_constant_p("Primitive") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("Primitive")); }) : (rb_intern)("Primitive"))) {
                    return name;
                }
                break;
              default: break;
            }
        }
        break;
      case NODE_VCALL:
      case NODE_FCALL:
        if ((__builtin_expect(!!(strncmp(prefix, name, prefix_len) == 0), 0))) {
            return &name[prefix_len];
        }
        break;
      default: break;
    }
    return ((void *)0);
}
static int
delegate_call_p(const rb_iseq_t *iseq, unsigned int argc, const LINK_ANCHOR *args, unsigned int *pstart_index)
{
    if (argc == 0) {
        *pstart_index = 0;
        return 1;
    }
    else if (argc <= ((iseq)->body)->local_table_size) {
        unsigned int start=0;
        for (start = 0;
             argc + start <= ((iseq)->body)->local_table_size;
             start++) {
            const LINK_ELEMENT *elem = FIRST_ELEMENT(args);
            for (unsigned int i=start; i-start<argc; i++) {
                if (((elem)->type == ISEQ_ELEMENT_INSN) &&
                    (((INSN*)(elem))->insn_id) == YARVINSN_getlocal) {
                    int local_index = RB_FIX2INT((((INSN*)(elem))->operands[(0)]));
                    int local_level = RB_FIX2INT((((INSN*)(elem))->operands[(1)]));
                    if (local_level == 0) {
                        unsigned int index = ((iseq)->body)->local_table_size - (local_index - ( 3) + 1);
                        if (0) {
                            fprintf(stderr, "lvar:%s (%d), id:%s (%d) local_index:%d, local_size:%d\n",
                                    rb_id2name(((iseq)->body)->local_table[i]), i,
                                    rb_id2name(((iseq)->body)->local_table[index]), index,
                                    local_index, (int)((iseq)->body)->local_table_size);
                        }
                        if (i == index) {
                            elem = elem->next;
                            continue;
                        }
                        else {
                            goto next;
                        }
                    }
                    else {
                        goto fail;
                    }
                }
                else {
                    goto fail;
                }
            }
            goto success;
          next:;
        }
      fail:
        return 0;
      success:
        *pstart_index = start;
        return 1;
    }
    else {
        return 0;
    }
}
static int
compile_builtin_attr(rb_iseq_t *iseq, const NODE *node)
{
    VALUE symbol;
    VALUE string;
    if (!node) goto no_arg;
    while (node) {
        if (!nd_type_p(node, NODE_LIST)) goto bad_arg;
        const NODE *next = ((rb_node_list_t *)(node))->nd_next;
        node = ((rb_node_list_t *)(node))->nd_head;
        if (!node) goto no_arg;
        switch (((int) ((((NODE *)(node))->flags & (((VALUE)0x7f)<<8))>>8))) {
          case NODE_SYM:
            symbol = rb_node_sym_string_val(node);
            break;
          default:
            goto bad_arg;
        }
        if (!RB_SYMBOL_P(symbol)) goto non_symbol_arg;
        string = rb_sym2str(symbol);
        if (strcmp(RSTRING_PTR(string), "leaf") == 0) {
            ((iseq)->body)->builtin_attrs |= BUILTIN_ATTR_LEAF;
        }
        else if (strcmp(RSTRING_PTR(string), "inline_block") == 0) {
            ((iseq)->body)->builtin_attrs |= BUILTIN_ATTR_INLINE_BLOCK;
        }
        else if (strcmp(RSTRING_PTR(string), "use_block") == 0) {
            iseq_set_use_block(iseq);
        }
        else if (strcmp(RSTRING_PTR(string), "c_trace") == 0) {
            ((iseq)->body)->builtin_attrs |= BUILTIN_ATTR_C_TRACE;
        }
        else {
            goto unknown_arg;
        }
        node = next;
    }
    return 1;
  no_arg:
    append_compile_error(iseq, (int)(((long)(node)->flags)>>(8 +7)), "attr!: no argument");
    return 0;
  non_symbol_arg:
    append_compile_error(iseq, (int)(((long)(node)->flags)>>(8 +7)), "non symbol argument to attr!: %s", rb_builtin_class_name(symbol));
    return 0;
  unknown_arg:
    append_compile_error(iseq, (int)(((long)(node)->flags)>>(8 +7)), "unknown argument to attr!: %s", RSTRING_PTR(string));
    return 0;
  bad_arg:
    do { const NODE *error_node = (node); append_compile_error(iseq, (int)(((long)(error_node)->flags)>>(8 +7)), "attr!" ": unknown node (%s)", ruby_node_name(((int) ((((NODE *)(error_node))->flags & (((VALUE)0x7f)<<8))>>8)))); return 0; } while (0);
}
static int
compile_builtin_arg(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *node, const NODE *line_node, int popped)
{
    VALUE name;
    if (!node) goto no_arg;
    if (!nd_type_p(node, NODE_LIST)) goto bad_arg;
    if (((rb_node_list_t *)(node))->nd_next) goto too_many_arg;
    node = ((rb_node_list_t *)(node))->nd_head;
    if (!node) goto no_arg;
    switch (((int) ((((NODE *)(node))->flags & (((VALUE)0x7f)<<8))>>8))) {
      case NODE_SYM:
        name = rb_node_sym_string_val(node);
        break;
      default:
        goto bad_arg;
    }
    if (!RB_SYMBOL_P(name)) goto non_symbol_arg;
    if (!popped) {
        compile_lvar(iseq, ret, line_node, rb_sym2id(name));
    }
    return 1;
  no_arg:
    append_compile_error(iseq, (int)(((long)(node)->flags)>>(8 +7)), "arg!: no argument");
    return 0;
  too_many_arg:
    append_compile_error(iseq, (int)(((long)(node)->flags)>>(8 +7)), "arg!: too many argument");
    return 0;
  non_symbol_arg:
    append_compile_error(iseq, (int)(((long)(node)->flags)>>(8 +7)), "non symbol argument to arg!: %s",
                  rb_builtin_class_name(name));
    return 0;
  bad_arg:
    do { const NODE *error_node = (node); append_compile_error(iseq, (int)(((long)(error_node)->flags)>>(8 +7)), "arg!" ": unknown node (%s)", ruby_node_name(((int) ((((NODE *)(error_node))->flags & (((VALUE)0x7f)<<8))>>8)))); return 0; } while (0);
}
static NODE *
mandatory_node(const rb_iseq_t *iseq, const NODE *cond_node)
{
    const NODE *node = ISEQ_COMPILE_DATA(iseq)->root_node;
    if (((int) ((((NODE *)(node))->flags & (((VALUE)0x7f)<<8))>>8)) == NODE_IF && ((rb_node_if_t *)(node))->nd_cond == cond_node) {
        return ((rb_node_if_t *)(node))->nd_body;
    }
    else {
        rb_bug("mandatory_node: can't find mandatory node");
    }
}
static int
compile_builtin_mandatory_only_method(rb_iseq_t *iseq, const NODE *node, const NODE *line_node)
{
    struct rb_args_info args = {
        .pre_args_num = ((iseq)->body)->param.lead_num,
    };
    rb_node_args_t args_node;
    rb_node_init(((NODE *)(&args_node)), NODE_ARGS);
    args_node.nd_ainfo = args;
    const int skip_local_size = ((iseq)->body)->param.size - ((iseq)->body)->param.lead_num;
    const int table_size = ((iseq)->body)->local_table_size - skip_local_size;
    VALUE idtmp = 0;
    rb_ast_id_table_t *tbl = ((sizeof(rb_ast_id_table_t) + table_size * sizeof(ID)) < 1024 ? ((idtmp) = 0, __builtin_alloca (sizeof(rb_ast_id_table_t) + table_size * sizeof(ID))) : rb_alloc_tmp_buffer(&(idtmp), (sizeof(rb_ast_id_table_t) + table_size * sizeof(ID))));
    tbl->size = table_size;
    int i;
    for (i=0; i<((iseq)->body)->param.lead_num; i++) {
        tbl->ids[i] = ((iseq)->body)->local_table[i];
    }
    for (; i<table_size; i++) {
        tbl->ids[i] = ((iseq)->body)->local_table[i + skip_local_size];
    }
    rb_node_scope_t scope_node;
    rb_node_init(((NODE *)(&scope_node)), NODE_SCOPE);
    scope_node.nd_tbl = tbl;
    scope_node.nd_body = mandatory_node(iseq, node);
    scope_node.nd_args = &args_node;
    VALUE ast_value = rb_ruby_ast_new(((NODE *)(&scope_node)));
    ((iseq)->body)->mandatory_only_iseq =
      rb_iseq_new_with_opt(ast_value, rb_iseq_base_label(iseq),
                           rb_iseq_path(iseq), rb_iseq_realpath(iseq),
                           (int)(((long)(line_node)->flags)>>(8 +7)), ((void *)0), 0,
                           ISEQ_TYPE_METHOD, ISEQ_COMPILE_DATA(iseq)->option,
                           ((iseq)->body)->variable.script_lines);
    rb_free_tmp_buffer(&(idtmp));
    return 1;
}
static int
compile_builtin_function_call(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, const NODE *line_node, int popped,
                              const rb_iseq_t *parent_block, LINK_ANCHOR *args, const char *builtin_func)
{
    NODE *args_node = get_nd_args(node);
    if (parent_block != ((void *)0)) {
        append_compile_error(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), "should not call builtins here.");
        return 0;
    }
    else {
        char inline_func[sizeof("_bi") + ((((sizeof(int)) * 8) * 3010 + 9998) / 9999)];
        _Bool cconst = 0;
      retry:;
        const struct rb_builtin_function *bf = iseq_builtin_function_lookup(iseq, builtin_func);
        if (bf == ((void *)0)) {
            if (strcmp("cstmt!", builtin_func) == 0 ||
                strcmp("cexpr!", builtin_func) == 0) {
            }
            else if (strcmp("cconst!", builtin_func) == 0) {
                cconst = 1;
            }
            else if (strcmp("cinit!", builtin_func) == 0) {
                return 1;
            }
            else if (strcmp("attr!", builtin_func) == 0) {
                return compile_builtin_attr(iseq, args_node);
            }
            else if (strcmp("arg!", builtin_func) == 0) {
                return compile_builtin_arg(iseq, ret, args_node, line_node, popped);
            }
            else if (strcmp("mandatory_only?", builtin_func) == 0) {
                if (popped) {
                    rb_bug("mandatory_only? should be in if condition");
                }
                else if (!LIST_INSN_SIZE_ZERO(ret)) {
                    rb_bug("mandatory_only? should be put on top");
                }
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qfalse))));
                return compile_builtin_mandatory_only_method(iseq, node, line_node);
            }
            else if (1) {
                rb_bug("can't find builtin function:%s", builtin_func);
            }
            else {
                append_compile_error(iseq, (int)(((long)(node)->flags)>>(8 +7)), "can't find builtin function:%s", builtin_func);
                return 0;
            }
            int inline_index = (int)(((long)(node)->flags)>>(8 +7));
            ruby_snprintf(inline_func, sizeof(inline_func), "_bi" "%d", inline_index);
            builtin_func = inline_func;
            args_node = ((void *)0);
            goto retry;
        }
        if (cconst) {
            typedef VALUE(*builtin_func0)(void *, VALUE);
            VALUE const_val = (*(builtin_func0)(uintptr_t)bf->func_ptr)(((void *)0), ((VALUE)RUBY_Qnil));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_putobject, 1, (VALUE)(const_val)));
            return 1;
        }
        unsigned int flag = 0;
        struct rb_callinfo_kwarg *keywords = ((void *)0);
        VALUE argc = setup_args(iseq, args, args_node, &flag, &keywords);
        if (RB_FIX2INT(argc) != bf->argc) {
            append_compile_error(iseq, (int)(((long)(node)->flags)>>(8 +7)), "argc is not match for builtin function:%s (expect %d but %d)",
                          builtin_func, bf->argc, RB_FIX2INT(argc));
            return 0;
        }
        unsigned int start_index;
        if (delegate_call_p(iseq, RB_FIX2INT(argc), args, &start_index)) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_opt_invokebuiltin_delegate, 2, (VALUE)(bf), (VALUE)(__builtin_choose_expr( __builtin_constant_p(start_index), ((VALUE)(start_index)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(start_index)))));
        }
        else {
            APPEND_LIST((ret), (args));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_invokebuiltin, 1, (VALUE)(bf)));
        }
        if (popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
        return 1;
    }
}
static int
compile_call(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, const enum node_type type, const NODE *const line_node, int popped, _Bool assume_receiver)
{
    LINK_ANCHOR recv[1] = {{{ISEQ_ELEMENT_ANCHOR,},&recv[0].anchor}};
    LINK_ANCHOR args[1] = {{{ISEQ_ELEMENT_ANCHOR,},&args[0].anchor}};
    ID mid = get_node_call_nd_mid(node);
    VALUE argc;
    unsigned int flag = 0;
    struct rb_callinfo_kwarg *keywords = ((void *)0);
    const rb_iseq_t *parent_block = ISEQ_COMPILE_DATA(iseq)->current_block;
    LABEL *else_label = ((void *)0);
    VALUE branches = ((VALUE)RUBY_Qfalse);
    ISEQ_COMPILE_DATA(iseq)->current_block = ((void *)0);
    ((recv->last = &recv->anchor)->next = ((void *)0));
    ((args->last = &args->anchor)->next = ((void *)0));
    const char *builtin_func;
    if ((__builtin_expect(!!(iseq_has_builtin_function_table(iseq)), 0)) &&
        (builtin_func = iseq_builtin_function_name(type, get_nd_recv(node), mid)) != ((void *)0)) {
        return compile_builtin_function_call(iseq, ret, node, line_node, popped, parent_block, args, builtin_func);
    }
    if (!assume_receiver) {
        if (type == NODE_CALL || type == NODE_OPCALL || type == NODE_QCALL) {
            int idx, level;
            if (mid == idCall &&
                nd_type_p(get_nd_recv(node), NODE_LVAR) &&
                iseq_block_param_id_p(iseq, ((rb_node_lvar_t *)(get_nd_recv(node)))->nd_vid, &idx, &level)) {
                ADD_ELEM((recv), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(get_nd_recv(node))->flags)>>(8 +7)), (((NODE *)(get_nd_recv(node)))->node_id), YARVINSN_getblockparamproxy, 2, (VALUE)(__builtin_choose_expr( __builtin_constant_p(idx + ( 3) - 1), ((VALUE)(idx + ( 3) - 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(idx + ( 3) - 1))), (VALUE)(__builtin_choose_expr( __builtin_constant_p(level), ((VALUE)(level)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(level)))));
            }
            else if (private_recv_p(node)) {
                ADD_ELEM((recv), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putself, 0));
                flag |= (0x01 << VM_CALL_FCALL_bit);
            }
            else {
                if (!(((iseq_compile_each(iseq, (recv), (get_nd_recv(node)), 0))))) {;return 0;};
            }
            if (type == NODE_QCALL) {
                else_label = qcall_branch_start(iseq, recv, &branches, node, line_node);
            }
        }
        else if (type == NODE_FCALL || type == NODE_VCALL) {
            ADD_ELEM(((recv)), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)((line_node))->flags)>>(8 +7)), (((NODE *)((line_node)))->node_id), YARVINSN_putself, 0));
        }
    }
    if (type != NODE_VCALL) {
        argc = setup_args(iseq, args, get_nd_args(node), &flag, &keywords);
        if (!(!RB_NIL_P(argc))) {;return 0;};
    }
    else {
        argc = __builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0));
    }
    APPEND_LIST((ret), (recv));
    APPEND_LIST((ret), (args));
    ((void)0);
    ((void)0);
    switch ((int)type) {
      case NODE_VCALL:
        flag |= (0x01 << VM_CALL_VCALL_bit);
      case NODE_FCALL:
        flag |= (0x01 << VM_CALL_FCALL_bit);
    }
    if ((flag & (0x01 << VM_CALL_ARGS_BLOCKARG_bit)) && (flag & (0x01 << VM_CALL_KW_SPLAT_bit)) && !(flag & (0x01 << VM_CALL_KW_SPLAT_MUT_bit))) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_splatkw, 0));
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), (mid), (VALUE)(argc), (parent_block), (VALUE)(__builtin_choose_expr( __builtin_constant_p(flag), ((VALUE)(flag)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(flag))), (keywords)));
    qcall_branch_end(iseq, ret, else_label, branches, node, line_node);
    if (popped) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(line_node)->flags)>>(8 +7)), (((NODE *)(line_node))->node_id), YARVINSN_pop, 0));
    }
    return 1;
}
static int
compile_op_asgn1(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, int popped)
{
    const int line = (int)(((long)(node)->flags)>>(8 +7));
    VALUE argc;
    unsigned int flag = 0;
    int asgnflag = 0;
    ID id = ((rb_node_op_asgn1_t *)(node))->nd_mid;
    if (!popped) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putnil, 0));
    }
    asgnflag = (private_recv_p(node) ? (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putself, 0)), (0x01 << VM_CALL_FCALL_bit)) : ((iseq_compile_each(iseq, (ret), (((rb_node_op_asgn1_t *)(node))->nd_recv), 0))) ? 0 : -1);
    if (!(asgnflag != -1)) {;return 0;};
    switch (((int) ((((NODE *)(((rb_node_op_asgn1_t *)(node))->nd_index))->flags & (((VALUE)0x7f)<<8))>>8))) {
      case NODE_ZLIST:
        argc = __builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0));
        break;
      default:
        argc = setup_args(iseq, ret, ((rb_node_op_asgn1_t *)(node))->nd_index, &flag, ((void *)0));
        if (!(!RB_NIL_P(argc))) {;return 0;};
    }
    int dup_argn = RB_FIX2INT(argc) + 1;
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_dupn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(dup_argn), ((VALUE)(dup_argn)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(dup_argn)))));
    flag |= asgnflag;
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), (idAREF), (VALUE)(argc), (((void *)0)), (VALUE)(__builtin_choose_expr( __builtin_constant_p(flag & ~(0x01 << VM_CALL_ARGS_SPLAT_MUT_bit)), ((VALUE)(flag & ~(0x01 << VM_CALL_ARGS_SPLAT_MUT_bit))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(flag & ~(0x01 << VM_CALL_ARGS_SPLAT_MUT_bit)))), (((void *)0))));
    if (id == idOROP || id == idANDOP) {
        LABEL *label = new_label_body(iseq, (line));
        LABEL *lfin = new_label_body(iseq, (line));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_dup, 0));
        if (id == idOROP) {
            (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_branchif, 1, (VALUE)(label))), ((label)->refcnt++));
        }
        else {
            (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_branchunless, 1, (VALUE)(label))), ((label)->refcnt++));
        }
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pop, 0));
        if (!(((iseq_compile_each(iseq, (ret), (((rb_node_op_asgn1_t *)(node))->nd_rvalue), 0))))) {;return 0;};
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(dup_argn+1), ((VALUE)(dup_argn+1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(dup_argn+1)))));
        }
        if (flag & (0x01 << VM_CALL_ARGS_SPLAT_bit)) {
            if (!(flag & (0x01 << VM_CALL_ARGS_SPLAT_MUT_bit))) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_swap, 0));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_splatarray, 1, (VALUE)(((VALUE)RUBY_Qtrue))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_swap, 0));
                flag |= (0x01 << VM_CALL_ARGS_SPLAT_MUT_bit);
            }
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pushtoarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), (idASET), (VALUE)(argc), (((void *)0)), (VALUE)(__builtin_choose_expr( __builtin_constant_p(flag), ((VALUE)(flag)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(flag))), (((void *)0))));
        }
        else {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), (idASET), (VALUE)(((argc)+(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1))&~RUBY_FIXNUM_FLAG))), (((void *)0)), (VALUE)(__builtin_choose_expr( __builtin_constant_p(flag), ((VALUE)(flag)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(flag))), (((void *)0))));
        }
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pop, 0));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_jump, 1, (VALUE)(lfin))), ((lfin)->refcnt++));
        ADD_ELEM((ret), (LINK_ELEMENT *) (label));
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(dup_argn+1), ((VALUE)(dup_argn+1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(dup_argn+1)))));
        }
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_adjuststack, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(dup_argn+1), ((VALUE)(dup_argn+1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(dup_argn+1)))));
        ADD_ELEM((ret), (LINK_ELEMENT *) (lfin));
    }
    else {
        if (!(((iseq_compile_each(iseq, (ret), (((rb_node_op_asgn1_t *)(node))->nd_rvalue), 0))))) {;return 0;};
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((node))->flags)>>(8 +7)), (((NODE *)((node)))->node_id), ((id)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(dup_argn+1), ((VALUE)(dup_argn+1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(dup_argn+1)))));
        }
        if (flag & (0x01 << VM_CALL_ARGS_SPLAT_bit)) {
            if (flag & (0x01 << VM_CALL_KW_SPLAT_bit)) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))));
                if (!(flag & (0x01 << VM_CALL_ARGS_SPLAT_MUT_bit))) {
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_splatarray, 1, (VALUE)(((VALUE)RUBY_Qtrue))));
                    flag |= (0x01 << VM_CALL_ARGS_SPLAT_MUT_bit);
                }
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_swap, 0));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pushtoarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pop, 0));
            }
            else {
                if (!(flag & (0x01 << VM_CALL_ARGS_SPLAT_MUT_bit))) {
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_swap, 0));
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_splatarray, 1, (VALUE)(((VALUE)RUBY_Qtrue))));
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_swap, 0));
                    flag |= (0x01 << VM_CALL_ARGS_SPLAT_MUT_bit);
                }
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pushtoarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
            }
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), (idASET), (VALUE)(argc), (((void *)0)), (VALUE)(__builtin_choose_expr( __builtin_constant_p(flag), ((VALUE)(flag)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(flag))), (((void *)0))));
        }
        else {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), (idASET), (VALUE)(((argc)+(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1))&~RUBY_FIXNUM_FLAG))), (((void *)0)), (VALUE)(__builtin_choose_expr( __builtin_constant_p(flag), ((VALUE)(flag)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(flag))), (((void *)0))));
        }
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pop, 0));
    }
    return 1;
}
static int
compile_op_asgn2(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, int popped)
{
    const int line = (int)(((long)(node)->flags)>>(8 +7));
    ID atype = ((rb_node_op_asgn2_t *)(node))->nd_mid;
    ID vid = ((rb_node_op_asgn2_t *)(node))->nd_vid, aid = rb_id_attrset(vid);
    int asgnflag;
    LABEL *lfin = new_label_body(iseq, (line));
    LABEL *lcfin = new_label_body(iseq, (line));
    LABEL *lskip = 0;
    asgnflag = (private_recv_p(node) ? (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putself, 0)), (0x01 << VM_CALL_FCALL_bit)) : ((iseq_compile_each(iseq, (ret), (((rb_node_op_asgn2_t *)(node))->nd_recv), 0))) ? 0 : -1);
    if (!(asgnflag != -1)) {;return 0;};
    if (((rb_node_op_asgn2_t *)(node))->nd_aid) {
        lskip = new_label_body(iseq, (line));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_dup, 0));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_branchnil, 1, (VALUE)(lskip))), ((lskip)->refcnt++));
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_dup, 0));
    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((node))->flags)>>(8 +7)), (((NODE *)((node)))->node_id), ((vid)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))), (((void *)0)), (VALUE)((VALUE)(__builtin_choose_expr( __builtin_constant_p(asgnflag), ((VALUE)(asgnflag)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(asgnflag)))), (((void *)0))));
    if (atype == idOROP || atype == idANDOP) {
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_dup, 0));
        }
        if (atype == idOROP) {
            (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_branchif, 1, (VALUE)(lcfin))), ((lcfin)->refcnt++));
        }
        else {
            (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_branchunless, 1, (VALUE)(lcfin))), ((lcfin)->refcnt++));
        }
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pop, 0));
        }
        if (!(((iseq_compile_each(iseq, (ret), (((rb_node_op_asgn2_t *)(node))->nd_value), 0))))) {;return 0;};
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_swap, 0));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
        }
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((node))->flags)>>(8 +7)), (((NODE *)((node)))->node_id), ((aid)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)(__builtin_choose_expr( __builtin_constant_p(asgnflag), ((VALUE)(asgnflag)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(asgnflag)))), (((void *)0))));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_jump, 1, (VALUE)(lfin))), ((lfin)->refcnt++));
        ADD_ELEM((ret), (LINK_ELEMENT *) (lcfin));
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_swap, 0));
        }
        ADD_ELEM((ret), (LINK_ELEMENT *) (lfin));
    }
    else {
        if (!(((iseq_compile_each(iseq, (ret), (((rb_node_op_asgn2_t *)(node))->nd_value), 0))))) {;return 0;};
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((node))->flags)>>(8 +7)), (((NODE *)((node)))->node_id), ((atype)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_swap, 0));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
        }
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((node))->flags)>>(8 +7)), (((NODE *)((node)))->node_id), ((aid)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)(__builtin_choose_expr( __builtin_constant_p(asgnflag), ((VALUE)(asgnflag)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(asgnflag)))), (((void *)0))));
    }
    if (lskip && popped) {
        ADD_ELEM((ret), (LINK_ELEMENT *) (lskip));
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pop, 0));
    if (lskip && !popped) {
        ADD_ELEM((ret), (LINK_ELEMENT *) (lskip));
    }
    return 1;
}
static int compile_shareable_constant_value(rb_iseq_t *iseq, LINK_ANCHOR *ret, enum rb_parser_shareability shareable, const NODE *lhs, const NODE *value);
static int
compile_op_cdecl(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, int popped)
{
    const int line = (int)(((long)(node)->flags)>>(8 +7));
    LABEL *lfin = 0;
    LABEL *lassign = 0;
    ID mid;
    switch (((int) ((((NODE *)(((rb_node_op_cdecl_t *)(node))->nd_head))->flags & (((VALUE)0x7f)<<8))>>8))) {
      case NODE_COLON3:
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putobject, 1, (VALUE)(rb_cObject)));
        break;
      case NODE_COLON2:
        if (!(((iseq_compile_each(iseq, (ret), (((rb_node_colon2_t *)(((rb_node_op_cdecl_t *)(node))->nd_head))->nd_head), 0))))) {;return 0;};
        break;
      default:
        append_compile_error(iseq, (int)(((long)(node)->flags)>>(8 +7)), "%s: invalid node in NODE_OP_CDECL",
                      ruby_node_name(((int) ((((NODE *)(((rb_node_op_cdecl_t *)(node))->nd_head))->flags & (((VALUE)0x7f)<<8))>>8))));
        return 0;
    }
    mid = get_node_colon_nd_mid(((rb_node_op_cdecl_t *)(node))->nd_head);
    if (((rb_node_op_cdecl_t *)(node))->nd_aid == idOROP) {
        lassign = new_label_body(iseq, (line));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_dup, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_defined, 3, (VALUE)(__builtin_choose_expr( __builtin_constant_p(DEFINED_CONST_FROM), ((VALUE)(DEFINED_CONST_FROM)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(DEFINED_CONST_FROM))), (VALUE)(rb_id2sym(mid)), (VALUE)(((VALUE)RUBY_Qtrue))));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_branchunless, 1, (VALUE)(lassign))), ((lassign)->refcnt++));
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_dup, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qtrue))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_getconstant, 1, (VALUE)(rb_id2sym(mid))));
    if (((rb_node_op_cdecl_t *)(node))->nd_aid == idOROP || ((rb_node_op_cdecl_t *)(node))->nd_aid == idANDOP) {
        lfin = new_label_body(iseq, (line));
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_dup, 0));
        if (((rb_node_op_cdecl_t *)(node))->nd_aid == idOROP)
            (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_branchif, 1, (VALUE)(lfin))), ((lfin)->refcnt++));
        else
            (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_branchunless, 1, (VALUE)(lfin))), ((lfin)->refcnt++));
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pop, 0));
        if (lassign) ADD_ELEM((ret), (LINK_ELEMENT *) (lassign));
        if (!(compile_shareable_constant_value(iseq, ret, ((rb_node_op_cdecl_t *)(node))->shareability, ((rb_node_op_cdecl_t *)(node))->nd_head, ((rb_node_op_cdecl_t *)(node))->nd_value))) {;return 0;};
        if (popped)
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
        else {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_dupn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_swap, 0));
        }
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_setconstant, 1, (VALUE)(rb_id2sym(mid))));
        ADD_ELEM((ret), (LINK_ELEMENT *) (lfin));
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_swap, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pop, 0));
    }
    else {
        if (!(compile_shareable_constant_value(iseq, ret, ((rb_node_op_cdecl_t *)(node))->shareability, ((rb_node_op_cdecl_t *)(node))->nd_head, ((rb_node_op_cdecl_t *)(node))->nd_value))) {;return 0;};
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((node))->flags)>>(8 +7)), (((NODE *)((node)))->node_id), ((((rb_node_op_cdecl_t *)(node))->nd_aid)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p((0x01 << VM_CALL_FCALL_bit)), ((VALUE)((0x01 << VM_CALL_FCALL_bit))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((0x01 << VM_CALL_FCALL_bit)))), (((void *)0))));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_swap, 0));
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_swap, 0));
        }
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_setconstant, 1, (VALUE)(rb_id2sym(mid))));
    }
    return 1;
}
static int
compile_op_log(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, int popped, const enum node_type type)
{
    const int line = (int)(((long)(node)->flags)>>(8 +7));
    LABEL *lfin = new_label_body(iseq, (line));
    LABEL *lassign;
    if (type == NODE_OP_ASGN_OR && !nd_type_p(((rb_node_op_asgn_or_t *)(node))->nd_head, NODE_IVAR)) {
        LABEL *lfinish[2];
        lfinish[0] = lfin;
        lfinish[1] = 0;
        defined_expr(iseq, ret, ((rb_node_op_asgn_or_t *)(node))->nd_head, lfinish, ((VALUE)RUBY_Qfalse), 0);
        lassign = lfinish[1];
        if (!lassign) {
            lassign = new_label_body(iseq, (line));
        }
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_branchunless, 1, (VALUE)(lassign))), ((lassign)->refcnt++));
    }
    else {
        lassign = new_label_body(iseq, (line));
    }
    if (!(((iseq_compile_each(iseq, (ret), (((rb_node_op_asgn_or_t *)(node))->nd_head), 0))))) {;return 0;};
    if (!popped) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_dup, 0));
    }
    if (type == NODE_OP_ASGN_AND) {
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_branchunless, 1, (VALUE)(lfin))), ((lfin)->refcnt++));
    }
    else {
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_branchif, 1, (VALUE)(lfin))), ((lfin)->refcnt++));
    }
    if (!popped) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pop, 0));
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) (lassign));
    if (!(((iseq_compile_each(iseq, (ret), (((rb_node_op_asgn_or_t *)(node))->nd_value), (popped)))))) {;return 0;};
    ADD_ELEM((ret), (LINK_ELEMENT *) (lfin));
    return 1;
}
static int
compile_super(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, int popped, const enum node_type type)
{
    struct rb_iseq_constant_body *const body = ((iseq)->body);
    LINK_ANCHOR args[1] = {{{ISEQ_ELEMENT_ANCHOR,},&args[0].anchor}};
    int argc;
    unsigned int flag = 0;
    struct rb_callinfo_kwarg *keywords = ((void *)0);
    const rb_iseq_t *parent_block = ISEQ_COMPILE_DATA(iseq)->current_block;
    int use_block = 1;
    ((args->last = &args->anchor)->next = ((void *)0));
    ISEQ_COMPILE_DATA(iseq)->current_block = ((void *)0);
    if (type == NODE_SUPER) {
        VALUE vargc = setup_args(iseq, args, ((rb_node_super_t *)(node))->nd_args, &flag, &keywords);
        if (!(!RB_NIL_P(vargc))) {;return 0;};
        argc = RB_FIX2INT(vargc);
        if ((flag & (0x01 << VM_CALL_ARGS_BLOCKARG_bit)) && (flag & (0x01 << VM_CALL_KW_SPLAT_bit)) && !(flag & (0x01 << VM_CALL_KW_SPLAT_MUT_bit))) {
            ADD_ELEM((args), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_splatkw, 0));
        }
        if (flag & (0x01 << VM_CALL_ARGS_BLOCKARG_bit)) {
            use_block = 0;
        }
    }
    else {
        int i;
        const rb_iseq_t *liseq = body->local_iseq;
        const struct rb_iseq_constant_body *const local_body = ((liseq)->body);
        const struct rb_iseq_param_keyword *const local_kwd = local_body->param.keyword;
        int lvar_level = get_lvar_level(iseq);
        argc = local_body->param.lead_num;
        for (i = 0; i < local_body->param.lead_num; i++) {
            int idx = local_body->local_table_size - i;
            iseq_add_getlocal(iseq, (args), (node), (idx), (lvar_level));
        }
        if (local_body->param.flags.forwardable) {
            flag |= (0x01 << VM_CALL_FORWARDING_bit);
            int idx = local_body->local_table_size - get_local_var_idx(liseq, idDot3);
            iseq_add_getlocal(iseq, (args), (node), (idx), (lvar_level));
        }
        if (local_body->param.flags.has_opt) {
            int j;
            for (j = 0; j < local_body->param.opt_num; j++) {
                int idx = local_body->local_table_size - (i + j);
                iseq_add_getlocal(iseq, (args), (node), (idx), (lvar_level));
            }
            i += j;
            argc = i;
        }
        if (local_body->param.flags.has_rest) {
            int idx = local_body->local_table_size - local_body->param.rest_start;
            iseq_add_getlocal(iseq, (args), (node), (idx), (lvar_level));
            ADD_ELEM((args), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_splatarray, 1, (VALUE)(((local_body->param.flags.has_post) ? ((VALUE)RUBY_Qtrue) : ((VALUE)RUBY_Qfalse)))));
            argc = local_body->param.rest_start + 1;
            flag |= (0x01 << VM_CALL_ARGS_SPLAT_bit);
        }
        if (local_body->param.flags.has_post) {
            int post_len = local_body->param.post_num;
            int post_start = local_body->param.post_start;
            if (local_body->param.flags.has_rest) {
                int j;
                for (j=0; j<post_len; j++) {
                    int idx = local_body->local_table_size - (post_start + j);
                    iseq_add_getlocal(iseq, (args), (node), (idx), (lvar_level));
                }
                ADD_ELEM((args), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pushtoarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(j), ((VALUE)(j)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(j)))));
                flag |= (0x01 << VM_CALL_ARGS_SPLAT_MUT_bit);
            }
            else {
                int j;
                for (j=0; j<post_len; j++) {
                    int idx = local_body->local_table_size - (post_start + j);
                    iseq_add_getlocal(iseq, (args), (node), (idx), (lvar_level));
                }
                argc = post_len + post_start;
            }
        }
        if (local_body->param.flags.has_kw) {
            int local_size = local_body->local_table_size;
            argc++;
            ADD_ELEM((args), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
            if (local_body->param.flags.has_kwrest) {
                int idx = local_body->local_table_size - local_kwd->rest_start;
                iseq_add_getlocal(iseq, (args), (node), (idx), (lvar_level));
                ((void)0);
                ADD_ELEM(((args)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((node))->flags)>>(8 +7)), (((NODE *)((node)))->node_id), (((__builtin_constant_p("dup") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("dup")); }) : (rb_intern)("dup")))), (VALUE)((__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
            }
            else {
                ADD_ELEM((args), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_newhash, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))));
            }
            for (i = 0; i < local_kwd->num; ++i) {
                ID id = local_kwd->table[i];
                int idx = local_size - get_local_var_idx(liseq, id);
                ADD_ELEM((args), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putobject, 1, (VALUE)(rb_id2sym(id))));
                iseq_add_getlocal(iseq, (args), (node), (idx), (lvar_level));
            }
            ADD_ELEM(((args)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((node))->flags)>>(8 +7)), (((NODE *)((node)))->node_id), ((id_core_hash_merge_ptr)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(i * 2 + 1), ((VALUE)(i * 2 + 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(i * 2 + 1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
            flag |= (0x01 << VM_CALL_KW_SPLAT_bit)| (0x01 << VM_CALL_KW_SPLAT_MUT_bit);
        }
        else if (local_body->param.flags.has_kwrest) {
            int idx = local_body->local_table_size - local_kwd->rest_start;
            iseq_add_getlocal(iseq, (args), (node), (idx), (lvar_level));
            argc++;
            flag |= (0x01 << VM_CALL_KW_SPLAT_bit);
        }
    }
    if (use_block && parent_block == ((void *)0)) {
        iseq_set_use_block(((iseq)->body)->local_iseq);
    }
    flag |= (0x01 << VM_CALL_SUPER_bit) | (0x01 << VM_CALL_FCALL_bit);
    if (type == NODE_ZSUPER) flag |= (0x01 << VM_CALL_ZSUPER_bit);
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putself, 0));
    APPEND_LIST((ret), (args));
    const struct rb_callinfo * ci = new_callinfo(iseq, 0, argc, flag, keywords, parent_block != ((void *)0));
    if (vm_ci_flag(ci) & (0x01 << VM_CALL_FORWARDING_bit)) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_invokesuperforward, 2, (VALUE)(ci), (VALUE)(parent_block)));
    }
    else {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_invokesuper, 2, (VALUE)(ci), (VALUE)(parent_block)));
    }
    if (popped) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pop, 0));
    }
    return 1;
}
static int
compile_yield(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, int popped)
{
    LINK_ANCHOR args[1] = {{{ISEQ_ELEMENT_ANCHOR,},&args[0].anchor}};
    VALUE argc;
    unsigned int flag = 0;
    struct rb_callinfo_kwarg *keywords = ((void *)0);
    ((args->last = &args->anchor)->next = ((void *)0));
    switch (((((iseq)->body)->local_iseq)->body)->type) {
      case ISEQ_TYPE_TOP:
      case ISEQ_TYPE_MAIN:
      case ISEQ_TYPE_CLASS:
        append_compile_error(iseq, (int)(((long)(node)->flags)>>(8 +7)), "Invalid yield");
        return 0;
      default: ;
    }
    if (((rb_node_yield_t *)(node))->nd_head) {
        argc = setup_args(iseq, args, ((rb_node_yield_t *)(node))->nd_head, &flag, &keywords);
        if (!(!RB_NIL_P(argc))) {;return 0;};
    }
    else {
        argc = __builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0));
    }
    APPEND_LIST((ret), (args));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_invokeblock, 1, (VALUE)(new_callinfo(iseq, 0, RB_FIX2INT(argc), flag, keywords, 0))));
    iseq_set_use_block(((iseq)->body)->local_iseq);
    if (popped) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pop, 0));
    }
    int level = 0;
    const rb_iseq_t *tmp_iseq = iseq;
    for (; tmp_iseq != ((iseq)->body)->local_iseq; level++ ) {
        tmp_iseq = ((tmp_iseq)->body)->parent_iseq;
    }
    if (level > 0) access_outer_variables(iseq, level, (__builtin_constant_p("yield") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("yield")); }) : (rb_intern)("yield")), 1);
    return 1;
}
static int
compile_match(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, int popped, const enum node_type type)
{
    LINK_ANCHOR recv[1] = {{{ISEQ_ELEMENT_ANCHOR,},&recv[0].anchor}};
    LINK_ANCHOR val[1] = {{{ISEQ_ELEMENT_ANCHOR,},&val[0].anchor}};
    ((recv->last = &recv->anchor)->next = ((void *)0));
    ((val->last = &val->anchor)->next = ((void *)0));
    switch ((int)type) {
      case NODE_MATCH:
        ADD_ELEM((recv), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putobject, 1, (VALUE)(rb_node_regx_string_val(node))));
        ADD_ELEM((val), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_getspecial, 2, (VALUE)(__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (VALUE)(__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))));
        break;
      case NODE_MATCH2:
        if (!(((iseq_compile_each(iseq, (recv), (((rb_node_match2_t *)(node))->nd_recv), 0))))) {;return 0;};
        if (!(((iseq_compile_each(iseq, (val), (((rb_node_match2_t *)(node))->nd_value), 0))))) {;return 0;};
        break;
      case NODE_MATCH3:
        if (!(((iseq_compile_each(iseq, (recv), (((rb_node_match3_t *)(node))->nd_value), 0))))) {;return 0;};
        if (!(((iseq_compile_each(iseq, (val), (((rb_node_match3_t *)(node))->nd_recv), 0))))) {;return 0;};
        break;
    }
    APPEND_LIST((ret), (recv));
    APPEND_LIST((ret), (val));
    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((node))->flags)>>(8 +7)), (((NODE *)((node)))->node_id), ((idEqTilde)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
    if (nd_type_p(node, NODE_MATCH2) && ((rb_node_match2_t *)(node))->nd_args) {
        compile_named_capture_assign(iseq, ret, ((rb_node_match2_t *)(node))->nd_args);
    }
    if (popped) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pop, 0));
    }
    return 1;
}
static int
compile_colon2(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, int popped)
{
    if (rb_is_const_id(((rb_node_colon2_t *)(node))->nd_mid)) {
        VALUE segments;
        if (ISEQ_COMPILE_DATA(iseq)->option->inline_const_cache &&
                (segments = collect_const_segments(iseq, node))) {
            ((iseq)->body)->ic_size++;
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_opt_getconstant_path, 1, (VALUE)(segments)));
            (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(segments), "compile.c", 10014));
        }
        else {
            LINK_ANCHOR pref[1] = {{{ISEQ_ELEMENT_ANCHOR,},&pref[0].anchor}};
            LINK_ANCHOR body[1] = {{{ISEQ_ELEMENT_ANCHOR,},&body[0].anchor}};
            ((pref->last = &pref->anchor)->next = ((void *)0));
            ((body->last = &body->anchor)->next = ((void *)0));
            if (!(compile_const_prefix(iseq, node, pref, body))) {;return 0;};
            if (LIST_INSN_SIZE_ZERO(pref)) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putnil, 0));
                APPEND_LIST((ret), (body));
            }
            else {
                APPEND_LIST((ret), (pref));
                APPEND_LIST((ret), (body));
            }
        }
    }
    else {
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)((node))->flags)>>(8 +7)), (((NODE *)((node)))->node_id), YARVINSN_putself, 0));
        if (!(((iseq_compile_each(iseq, (ret), (((rb_node_colon2_t *)(node))->nd_head), 0))))) {;return 0;};
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((node))->flags)>>(8 +7)), (((NODE *)((node)))->node_id), ((((rb_node_colon2_t *)(node))->nd_mid)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p((0x01 << VM_CALL_FCALL_bit)), ((VALUE)((0x01 << VM_CALL_FCALL_bit))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((0x01 << VM_CALL_FCALL_bit)))), (((void *)0))));
    }
    if (popped) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pop, 0));
    }
    return 1;
}
static int
compile_colon3(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, int popped)
{
    ((void)0);
    if (ISEQ_COMPILE_DATA(iseq)->option->inline_const_cache) {
        ((iseq)->body)->ic_size++;
        VALUE segments = __extension__ ({ const VALUE args_to_new_ary[] = {rb_id2sym(idNULL), rb_id2sym(((rb_node_colon3_t *)(node))->nd_mid)}; if (__builtin_constant_p(2)) { __extension__ _Static_assert(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))) == (2), "rb_ary_new_from_args" ": " "numberof(args_to_new_ary) == (2)"); } rb_ary_new_from_values(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))), args_to_new_ary); });
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_opt_getconstant_path, 1, (VALUE)(segments)));
        (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(segments), "compile.c", 10056));
    }
    else {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putobject, 1, (VALUE)(rb_cObject)));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qtrue))));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_getconstant, 1, (VALUE)(rb_id2sym(((rb_node_colon3_t *)(node))->nd_mid))));
    }
    if (popped) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pop, 0));
    }
    return 1;
}
static int
compile_dots(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, int popped, const int excl)
{
    VALUE flag = __builtin_choose_expr( __builtin_constant_p(excl), ((VALUE)(excl)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(excl));
    const NODE *b = ((rb_node_dot2_t *)(node))->nd_beg;
    const NODE *e = ((rb_node_dot2_t *)(node))->nd_end;
    if (optimizable_range_item_p(b) && optimizable_range_item_p(e)) {
        if (!popped) {
            VALUE bv = optimized_range_item(b);
            VALUE ev = optimized_range_item(e);
            VALUE val = rb_range_new(bv, ev, excl);
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putobject, 1, (VALUE)(val)));
            (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(val), "compile.c", 10083));
        }
    }
    else {
        if (!(((iseq_compile_each(iseq, (ret), (b), (popped)))))) {;return 0;};
        if (!(((iseq_compile_each(iseq, (ret), (e), (popped)))))) {;return 0;};
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_newrange, 1, (VALUE)(flag)));
        }
    }
    return 1;
}
static int
compile_errinfo(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, int popped)
{
    if (!popped) {
        if (((iseq)->body)->type == ISEQ_TYPE_RESCUE) {
            iseq_add_getlocal(iseq, (ret), (node), ((1)), (0));
        }
        else {
            const rb_iseq_t *ip = iseq;
            int level = 0;
            while (ip) {
                if (((ip)->body)->type == ISEQ_TYPE_RESCUE) {
                    break;
                }
                ip = ((ip)->body)->parent_iseq;
                level++;
            }
            if (ip) {
                iseq_add_getlocal(iseq, (ret), (node), ((1)), (level));
            }
            else {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putnil, 0));
            }
        }
    }
    return 1;
}
static int
compile_kw_arg(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, int popped)
{
    struct rb_iseq_constant_body *const body = ((iseq)->body);
    LABEL *end_label = new_label_body(iseq, ((int)(((long)(node)->flags)>>(8 +7))));
    const NODE *default_value = get_nd_value(((rb_node_kw_arg_t *)(node))->nd_body);
    if (default_value == ((NODE *)-1)) {
        append_compile_error(iseq, (int)(((long)(node)->flags)>>(8 +7)), "unreachable");
        return 0;
    }
    else if (nd_type_p(default_value, NODE_SYM) ||
             nd_type_p(default_value, NODE_REGX) ||
             nd_type_p(default_value, NODE_LINE) ||
             nd_type_p(default_value, NODE_INTEGER) ||
             nd_type_p(default_value, NODE_FLOAT) ||
             nd_type_p(default_value, NODE_RATIONAL) ||
             nd_type_p(default_value, NODE_IMAGINARY) ||
             nd_type_p(default_value, NODE_NIL) ||
             nd_type_p(default_value, NODE_TRUE) ||
             nd_type_p(default_value, NODE_FALSE)) {
        append_compile_error(iseq, (int)(((long)(node)->flags)>>(8 +7)), "unreachable");
        return 0;
    }
    else {
        int kw_bits_idx = body->local_table_size - body->param.keyword->bits_start;
        int keyword_idx = body->param.keyword->num;
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_checkkeyword, 2, (VALUE)(__builtin_choose_expr( __builtin_constant_p(kw_bits_idx + ( 3) - 1), ((VALUE)(kw_bits_idx + ( 3) - 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(kw_bits_idx + ( 3) - 1))), (VALUE)(__builtin_choose_expr( __builtin_constant_p(keyword_idx), ((VALUE)(keyword_idx)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(keyword_idx)))));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_branchif, 1, (VALUE)(end_label))), ((end_label)->refcnt++));
        if (!(((iseq_compile_each(iseq, (ret), (((rb_node_kw_arg_t *)(node))->nd_body), 1))))) {;return 0;};
        ADD_ELEM((ret), (LINK_ELEMENT *) (end_label));
    }
    return 1;
}
static int
compile_attrasgn(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, int popped)
{
    LINK_ANCHOR recv[1] = {{{ISEQ_ELEMENT_ANCHOR,},&recv[0].anchor}};
    LINK_ANCHOR args[1] = {{{ISEQ_ELEMENT_ANCHOR,},&args[0].anchor}};
    unsigned int flag = 0;
    ID mid = ((rb_node_attrasgn_t *)(node))->nd_mid;
    VALUE argc;
    LABEL *else_label = ((void *)0);
    VALUE branches = ((VALUE)RUBY_Qfalse);
    if (mid == idASET && !private_recv_p(node) && ((rb_node_attrasgn_t *)(node))->nd_args &&
        nd_type_p(((rb_node_attrasgn_t *)(node))->nd_args, NODE_LIST) && ((rb_node_list_t *)(((rb_node_attrasgn_t *)(node))->nd_args))->as.nd_alen == 2 &&
        (nd_type_p(((rb_node_list_t *)(((rb_node_attrasgn_t *)(node))->nd_args))->nd_head, NODE_STR) || nd_type_p(((rb_node_list_t *)(((rb_node_attrasgn_t *)(node))->nd_args))->nd_head, NODE_FILE)) &&
        ISEQ_COMPILE_DATA(iseq)->current_block == ((void *)0) &&
        !frozen_string_literal_p(iseq) &&
        ISEQ_COMPILE_DATA(iseq)->option->specialized_instruction)
    {
        VALUE str = get_string_value(((rb_node_list_t *)(((rb_node_attrasgn_t *)(node))->nd_args))->nd_head);
        if (!(((iseq_compile_each(iseq, (ret), (((rb_node_attrasgn_t *)(node))->nd_recv), 0))))) {;return 0;};
        if (!(((iseq_compile_each(iseq, (ret), (((rb_node_list_t *)(((rb_node_list_t *)(((rb_node_attrasgn_t *)(node))->nd_args))->nd_next))->nd_head), 0))))) {;return 0;};
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_swap, 0));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
        }
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_opt_aset_with, 2, (VALUE)(str), (VALUE)(new_callinfo(iseq, idASET, 2, 0, ((void *)0), 0))));
        (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(str), "compile.c", 10195));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pop, 0));
        return 1;
    }
    ((recv->last = &recv->anchor)->next = ((void *)0));
    ((args->last = &args->anchor)->next = ((void *)0));
    argc = setup_args(iseq, args, ((rb_node_attrasgn_t *)(node))->nd_args, &flag, ((void *)0));
    if (!(!RB_NIL_P(argc))) {;return 0;};
    int asgnflag = (private_recv_p(node) ? (ADD_ELEM((recv), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putself, 0)), (0x01 << VM_CALL_FCALL_bit)) : ((iseq_compile_each(iseq, (recv), (((rb_node_attrasgn_t *)(node))->nd_recv), 0))) ? 0 : -1);
    if (!(asgnflag != -1)) {;return 0;};
    flag |= (unsigned int)asgnflag;
    ((void)0);
    ((void)0);
    if (!rb_is_attrset_id(mid)) {
        mid = rb_id_attrset(mid);
        else_label = qcall_branch_start(iseq, recv, &branches, node, node);
    }
    if (!popped) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putnil, 0));
        APPEND_LIST((ret), (recv));
        APPEND_LIST((ret), (args));
        if (flag & (0x01 << VM_CALL_ARGS_SPLAT_bit)) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_dup, 0));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(-1), ((VALUE)(-1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(-1)))));
            ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((node))->flags)>>(8 +7)), (((NODE *)((node)))->node_id), ((idAREF)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)(__builtin_choose_expr( __builtin_constant_p(asgnflag), ((VALUE)(asgnflag)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(asgnflag)))), (((void *)0))));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_setn, 1, (VALUE)(((argc)+(__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2))&~RUBY_FIXNUM_FLAG)))));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pop, 0));
        }
        else {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_setn, 1, (VALUE)(((argc)+(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1))&~RUBY_FIXNUM_FLAG)))));
        }
    }
    else {
        APPEND_LIST((ret), (recv));
        APPEND_LIST((ret), (args));
    }
    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((node))->flags)>>(8 +7)), (((NODE *)((node)))->node_id), ((mid)), (VALUE)((argc)), (((void *)0)), (VALUE)((VALUE)(__builtin_choose_expr( __builtin_constant_p(flag), ((VALUE)(flag)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(flag)))), (((void *)0))));
    qcall_branch_end(iseq, ret, else_label, branches, node, node);
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pop, 0));
    return 1;
}
static int
compile_make_shareable_node(rb_iseq_t *iseq, LINK_ANCHOR *ret, LINK_ANCHOR *sub, const NODE *value, _Bool copy)
{
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(value)->flags)>>(8 +7)), (((NODE *)(value))->node_id), YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
    APPEND_LIST((ret), (sub));
    if (copy) {
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((value))->flags)>>(8 +7)), (((NODE *)((value)))->node_id), (((__builtin_constant_p("make_shareable_copy") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("make_shareable_copy")); }) : (rb_intern)("make_shareable_copy")))), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)(__builtin_choose_expr( __builtin_constant_p((0x01 << VM_CALL_ARGS_SIMPLE_bit)), ((VALUE)((0x01 << VM_CALL_ARGS_SIMPLE_bit))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((0x01 << VM_CALL_ARGS_SIMPLE_bit))))), (((void *)0))));
    }
    else {
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((value))->flags)>>(8 +7)), (((NODE *)((value)))->node_id), (((__builtin_constant_p("make_shareable") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("make_shareable")); }) : (rb_intern)("make_shareable")))), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)(__builtin_choose_expr( __builtin_constant_p((0x01 << VM_CALL_ARGS_SIMPLE_bit)), ((VALUE)((0x01 << VM_CALL_ARGS_SIMPLE_bit))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((0x01 << VM_CALL_ARGS_SIMPLE_bit))))), (((void *)0))));
    }
    return 1;
}
static VALUE
node_const_decl_val(const NODE *node)
{
    VALUE path;
    switch (((int) ((((NODE *)(node))->flags & (((VALUE)0x7f)<<8))>>8))) {
      case NODE_CDECL:
        if (((rb_node_cdecl_t *)(node))->nd_vid) {
            path = rb_id2str(((rb_node_cdecl_t *)(node))->nd_vid);
            goto end;
        }
        else {
            node = ((rb_node_cdecl_t *)(node))->nd_else;
        }
        break;
      case NODE_COLON2:
        break;
      case NODE_COLON3:
        path = ((__builtin_constant_p("::") ? rbimpl_str_new_cstr : rb_str_new_cstr) ("::"));
        rb_str_append(path, rb_id2str(((rb_node_colon3_t *)(node))->nd_mid));
        goto end;
      default:
        rb_bug("unexpected node: %s", ruby_node_name(((int) ((((NODE *)(node))->flags & (((VALUE)0x7f)<<8))>>8))));
        __builtin_unreachable();
    }
    path = rb_ary_new();
    if (node) {
        for (; node && nd_type_p(node, NODE_COLON2); node = ((rb_node_colon2_t *)(node))->nd_head) {
            rb_ary_push(path, rb_id2str(((rb_node_colon2_t *)(node))->nd_mid));
        }
        if (node && nd_type_p(node, NODE_CONST)) {
            rb_ary_push(path, rb_id2str(((rb_node_const_t *)(node))->nd_vid));
        }
        else if (node && nd_type_p(node, NODE_COLON3)) {
            rb_ary_push(path, rb_id2str(((rb_node_colon3_t *)(node))->nd_mid));
            rb_ary_push(path, ((__builtin_constant_p(0) && __builtin_constant_p(0) ? rb_str_new_static : rb_str_new) ((0), (0))));
        }
        else {
            rb_ary_push(path, ((__builtin_constant_p("...") ? rbimpl_str_new_cstr : rb_str_new_cstr) ("...")));
        }
        path = rb_ary_join(rb_ary_reverse(path), ((__builtin_constant_p("::") ? rbimpl_str_new_cstr : rb_str_new_cstr) ("::")));
    }
  end:
    path = rb_fstring(path);
    return path;
}
static VALUE
const_decl_path(NODE *dest)
{
    VALUE path = ((VALUE)RUBY_Qnil);
    if (!nd_type_p(dest, NODE_CALL)) {
        path = node_const_decl_val(dest);
    }
    return path;
}
static int
compile_ensure_shareable_node(rb_iseq_t *iseq, LINK_ANCHOR *ret, NODE *dest, const NODE *value)
{
    VALUE path = const_decl_path(dest);
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(value)->flags)>>(8 +7)), (((NODE *)(value))->node_id), YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
    if (!(((iseq_compile_each(iseq, (ret), (value), 0))))) {;return 0;};
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(value)->flags)>>(8 +7)), (((NODE *)(value))->node_id), YARVINSN_putobject, 1, (VALUE)(path)));
    (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(path), "compile.c", 10338));
    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((value))->flags)>>(8 +7)), (((NODE *)((value)))->node_id), (((__builtin_constant_p("ensure_shareable") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("ensure_shareable")); }) : (rb_intern)("ensure_shareable")))), (VALUE)((__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))), (((void *)0)), (VALUE)((VALUE)(__builtin_choose_expr( __builtin_constant_p((0x01 << VM_CALL_ARGS_SIMPLE_bit)), ((VALUE)((0x01 << VM_CALL_ARGS_SIMPLE_bit))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((0x01 << VM_CALL_ARGS_SIMPLE_bit))))), (((void *)0))));
    return 1;
}
static int
compile_shareable_literal_constant(rb_iseq_t *iseq, LINK_ANCHOR *ret, enum rb_parser_shareability shareable, NODE *dest, const NODE *node, size_t level, VALUE *value_p, int *shareable_literal_p)
{
    VALUE lit = ((VALUE)RUBY_Qnil);
    LINK_ANCHOR anchor[1] = {{{ISEQ_ELEMENT_ANCHOR,},&anchor[0].anchor}};
    enum node_type type = ((int) ((((NODE *)(node))->flags & (((VALUE)0x7f)<<8))>>8));
    switch (type) {
      case NODE_TRUE:
        *value_p = ((VALUE)RUBY_Qtrue);
        goto compile;
      case NODE_FALSE:
        *value_p = ((VALUE)RUBY_Qfalse);
        goto compile;
      case NODE_NIL:
        *value_p = ((VALUE)RUBY_Qnil);
        goto compile;
      case NODE_SYM:
        *value_p = rb_node_sym_string_val(node);
        goto compile;
      case NODE_REGX:
        *value_p = rb_node_regx_string_val(node);
        goto compile;
      case NODE_LINE:
        *value_p = rb_node_line_lineno_val(node);
        goto compile;
      case NODE_INTEGER:
        *value_p = rb_node_integer_literal_val(node);
        goto compile;
      case NODE_FLOAT:
        *value_p = rb_node_float_literal_val(node);
        goto compile;
      case NODE_RATIONAL:
        *value_p = rb_node_rational_literal_val(node);
        goto compile;
      case NODE_IMAGINARY:
        *value_p = rb_node_imaginary_literal_val(node);
        goto compile;
      case NODE_ENCODING:
        *value_p = rb_node_encoding_val(node);
      compile:
        if (!(((iseq_compile_each(iseq, (ret), (node), 0))))) {;return 0;};
        *shareable_literal_p = 1;
        return 1;
      case NODE_DSTR:
        if (!(((iseq_compile_each(iseq, (ret), (node), 0))))) {;return 0;};
        if (shareable == rb_parser_shareable_literal) {
            ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((node))->flags)>>(8 +7)), (((NODE *)((node)))->node_id), ((idUMinus)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))), (((void *)0)), (VALUE)((VALUE)(__builtin_choose_expr( __builtin_constant_p((0x01 << VM_CALL_ARGS_SIMPLE_bit)), ((VALUE)((0x01 << VM_CALL_ARGS_SIMPLE_bit))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((0x01 << VM_CALL_ARGS_SIMPLE_bit))))), (((void *)0))));
        }
        *value_p = ((VALUE)RUBY_Qundef);
        *shareable_literal_p = 1;
        return 1;
      case NODE_STR:{
        VALUE lit = rb_node_str_string_val(node);
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putobject, 1, (VALUE)(lit)));
        (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(lit), "compile.c", 10413));
        *value_p = lit;
        *shareable_literal_p = 1;
        return 1;
      }
      case NODE_FILE:{
        VALUE lit = rb_node_file_path_val(node);
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putobject, 1, (VALUE)(lit)));
        (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(lit), "compile.c", 10423));
        *value_p = lit;
        *shareable_literal_p = 1;
        return 1;
      }
      case NODE_ZLIST:{
        VALUE lit = rb_ary_new();
        rb_obj_freeze_inline(lit);
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putobject, 1, (VALUE)(lit)));
        (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(lit), "compile.c", 10434));
        *value_p = lit;
        *shareable_literal_p = 1;
        return 1;
      }
      case NODE_LIST:{
        ((anchor->last = &anchor->anchor)->next = ((void *)0));
        lit = rb_ary_new();
        for (NODE *n = (NODE *)node; n; n = ((rb_node_list_t *)(n))->nd_next) {
            VALUE val;
            int shareable_literal_p2;
            NODE *elt = ((rb_node_list_t *)(n))->nd_head;
            if (elt) {
                if (!(compile_shareable_literal_constant(iseq, anchor, shareable, dest, elt, level+1, &val, &shareable_literal_p2))) {;return 0;};
                if (shareable_literal_p2) {
                }
                else if (RB_TEST(lit)) {
                    rb_ary_clear(lit);
                    lit = ((VALUE)RUBY_Qfalse);
                }
            }
            if (RB_TEST(lit)) {
                if (!RB_UNDEF_P(val)) {
                    rb_ary_push(lit, val);
                }
                else {
                    rb_ary_clear(lit);
                    lit = ((VALUE)RUBY_Qnil);
                }
            }
        }
        break;
      }
      case NODE_HASH:{
        if (!((rb_node_hash_t *)(node))->nd_brace) {
            *value_p = ((VALUE)RUBY_Qundef);
            *shareable_literal_p = 0;
            return 1;
        }
        ((anchor->last = &anchor->anchor)->next = ((void *)0));
        lit = rb_hash_new();
        for (NODE *n = ((rb_node_hash_t *)(node))->nd_head; n; n = ((rb_node_list_t *)(((rb_node_list_t *)(n))->nd_next))->nd_next) {
            VALUE key_val = 0;
            VALUE value_val = 0;
            int shareable_literal_p2;
            NODE *key = ((rb_node_list_t *)(n))->nd_head;
            NODE *val = ((rb_node_list_t *)(((rb_node_list_t *)(n))->nd_next))->nd_head;
            if (key) {
                if (!(compile_shareable_literal_constant(iseq, anchor, shareable, dest, key, level+1, &key_val, &shareable_literal_p2))) {;return 0;};
                if (shareable_literal_p2) {
                }
                else if (RB_TEST(lit)) {
                    rb_hash_clear(lit);
                    lit = ((VALUE)RUBY_Qfalse);
                }
            }
            if (val) {
                if (!(compile_shareable_literal_constant(iseq, anchor, shareable, dest, val, level+1, &value_val, &shareable_literal_p2))) {;return 0;};
                if (shareable_literal_p2) {
                }
                else if (RB_TEST(lit)) {
                    rb_hash_clear(lit);
                    lit = ((VALUE)RUBY_Qfalse);
                }
            }
            if (RB_TEST(lit)) {
                if (!RB_UNDEF_P(key_val) && !RB_UNDEF_P(value_val)) {
                    rb_hash_aset(lit, key_val, value_val);
                }
                else {
                    rb_hash_clear(lit);
                    lit = ((VALUE)RUBY_Qnil);
                }
            }
        }
        break;
      }
      default:
        if (shareable == rb_parser_shareable_literal &&
            (1 || level > 0)) {
            if (!(compile_ensure_shareable_node(iseq, ret, dest, node))) {;return 0;};
            *value_p = ((VALUE)RUBY_Qundef);
            *shareable_literal_p = 1;
            return 1;
        }
        if (!(((iseq_compile_each(iseq, (ret), (node), 0))))) {;return 0;};
        *value_p = ((VALUE)RUBY_Qundef);
        *shareable_literal_p = 0;
        return 1;
    }
    if (!lit) {
        if (((int) ((((NODE *)(node))->flags & (((VALUE)0x7f)<<8))>>8)) == NODE_LIST) {
            ADD_ELEM((anchor), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_newarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(((rb_node_list_t *)(node))->as.nd_alen), ((VALUE)(((rb_node_list_t *)(node))->as.nd_alen)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(((rb_node_list_t *)(node))->as.nd_alen)))));
        }
        else if (((int) ((((NODE *)(node))->flags & (((VALUE)0x7f)<<8))>>8)) == NODE_HASH) {
            int len = (int)((rb_node_list_t *)(((rb_node_hash_t *)(node))->nd_head))->as.nd_alen;
            ADD_ELEM((anchor), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_newhash, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(len), ((VALUE)(len)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(len)))));
        }
        *value_p = ((VALUE)RUBY_Qundef);
        *shareable_literal_p = 0;
        APPEND_LIST((ret), (anchor));
        return 1;
    }
    if (RB_NIL_P(lit)) {
        if (((int) ((((NODE *)(node))->flags & (((VALUE)0x7f)<<8))>>8)) == NODE_LIST) {
            ADD_ELEM((anchor), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_newarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(((rb_node_list_t *)(node))->as.nd_alen), ((VALUE)(((rb_node_list_t *)(node))->as.nd_alen)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(((rb_node_list_t *)(node))->as.nd_alen)))));
        }
        else if (((int) ((((NODE *)(node))->flags & (((VALUE)0x7f)<<8))>>8)) == NODE_HASH) {
            int len = (int)((rb_node_list_t *)(((rb_node_hash_t *)(node))->nd_head))->as.nd_alen;
            ADD_ELEM((anchor), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_newhash, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(len), ((VALUE)(len)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(len)))));
        }
        if (!(compile_make_shareable_node(iseq, ret, anchor, node, 0))) {;return 0;};
        *value_p = ((VALUE)RUBY_Qundef);
        *shareable_literal_p = 1;
    }
    else {
        VALUE val = rb_ractor_make_shareable(lit);
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putobject, 1, (VALUE)(val)));
        (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(val), "compile.c", 10563));
        *value_p = val;
        *shareable_literal_p = 1;
    }
    return 1;
}
static int
compile_shareable_constant_value(rb_iseq_t *iseq, LINK_ANCHOR *ret, enum rb_parser_shareability shareable, const NODE *lhs, const NODE *value)
{
    int literal_p = 0;
    VALUE val;
    LINK_ANCHOR anchor[1] = {{{ISEQ_ELEMENT_ANCHOR,},&anchor[0].anchor}};
    ((anchor->last = &anchor->anchor)->next = ((void *)0));
    switch (shareable) {
      case rb_parser_shareable_none:
        if (!(((iseq_compile_each(iseq, (ret), (value), 0))))) {;return 0;};
        return 1;
      case rb_parser_shareable_literal:
        if (!(compile_shareable_literal_constant(iseq, anchor, shareable, (NODE *)lhs, value, 0, &val, &literal_p))) {;return 0;};
        APPEND_LIST((ret), (anchor));
        return 1;
      case rb_parser_shareable_copy:
      case rb_parser_shareable_everything:
        if (!(compile_shareable_literal_constant(iseq, anchor, shareable, (NODE *)lhs, value, 0, &val, &literal_p))) {;return 0;};
        if (!literal_p) {
            if (!(compile_make_shareable_node(iseq, ret, anchor, value, shareable == rb_parser_shareable_copy))) {;return 0;};
        }
        else {
            APPEND_LIST((ret), (anchor));
        }
        return 1;
      default:
        rb_bug("unexpected rb_parser_shareability: %d", shareable);
    }
}
static int iseq_compile_each0(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, int popped);
static int
iseq_compile_each(rb_iseq_t *iseq, LINK_ANCHOR *ret, const NODE *node, int popped)
{
    if (node == 0) {
        if (!popped) {
            int lineno = ISEQ_COMPILE_DATA(iseq)->last_line;
            if (lineno == 0) lineno = RB_FIX2INT(rb_iseq_first_lineno(iseq));
            if(0)printf("node: NODE_NIL(implicit)\n");
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (lineno), (-1), YARVINSN_putnil, 0));
        }
        return 1;
    }
    return iseq_compile_each0(iseq, ret, node, popped);
}
static int
iseq_compile_each0(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const NODE *const node, int popped)
{
    const int line = (int)(int)(((long)(node)->flags)>>(8 +7));
    const enum node_type type = ((int) ((((NODE *)(node))->flags & (((VALUE)0x7f)<<8))>>8));
    struct rb_iseq_constant_body *const body = ((iseq)->body);
    if (ISEQ_COMPILE_DATA(iseq)->last_line == line) {
    }
    else {
        if (((node)->flags & (((VALUE)1)<<7))) {
            int event = 0x0001;
            ISEQ_COMPILE_DATA(iseq)->last_line = line;
            if (((iseq)->body)->variable.coverage && RARRAY_AREF(((iseq)->body)->variable.coverage, 0)) {
                event |= 0x010000;
            }
            ADD_ELEM((ret), (LINK_ELEMENT *)new_trace_body(iseq, (event), 0));
        }
    }
    ((void)0);
    switch (type) {
      case NODE_BLOCK:
        if (!(compile_block(iseq, ret, node, popped))) {((void)0);return 0;};
        break;
      case NODE_IF:
      case NODE_UNLESS:
        if (!(compile_if(iseq, ret, node, popped, type))) {((void)0);return 0;};
        break;
      case NODE_CASE:
        if (!(compile_case(iseq, ret, node, popped))) {((void)0);return 0;};
        break;
      case NODE_CASE2:
        if (!(compile_case2(iseq, ret, node, popped))) {((void)0);return 0;};
        break;
      case NODE_CASE3:
        if (!(compile_case3(iseq, ret, node, popped))) {((void)0);return 0;};
        break;
      case NODE_WHILE:
      case NODE_UNTIL:
        if (!(compile_loop(iseq, ret, node, popped, type))) {((void)0);return 0;};
        break;
      case NODE_FOR:
      case NODE_ITER:
        if (!(compile_iter(iseq, ret, node, popped))) {((void)0);return 0;};
        break;
      case NODE_FOR_MASGN:
        if (!(compile_for_masgn(iseq, ret, node, popped))) {((void)0);return 0;};
        break;
      case NODE_BREAK:
        if (!(compile_break(iseq, ret, node, popped))) {((void)0);return 0;};
        break;
      case NODE_NEXT:
        if (!(compile_next(iseq, ret, node, popped))) {((void)0);return 0;};
        break;
      case NODE_REDO:
        if (!(compile_redo(iseq, ret, node, popped))) {((void)0);return 0;};
        break;
      case NODE_RETRY:
        if (!(compile_retry(iseq, ret, node, popped))) {((void)0);return 0;};
        break;
      case NODE_BEGIN:{
        if (!(((iseq_compile_each(iseq, (ret), (((rb_node_begin_t *)(node))->nd_body), (popped)))))) {((void)0);return 0;};
        break;
      }
      case NODE_RESCUE:
        if (!(compile_rescue(iseq, ret, node, popped))) {((void)0);return 0;};
        break;
      case NODE_RESBODY:
        if (!(compile_resbody(iseq, ret, node, popped))) {((void)0);return 0;};
        break;
      case NODE_ENSURE:
        if (!(compile_ensure(iseq, ret, node, popped))) {((void)0);return 0;};
        break;
      case NODE_AND:
      case NODE_OR:{
        LABEL *end_label = new_label_body(iseq, (line));
        if (!(((iseq_compile_each(iseq, (ret), (((rb_node_or_t *)(node))->nd_1st), 0))))) {((void)0);return 0;};
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_dup, 0));
        }
        if (type == NODE_AND) {
            (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_branchunless, 1, (VALUE)(end_label))), ((end_label)->refcnt++));
        }
        else {
            (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_branchif, 1, (VALUE)(end_label))), ((end_label)->refcnt++));
        }
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pop, 0));
        }
        if (!(((iseq_compile_each(iseq, (ret), (((rb_node_or_t *)(node))->nd_2nd), (popped)))))) {((void)0);return 0;};
        ADD_ELEM((ret), (LINK_ELEMENT *) (end_label));
        break;
      }
      case NODE_MASGN:{
        compile_massign(iseq, ret, node, popped);
        break;
      }
      case NODE_LASGN:{
        ID id = ((rb_node_lasgn_t *)(node))->nd_vid;
        int idx = ((body->local_iseq)->body)->local_table_size - get_local_var_idx(iseq, id);
        if(0)printf("lvar: %s idx: %d\n", rb_id2name(id), idx);
        if (!(((iseq_compile_each(iseq, (ret), (((rb_node_lasgn_t *)(node))->nd_value), 0))))) {((void)0);return 0;};
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_dup, 0));
        }
        iseq_add_setlocal(iseq, (ret), (node), (idx), (get_lvar_level(iseq)));
        break;
      }
      case NODE_DASGN: {
        int idx, lv, ls;
        ID id = ((rb_node_dasgn_t *)(node))->nd_vid;
        if (!(((iseq_compile_each(iseq, (ret), (((rb_node_dasgn_t *)(node))->nd_value), 0))))) {((void)0);return 0;};
        ((void)0);
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_dup, 0));
        }
        idx = get_dyna_var_idx(iseq, id, &lv, &ls);
        if (idx < 0) {
            append_compile_error(iseq, (int)(((long)(node)->flags)>>(8 +7)), "NODE_DASGN: unknown id (%""l""i" "\v"")",
                          rb_id2str(id));
            goto ng;
        }
        iseq_add_setlocal(iseq, (ret), (node), (ls - idx), (lv));
        break;
      }
      case NODE_GASGN:{
        if (!(((iseq_compile_each(iseq, (ret), (((rb_node_gasgn_t *)(node))->nd_value), 0))))) {((void)0);return 0;};
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_dup, 0));
        }
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_setglobal, 1, (VALUE)(rb_id2sym(((rb_node_gasgn_t *)(node))->nd_vid))));
        break;
      }
      case NODE_IASGN:{
        if (!(((iseq_compile_each(iseq, (ret), (((rb_node_iasgn_t *)(node))->nd_value), 0))))) {((void)0);return 0;};
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_dup, 0));
        }
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_setinstancevariable, 2, (VALUE)(rb_id2sym(((rb_node_iasgn_t *)(node))->nd_vid)), (VALUE)(get_ivar_ic_value(iseq,((rb_node_iasgn_t *)(node))->nd_vid))));
        break;
      }
      case NODE_CDECL:{
        if (((rb_node_cdecl_t *)(node))->nd_vid) {
            if (!(compile_shareable_constant_value(iseq, ret, ((rb_node_cdecl_t *)(node))->shareability, node, ((rb_node_cdecl_t *)(node))->nd_value))) {((void)0);return 0;};
            if (!popped) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_dup, 0));
            }
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_CONST_BASE), ((VALUE)(VM_SPECIAL_OBJECT_CONST_BASE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_CONST_BASE)))));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_setconstant, 1, (VALUE)(rb_id2sym(((rb_node_cdecl_t *)(node))->nd_vid))));
        }
        else {
            compile_cpath(ret, iseq, ((rb_node_cdecl_t *)(node))->nd_else);
            if (!(compile_shareable_constant_value(iseq, ret, ((rb_node_cdecl_t *)(node))->shareability, node, ((rb_node_cdecl_t *)(node))->nd_value))) {((void)0);return 0;};
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_swap, 0));
            if (!popped) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_swap, 0));
            }
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_setconstant, 1, (VALUE)(rb_id2sym(get_node_colon_nd_mid(((rb_node_cdecl_t *)(node))->nd_else)))));
        }
        break;
      }
      case NODE_CVASGN:{
        if (!(((iseq_compile_each(iseq, (ret), (((rb_node_cvasgn_t *)(node))->nd_value), 0))))) {((void)0);return 0;};
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_dup, 0));
        }
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_setclassvariable, 2, (VALUE)(rb_id2sym(((rb_node_cvasgn_t *)(node))->nd_vid)), (VALUE)(get_cvar_ic_value(iseq, ((rb_node_cvasgn_t *)(node))->nd_vid))));
        break;
      }
      case NODE_OP_ASGN1:
        if (!(compile_op_asgn1(iseq, ret, node, popped))) {((void)0);return 0;};
        break;
      case NODE_OP_ASGN2:
        if (!(compile_op_asgn2(iseq, ret, node, popped))) {((void)0);return 0;};
        break;
      case NODE_OP_CDECL:
        if (!(compile_op_cdecl(iseq, ret, node, popped))) {((void)0);return 0;};
        break;
      case NODE_OP_ASGN_AND:
      case NODE_OP_ASGN_OR:
        if (!(compile_op_log(iseq, ret, node, popped, type))) {((void)0);return 0;};
        break;
      case NODE_CALL:
      case NODE_OPCALL:
        if (compile_call_precheck_freeze(iseq, ret, node, node, popped) == 1) {
            break;
        }
      case NODE_QCALL:
      case NODE_FCALL:
      case NODE_VCALL:
        if (compile_call(iseq, ret, node, type, node, popped, 0) == 0) {
            goto ng;
        }
        break;
      case NODE_SUPER:
      case NODE_ZSUPER:
        if (!(compile_super(iseq, ret, node, popped, type))) {((void)0);return 0;};
        break;
      case NODE_LIST:{
        if (!(compile_array(iseq, ret, node, popped, 1) >= 0)) {((void)0);return 0;};
        break;
      }
      case NODE_ZLIST:{
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_newarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))));
        }
        break;
      }
      case NODE_HASH:
        if (!(compile_hash(iseq, ret, node, 0, popped) >= 0)) {((void)0);return 0;};
        break;
      case NODE_RETURN:
        if (!(compile_return(iseq, ret, node, popped))) {((void)0);return 0;};
        break;
      case NODE_YIELD:
        if (!(compile_yield(iseq, ret, node, popped))) {((void)0);return 0;};
        break;
      case NODE_LVAR:{
        if (!popped) {
            compile_lvar(iseq, ret, node, ((rb_node_lvar_t *)(node))->nd_vid);
        }
        break;
      }
      case NODE_DVAR:{
        int lv, idx, ls;
        ((void)0);
        if (!popped) {
            idx = get_dyna_var_idx(iseq, ((rb_node_dvar_t *)(node))->nd_vid, &lv, &ls);
            if (idx < 0) {
                append_compile_error(iseq, (int)(((long)(node)->flags)>>(8 +7)), "unknown dvar (%""l""i" "\v"")",
                              rb_id2str(((rb_node_dvar_t *)(node))->nd_vid));
                goto ng;
            }
            iseq_add_getlocal(iseq, (ret), (node), (ls - idx), (lv));
        }
        break;
      }
      case NODE_GVAR:{
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_getglobal, 1, (VALUE)(rb_id2sym(((rb_node_gvar_t *)(node))->nd_vid))));
        if (popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pop, 0));
        }
        break;
      }
      case NODE_IVAR:{
        ((void)0);
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_getinstancevariable, 2, (VALUE)(rb_id2sym(((rb_node_ivar_t *)(node))->nd_vid)), (VALUE)(get_ivar_ic_value(iseq, ((rb_node_ivar_t *)(node))->nd_vid))));
        }
        break;
      }
      case NODE_CONST:{
        ((void)0);
        if (ISEQ_COMPILE_DATA(iseq)->option->inline_const_cache) {
            body->ic_size++;
            VALUE segments = __extension__ ({ const VALUE args_to_new_ary[] = {rb_id2sym(((rb_node_const_t *)(node))->nd_vid)}; if (__builtin_constant_p(1)) { __extension__ _Static_assert(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))) == (1), "rb_ary_new_from_args" ": " "numberof(args_to_new_ary) == (1)"); } rb_ary_new_from_values(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))), args_to_new_ary); });
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_opt_getconstant_path, 1, (VALUE)(segments)));
            (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(segments), "compile.c", 10911));
        }
        else {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putnil, 0));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qtrue))));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_getconstant, 1, (VALUE)(rb_id2sym(((rb_node_const_t *)(node))->nd_vid))));
        }
        if (popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pop, 0));
        }
        break;
      }
      case NODE_CVAR:{
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_getclassvariable, 2, (VALUE)(rb_id2sym(((rb_node_cvar_t *)(node))->nd_vid)), (VALUE)(get_cvar_ic_value(iseq, ((rb_node_cvar_t *)(node))->nd_vid))));
        }
        break;
      }
      case NODE_NTH_REF:{
        if (!popped) {
            if (!((rb_node_nth_ref_t *)(node))->nd_nth) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putnil, 0));
                break;
            }
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_getspecial, 2, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1))), (VALUE)(__builtin_choose_expr( __builtin_constant_p(((rb_node_nth_ref_t *)(node))->nd_nth << 1), ((VALUE)(((rb_node_nth_ref_t *)(node))->nd_nth << 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(((rb_node_nth_ref_t *)(node))->nd_nth << 1)))));
        }
        break;
      }
      case NODE_BACK_REF:{
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_getspecial, 2, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1))), (VALUE)(__builtin_choose_expr( __builtin_constant_p(0x01 | (((rb_node_back_ref_t *)(node))->nd_nth << 1)), ((VALUE)(0x01 | (((rb_node_back_ref_t *)(node))->nd_nth << 1))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0x01 | (((rb_node_back_ref_t *)(node))->nd_nth << 1))))));
        }
        break;
      }
      case NODE_MATCH:
      case NODE_MATCH2:
      case NODE_MATCH3:
        if (!(compile_match(iseq, ret, node, popped, type))) {((void)0);return 0;};
        break;
      case NODE_SYM:{
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putobject, 1, (VALUE)(rb_node_sym_string_val(node))));
        }
        break;
      }
      case NODE_LINE:{
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putobject, 1, (VALUE)(rb_node_line_lineno_val(node))));
        }
        break;
      }
      case NODE_ENCODING:{
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putobject, 1, (VALUE)(rb_node_encoding_val(node))));
        }
        break;
      }
      case NODE_INTEGER:{
        VALUE lit = rb_node_integer_literal_val(node);
        ((void)0);
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putobject, 1, (VALUE)(lit)));
            (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(lit), "compile.c", 10978));
        }
        break;
      }
      case NODE_FLOAT:{
        VALUE lit = rb_node_float_literal_val(node);
        ((void)0);
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putobject, 1, (VALUE)(lit)));
            (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(lit), "compile.c", 10987));
        }
        break;
      }
      case NODE_RATIONAL:{
        VALUE lit = rb_node_rational_literal_val(node);
        ((void)0);
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putobject, 1, (VALUE)(lit)));
            (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(lit), "compile.c", 10996));
        }
        break;
      }
      case NODE_IMAGINARY:{
        VALUE lit = rb_node_imaginary_literal_val(node);
        ((void)0);
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putobject, 1, (VALUE)(lit)));
            (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(lit), "compile.c", 11005));
        }
        break;
      }
      case NODE_FILE:
      case NODE_STR:{
        ((void)0);
        if (!popped) {
            VALUE lit = get_string_value(node);
            const rb_compile_option_t *option = ISEQ_COMPILE_DATA(iseq)->option;
            if ((option->debug_frozen_string_literal || RB_TEST((*rb_ruby_debug_ptr()))) &&
                option->frozen_string_literal != 0) {
                lit = rb_str_with_debug_created_info(lit, rb_iseq_path(iseq), line);
            }
            switch (option->frozen_string_literal) {
              case -1:
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putchilledstring, 1, (VALUE)(lit)));
                break;
              case 0:
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putstring, 1, (VALUE)(lit)));
                break;
              case 1:
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putobject, 1, (VALUE)(lit)));
                break;
              default:
                rb_bug("invalid frozen_string_literal");
            }
            (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(lit), "compile.c", 11032));
        }
        break;
      }
      case NODE_DSTR:{
        compile_dstr(iseq, ret, node);
        if (popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pop, 0));
        }
        break;
      }
      case NODE_XSTR:{
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)((node))->flags)>>(8 +7)), (((NODE *)((node)))->node_id), YARVINSN_putself, 0));
        VALUE str = rb_node_str_string_val(node);
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putobject, 1, (VALUE)(str)));
        (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(str), "compile.c", 11048));
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((node))->flags)>>(8 +7)), (((NODE *)((node)))->node_id), ((idBackquote)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p((0x01 << VM_CALL_FCALL_bit)), ((VALUE)((0x01 << VM_CALL_FCALL_bit))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((0x01 << VM_CALL_FCALL_bit)))), (((void *)0))));
        if (popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pop, 0));
        }
        break;
      }
      case NODE_DXSTR:{
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)((node))->flags)>>(8 +7)), (((NODE *)((node)))->node_id), YARVINSN_putself, 0));
        compile_dstr(iseq, ret, node);
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((node))->flags)>>(8 +7)), (((NODE *)((node)))->node_id), ((idBackquote)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p((0x01 << VM_CALL_FCALL_bit)), ((VALUE)((0x01 << VM_CALL_FCALL_bit))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((0x01 << VM_CALL_FCALL_bit)))), (((void *)0))));
        if (popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pop, 0));
        }
        break;
      }
      case NODE_EVSTR:
        if (!(compile_evstr(iseq, ret, ((rb_node_evstr_t *)(node))->nd_body, popped))) {((void)0);return 0;};
        break;
      case NODE_REGX:{
        if (!popped) {
            VALUE lit = rb_node_regx_string_val(node);
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putobject, 1, (VALUE)(lit)));
            (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(lit), "compile.c", 11073));
        }
        break;
      }
      case NODE_DREGX:
        compile_dregx(iseq, ret, node, popped);
        break;
      case NODE_ONCE:{
        int ic_index = body->ise_size++;
        const rb_iseq_t *block_iseq;
        block_iseq = new_child_iseq(iseq, (((rb_node_once_t *)(node))->nd_body), rb_fstring(make_name_for_block(iseq)), iseq, (ISEQ_TYPE_PLAIN), (line));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_once, 2, (VALUE)(block_iseq), (VALUE)(__builtin_choose_expr( __builtin_constant_p(ic_index), ((VALUE)(ic_index)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(ic_index)))));
        (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)((VALUE)block_iseq), "compile.c", 11086));
        if (popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pop, 0));
        }
        break;
      }
      case NODE_ARGSCAT:{
        if (popped) {
            if (!(((iseq_compile_each(iseq, (ret), (((rb_node_argscat_t *)(node))->nd_head), 0))))) {((void)0);return 0;};
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_splatarray, 1, (VALUE)(((VALUE)RUBY_Qfalse))));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pop, 0));
            if (!(((iseq_compile_each(iseq, (ret), (((rb_node_argscat_t *)(node))->nd_body), 0))))) {((void)0);return 0;};
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_splatarray, 1, (VALUE)(((VALUE)RUBY_Qfalse))));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pop, 0));
        }
        else {
            if (!(((iseq_compile_each(iseq, (ret), (((rb_node_argscat_t *)(node))->nd_head), 0))))) {((void)0);return 0;};
            const NODE *body_node = ((rb_node_argscat_t *)(node))->nd_body;
            if (nd_type_p(body_node, NODE_LIST)) {
                if (!(compile_array(iseq, ret, body_node, popped, 0) >= 0)) {((void)0);return 0;};
            }
            else {
                if (!(((iseq_compile_each(iseq, (ret), (body_node), 0))))) {((void)0);return 0;};
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_concattoarray, 0));
            }
        }
        break;
      }
      case NODE_ARGSPUSH:{
        if (popped) {
            if (!(((iseq_compile_each(iseq, (ret), (((rb_node_argspush_t *)(node))->nd_head), 0))))) {((void)0);return 0;};
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_splatarray, 1, (VALUE)(((VALUE)RUBY_Qfalse))));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pop, 0));
            if (!(((iseq_compile_each(iseq, (ret), (((rb_node_argspush_t *)(node))->nd_body), (popped)))))) {((void)0);return 0;};
        }
        else {
            if (!(((iseq_compile_each(iseq, (ret), (((rb_node_argspush_t *)(node))->nd_head), 0))))) {((void)0);return 0;};
            const NODE *body_node = ((rb_node_argspush_t *)(node))->nd_body;
            if (keyword_node_p(body_node)) {
                if (!(((iseq_compile_each(iseq, (ret), (body_node), (0)))))) {((void)0);return 0;};
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pushtoarraykwsplat, 0));
            }
            else if (static_literal_node_p(body_node, iseq, 0)) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(body_node)->flags)>>(8 +7)), (((NODE *)(body_node))->node_id), YARVINSN_putobject, 1, (VALUE)(static_literal_value(body_node, iseq))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pushtoarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
            }
            else {
                if (!(((iseq_compile_each(iseq, (ret), (body_node), (0)))))) {((void)0);return 0;};
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pushtoarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
            }
        }
        break;
      }
      case NODE_SPLAT:{
        if (!(((iseq_compile_each(iseq, (ret), (((rb_node_splat_t *)(node))->nd_head), 0))))) {((void)0);return 0;};
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_splatarray, 1, (VALUE)(((VALUE)RUBY_Qtrue))));
        if (popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pop, 0));
        }
        break;
      }
      case NODE_DEFN:{
        ID mid = ((rb_node_defn_t *)(node))->nd_mid;
        const rb_iseq_t *method_iseq = new_child_iseq(iseq, (((rb_node_defn_t *)(node))->nd_defn), rb_fstring(rb_id2str(mid)), 0, (ISEQ_TYPE_METHOD), (line));
        ((void)0);
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_definemethod, 2, (VALUE)(rb_id2sym(mid)), (VALUE)(method_iseq)));
        (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)((VALUE)method_iseq), "compile.c", 11157));
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putobject, 1, (VALUE)(rb_id2sym(mid))));
        }
        break;
      }
      case NODE_DEFS:{
        ID mid = ((rb_node_defs_t *)(node))->nd_mid;
        const rb_iseq_t * singleton_method_iseq = new_child_iseq(iseq, (((rb_node_defs_t *)(node))->nd_defn), rb_fstring(rb_id2str(mid)), 0, (ISEQ_TYPE_METHOD), (line));
        ((void)0);
        if (!(((iseq_compile_each(iseq, (ret), (((rb_node_defs_t *)(node))->nd_recv), 0))))) {((void)0);return 0;};
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_definesmethod, 2, (VALUE)(rb_id2sym(mid)), (VALUE)(singleton_method_iseq)));
        (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)((VALUE)singleton_method_iseq), "compile.c", 11174));
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putobject, 1, (VALUE)(rb_id2sym(mid))));
        }
        break;
      }
      case NODE_ALIAS:{
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_CBASE), ((VALUE)(VM_SPECIAL_OBJECT_CBASE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_CBASE)))));
        if (!(((iseq_compile_each(iseq, (ret), (((rb_node_alias_t *)(node))->nd_1st), 0))))) {((void)0);return 0;};
        if (!(((iseq_compile_each(iseq, (ret), (((rb_node_alias_t *)(node))->nd_2nd), 0))))) {((void)0);return 0;};
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((node))->flags)>>(8 +7)), (((NODE *)((node)))->node_id), ((id_core_set_method_alias)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
        if (popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pop, 0));
        }
        break;
      }
      case NODE_VALIAS:{
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putobject, 1, (VALUE)(rb_id2sym(((rb_node_valias_t *)(node))->nd_alias))));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putobject, 1, (VALUE)(rb_id2sym(((rb_node_valias_t *)(node))->nd_orig))));
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((node))->flags)>>(8 +7)), (((NODE *)((node)))->node_id), ((id_core_set_variable_alias)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
        if (popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pop, 0));
        }
        break;
      }
      case NODE_UNDEF:{
        const rb_parser_ary_t *ary = ((rb_node_undef_t *)(node))->nd_undefs;
        for (long i = 0; i < ary->len; i++) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_CBASE), ((VALUE)(VM_SPECIAL_OBJECT_CBASE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_CBASE)))));
            if (!(((iseq_compile_each(iseq, (ret), (ary->data[i]), 0))))) {((void)0);return 0;};
            ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((node))->flags)>>(8 +7)), (((NODE *)((node)))->node_id), ((id_core_undef_method)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
            if (i < ary->len - 1) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pop, 0));
            }
        }
        if (popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pop, 0));
        }
        break;
      }
      case NODE_CLASS:{
        const rb_iseq_t *class_iseq = new_child_iseq(iseq, (((rb_node_class_t *)(node))->nd_body), rb_fstring(rb_str_freeze(rb_sprintf("<class:%""l""i" "\v"">", rb_id2str(get_node_colon_nd_mid(((rb_node_class_t *)(node))->nd_cpath))))), iseq, (ISEQ_TYPE_CLASS), (line));
        const int flags = VM_DEFINECLASS_TYPE_CLASS |
            (((rb_node_class_t *)(node))->nd_super ? 0x10 : 0) |
            compile_cpath(ret, iseq, ((rb_node_class_t *)(node))->nd_cpath);
        if (!(((iseq_compile_each(iseq, (ret), (((rb_node_class_t *)(node))->nd_super), 0))))) {((void)0);return 0;};
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_defineclass, 3, (VALUE)(rb_id2sym(get_node_colon_nd_mid(((rb_node_class_t *)(node))->nd_cpath))), (VALUE)(class_iseq), (VALUE)(__builtin_choose_expr( __builtin_constant_p(flags), ((VALUE)(flags)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(flags)))));
        (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)((VALUE)class_iseq), "compile.c", 11233));
        if (popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pop, 0));
        }
        break;
      }
      case NODE_MODULE:{
        const rb_iseq_t *module_iseq = new_child_iseq(iseq, (((rb_node_module_t *)(node))->nd_body), rb_fstring(rb_str_freeze(rb_sprintf("<module:%""l""i" "\v"">", rb_id2str(get_node_colon_nd_mid(((rb_node_module_t *)(node))->nd_cpath))))), iseq, (ISEQ_TYPE_CLASS), (line));
        const int flags = VM_DEFINECLASS_TYPE_MODULE |
            compile_cpath(ret, iseq, ((rb_node_module_t *)(node))->nd_cpath);
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putnil, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_defineclass, 3, (VALUE)(rb_id2sym(get_node_colon_nd_mid(((rb_node_module_t *)(node))->nd_cpath))), (VALUE)(module_iseq), (VALUE)(__builtin_choose_expr( __builtin_constant_p(flags), ((VALUE)(flags)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(flags)))));
        (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)((VALUE)module_iseq), "compile.c", 11249));
        if (popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pop, 0));
        }
        break;
      }
      case NODE_SCLASS:{
        ID singletonclass;
        const rb_iseq_t *singleton_class = new_child_iseq(iseq, (((rb_node_sclass_t *)(node))->nd_body), rb_fstring(rb_fstring_new(("singleton class"), ((sizeof("singleton class" "") / sizeof("singleton class" ""[0])) - 1))), 0, (ISEQ_TYPE_CLASS), (line));
        if (!(((iseq_compile_each(iseq, (ret), (((rb_node_sclass_t *)(node))->nd_recv), 0))))) {((void)0);return 0;};
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putnil, 0));
        do { static ID rbimpl_id; (singletonclass) = rbimpl_intern_const(&rbimpl_id, ("singletonclass")); } while (0);
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_defineclass, 3, (VALUE)(rb_id2sym(singletonclass)), (VALUE)(singleton_class), (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_DEFINECLASS_TYPE_SINGLETON_CLASS), ((VALUE)(VM_DEFINECLASS_TYPE_SINGLETON_CLASS)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_DEFINECLASS_TYPE_SINGLETON_CLASS)))));
        (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)((VALUE)singleton_class), "compile.c", 11267));
        if (popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pop, 0));
        }
        break;
      }
      case NODE_COLON2:
        if (!(compile_colon2(iseq, ret, node, popped))) {((void)0);return 0;};
        break;
      case NODE_COLON3:
        if (!(compile_colon3(iseq, ret, node, popped))) {((void)0);return 0;};
        break;
      case NODE_DOT2:
        if (!(compile_dots(iseq, ret, node, popped, 0))) {((void)0);return 0;};
        break;
      case NODE_DOT3:
        if (!(compile_dots(iseq, ret, node, popped, 1))) {((void)0);return 0;};
        break;
      case NODE_FLIP2:
      case NODE_FLIP3:{
        LABEL *lend = new_label_body(iseq, (line));
        LABEL *ltrue = new_label_body(iseq, (line));
        LABEL *lfalse = new_label_body(iseq, (line));
        if (!(compile_flip_flop(iseq, ret, node, type == NODE_FLIP2, ltrue, lfalse))) {((void)0);return 0;};
        ADD_ELEM((ret), (LINK_ELEMENT *) (ltrue));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qtrue))));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_jump, 1, (VALUE)(lend))), ((lend)->refcnt++));
        ADD_ELEM((ret), (LINK_ELEMENT *) (lfalse));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qfalse))));
        ADD_ELEM((ret), (LINK_ELEMENT *) (lend));
        break;
      }
      case NODE_SELF:{
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putself, 0));
        }
        break;
      }
      case NODE_NIL:{
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putnil, 0));
        }
        break;
      }
      case NODE_TRUE:{
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qtrue))));
        }
        break;
      }
      case NODE_FALSE:{
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qfalse))));
        }
        break;
      }
      case NODE_ERRINFO:
        if (!(compile_errinfo(iseq, ret, node, popped))) {((void)0);return 0;};
        break;
      case NODE_DEFINED:
        if (!popped) {
            if (!(compile_defined_expr(iseq, ret, node, ((VALUE)RUBY_Qtrue), 0))) {((void)0);return 0;};
        }
        break;
      case NODE_POSTEXE:{
        int is_index = body->ise_size++;
        struct rb_iseq_new_with_callback_callback_func *ifunc =
            rb_iseq_new_with_callback_new_callback(build_postexe_iseq, ((rb_node_postexe_t *)(node))->nd_body);
        const rb_iseq_t *once_iseq =
            new_child_iseq_with_callback(iseq, ifunc,
                                 rb_fstring(make_name_for_block(iseq)), iseq, ISEQ_TYPE_BLOCK, line);
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_once, 2, (VALUE)(once_iseq), (VALUE)(__builtin_choose_expr( __builtin_constant_p(is_index), ((VALUE)(is_index)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(is_index)))));
        (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)((VALUE)once_iseq), "compile.c", 11345));
        if (popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pop, 0));
        }
        break;
      }
      case NODE_KW_ARG:
        if (!(compile_kw_arg(iseq, ret, node, popped))) {((void)0);return 0;};
        break;
      case NODE_DSYM:{
        compile_dstr(iseq, ret, node);
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_intern, 0));
        }
        else {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pop, 0));
        }
        break;
      }
      case NODE_ATTRASGN:
        if (!(compile_attrasgn(iseq, ret, node, popped))) {((void)0);return 0;};
        break;
      case NODE_LAMBDA:{
        const rb_iseq_t *block = new_child_iseq(iseq, (((rb_node_lambda_t *)(node))->nd_body), rb_fstring(make_name_for_block(iseq)), iseq, (ISEQ_TYPE_BLOCK), (line));
        VALUE argc = __builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int)(((long)((node))->flags)>>(8 +7)), (((NODE *)((node)))->node_id), ((idLambda)), (VALUE)((argc)), ((block)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p((0x01 << VM_CALL_FCALL_bit)), ((VALUE)((0x01 << VM_CALL_FCALL_bit))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((0x01 << VM_CALL_FCALL_bit)))), (((void *)0))));
        (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)((VALUE)block), "compile.c", 11375));
        if (popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int)(((long)(node)->flags)>>(8 +7)), (((NODE *)(node))->node_id), YARVINSN_pop, 0));
        }
        break;
      }
      default:
        do { const NODE *error_node = (node); append_compile_error(iseq, (int)(((long)(error_node)->flags)>>(8 +7)), "iseq_compile_each" ": unknown node (%s)", ruby_node_name(((int) ((((NODE *)(error_node))->flags & (((VALUE)0x7f)<<8))>>8)))); return 0; } while (0);
      ng:
        ((void)0);
        return 0;
    }
    ((void)0);
    return 1;
}
static int
insn_data_length(INSN *iobj)
{
    return insn_len(iobj->insn_id);
}
static int
calc_sp_depth(int depth, INSN *insn)
{
    return comptime_insn_stack_increase(depth, insn->insn_id, insn->operands);
}
static VALUE
opobj_inspect(VALUE obj)
{
    if (!RB_SPECIAL_CONST_P(obj) && !RBASIC_CLASS(obj)) {
        switch (RB_BUILTIN_TYPE(obj)) {
          case RUBY_T_STRING:
            obj = ((__builtin_constant_p(RSTRING_PTR(obj)) ? rbimpl_str_new_cstr : rb_str_new_cstr) (RSTRING_PTR(obj)));
            break;
          case RUBY_T_ARRAY:
            obj = rb_ary_dup(obj);
            break;
          default:
            break;
        }
    }
    return rb_inspect(obj);
}
static VALUE
insn_data_to_s_detail(INSN *iobj)
{
    VALUE str = rb_sprintf("%-20s ", insn_name(iobj->insn_id));
    if (iobj->operands) {
        const char *types = insn_op_types(iobj->insn_id);
        int j;
        for (j = 0; types[j]; j++) {
            char type = types[j];
            switch (type) {
              case TS_OFFSET:
                {
                    LABEL *lobj = (LABEL *)(((INSN*)(iobj))->operands[(j)]);
                    rb_str_catf(str, "<L%03d>", lobj->label_no);
                    break;
                }
                break;
              case TS_ISEQ:
                {
                    rb_iseq_t *iseq = (rb_iseq_t *)(((INSN*)(iobj))->operands[(j)]);
                    VALUE val = ((VALUE)RUBY_Qnil);
                    if (0 && iseq) {
                        val = (VALUE)iseq;
                    }
                    rb_str_concat(str, opobj_inspect(val));
                }
                break;
              case TS_LINDEX:
              case TS_NUM:
              case TS_VALUE:
                {
                    VALUE v = (((INSN*)(iobj))->operands[(j)]);
                    if (!rb_class_of(v))
                        ((__builtin_constant_p("<hidden>") ? rbimpl_str_cat_cstr : rb_str_cat_cstr) ((str), ("<hidden>")));
                    else {
                        rb_str_concat(str, opobj_inspect(v));
                    }
                    break;
                }
              case TS_ID:
                rb_str_concat(str, opobj_inspect((((INSN*)(iobj))->operands[(j)])));
                break;
              case TS_IC:
                rb_str_concat(str, opobj_inspect((((INSN*)(iobj))->operands[(j)])));
                break;
              case TS_IVC:
                rb_str_catf(str, "<ivc:%d>", RB_FIX2INT((((INSN*)(iobj))->operands[(j)])));
                break;
              case TS_ICVARC:
                rb_str_catf(str, "<icvarc:%d>", RB_FIX2INT((((INSN*)(iobj))->operands[(j)])));
                break;
              case TS_ISE:
                rb_str_catf(str, "<ise:%d>", RB_FIX2INT((((INSN*)(iobj))->operands[(j)])));
                break;
              case TS_CALLDATA:
                {
                    const struct rb_callinfo *ci = (struct rb_callinfo *)(((INSN*)(iobj))->operands[(j)]);
                    ((__builtin_constant_p("<calldata:") ? rbimpl_str_cat_cstr : rb_str_cat_cstr) ((str), ("<calldata:")));
                    if (vm_ci_mid(ci)) rb_str_catf(str, "%""l""i" "\v", rb_id2str(vm_ci_mid(ci)));
                    rb_str_catf(str, ", %d>", vm_ci_argc(ci));
                    break;
                }
              case TS_CDHASH:
                ((__builtin_constant_p("<ch>") ? rbimpl_str_cat_cstr : rb_str_cat_cstr) ((str), ("<ch>")));
                break;
              case TS_FUNCPTR:
                {
                    void *func = (void *)(((INSN*)(iobj))->operands[(j)]);
                    Dl_info info;
                    if (dladdr(func, &info) && info.dli_sname) {
                        ((__builtin_constant_p(info.dli_sname) ? rbimpl_str_cat_cstr : rb_str_cat_cstr) ((str), (info.dli_sname)));
                        break;
                    }
                    rb_str_catf(str, "<%p>", func);
                }
                break;
              case TS_BUILTIN:
                ((__builtin_constant_p("<TS_BUILTIN>") ? rbimpl_str_cat_cstr : rb_str_cat_cstr) ((str), ("<TS_BUILTIN>")));
                break;
              default:{
                rb_raise(rb_eSyntaxError, "unknown operand type: %c", type);
              }
            }
            if (types[j + 1]) {
                ((__builtin_constant_p(", ") ? rbimpl_str_cat_cstr : rb_str_cat_cstr) ((str), (", ")));
            }
        }
    }
    return str;
}
static void
dump_disasm_list(const LINK_ELEMENT *link)
{
    dump_disasm_list_with_cursor(link, ((void *)0), ((void *)0));
}
static void
dump_disasm_list_with_cursor(const LINK_ELEMENT *link, const LINK_ELEMENT *curr, const LABEL *dest)
{
    int pos = 0;
    INSN *iobj;
    LABEL *lobj;
    VALUE str;
    printf("-- raw disasm--------\n");
    while (link) {
        if (curr) printf(curr == link ? "*" : " ");
        switch (link->type) {
          case ISEQ_ELEMENT_INSN:
            {
                iobj = (INSN *)link;
                str = insn_data_to_s_detail(iobj);
                printf("  %04d %-65s(%4u)\n", pos, rb_string_value_cstr(&(str)), iobj->insn_info.line_no);
                pos += insn_data_length(iobj);
                break;
            }
          case ISEQ_ELEMENT_LABEL:
            {
                lobj = (LABEL *)link;
                printf("<L%03d>"" [sp: %d, unremovable: %d, refcnt: %d]%s\n", lobj->label_no, lobj->sp, lobj->unremovable, lobj->refcnt,
                       dest == lobj ? " <---" : "");
                break;
            }
          case ISEQ_ELEMENT_TRACE:
            {
                TRACE *trace = (TRACE *)link;
                printf("  trace: %0x\n", trace->event);
                break;
            }
          case ISEQ_ELEMENT_ADJUST:
            {
                ADJUST *adjust = (ADJUST *)link;
                printf("  adjust: [label: %d]\n", adjust->label ? adjust->label->label_no : -1);
                break;
            }
          default:
            rb_raise(rb_eSyntaxError, "dump_disasm_list error: %d\n", (int)link->type);
        }
        link = link->next;
    }
    printf("---------------------\n");
    fflush(stdout);
}
int
rb_insn_len(VALUE insn)
{
    return insn_len(insn);
}
const char *
rb_insns_name(int i)
{
    return insn_name(i);
}
VALUE
rb_insns_name_array(void)
{
    VALUE ary = rb_ary_new_capa(VM_INSTRUCTION_SIZE);
    int i;
    for (i = 0; i < VM_INSTRUCTION_SIZE; i++) {
        rb_ary_push(ary, (__builtin_constant_p(insn_name(i)) ? rb_fstring_new((insn_name(i)), (long)strlen(insn_name(i))) : (rb_fstring_cstr)(insn_name(i))));
    }
    return rb_ary_freeze(ary);
}
static LABEL *
register_label(rb_iseq_t *iseq, struct st_table *labels_table, VALUE obj)
{
    LABEL *label = 0;
    st_data_t tmp;
    obj = rb_to_symbol_type(obj);
    if (rb_st_lookup(labels_table, obj, &tmp) == 0) {
        label = new_label_body(iseq, (0));
        rb_st_insert(labels_table, obj, (st_data_t)label);
    }
    else {
        label = (LABEL *)tmp;
    }
    ((label)->refcnt++);
    return label;
}
static VALUE
get_exception_sym2type(VALUE sym)
{
    static VALUE symRescue, symEnsure, symRetry;
    static VALUE symBreak, symRedo, symNext;
    if (symRescue == 0) {
        symRescue = rb_id2sym(rb_intern_const("rescue"));
        symEnsure = rb_id2sym(rb_intern_const("ensure"));
        symRetry = rb_id2sym(rb_intern_const("retry"));
        symBreak = rb_id2sym(rb_intern_const("break"));
        symRedo = rb_id2sym(rb_intern_const("redo"));
        symNext = rb_id2sym(rb_intern_const("next"));
    }
    if (sym == symRescue) return CATCH_TYPE_RESCUE;
    if (sym == symEnsure) return CATCH_TYPE_ENSURE;
    if (sym == symRetry) return CATCH_TYPE_RETRY;
    if (sym == symBreak) return CATCH_TYPE_BREAK;
    if (sym == symRedo) return CATCH_TYPE_REDO;
    if (sym == symNext) return CATCH_TYPE_NEXT;
    rb_raise(rb_eSyntaxError, "invalid exception symbol: %+""l""i" "\v", sym);
    return 0;
}
static int
iseq_build_from_ary_exception(rb_iseq_t *iseq, struct st_table *labels_table,
                     VALUE exception)
{
    int i;
    for (i=0; i<rb_array_len(exception); i++) {
        const rb_iseq_t *eiseq;
        VALUE v, type;
        LABEL *lstart, *lend, *lcont;
        unsigned int sp;
        v = rb_to_array_type(RARRAY_AREF(exception, i));
        if (rb_array_len(v) != 6) {
            rb_raise(rb_eSyntaxError, "wrong exception entry");
        }
        type = get_exception_sym2type(RARRAY_AREF(v, 0));
        if (RB_NIL_P(RARRAY_AREF(v, 1))) {
            eiseq = ((void *)0);
        }
        else {
            eiseq = rb_iseqw_to_iseq(rb_iseq_load(RARRAY_AREF(v, 1), (VALUE)iseq, ((VALUE)RUBY_Qnil)));
        }
        lstart = register_label(iseq, labels_table, RARRAY_AREF(v, 2));
        lend = register_label(iseq, labels_table, RARRAY_AREF(v, 3));
        lcont = register_label(iseq, labels_table, RARRAY_AREF(v, 4));
        sp = RB_NUM2UINT(RARRAY_AREF(v, 5));
        if (type == CATCH_TYPE_RESCUE ||
            type == CATCH_TYPE_BREAK ||
            type == CATCH_TYPE_NEXT) {
            ++sp;
        }
        lcont->sp = sp;
        do { VALUE _e = __extension__ ({ const VALUE args_to_new_ary[] = {(type), (VALUE)(lstart) | 1, (VALUE)(lend) | 1, (VALUE)(eiseq), (VALUE)(lcont) | 1}; if (__builtin_constant_p(5)) { __extension__ _Static_assert(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))) == (5), "rb_ary_new_from_args" ": " "numberof(args_to_new_ary) == (5)"); } rb_ary_new_from_values(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))), args_to_new_ary); }); ((lstart) ? (((lstart)->refcnt++), (lstart)->unremovable=1) : 0); ((lend)->refcnt++); ((lcont)->refcnt++); if (RB_NIL_P(ISEQ_COMPILE_DATA(iseq)->catch_table_ary)) (rb_obj_write((VALUE)(iseq), (VALUE *)(&ISEQ_COMPILE_DATA(iseq)->catch_table_ary), (VALUE)(rb_ary_hidden_new(3)), "compile.c", 11685)); rb_ary_push(ISEQ_COMPILE_DATA(iseq)->catch_table_ary, freeze_hide_obj(_e)); } while (0);
        (*__extension__ ({ volatile VALUE *rb_gc_guarded_ptr = &(v); __asm__("" : : "m"(rb_gc_guarded_ptr)); rb_gc_guarded_ptr; }));
    }
    return 1;
}
static struct st_table *
insn_make_insn_table(void)
{
    struct st_table *table;
    int i;
    table = rb_st_init_numtable_with_size(VM_INSTRUCTION_SIZE);
    for (i=0; i<VM_INSTRUCTION_SIZE; i++) {
        rb_st_insert(table, rb_id2sym(rb_intern_const(insn_name(i))), i);
    }
    return table;
}
static const rb_iseq_t *
iseq_build_load_iseq(const rb_iseq_t *iseq, VALUE op)
{
    VALUE iseqw;
    const rb_iseq_t *loaded_iseq;
    if (RB_TYPE_P(op, RUBY_T_ARRAY)) {
        iseqw = rb_iseq_load(op, (VALUE)iseq, ((VALUE)RUBY_Qnil));
    }
    else if (rb_class_of(op) == rb_cISeq) {
        iseqw = op;
    }
    else {
        rb_raise(rb_eSyntaxError, "ISEQ is required");
    }
    loaded_iseq = rb_iseqw_to_iseq(iseqw);
    return loaded_iseq;
}
static VALUE
iseq_build_callinfo_from_hash(rb_iseq_t *iseq, VALUE op)
{
    ID mid = 0;
    int orig_argc = 0;
    unsigned int flag = 0;
    struct rb_callinfo_kwarg *kw_arg = 0;
    if (!RB_NIL_P(op)) {
        VALUE vmid = rb_hash_aref(op, rb_id2sym(rb_intern_const("mid")));
        VALUE vflag = rb_hash_aref(op, rb_id2sym(rb_intern_const("flag")));
        VALUE vorig_argc = rb_hash_aref(op, rb_id2sym(rb_intern_const("orig_argc")));
        VALUE vkw_arg = rb_hash_aref(op, rb_id2sym(rb_intern_const("kw_arg")));
        if (!RB_NIL_P(vmid)) mid = rb_sym2id(vmid);
        if (!RB_NIL_P(vflag)) flag = RB_NUM2UINT(vflag);
        if (!RB_NIL_P(vorig_argc)) orig_argc = RB_FIX2INT(vorig_argc);
        if (!RB_NIL_P(vkw_arg)) {
            int i;
            int len = RARRAY_LENINT(vkw_arg);
            size_t n = rb_callinfo_kwarg_bytes(len);
            kw_arg = ruby_xmalloc(n);
            kw_arg->references = 0;
            kw_arg->keyword_len = len;
            for (i = 0; i < len; i++) {
                VALUE kw = RARRAY_AREF(vkw_arg, i);
                rb_sym2id(kw);
                kw_arg->keywords[i] = kw;
            }
        }
    }
    const struct rb_callinfo *ci = new_callinfo(iseq, mid, orig_argc, flag, kw_arg, (flag & (0x01 << VM_CALL_ARGS_SIMPLE_bit)) == 0);
    (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(ci), "compile.c", 11761));
    return (VALUE)ci;
}
static rb_event_flag_t
event_name_to_flag(VALUE sym)
{
                if (sym == rb_id2sym(rb_intern_const("RUBY_EVENT_LINE"))) return 0x0001;;
                if (sym == rb_id2sym(rb_intern_const("RUBY_EVENT_CLASS"))) return 0x0002;;
                if (sym == rb_id2sym(rb_intern_const("RUBY_EVENT_END"))) return 0x0004;;
                if (sym == rb_id2sym(rb_intern_const("RUBY_EVENT_CALL"))) return 0x0008;;
                if (sym == rb_id2sym(rb_intern_const("RUBY_EVENT_RETURN"))) return 0x0010;;
                if (sym == rb_id2sym(rb_intern_const("RUBY_EVENT_B_CALL"))) return 0x0100;;
                if (sym == rb_id2sym(rb_intern_const("RUBY_EVENT_B_RETURN"))) return 0x0200;;
                if (sym == rb_id2sym(rb_intern_const("RUBY_EVENT_RESCUE"))) return 0x4000;;
    return 0x0000;
}
static int
iseq_build_from_ary_body(rb_iseq_t *iseq, LINK_ANCHOR *const anchor,
                         VALUE body, VALUE node_ids, VALUE labels_wrapper)
{
    long i, len = rb_array_len(body);
    struct st_table *labels_table = (((struct RTypedData *)(labels_wrapper))->data);
    int j;
    int line_no = 0, node_id = -1, insn_idx = 0;
    int ret = 1;
    static struct st_table *insn_table;
    if (insn_table == 0) {
        insn_table = insn_make_insn_table();
    }
    for (i=0; i<len; i++) {
        VALUE obj = RARRAY_AREF(body, i);
        if (RB_SYMBOL_P(obj)) {
            rb_event_flag_t event;
            if ((event = event_name_to_flag(obj)) != 0x0000) {
                ADD_ELEM((anchor), (LINK_ELEMENT *)new_trace_body(iseq, (event), 0));
            }
            else {
                LABEL *label = register_label(iseq, labels_table, obj);
                ADD_ELEM((anchor), (LINK_ELEMENT *) (label));
            }
        }
        else if (RB_FIXNUM_P(obj)) {
            line_no = rb_num2int_inline(obj);
        }
        else if (RB_TYPE_P(obj, RUBY_T_ARRAY)) {
            VALUE *argv = 0;
            int argc = RARRAY_LENINT(obj) - 1;
            st_data_t insn_id;
            VALUE insn;
            if (node_ids) {
                node_id = rb_num2int_inline(rb_ary_entry(node_ids, insn_idx++));
            }
            insn = (argc < 0) ? ((VALUE)RUBY_Qnil) : RARRAY_AREF(obj, 0);
            if (rb_st_lookup(insn_table, (st_data_t)insn, &insn_id) == 0) {
                append_compile_error(iseq, line_no,
                              "unknown instruction: %+""l""i" "\v", insn);
                ret = 0;
                break;
            }
            if (argc != insn_len((VALUE)insn_id)-1) {
                append_compile_error(iseq, line_no,
                              "operand size mismatch");
                ret = 0;
                break;
            }
            if (argc > 0) {
                argv = compile_data_calloc2(iseq, sizeof(VALUE), argc);
                ADD_ELEM(anchor,
                         (LINK_ELEMENT*)new_insn_core(iseq, line_no, node_id,
                                                      (enum ruby_vminsn_type)insn_id, argc, argv));
                for (j=0; j<argc; j++) {
                    VALUE op = rb_ary_entry(obj, j+1);
                    switch (insn_op_type((VALUE)insn_id, j)) {
                      case TS_OFFSET: {
                        LABEL *label = register_label(iseq, labels_table, op);
                        argv[j] = (VALUE)label;
                        break;
                      }
                      case TS_LINDEX:
                      case TS_NUM:
                        (void)rb_num2int_inline(op);
                        argv[j] = op;
                        break;
                      case TS_VALUE:
                        argv[j] = op;
                        (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(op), "compile.c", 11866));
                        break;
                      case TS_ISEQ:
                        {
                            if (op != ((VALUE)RUBY_Qnil)) {
                                VALUE v = (VALUE)iseq_build_load_iseq(iseq, op);
                                argv[j] = v;
                                (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(v), "compile.c", 11873));
                            }
                            else {
                                argv[j] = 0;
                            }
                        }
                        break;
                      case TS_ISE:
                        argv[j] = op;
                        if (RB_NUM2UINT(op) >= ((iseq)->body)->ise_size) {
                            ((iseq)->body)->ise_size = rb_num2int_inline(op) + 1;
                        }
                        break;
                      case TS_IC:
                        {
                            VALUE segments = rb_ary_new();
                            op = rb_to_array_type(op);
                            for (int i = 0; i < rb_array_len(op); i++) {
                                VALUE sym = RARRAY_AREF(op, i);
                                sym = rb_to_symbol_type(sym);
                                rb_ary_push(segments, sym);
                            }
                            (*__extension__ ({ volatile VALUE *rb_gc_guarded_ptr = &(op); __asm__("" : : "m"(rb_gc_guarded_ptr)); rb_gc_guarded_ptr; }));
                            argv[j] = segments;
                            (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(segments), "compile.c", 11899));
                            ((iseq)->body)->ic_size++;
                        }
                        break;
                      case TS_IVC:
                        argv[j] = op;
                        if (RB_NUM2UINT(op) >= ((iseq)->body)->ivc_size) {
                            ((iseq)->body)->ivc_size = rb_num2int_inline(op) + 1;
                        }
                        break;
                      case TS_ICVARC:
                        argv[j] = op;
                        if (RB_NUM2UINT(op) >= ((iseq)->body)->icvarc_size) {
                            ((iseq)->body)->icvarc_size = rb_num2int_inline(op) + 1;
                        }
                        break;
                      case TS_CALLDATA:
                        argv[j] = iseq_build_callinfo_from_hash(iseq, op);
                        break;
                      case TS_ID:
                        argv[j] = rb_to_symbol_type(op);
                        break;
                      case TS_CDHASH:
                        {
                            int i;
                            VALUE map = rb_hash_new_with_size(rb_array_len(op)/2);
                            rb_hash_tbl_raw(map, "compile.c", 11926)->type = &cdhash_type;
                            op = rb_to_array_type(op);
                            for (i=0; i<rb_array_len(op); i+=2) {
                                VALUE key = RARRAY_AREF(op, i);
                                VALUE sym = RARRAY_AREF(op, i+1);
                                LABEL *label =
                                  register_label(iseq, labels_table, sym);
                                rb_hash_aset(map, key, (VALUE)label | 1);
                            }
                            (*__extension__ ({ volatile VALUE *rb_gc_guarded_ptr = &(op); __asm__("" : : "m"(rb_gc_guarded_ptr)); rb_gc_guarded_ptr; }));
                            argv[j] = map;
                            (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(map), "compile.c", 11937));
                        }
                        break;
                      case TS_FUNCPTR:
                        {
                            long funcptr = rb_num2long_inline(op);
                            argv[j] = (VALUE)funcptr;
                        }
                        break;
                      default:
                        rb_raise(rb_eSyntaxError, "unknown operand: %c", insn_op_type((VALUE)insn_id, j));
                    }
                }
            }
            else {
                ADD_ELEM(anchor,
                         (LINK_ELEMENT*)new_insn_core(iseq, line_no, node_id,
                                                      (enum ruby_vminsn_type)insn_id, argc, ((void *)0)));
            }
        }
        else {
            rb_raise(rb_eTypeError, "unexpected object for instruction");
        }
    }
    (((struct RTypedData *)(labels_wrapper))->data) = 0;
    (*__extension__ ({ volatile VALUE *rb_gc_guarded_ptr = &(labels_wrapper); __asm__("" : : "m"(rb_gc_guarded_ptr)); rb_gc_guarded_ptr; }));
    validate_labels(iseq, labels_table);
    if (!ret) return ret;
    return iseq_setup(iseq, anchor);
}
static int
int_param(int *dst, VALUE param, VALUE sym)
{
    VALUE val = rb_hash_aref(param, sym);
    if (RB_FIXNUM_P(val)) {
        *dst = RB_FIX2INT(val);
        return 1;
    }
    else if (!RB_NIL_P(val)) {
        rb_raise(rb_eTypeError, "invalid %+""l""i" "\v"" Fixnum: %+""l""i" "\v",
                 sym, val);
    }
    return 0;
}
static const struct rb_iseq_param_keyword *
iseq_build_kw(rb_iseq_t *iseq, VALUE params, VALUE keywords)
{
    int i, j;
    int len = RARRAY_LENINT(keywords);
    int default_len;
    VALUE key, sym, default_val;
    VALUE *dvs;
    ID *ids;
    struct rb_iseq_param_keyword *keyword = (((struct rb_iseq_param_keyword *)ruby_xcalloc((1), sizeof(struct rb_iseq_param_keyword))));
    ((iseq)->body)->param.flags.has_kw = 1;
    keyword->num = len;
    (void)int_param(&keyword->bits_start, params, rb_id2sym(rb_intern_const("kwbits")));
    i = keyword->bits_start - keyword->num;
    ids = (ID *)&((iseq)->body)->local_table[i];
    for (i = 0; i < len; i++) {
        VALUE val = RARRAY_AREF(keywords, i);
        if (!RB_SYMBOL_P(val)) {
            goto default_values;
        }
        ids[i] = rb_sym2id(val);
        keyword->required_num++;
    }
  default_values:
    default_len = len - i;
    if (default_len == 0) {
        keyword->table = ids;
        return keyword;
    }
    else if (default_len < 0) {
        __builtin_unreachable();
    }
    dvs = ((VALUE *)ruby_xmalloc2(((unsigned int)default_len), sizeof(VALUE)));
    for (j = 0; i < len; i++, j++) {
        key = RARRAY_AREF(keywords, i);
        rb_to_array_type(key);
        switch (rb_array_len(key)) {
          case 1:
            sym = RARRAY_AREF(key, 0);
            default_val = ((VALUE)RUBY_Qundef);
            break;
          case 2:
            sym = RARRAY_AREF(key, 0);
            default_val = RARRAY_AREF(key, 1);
            break;
          default:
            rb_raise(rb_eTypeError, "keyword default has unsupported len %+""l""i" "\v", key);
        }
        ids[i] = rb_sym2id(sym);
        (rb_obj_write((VALUE)(iseq), (VALUE *)(&dvs[j]), (VALUE)(default_val), "compile.c", 12050));
    }
    keyword->table = ids;
    keyword->default_values = dvs;
    return keyword;
}
static void
iseq_insn_each_object_mark_and_pin(VALUE obj, VALUE _)
{
    rb_gc_mark(obj);
}
void
rb_iseq_mark_and_pin_insn_storage(struct iseq_compile_data_storage *storage)
{
    INSN *iobj = 0;
    size_t size = sizeof(INSN);
    unsigned int pos = 0;
    while (storage) {
        const size_t padding = 0;
        size_t offset = pos + size + padding;
        if (offset > storage->size || offset > storage->pos) {
            pos = 0;
            storage = storage->next;
        }
        else {
            iobj = (INSN *)&storage->buff[pos];
            if (iobj->operands) {
                iseq_insn_each_markable_object(iobj, iseq_insn_each_object_mark_and_pin, (VALUE)0);
            }
            pos += (int)size;
        }
    }
}
static const rb_data_type_t labels_wrapper_type = {
    .wrap_struct_name = "compiler/labels_wrapper",
    .function = {
        .dmark = (RUBY_DATA_FUNC)rb_mark_set,
        .dfree = (RUBY_DATA_FUNC)rb_st_free_table,
    },
    .flags = RUBY_TYPED_FREE_IMMEDIATELY | RUBY_TYPED_WB_PROTECTED,
};
void
rb_iseq_build_from_ary(rb_iseq_t *iseq, VALUE misc, VALUE locals, VALUE params,
                         VALUE exception, VALUE body)
{
    int i, len;
    unsigned int arg_size, local_size, stack_max;
    ID *tbl;
    struct st_table *labels_table = rb_st_init_numtable();
    VALUE labels_wrapper = rb_data_typed_object_wrap((0),(labels_table),(&labels_wrapper_type));
    VALUE arg_opt_labels = rb_hash_aref(params, rb_id2sym(rb_intern_const("opt")));
    VALUE keywords = rb_hash_aref(params, rb_id2sym(rb_intern_const("keyword")));
    VALUE sym_arg_rest = rb_id2sym(rb_intern_const("#arg_rest"));
    LINK_ANCHOR anchor[1] = {{{ISEQ_ELEMENT_ANCHOR,},&anchor[0].anchor}};
    ((anchor->last = &anchor->anchor)->next = ((void *)0));
    len = RARRAY_LENINT(locals);
    ((iseq)->body)->local_table_size = len;
    ((iseq)->body)->local_table = tbl = len > 0 ? (ID *)((ID *)ruby_xmalloc2((((iseq)->body)->local_table_size), sizeof(ID))) : ((void *)0);
    for (i = 0; i < len; i++) {
        VALUE lv = RARRAY_AREF(locals, i);
        if (sym_arg_rest == lv) {
            tbl[i] = 0;
        }
        else {
            tbl[i] = RB_FIXNUM_P(lv) ? (ID)rb_fix2long(lv) : rb_sym2id(rb_to_symbol_type(lv));
        }
    }
    if (int_param(&((iseq)->body)->param.lead_num, params, rb_id2sym(rb_intern_const("lead_num")))) {
        ((iseq)->body)->param.flags.has_lead = 1;
    }
    if (int_param(&((iseq)->body)->param.post_num, params, rb_id2sym(rb_intern_const("post_num")))) ((iseq)->body)->param.flags.has_post = 1;
    if (int_param(&((iseq)->body)->param.post_start, params, rb_id2sym(rb_intern_const("post_start")))) ((iseq)->body)->param.flags.has_post = 1;
    if (int_param(&((iseq)->body)->param.rest_start, params, rb_id2sym(rb_intern_const("rest_start")))) ((iseq)->body)->param.flags.has_rest = 1;
    if (int_param(&((iseq)->body)->param.block_start, params, rb_id2sym(rb_intern_const("block_start")))) ((iseq)->body)->param.flags.has_block = 1;
    {
        int x;
        arg_size = (int_param(&x, misc, rb_id2sym(rb_intern_const("arg_size"))) ? (unsigned int)x : 0);
        local_size = (int_param(&x, misc, rb_id2sym(rb_intern_const("local_size"))) ? (unsigned int)x : 0);
        stack_max = (int_param(&x, misc, rb_id2sym(rb_intern_const("stack_max"))) ? (unsigned int)x : 0);
    }
    VALUE node_ids = ((VALUE)RUBY_Qfalse);
    node_ids = rb_hash_aref(misc, rb_id2sym((__builtin_constant_p("node_ids") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("node_ids")); }) : (rb_intern)("node_ids"))));
    if (!RB_TYPE_P(node_ids, RUBY_T_ARRAY)) {
        rb_raise(rb_eTypeError, "node_ids is not an array");
    }
    if (RB_TYPE_P(arg_opt_labels, RUBY_T_ARRAY)) {
        len = RARRAY_LENINT(arg_opt_labels);
        ((iseq)->body)->param.flags.has_opt = !!(len - 1 >= 0);
        if (((iseq)->body)->param.flags.has_opt) {
            VALUE *opt_table = ((VALUE *)ruby_xmalloc2((len), sizeof(VALUE)));
            for (i = 0; i < len; i++) {
                VALUE ent = RARRAY_AREF(arg_opt_labels, i);
                LABEL *label = register_label(iseq, labels_table, ent);
                opt_table[i] = (VALUE)label;
            }
            ((iseq)->body)->param.opt_num = len - 1;
            ((iseq)->body)->param.opt_table = opt_table;
        }
    }
    else if (!RB_NIL_P(arg_opt_labels)) {
        rb_raise(rb_eTypeError, ":opt param is not an array: %+""l""i" "\v",
                 arg_opt_labels);
    }
    if (RB_TYPE_P(keywords, RUBY_T_ARRAY)) {
        ((iseq)->body)->param.keyword = iseq_build_kw(iseq, params, keywords);
    }
    else if (!RB_NIL_P(keywords)) {
        rb_raise(rb_eTypeError, ":keywords param is not an array: %+""l""i" "\v",
                 keywords);
    }
    if (((VALUE)RUBY_Qtrue) == rb_hash_aref(params, rb_id2sym(rb_intern_const("ambiguous_param0")))) {
        ((iseq)->body)->param.flags.ambiguous_param0 = 1;
    }
    if (((VALUE)RUBY_Qtrue) == rb_hash_aref(params, rb_id2sym(rb_intern_const("use_block")))) {
        ((iseq)->body)->param.flags.use_block = 1;
    }
    if (int_param(&i, params, rb_id2sym(rb_intern_const("kwrest")))) {
        struct rb_iseq_param_keyword *keyword = (struct rb_iseq_param_keyword *)((iseq)->body)->param.keyword;
        if (keyword == ((void *)0)) {
            ((iseq)->body)->param.keyword = keyword = (((struct rb_iseq_param_keyword *)ruby_xcalloc((1), sizeof(struct rb_iseq_param_keyword))));
        }
        keyword->rest_start = i;
        ((iseq)->body)->param.flags.has_kwrest = 1;
    }
    iseq_calc_param_size(iseq);
    iseq_build_from_ary_exception(iseq, labels_table, exception);
    iseq_build_from_ary_body(iseq, anchor, body, node_ids, labels_wrapper);
    ((iseq)->body)->param.size = arg_size;
    ((iseq)->body)->local_table_size = local_size;
    ((iseq)->body)->stack_max = stack_max;
}
int
rb_dvar_defined(ID id, const rb_iseq_t *iseq)
{
    if (iseq) {
        const struct rb_iseq_constant_body *body = ((iseq)->body);
        while (body->type == ISEQ_TYPE_BLOCK ||
               body->type == ISEQ_TYPE_RESCUE ||
               body->type == ISEQ_TYPE_ENSURE ||
               body->type == ISEQ_TYPE_EVAL ||
               body->type == ISEQ_TYPE_MAIN
               ) {
            unsigned int i;
            for (i = 0; i < body->local_table_size; i++) {
                if (body->local_table[i] == id) {
                    return 1;
                }
            }
            iseq = body->parent_iseq;
            body = ((iseq)->body);
        }
    }
    return 0;
}
int
rb_local_defined(ID id, const rb_iseq_t *iseq)
{
    if (iseq) {
        unsigned int i;
        const struct rb_iseq_constant_body *const body = ((((iseq)->body)->local_iseq)->body);
        for (i=0; i<body->local_table_size; i++) {
            if (body->local_table[i] == id) {
                return 1;
            }
        }
    }
    return 0;
}
typedef uint32_t ibf_offset_t;
static const char IBF_ENDIAN_MARK =
    'l'
    ;
struct ibf_header {
    char magic[4];
    uint32_t major_version;
    uint32_t minor_version;
    uint32_t size;
    uint32_t extra_size;
    uint32_t iseq_list_size;
    uint32_t global_object_list_size;
    ibf_offset_t iseq_list_offset;
    ibf_offset_t global_object_list_offset;
    uint8_t endian;
    uint8_t wordsize;
};
struct ibf_dump_buffer {
    VALUE str;
    st_table *obj_table;
};
struct ibf_dump {
    st_table *iseq_table;
    struct ibf_dump_buffer global_buffer;
    struct ibf_dump_buffer *current_buffer;
};
struct ibf_load_buffer {
    const char *buff;
    ibf_offset_t size;
    VALUE obj_list;
    unsigned int obj_list_size;
    ibf_offset_t obj_list_offset;
};
struct ibf_load {
    const struct ibf_header *header;
    VALUE iseq_list;
    struct ibf_load_buffer global_buffer;
    VALUE loader_obj;
    rb_iseq_t *iseq;
    VALUE str;
    struct ibf_load_buffer *current_buffer;
};
struct pinned_list {
    long size;
    VALUE buffer[1];
};
static void
pinned_list_mark(void *ptr)
{
    long i;
    struct pinned_list *list = (struct pinned_list *)ptr;
    for (i = 0; i < list->size; i++) {
        if (list->buffer[i]) {
            rb_gc_mark(list->buffer[i]);
        }
    }
}
static const rb_data_type_t pinned_list_type = {
    "pinned_list",
    {
        pinned_list_mark,
        ((void (*)(void *))(-1)),
        ((void *)0),
    },
    0, 0, RUBY_TYPED_WB_PROTECTED | RUBY_TYPED_FREE_IMMEDIATELY | RUBY_TYPED_EMBEDDABLE
};
static VALUE
pinned_list_fetch(VALUE list, long offset)
{
    struct pinned_list * ptr;
    ((ptr) = ((struct pinned_list *)rb_check_typeddata((list), (&pinned_list_type))));
    if (offset >= ptr->size) {
        rb_raise(rb_eIndexError, "object index out of range: %ld", offset);
    }
    return ptr->buffer[offset];
}
static void
pinned_list_store(VALUE list, long offset, VALUE object)
{
    struct pinned_list * ptr;
    ((ptr) = ((struct pinned_list *)rb_check_typeddata((list), (&pinned_list_type))));
    if (offset >= ptr->size) {
        rb_raise(rb_eIndexError, "object index out of range: %ld", offset);
    }
    (rb_obj_write((VALUE)(list), (VALUE *)(&ptr->buffer[offset]), (VALUE)(object), "compile.c", 12393));
}
static VALUE
pinned_list_new(long size)
{
    size_t memsize = __builtin_offsetof (struct pinned_list, buffer) + size * sizeof(VALUE);
    VALUE obj_list = rb_data_typed_object_zalloc(0, memsize, &pinned_list_type);
    struct pinned_list * ptr = RTYPEDDATA_GET_DATA(obj_list);
    ptr->size = size;
    return obj_list;
}
static ibf_offset_t
ibf_dump_pos(struct ibf_dump *dump)
{
    long pos = RSTRING_LEN(dump->current_buffer->str);
    if (pos >= (0x7fffffff * 2U + 1U)) {
        rb_raise(rb_eRuntimeError, "dump size exceeds");
    }
    return (unsigned int)pos;
}
static void
ibf_dump_align(struct ibf_dump *dump, size_t align)
{
    ibf_offset_t pos = ibf_dump_pos(dump);
    if (pos % align) {
        static const char padding[sizeof(VALUE)];
        size_t size = align - ((size_t)pos % align);
        if (pos + size >= (0x7fffffff * 2U + 1U)) {
            rb_raise(rb_eRuntimeError, "dump size exceeds");
        }
        for (; size > sizeof(padding); size -= sizeof(padding)) {
            rb_str_cat(dump->current_buffer->str, padding, sizeof(padding));
        }
        rb_str_cat(dump->current_buffer->str, padding, size);
    }
}
static ibf_offset_t
ibf_dump_write(struct ibf_dump *dump, const void *buff, unsigned long size)
{
    ibf_offset_t pos = ibf_dump_pos(dump);
    rb_str_cat(dump->current_buffer->str, (const char *)buff, size);
    return pos;
}
static ibf_offset_t
ibf_dump_write_byte(struct ibf_dump *dump, unsigned char byte)
{
    return ibf_dump_write(dump, &byte, sizeof(unsigned char));
}
static void
ibf_dump_overwrite(struct ibf_dump *dump, void *buff, unsigned int size, long offset)
{
    VALUE str = dump->current_buffer->str;
    char *ptr = RSTRING_PTR(str);
    if ((unsigned long)(size + offset) > (unsigned long)RSTRING_LEN(str))
        rb_bug("ibf_dump_overwrite: overflow");
    ruby_nonempty_memcpy(ptr + offset, buff, size);
}
static const void *
ibf_load_ptr(const struct ibf_load *load, ibf_offset_t *offset, int size)
{
    ibf_offset_t beg = *offset;
    *offset += size;
    return load->current_buffer->buff + beg;
}
static void *
ibf_load_alloc(const struct ibf_load *load, ibf_offset_t offset, size_t x, size_t y)
{
    void *buff = ruby_xmalloc2(x, y);
    size_t size = x * y;
    ruby_nonempty_memcpy(buff, load->current_buffer->buff + offset, size);
    return buff;
}
static int
ibf_table_lookup(struct st_table *table, st_data_t key)
{
    st_data_t val;
    if (rb_st_lookup(table, key, &val)) {
        return (int)val;
    }
    else {
        return -1;
    }
}
static int
ibf_table_find_or_insert(struct st_table *table, st_data_t key)
{
    int index = ibf_table_lookup(table, key);
    if (index < 0) {
        index = (int)table->num_entries;
        rb_st_insert(table, key, (st_data_t)index);
    }
    return index;
}
static void ibf_dump_object_list(struct ibf_dump *dump, ibf_offset_t *obj_list_offset, unsigned int *obj_list_size);
static VALUE ibf_load_object(const struct ibf_load *load, VALUE object_index);
static rb_iseq_t *ibf_load_iseq(const struct ibf_load *load, const rb_iseq_t *index_iseq);
static st_table *
ibf_dump_object_table_new(void)
{
    st_table *obj_table = rb_st_init_numtable();
    rb_st_insert(obj_table, (st_data_t)((VALUE)RUBY_Qnil), (st_data_t)0);
    return obj_table;
}
static VALUE
ibf_dump_object(struct ibf_dump *dump, VALUE obj)
{
    return ibf_table_find_or_insert(dump->current_buffer->obj_table, (st_data_t)obj);
}
static VALUE
ibf_dump_id(struct ibf_dump *dump, ID id)
{
    if (id == 0 || rb_id2name(id) == ((void *)0)) {
        return 0;
    }
    return ibf_dump_object(dump, rb_id2sym(id));
}
static ID
ibf_load_id(const struct ibf_load *load, const ID id_index)
{
    if (id_index == 0) {
        return 0;
    }
    VALUE sym = ibf_load_object(load, id_index);
    if (rb_integer_type_p(sym)) {
        return rb_num2ulong_inline(sym);
    }
    return rb_sym2id(sym);
}
static ibf_offset_t ibf_dump_iseq_each(struct ibf_dump *dump, const rb_iseq_t *iseq);
static int
ibf_dump_iseq(struct ibf_dump *dump, const rb_iseq_t *iseq)
{
    if (iseq == ((void *)0)) {
        return -1;
    }
    else {
        return ibf_table_find_or_insert(dump->iseq_table, (st_data_t)iseq);
    }
}
static unsigned char
ibf_load_byte(const struct ibf_load *load, ibf_offset_t *offset)
{
    if (*offset >= load->current_buffer->size) { rb_raise(rb_eRuntimeError, "invalid bytecode"); }
    return (unsigned char)load->current_buffer->buff[(*offset)++];
}
static void
ibf_dump_write_small_value(struct ibf_dump *dump, VALUE x)
{
    if (sizeof(VALUE) > 8 || 8 != 8) {
        ibf_dump_write(dump, &x, sizeof(VALUE));
        return;
    }
    enum { max_byte_length = sizeof(VALUE) + 1 };
    unsigned char bytes[max_byte_length];
    ibf_offset_t n;
    for (n = 0; n < sizeof(VALUE) && (x >> (7 - n)); n++, x >>= 8) {
        bytes[max_byte_length - 1 - n] = (unsigned char)x;
    }
    x <<= 1;
    x |= 1;
    x <<= n;
    bytes[max_byte_length - 1 - n] = (unsigned char)x;
    n++;
    ibf_dump_write(dump, bytes + max_byte_length - n, n);
}
static VALUE
ibf_load_small_value(const struct ibf_load *load, ibf_offset_t *offset)
{
    if (sizeof(VALUE) > 8 || 8 != 8) {
        union { char s[sizeof(VALUE)]; VALUE v; } x;
        ruby_nonempty_memcpy(x.s, load->current_buffer->buff + *offset, sizeof(VALUE));
        *offset += sizeof(VALUE);
        return x.v;
    }
    enum { max_byte_length = sizeof(VALUE) + 1 };
    const unsigned char *buffer = (const unsigned char *)load->current_buffer->buff;
    const unsigned char c = buffer[*offset];
    ibf_offset_t n =
        c & 1 ? 1 :
        c == 0 ? 9 : ntz_int32(c) + 1;
    VALUE x = (VALUE)c >> n;
    if (*offset + n > load->current_buffer->size) {
        rb_raise(rb_eRuntimeError, "invalid byte sequence");
    }
    ibf_offset_t i;
    for (i = 1; i < n; i++) {
        x <<= 8;
        x |= (VALUE)buffer[*offset + i];
    }
    *offset += n;
    return x;
}
static void
ibf_dump_builtin(struct ibf_dump *dump, const struct rb_builtin_function *bf)
{
    ibf_dump_write_small_value(dump, (VALUE)bf->index);
    size_t len = strlen(bf->name);
    ibf_dump_write_small_value(dump, (VALUE)len);
    ibf_dump_write(dump, bf->name, len);
}
static const struct rb_builtin_function *
ibf_load_builtin(const struct ibf_load *load, ibf_offset_t *offset)
{
    int i = (int)ibf_load_small_value(load, offset);
    int len = (int)ibf_load_small_value(load, offset);
    const char *name = (char *)ibf_load_ptr(load, offset, len);
    if (0) {
        fprintf(stderr, "%.*s!!\n", len, name);
    }
    const struct rb_builtin_function *table = rb_current_vm()->builtin_function_table;
    if (table == ((void *)0)) rb_raise(rb_eArgError, "builtin function table is not provided");
    if (strncmp(table[i].name, name, len) != 0) {
        rb_raise(rb_eArgError, "builtin function index (%d) mismatch (expect %s but %s)", i, name, table[i].name);
    }
    return &table[i];
}
static ibf_offset_t
ibf_dump_code(struct ibf_dump *dump, const rb_iseq_t *iseq)
{
    const struct rb_iseq_constant_body *const body = ((iseq)->body);
    const int iseq_size = body->iseq_size;
    int code_index;
    const VALUE *orig_code = rb_iseq_original_iseq(iseq);
    ibf_offset_t offset = ibf_dump_pos(dump);
    for (code_index=0; code_index<iseq_size;) {
        const VALUE insn = orig_code[code_index++];
        const char *types = insn_op_types(insn);
        int op_index;
        if (insn >= 0x100) { rb_raise(rb_eRuntimeError, "invalid instruction"); }
        ibf_dump_write_small_value(dump, insn);
        for (op_index=0; types[op_index]; op_index++, code_index++) {
            VALUE op = orig_code[code_index];
            VALUE wv;
            switch (types[op_index]) {
              case TS_CDHASH:
              case TS_VALUE:
                wv = ibf_dump_object(dump, op);
                break;
              case TS_ISEQ:
                wv = (VALUE)ibf_dump_iseq(dump, (const rb_iseq_t *)op);
                break;
              case TS_IC:
                {
                    IC ic = (IC)op;
                    VALUE arr = idlist_to_array(ic->segments);
                    wv = ibf_dump_object(dump, arr);
                }
                break;
              case TS_ISE:
              case TS_IVC:
              case TS_ICVARC:
                {
                    union iseq_inline_storage_entry *is = (union iseq_inline_storage_entry *)op;
                    wv = is - ISEQ_IS_ENTRY_START(body, types[op_index]);
                }
                break;
              case TS_CALLDATA:
                {
                    goto skip_wv;
                }
              case TS_ID:
                wv = ibf_dump_id(dump, (ID)op);
                break;
              case TS_FUNCPTR:
                rb_raise(rb_eRuntimeError, "TS_FUNCPTR is not supported");
                goto skip_wv;
              case TS_BUILTIN:
                ibf_dump_builtin(dump, (const struct rb_builtin_function *)op);
                goto skip_wv;
              default:
                wv = op;
                break;
            }
            ibf_dump_write_small_value(dump, wv);
          skip_wv:;
        }
        ((void)0);
    }
    return offset;
}
static VALUE *
ibf_load_code(const struct ibf_load *load, rb_iseq_t *iseq, ibf_offset_t bytecode_offset, ibf_offset_t bytecode_size, unsigned int iseq_size)
{
    VALUE iseqv = (VALUE)iseq;
    unsigned int code_index;
    ibf_offset_t reading_pos = bytecode_offset;
    VALUE *code = ((VALUE *)ruby_xmalloc2((iseq_size), sizeof(VALUE)));
    struct rb_iseq_constant_body *load_body = ((iseq)->body);
    struct rb_call_data *cd_entries = load_body->call_data;
    int ic_index = 0;
    iseq_bits_t * mark_offset_bits;
    iseq_bits_t tmp[1] = {0};
    if ((((iseq_size) + ((sizeof(iseq_bits_t) * 8)) - 1) / ((sizeof(iseq_bits_t) * 8))) == 1) {
        mark_offset_bits = tmp;
    }
    else {
        mark_offset_bits = ((iseq_bits_t *)ruby_xcalloc(((((iseq_size) + ((sizeof(iseq_bits_t) * 8)) - 1) / ((sizeof(iseq_bits_t) * 8)))), sizeof(iseq_bits_t)));
    }
    _Bool needs_bitmap = 0;
    for (code_index=0; code_index<iseq_size;) {
        const VALUE insn = code[code_index] = ibf_load_small_value(load, &reading_pos);
        const char *types = insn_op_types(insn);
        int op_index;
        code_index++;
        for (op_index=0; types[op_index]; op_index++, code_index++) {
            const char operand_type = types[op_index];
            switch (operand_type) {
              case TS_VALUE:
                {
                    VALUE op = ibf_load_small_value(load, &reading_pos);
                    VALUE v = ibf_load_object(load, op);
                    code[code_index] = v;
                    if (!RB_SPECIAL_CONST_P(v)) {
                        (rb_obj_written((VALUE)(iseqv), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(v), "compile.c", 12802));
                        (mark_offset_bits[(code_index) / (sizeof(iseq_bits_t) * 8)] |= ((iseq_bits_t)1 << ((code_index) % (sizeof(iseq_bits_t) * 8))));
                        needs_bitmap = 1;
                    }
                    break;
                }
              case TS_CDHASH:
                {
                    VALUE op = ibf_load_small_value(load, &reading_pos);
                    VALUE v = ibf_load_object(load, op);
                    v = rb_hash_dup(v);
                    rb_hash_tbl_raw(v, "compile.c", 12813)->type = &cdhash_type;
                    rb_hash_rehash(v);
                    freeze_hide_obj(v);
                    pinned_list_store(load->current_buffer->obj_list, (long)op, v);
                    code[code_index] = v;
                    (mark_offset_bits[(code_index) / (sizeof(iseq_bits_t) * 8)] |= ((iseq_bits_t)1 << ((code_index) % (sizeof(iseq_bits_t) * 8))));
                    (rb_obj_written((VALUE)(iseqv), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(v), "compile.c", 12824));
                    needs_bitmap = 1;
                    break;
                }
              case TS_ISEQ:
                {
                    VALUE op = (VALUE)ibf_load_small_value(load, &reading_pos);
                    VALUE v = (VALUE)ibf_load_iseq(load, (const rb_iseq_t *)op);
                    code[code_index] = v;
                    if (!RB_SPECIAL_CONST_P(v)) {
                        (rb_obj_written((VALUE)(iseqv), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(v), "compile.c", 12834));
                        (mark_offset_bits[(code_index) / (sizeof(iseq_bits_t) * 8)] |= ((iseq_bits_t)1 << ((code_index) % (sizeof(iseq_bits_t) * 8))));
                        needs_bitmap = 1;
                    }
                    break;
                }
              case TS_IC:
                {
                    VALUE op = ibf_load_small_value(load, &reading_pos);
                    VALUE arr = ibf_load_object(load, op);
                    IC ic = &(load_body->is_entries[(ic_index++) + load_body->ise_size + load_body->icvarc_size + load_body->ivc_size].ic_cache);;
                    ic->segments = array_to_idlist(arr);
                    code[code_index] = (VALUE)ic;
                }
                break;
              case TS_ISE:
              case TS_ICVARC:
              case TS_IVC:
                {
                    unsigned int op = (unsigned int)ibf_load_small_value(load, &reading_pos);
                    ISE ic = ISEQ_IS_ENTRY_START(load_body, operand_type) + op;
                    code[code_index] = (VALUE)ic;
                    if (operand_type == TS_IVC) {
                        IVC cache = (IVC)ic;
                        if (insn == YARVINSN_setinstancevariable) {
                            ID iv_name = (ID)code[code_index - 1];
                            cache->iv_set_name = iv_name;
                        }
                        else {
                            cache->iv_set_name = 0;
                        }
                        vm_ic_attr_index_initialize(cache, (((uintptr_t)1 << 32) - 1));
                    }
                }
                break;
              case TS_CALLDATA:
                {
                    code[code_index] = (VALUE)cd_entries++;
                }
                break;
              case TS_ID:
                {
                    VALUE op = ibf_load_small_value(load, &reading_pos);
                    code[code_index] = ibf_load_id(load, (ID)(VALUE)op);
                }
                break;
              case TS_FUNCPTR:
                rb_raise(rb_eRuntimeError, "TS_FUNCPTR is not supported");
                break;
              case TS_BUILTIN:
                code[code_index] = (VALUE)ibf_load_builtin(load, &reading_pos);
                break;
              default:
                code[code_index] = ibf_load_small_value(load, &reading_pos);
                continue;
            }
        }
        if (insn_len(insn) != op_index+1) {
            rb_raise(rb_eRuntimeError, "operand size mismatch");
        }
    }
    load_body->iseq_encoded = code;
    load_body->iseq_size = code_index;
    if ((((load_body->iseq_size) + ((sizeof(iseq_bits_t) * 8)) - 1) / ((sizeof(iseq_bits_t) * 8))) == 1) {
        load_body->mark_bits.single = mark_offset_bits[0];
    }
    else {
        if (needs_bitmap) {
            load_body->mark_bits.list = mark_offset_bits;
        }
        else {
            load_body->mark_bits.list = 0;
            ruby_xfree(mark_offset_bits);
        }
    }
    ((void)0);
    ((void)0);
    return code;
}
static ibf_offset_t
ibf_dump_param_opt_table(struct ibf_dump *dump, const rb_iseq_t *iseq)
{
    int opt_num = ((iseq)->body)->param.opt_num;
    if (opt_num > 0) {
        (__extension__(_Alignof(VALUE)) > 1 ? ibf_dump_align(dump, __extension__(_Alignof(VALUE))) : (void)0);
        return ibf_dump_write(dump, ((iseq)->body)->param.opt_table, sizeof(VALUE) * (opt_num + 1));
    }
    else {
        return ibf_dump_pos(dump);
    }
}
static VALUE *
ibf_load_param_opt_table(const struct ibf_load *load, ibf_offset_t opt_table_offset, int opt_num)
{
    if (opt_num > 0) {
        VALUE *table = ((VALUE *)ruby_xmalloc2((opt_num+1), sizeof(VALUE)));
        ruby_nonempty_memcpy((table), (load->current_buffer->buff + opt_table_offset), rbimpl_size_mul_or_raise(sizeof(VALUE), (opt_num+1)));
        return table;
    }
    else {
        return ((void *)0);
    }
}
static ibf_offset_t
ibf_dump_param_keyword(struct ibf_dump *dump, const rb_iseq_t *iseq)
{
    const struct rb_iseq_param_keyword *kw = ((iseq)->body)->param.keyword;
    if (kw) {
        struct rb_iseq_param_keyword dump_kw = *kw;
        int dv_num = kw->num - kw->required_num;
        ID *ids = kw->num > 0 ? ((ID *)__builtin_alloca (rbimpl_size_mul_or_raise(sizeof(ID), (kw->num)))) : ((void *)0);
        VALUE *dvs = dv_num > 0 ? ((VALUE *)__builtin_alloca (rbimpl_size_mul_or_raise(sizeof(VALUE), (dv_num)))) : ((void *)0);
        int i;
        for (i=0; i<kw->num; i++) ids[i] = (ID)ibf_dump_id(dump, kw->table[i]);
        for (i=0; i<dv_num; i++) dvs[i] = (VALUE)ibf_dump_object(dump, kw->default_values[i]);
        dump_kw.table = ((__extension__(_Alignof(ID)) > 1 ? ibf_dump_align(dump, __extension__(_Alignof(ID))) : (void)0), (ID *)(VALUE)ibf_dump_write(dump, (ids), sizeof(ID) * (kw->num)));
        dump_kw.default_values = ((__extension__(_Alignof(VALUE)) > 1 ? ibf_dump_align(dump, __extension__(_Alignof(VALUE))) : (void)0), (VALUE *)(VALUE)ibf_dump_write(dump, (dvs), sizeof(VALUE) * (dv_num)));
        (__extension__(_Alignof(struct rb_iseq_param_keyword)) > 1 ? ibf_dump_align(dump, __extension__(_Alignof(struct rb_iseq_param_keyword))) : (void)0);
        return ibf_dump_write(dump, &dump_kw, sizeof(struct rb_iseq_param_keyword) * 1);
    }
    else {
        return 0;
    }
}
static const struct rb_iseq_param_keyword *
ibf_load_param_keyword(const struct ibf_load *load, ibf_offset_t param_keyword_offset)
{
    if (param_keyword_offset) {
        struct rb_iseq_param_keyword *kw = (struct rb_iseq_param_keyword *)ibf_load_alloc(load, ((ibf_offset_t)(VALUE)(param_keyword_offset)), sizeof(struct rb_iseq_param_keyword), (1));
        int dv_num = kw->num - kw->required_num;
        VALUE *dvs = dv_num ? (VALUE *)ibf_load_alloc(load, ((ibf_offset_t)(VALUE)(kw->default_values)), sizeof(VALUE), (dv_num)) : ((void *)0);
        int i;
        for (i=0; i<dv_num; i++) {
            dvs[i] = ibf_load_object(load, dvs[i]);
        }
        kw->table = ((void *)0);
        kw->default_values = dvs;
        return kw;
    }
    else {
        return ((void *)0);
    }
}
static ibf_offset_t
ibf_dump_insns_info_body(struct ibf_dump *dump, const rb_iseq_t *iseq)
{
    ibf_offset_t offset = ibf_dump_pos(dump);
    const struct iseq_insn_info_entry *entries = ((iseq)->body)->insns_info.body;
    unsigned int i;
    for (i = 0; i < ((iseq)->body)->insns_info.size; i++) {
        ibf_dump_write_small_value(dump, entries[i].line_no);
        ibf_dump_write_small_value(dump, entries[i].node_id);
        ibf_dump_write_small_value(dump, entries[i].events);
    }
    return offset;
}
static struct iseq_insn_info_entry *
ibf_load_insns_info_body(const struct ibf_load *load, ibf_offset_t body_offset, unsigned int size)
{
    ibf_offset_t reading_pos = body_offset;
    struct iseq_insn_info_entry *entries = ((struct iseq_insn_info_entry *)ruby_xmalloc2((size), sizeof(struct iseq_insn_info_entry)));
    unsigned int i;
    for (i = 0; i < size; i++) {
        entries[i].line_no = (int)ibf_load_small_value(load, &reading_pos);
        entries[i].node_id = (int)ibf_load_small_value(load, &reading_pos);
        entries[i].events = (rb_event_flag_t)ibf_load_small_value(load, &reading_pos);
    }
    return entries;
}
static ibf_offset_t
ibf_dump_insns_info_positions(struct ibf_dump *dump, const unsigned int *positions, unsigned int size)
{
    ibf_offset_t offset = ibf_dump_pos(dump);
    unsigned int last = 0;
    unsigned int i;
    for (i = 0; i < size; i++) {
        ibf_dump_write_small_value(dump, positions[i] - last);
        last = positions[i];
    }
    return offset;
}
static unsigned int *
ibf_load_insns_info_positions(const struct ibf_load *load, ibf_offset_t positions_offset, unsigned int size)
{
    ibf_offset_t reading_pos = positions_offset;
    unsigned int *positions = ((unsigned int *)ruby_xmalloc2((size), sizeof(unsigned int)));
    unsigned int last = 0;
    unsigned int i;
    for (i = 0; i < size; i++) {
        positions[i] = last + (unsigned int)ibf_load_small_value(load, &reading_pos);
        last = positions[i];
    }
    return positions;
}
static ibf_offset_t
ibf_dump_local_table(struct ibf_dump *dump, const rb_iseq_t *iseq)
{
    const struct rb_iseq_constant_body *const body = ((iseq)->body);
    const int size = body->local_table_size;
    ID *table = ((ID *)__builtin_alloca (rbimpl_size_mul_or_raise(sizeof(ID), (size))));
    int i;
    for (i=0; i<size; i++) {
        VALUE v = ibf_dump_id(dump, body->local_table[i]);
        if (v == 0) {
            v = ibf_dump_object(dump, rb_ulong2num_inline(body->local_table[i]));
        }
        table[i] = v;
    }
    (__extension__(_Alignof(ID)) > 1 ? ibf_dump_align(dump, __extension__(_Alignof(ID))) : (void)0);
    return ibf_dump_write(dump, table, sizeof(ID) * size);
}
static ID *
ibf_load_local_table(const struct ibf_load *load, ibf_offset_t local_table_offset, int size)
{
    if (size > 0) {
        ID *table = (ID *)ibf_load_alloc(load, ((ibf_offset_t)(VALUE)(local_table_offset)), sizeof(ID), (size));
        int i;
        for (i=0; i<size; i++) {
            table[i] = ibf_load_id(load, table[i]);
        }
        return table;
    }
    else {
        return ((void *)0);
    }
}
static ibf_offset_t
ibf_dump_catch_table(struct ibf_dump *dump, const rb_iseq_t *iseq)
{
    const struct iseq_catch_table *table = ((iseq)->body)->catch_table;
    if (table) {
        int *iseq_indices = ((int *)__builtin_alloca (rbimpl_size_mul_or_raise(sizeof(int), (table->size))));
        unsigned int i;
        for (i=0; i<table->size; i++) {
            iseq_indices[i] = ibf_dump_iseq(dump, table->entries[i].iseq);
        }
        const ibf_offset_t offset = ibf_dump_pos(dump);
        for (i=0; i<table->size; i++) {
            ibf_dump_write_small_value(dump, iseq_indices[i]);
            ibf_dump_write_small_value(dump, table->entries[i].type);
            ibf_dump_write_small_value(dump, table->entries[i].start);
            ibf_dump_write_small_value(dump, table->entries[i].end);
            ibf_dump_write_small_value(dump, table->entries[i].cont);
            ibf_dump_write_small_value(dump, table->entries[i].sp);
        }
        return offset;
    }
    else {
        return ibf_dump_pos(dump);
    }
}
static struct iseq_catch_table *
ibf_load_catch_table(const struct ibf_load *load, ibf_offset_t catch_table_offset, unsigned int size)
{
    if (size) {
        struct iseq_catch_table *table = ruby_xmalloc(iseq_catch_table_bytes(size));
        table->size = size;
        ibf_offset_t reading_pos = catch_table_offset;
        unsigned int i;
        for (i=0; i<table->size; i++) {
            int iseq_index = (int)ibf_load_small_value(load, &reading_pos);
            table->entries[i].type = (enum rb_catch_type)ibf_load_small_value(load, &reading_pos);
            table->entries[i].start = (unsigned int)ibf_load_small_value(load, &reading_pos);
            table->entries[i].end = (unsigned int)ibf_load_small_value(load, &reading_pos);
            table->entries[i].cont = (unsigned int)ibf_load_small_value(load, &reading_pos);
            table->entries[i].sp = (unsigned int)ibf_load_small_value(load, &reading_pos);
            table->entries[i].iseq = ibf_load_iseq(load, (const rb_iseq_t *)(VALUE)iseq_index);
        }
        return table;
    }
    else {
        return ((void *)0);
    }
}
static ibf_offset_t
ibf_dump_ci_entries(struct ibf_dump *dump, const rb_iseq_t *iseq)
{
    const struct rb_iseq_constant_body *const body = ((iseq)->body);
    const unsigned int ci_size = body->ci_size;
    const struct rb_call_data *cds = body->call_data;
    ibf_offset_t offset = ibf_dump_pos(dump);
    unsigned int i;
    for (i = 0; i < ci_size; i++) {
        const struct rb_callinfo *ci = cds[i].ci;
        if (ci != ((void *)0)) {
            ibf_dump_write_small_value(dump, ibf_dump_id(dump, vm_ci_mid(ci)));
            ibf_dump_write_small_value(dump, vm_ci_flag(ci));
            ibf_dump_write_small_value(dump, vm_ci_argc(ci));
            const struct rb_callinfo_kwarg *kwarg = vm_ci_kwarg(ci);
            if (kwarg) {
                int len = kwarg->keyword_len;
                ibf_dump_write_small_value(dump, len);
                for (int j=0; j<len; j++) {
                    VALUE keyword = ibf_dump_object(dump, kwarg->keywords[j]);
                    ibf_dump_write_small_value(dump, keyword);
                }
            }
            else {
                ibf_dump_write_small_value(dump, 0);
            }
        }
        else {
            ibf_dump_write_small_value(dump, (VALUE)-1);
        }
    }
    return offset;
}
struct outer_variable_pair {
    ID id;
    VALUE name;
    VALUE val;
};
struct outer_variable_list {
    size_t num;
    struct outer_variable_pair pairs[1];
};
static enum rb_id_table_iterator_result
store_outer_variable(ID id, VALUE val, void *dump)
{
    struct outer_variable_list *ovlist = dump;
    struct outer_variable_pair *pair = &ovlist->pairs[ovlist->num++];
    pair->id = id;
    pair->name = rb_id2str(id);
    pair->val = val;
    return ID_TABLE_CONTINUE;
}
static int
outer_variable_cmp(const void *a, const void *b, void *arg)
{
    const struct outer_variable_pair *ap = (const struct outer_variable_pair *)a;
    const struct outer_variable_pair *bp = (const struct outer_variable_pair *)b;
    return rb_str_cmp(ap->name, bp->name);
}
static ibf_offset_t
ibf_dump_outer_variables(struct ibf_dump *dump, const rb_iseq_t *iseq)
{
    struct rb_id_table * ovs = ((iseq)->body)->outer_variables;
    ibf_offset_t offset = ibf_dump_pos(dump);
    size_t size = ovs ? rb_id_table_size(ovs) : 0;
    ibf_dump_write_small_value(dump, (VALUE)size);
    if (size > 0) {
        VALUE buff;
        size_t buffsize =
            rb_size_mul_add_or_raise(sizeof(struct outer_variable_pair), size,
                                     __builtin_offsetof (struct outer_variable_list, pairs),
                                     rb_eArgError);
        struct outer_variable_list *ovlist = ((buffsize) < 1024 ? ((buff) = 0, __builtin_alloca (buffsize)) : rb_alloc_tmp_buffer(&(buff), (buffsize)));
        ovlist->num = 0;
        rb_id_table_foreach(ovs, store_outer_variable, ovlist);
        qsort_r(ovlist->pairs, size, sizeof(struct outer_variable_pair), outer_variable_cmp, ((void *)0));
        for (size_t i = 0; i < size; ++i) {
            ID id = ovlist->pairs[i].id;
            ID val = ovlist->pairs[i].val;
            ibf_dump_write_small_value(dump, ibf_dump_id(dump, id));
            ibf_dump_write_small_value(dump, val);
        }
    }
    return offset;
}
static void
ibf_load_ci_entries(const struct ibf_load *load,
                    ibf_offset_t ci_entries_offset,
                    unsigned int ci_size,
                    struct rb_call_data **cd_ptr)
{
    ibf_offset_t reading_pos = ci_entries_offset;
    unsigned int i;
    struct rb_call_data *cds = ((struct rb_call_data *)ruby_xcalloc((ci_size), sizeof(struct rb_call_data)));
    *cd_ptr = cds;
    for (i = 0; i < ci_size; i++) {
        VALUE mid_index = ibf_load_small_value(load, &reading_pos);
        if (mid_index != (VALUE)-1) {
            ID mid = ibf_load_id(load, mid_index);
            unsigned int flag = (unsigned int)ibf_load_small_value(load, &reading_pos);
            unsigned int argc = (unsigned int)ibf_load_small_value(load, &reading_pos);
            struct rb_callinfo_kwarg *kwarg = ((void *)0);
            int kwlen = (int)ibf_load_small_value(load, &reading_pos);
            if (kwlen > 0) {
                kwarg = rb_xmalloc_mul_add(kwlen, sizeof(VALUE), sizeof(struct rb_callinfo_kwarg));
                kwarg->references = 0;
                kwarg->keyword_len = kwlen;
                for (int j=0; j<kwlen; j++) {
                    VALUE keyword = ibf_load_small_value(load, &reading_pos);
                    kwarg->keywords[j] = ibf_load_object(load, keyword);
                }
            }
            cds[i].ci = vm_ci_new_(mid, flag, argc, kwarg, "compile.c", 13295);
            (rb_obj_written((VALUE)(load->iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(cds[i].ci), "compile.c", 13296));
            cds[i].cc = rb_vm_empty_cc();
        }
        else {
            cds[i].ci = ((void *)0);
            cds[i].cc = ((void *)0);
        }
    }
}
static struct rb_id_table *
ibf_load_outer_variables(const struct ibf_load * load, ibf_offset_t outer_variables_offset)
{
    ibf_offset_t reading_pos = outer_variables_offset;
    struct rb_id_table *tbl = ((void *)0);
    size_t table_size = (size_t)ibf_load_small_value(load, &reading_pos);
    if (table_size > 0) {
        tbl = rb_id_table_create(table_size);
    }
    for (size_t i = 0; i < table_size; i++) {
        ID key = ibf_load_id(load, (ID)ibf_load_small_value(load, &reading_pos));
        VALUE value = ibf_load_small_value(load, &reading_pos);
        if (!key) key = rb_make_temporary_id(i);
        rb_id_table_insert(tbl, key, value);
    }
    return tbl;
}
static ibf_offset_t
ibf_dump_iseq_each(struct ibf_dump *dump, const rb_iseq_t *iseq)
{
    ((void)0);
    unsigned int *positions;
    const struct rb_iseq_constant_body *body = ((iseq)->body);
    const VALUE location_pathobj_index = ibf_dump_object(dump, body->location.pathobj);
    const VALUE location_base_label_index = ibf_dump_object(dump, body->location.base_label);
    const VALUE location_label_index = ibf_dump_object(dump, body->location.label);
    const ibf_offset_t bytecode_offset = ibf_dump_code(dump, iseq);
    const ibf_offset_t bytecode_size = ibf_dump_pos(dump) - bytecode_offset;
    const ibf_offset_t param_opt_table_offset = ibf_dump_param_opt_table(dump, iseq);
    const ibf_offset_t param_keyword_offset = ibf_dump_param_keyword(dump, iseq);
    const ibf_offset_t insns_info_body_offset = ibf_dump_insns_info_body(dump, iseq);
    positions = rb_iseq_insns_info_decode_positions(((iseq)->body));
    const ibf_offset_t insns_info_positions_offset = ibf_dump_insns_info_positions(dump, positions, body->insns_info.size);
    ruby_xfree(positions);
    const ibf_offset_t local_table_offset = ibf_dump_local_table(dump, iseq);
    const unsigned int catch_table_size = body->catch_table ? body->catch_table->size : 0;
    const ibf_offset_t catch_table_offset = ibf_dump_catch_table(dump, iseq);
    const int parent_iseq_index = ibf_dump_iseq(dump, ((iseq)->body)->parent_iseq);
    const int local_iseq_index = ibf_dump_iseq(dump, ((iseq)->body)->local_iseq);
    const int mandatory_only_iseq_index = ibf_dump_iseq(dump, ((iseq)->body)->mandatory_only_iseq);
    const ibf_offset_t ci_entries_offset = ibf_dump_ci_entries(dump, iseq);
    const ibf_offset_t outer_variables_offset = ibf_dump_outer_variables(dump, iseq);
    ibf_offset_t body_offset = ibf_dump_pos(dump);
    unsigned int param_flags =
        (body->param.flags.has_lead << 0) |
        (body->param.flags.has_opt << 1) |
        (body->param.flags.has_rest << 2) |
        (body->param.flags.has_post << 3) |
        (body->param.flags.has_kw << 4) |
        (body->param.flags.has_kwrest << 5) |
        (body->param.flags.has_block << 6) |
        (body->param.flags.ambiguous_param0 << 7) |
        (body->param.flags.accepts_no_kwarg << 8) |
        (body->param.flags.ruby2_keywords << 9) |
        (body->param.flags.anon_rest << 10) |
        (body->param.flags.anon_kwrest << 11) |
        (body->param.flags.use_block << 12) |
        (body->param.flags.forwardable << 13) ;
    ibf_dump_write_small_value(dump, body->type);
    ibf_dump_write_small_value(dump, body->iseq_size);
    ibf_dump_write_small_value(dump, (body_offset - (bytecode_offset)));
    ibf_dump_write_small_value(dump, bytecode_size);
    ibf_dump_write_small_value(dump, param_flags);
    ibf_dump_write_small_value(dump, body->param.size);
    ibf_dump_write_small_value(dump, body->param.lead_num);
    ibf_dump_write_small_value(dump, body->param.opt_num);
    ibf_dump_write_small_value(dump, body->param.rest_start);
    ibf_dump_write_small_value(dump, body->param.post_start);
    ibf_dump_write_small_value(dump, body->param.post_num);
    ibf_dump_write_small_value(dump, body->param.block_start);
    ibf_dump_write_small_value(dump, (body_offset - (param_opt_table_offset)));
    ibf_dump_write_small_value(dump, param_keyword_offset);
    ibf_dump_write_small_value(dump, location_pathobj_index);
    ibf_dump_write_small_value(dump, location_base_label_index);
    ibf_dump_write_small_value(dump, location_label_index);
    ibf_dump_write_small_value(dump, body->location.first_lineno);
    ibf_dump_write_small_value(dump, body->location.node_id);
    ibf_dump_write_small_value(dump, body->location.code_location.beg_pos.lineno);
    ibf_dump_write_small_value(dump, body->location.code_location.beg_pos.column);
    ibf_dump_write_small_value(dump, body->location.code_location.end_pos.lineno);
    ibf_dump_write_small_value(dump, body->location.code_location.end_pos.column);
    ibf_dump_write_small_value(dump, (body_offset - (insns_info_body_offset)));
    ibf_dump_write_small_value(dump, (body_offset - (insns_info_positions_offset)));
    ibf_dump_write_small_value(dump, body->insns_info.size);
    ibf_dump_write_small_value(dump, (body_offset - (local_table_offset)));
    ibf_dump_write_small_value(dump, catch_table_size);
    ibf_dump_write_small_value(dump, (body_offset - (catch_table_offset)));
    ibf_dump_write_small_value(dump, parent_iseq_index);
    ibf_dump_write_small_value(dump, local_iseq_index);
    ibf_dump_write_small_value(dump, mandatory_only_iseq_index);
    ibf_dump_write_small_value(dump, (body_offset - (ci_entries_offset)));
    ibf_dump_write_small_value(dump, (body_offset - (outer_variables_offset)));
    ibf_dump_write_small_value(dump, body->variable.flip_count);
    ibf_dump_write_small_value(dump, body->local_table_size);
    ibf_dump_write_small_value(dump, body->ivc_size);
    ibf_dump_write_small_value(dump, body->icvarc_size);
    ibf_dump_write_small_value(dump, body->ise_size);
    ibf_dump_write_small_value(dump, body->ic_size);
    ibf_dump_write_small_value(dump, body->ci_size);
    ibf_dump_write_small_value(dump, body->stack_max);
    ibf_dump_write_small_value(dump, body->builtin_attrs);
    ibf_dump_write_small_value(dump, body->prism ? 1 : 0);
    return body_offset;
}
static VALUE
ibf_load_location_str(const struct ibf_load *load, VALUE str_index)
{
    VALUE str = ibf_load_object(load, str_index);
    if (str != ((VALUE)RUBY_Qnil)) {
        str = rb_fstring(str);
    }
    return str;
}
static void
ibf_load_iseq_each(struct ibf_load *load, rb_iseq_t *iseq, ibf_offset_t offset)
{
    struct rb_iseq_constant_body *load_body = ((iseq)->body) = rb_iseq_constant_body_alloc();
    ibf_offset_t reading_pos = offset;
    const unsigned int type = (unsigned int)ibf_load_small_value(load, &reading_pos);
    const unsigned int iseq_size = (unsigned int)ibf_load_small_value(load, &reading_pos);
    const ibf_offset_t bytecode_offset = (ibf_offset_t)(offset - (ibf_load_small_value(load, &reading_pos)));
    const ibf_offset_t bytecode_size = (ibf_offset_t)ibf_load_small_value(load, &reading_pos);
    const unsigned int param_flags = (unsigned int)ibf_load_small_value(load, &reading_pos);
    const unsigned int param_size = (unsigned int)ibf_load_small_value(load, &reading_pos);
    const int param_lead_num = (int)ibf_load_small_value(load, &reading_pos);
    const int param_opt_num = (int)ibf_load_small_value(load, &reading_pos);
    const int param_rest_start = (int)ibf_load_small_value(load, &reading_pos);
    const int param_post_start = (int)ibf_load_small_value(load, &reading_pos);
    const int param_post_num = (int)ibf_load_small_value(load, &reading_pos);
    const int param_block_start = (int)ibf_load_small_value(load, &reading_pos);
    const ibf_offset_t param_opt_table_offset = (ibf_offset_t)(offset - (ibf_load_small_value(load, &reading_pos)));
    const ibf_offset_t param_keyword_offset = (ibf_offset_t)ibf_load_small_value(load, &reading_pos);
    const VALUE location_pathobj_index = ibf_load_small_value(load, &reading_pos);
    const VALUE location_base_label_index = ibf_load_small_value(load, &reading_pos);
    const VALUE location_label_index = ibf_load_small_value(load, &reading_pos);
    const int location_first_lineno = (int)ibf_load_small_value(load, &reading_pos);
    const int location_node_id = (int)ibf_load_small_value(load, &reading_pos);
    const int location_code_location_beg_pos_lineno = (int)ibf_load_small_value(load, &reading_pos);
    const int location_code_location_beg_pos_column = (int)ibf_load_small_value(load, &reading_pos);
    const int location_code_location_end_pos_lineno = (int)ibf_load_small_value(load, &reading_pos);
    const int location_code_location_end_pos_column = (int)ibf_load_small_value(load, &reading_pos);
    const ibf_offset_t insns_info_body_offset = (ibf_offset_t)(offset - (ibf_load_small_value(load, &reading_pos)));
    const ibf_offset_t insns_info_positions_offset = (ibf_offset_t)(offset - (ibf_load_small_value(load, &reading_pos)));
    const unsigned int insns_info_size = (unsigned int)ibf_load_small_value(load, &reading_pos);
    const ibf_offset_t local_table_offset = (ibf_offset_t)(offset - (ibf_load_small_value(load, &reading_pos)));
    const unsigned int catch_table_size = (unsigned int)ibf_load_small_value(load, &reading_pos);
    const ibf_offset_t catch_table_offset = (ibf_offset_t)(offset - (ibf_load_small_value(load, &reading_pos)));
    const int parent_iseq_index = (int)ibf_load_small_value(load, &reading_pos);
    const int local_iseq_index = (int)ibf_load_small_value(load, &reading_pos);
    const int mandatory_only_iseq_index = (int)ibf_load_small_value(load, &reading_pos);
    const ibf_offset_t ci_entries_offset = (ibf_offset_t)(offset - (ibf_load_small_value(load, &reading_pos)));
    const ibf_offset_t outer_variables_offset = (ibf_offset_t)(offset - (ibf_load_small_value(load, &reading_pos)));
    const rb_snum_t variable_flip_count = (rb_snum_t)ibf_load_small_value(load, &reading_pos);
    const unsigned int local_table_size = (unsigned int)ibf_load_small_value(load, &reading_pos);
    const unsigned int ivc_size = (unsigned int)ibf_load_small_value(load, &reading_pos);
    const unsigned int icvarc_size = (unsigned int)ibf_load_small_value(load, &reading_pos);
    const unsigned int ise_size = (unsigned int)ibf_load_small_value(load, &reading_pos);
    const unsigned int ic_size = (unsigned int)ibf_load_small_value(load, &reading_pos);
    const unsigned int ci_size = (unsigned int)ibf_load_small_value(load, &reading_pos);
    const unsigned int stack_max = (unsigned int)ibf_load_small_value(load, &reading_pos);
    const unsigned int builtin_attrs = (unsigned int)ibf_load_small_value(load, &reading_pos);
    const _Bool prism = (_Bool)ibf_load_small_value(load, &reading_pos);
    VALUE path = ibf_load_object(load, location_pathobj_index);
    {
        VALUE realpath = ((VALUE)RUBY_Qnil);
        if (RB_TYPE_P(path, RUBY_T_STRING)) {
            realpath = path = rb_fstring(path);
        }
        else if (RB_TYPE_P(path, RUBY_T_ARRAY)) {
            VALUE pathobj = path;
            if (rb_array_len(pathobj) != 2) {
                rb_raise(rb_eRuntimeError, "path object size mismatch");
            }
            path = rb_fstring(RARRAY_AREF(pathobj, 0));
            realpath = RARRAY_AREF(pathobj, 1);
            if (!RB_NIL_P(realpath)) {
                if (!RB_TYPE_P(realpath, RUBY_T_STRING)) {
                    rb_raise(rb_eArgError, "unexpected realpath %""l""x"
                             "(%x), path=%+""l""i" "\v",
                             realpath, ((int)rb_type(realpath)), path);
                }
                realpath = rb_fstring(realpath);
            }
        }
        else {
            rb_raise(rb_eRuntimeError, "unexpected path object");
        }
        rb_iseq_pathobj_set(iseq, path, realpath);
    }
    rb_execution_context_t *ec = rb_current_execution_context(1);
    VALUE dummy_frame = rb_vm_push_frame_fname(ec, path);
    load_body->type = type;
    load_body->stack_max = stack_max;
    load_body->param.flags.has_lead = (param_flags >> 0) & 1;
    load_body->param.flags.has_opt = (param_flags >> 1) & 1;
    load_body->param.flags.has_rest = (param_flags >> 2) & 1;
    load_body->param.flags.has_post = (param_flags >> 3) & 1;
    load_body->param.flags.has_kw = 0;
    load_body->param.flags.has_kwrest = (param_flags >> 5) & 1;
    load_body->param.flags.has_block = (param_flags >> 6) & 1;
    load_body->param.flags.ambiguous_param0 = (param_flags >> 7) & 1;
    load_body->param.flags.accepts_no_kwarg = (param_flags >> 8) & 1;
    load_body->param.flags.ruby2_keywords = (param_flags >> 9) & 1;
    load_body->param.flags.anon_rest = (param_flags >> 10) & 1;
    load_body->param.flags.anon_kwrest = (param_flags >> 11) & 1;
    load_body->param.flags.use_block = (param_flags >> 12) & 1;
    load_body->param.flags.forwardable = (param_flags >> 13) & 1;
    load_body->param.size = param_size;
    load_body->param.lead_num = param_lead_num;
    load_body->param.opt_num = param_opt_num;
    load_body->param.rest_start = param_rest_start;
    load_body->param.post_start = param_post_start;
    load_body->param.post_num = param_post_num;
    load_body->param.block_start = param_block_start;
    load_body->local_table_size = local_table_size;
    load_body->ci_size = ci_size;
    load_body->insns_info.size = insns_info_size;
    (rb_obj_write((VALUE)(iseq), (VALUE *)(&((iseq)->body)->variable.coverage), (VALUE)(((VALUE)RUBY_Qnil)), "compile.c", 13625));
    ISEQ_ORIGINAL_ISEQ_CLEAR(iseq);
    load_body->variable.flip_count = variable_flip_count;
    load_body->variable.script_lines = ((VALUE)RUBY_Qnil);
    load_body->location.first_lineno = location_first_lineno;
    load_body->location.node_id = location_node_id;
    load_body->location.code_location.beg_pos.lineno = location_code_location_beg_pos_lineno;
    load_body->location.code_location.beg_pos.column = location_code_location_beg_pos_column;
    load_body->location.code_location.end_pos.lineno = location_code_location_end_pos_lineno;
    load_body->location.code_location.end_pos.column = location_code_location_end_pos_column;
    load_body->builtin_attrs = builtin_attrs;
    load_body->prism = prism;
    load_body->ivc_size = ivc_size;
    load_body->icvarc_size = icvarc_size;
    load_body->ise_size = ise_size;
    load_body->ic_size = ic_size;
    if ((load_body->ic_size + load_body->ivc_size + load_body->ise_size + load_body->icvarc_size)) {
        load_body->is_entries = ((union iseq_inline_storage_entry *)ruby_xcalloc(((load_body->ic_size + load_body->ivc_size + load_body->ise_size + load_body->icvarc_size)), sizeof(union iseq_inline_storage_entry)));
    }
    else {
        load_body->is_entries = ((void *)0);
    }
                                      ibf_load_ci_entries(load, ci_entries_offset, ci_size, &load_body->call_data);
    load_body->outer_variables = ibf_load_outer_variables(load, outer_variables_offset);
    load_body->param.opt_table = ibf_load_param_opt_table(load, param_opt_table_offset, param_opt_num);
    load_body->param.keyword = ibf_load_param_keyword(load, param_keyword_offset);
    load_body->param.flags.has_kw = (param_flags >> 4) & 1;
    load_body->insns_info.body = ibf_load_insns_info_body(load, insns_info_body_offset, insns_info_size);
    load_body->insns_info.positions = ibf_load_insns_info_positions(load, insns_info_positions_offset, insns_info_size);
    load_body->local_table = ibf_load_local_table(load, local_table_offset, local_table_size);
    load_body->catch_table = ibf_load_catch_table(load, catch_table_offset, catch_table_size);
    load_body->parent_iseq = ibf_load_iseq(load, (const rb_iseq_t *)(VALUE)parent_iseq_index);
    load_body->local_iseq = ibf_load_iseq(load, (const rb_iseq_t *)(VALUE)local_iseq_index);
    load_body->mandatory_only_iseq = ibf_load_iseq(load, (const rb_iseq_t *)(VALUE)mandatory_only_iseq_index);
    if (load_body->param.keyword != ((void *)0)) {
        ((void)0);
        struct rb_iseq_param_keyword *keyword = (struct rb_iseq_param_keyword *) load_body->param.keyword;
        keyword->table = &load_body->local_table[keyword->bits_start - keyword->num];
    }
    ibf_load_code(load, iseq, bytecode_offset, bytecode_size, iseq_size);
    rb_iseq_insns_info_encode_positions(iseq);
    rb_iseq_translate_threaded_code(iseq);
    (rb_obj_write((VALUE)(iseq), (VALUE *)(&load_body->location.base_label), (VALUE)(ibf_load_location_str(load, location_base_label_index)), "compile.c", 13681));
    (rb_obj_write((VALUE)(iseq), (VALUE *)(&load_body->location.label), (VALUE)(ibf_load_location_str(load, location_label_index)), "compile.c", 13682));
    verify_call_cache(iseq);
    (*__extension__ ({ volatile VALUE *rb_gc_guarded_ptr = &(dummy_frame); __asm__("" : : "m"(rb_gc_guarded_ptr)); rb_gc_guarded_ptr; }));
    rb_vm_pop_frame_no_int(ec);
}
struct ibf_dump_iseq_list_arg
{
    struct ibf_dump *dump;
    VALUE offset_list;
};
static int
ibf_dump_iseq_list_i(st_data_t key, st_data_t val, st_data_t ptr)
{
    const rb_iseq_t *iseq = (const rb_iseq_t *)key;
    struct ibf_dump_iseq_list_arg *args = (struct ibf_dump_iseq_list_arg *)ptr;
    ibf_offset_t offset = ibf_dump_iseq_each(args->dump, iseq);
    rb_ary_push(args->offset_list, rb_uint2num_inline(offset));
    return ST_CONTINUE;
}
static void
ibf_dump_iseq_list(struct ibf_dump *dump, struct ibf_header *header)
{
    VALUE offset_list = rb_ary_hidden_new(dump->iseq_table->num_entries);
    struct ibf_dump_iseq_list_arg args;
    args.dump = dump;
    args.offset_list = offset_list;
    rb_st_foreach(dump->iseq_table, ibf_dump_iseq_list_i, (st_data_t)&args);
    st_index_t i;
    st_index_t size = dump->iseq_table->num_entries;
    ibf_offset_t *offsets = ((ibf_offset_t *)__builtin_alloca (rbimpl_size_mul_or_raise(sizeof(ibf_offset_t), (size))));
    for (i = 0; i < size; i++) {
        offsets[i] = RB_NUM2UINT(RARRAY_AREF(offset_list, i));
    }
    ibf_dump_align(dump, sizeof(ibf_offset_t));
    header->iseq_list_offset = ibf_dump_write(dump, offsets, sizeof(ibf_offset_t) * size);
    header->iseq_list_size = (unsigned int)size;
}
struct ibf_object_header {
    unsigned int type: 5;
    unsigned int special_const: 1;
    unsigned int frozen: 1;
    unsigned int internal: 1;
};
enum ibf_object_class_index {
    IBF_OBJECT_CLASS_OBJECT,
    IBF_OBJECT_CLASS_ARRAY,
    IBF_OBJECT_CLASS_STANDARD_ERROR,
    IBF_OBJECT_CLASS_NO_MATCHING_PATTERN_ERROR,
    IBF_OBJECT_CLASS_TYPE_ERROR,
    IBF_OBJECT_CLASS_NO_MATCHING_PATTERN_KEY_ERROR,
};
struct ibf_object_regexp {
    long srcstr;
    char option;
};
struct ibf_object_hash {
    long len;
    long keyval[];
};
struct ibf_object_struct_range {
    long class_index;
    long len;
    long beg;
    long end;
    int excl;
};
struct ibf_object_bignum {
    ssize_t slen;
    unsigned int digits[];
};
enum ibf_object_data_type {
    IBF_OBJECT_DATA_ENCODING,
};
struct ibf_object_complex_rational {
    long a, b;
};
struct ibf_object_symbol {
    long str;
};
static const void *
ibf_load_check_offset(const struct ibf_load *load, size_t offset)
{
    if (offset >= load->current_buffer->size) {
        rb_raise(rb_eIndexError, "object offset out of range: %""z""d", offset);
    }
    return load->current_buffer->buff + offset;
}
__attribute__((__noreturn__)) static void ibf_dump_object_unsupported(struct ibf_dump *dump, VALUE obj);
static void
ibf_dump_object_unsupported(struct ibf_dump *dump, VALUE obj)
{
    char buff[0x100];
    rb_raw_obj_info(buff, sizeof(buff), obj);
    rb_raise(rb_eNotImpError, "ibf_dump_object_unsupported: %s", buff);
}
__attribute__((__noreturn__)) static VALUE ibf_load_object_unsupported(const struct ibf_load *load, const struct ibf_object_header *header, ibf_offset_t offset);
static VALUE
ibf_load_object_unsupported(const struct ibf_load *load, const struct ibf_object_header *header, ibf_offset_t offset)
{
    rb_raise(rb_eArgError, "unsupported");
    __builtin_unreachable();
}
static void
ibf_dump_object_class(struct ibf_dump *dump, VALUE obj)
{
    enum ibf_object_class_index cindex;
    if (obj == rb_cObject) {
        cindex = IBF_OBJECT_CLASS_OBJECT;
    }
    else if (obj == rb_cArray) {
        cindex = IBF_OBJECT_CLASS_ARRAY;
    }
    else if (obj == rb_eStandardError) {
        cindex = IBF_OBJECT_CLASS_STANDARD_ERROR;
    }
    else if (obj == rb_eNoMatchingPatternError) {
        cindex = IBF_OBJECT_CLASS_NO_MATCHING_PATTERN_ERROR;
    }
    else if (obj == rb_eTypeError) {
        cindex = IBF_OBJECT_CLASS_TYPE_ERROR;
    }
    else if (obj == rb_eNoMatchingPatternKeyError) {
        cindex = IBF_OBJECT_CLASS_NO_MATCHING_PATTERN_KEY_ERROR;
    }
    else {
        rb_obj_info_dump(obj);
        rb_p(obj);
        rb_bug("unsupported class");
    }
    ibf_dump_write_small_value(dump, (VALUE)cindex);
}
static VALUE
ibf_load_object_class(const struct ibf_load *load, const struct ibf_object_header *header, ibf_offset_t offset)
{
    enum ibf_object_class_index cindex = (enum ibf_object_class_index)ibf_load_small_value(load, &offset);
    switch (cindex) {
      case IBF_OBJECT_CLASS_OBJECT:
        return rb_cObject;
      case IBF_OBJECT_CLASS_ARRAY:
        return rb_cArray;
      case IBF_OBJECT_CLASS_STANDARD_ERROR:
        return rb_eStandardError;
      case IBF_OBJECT_CLASS_NO_MATCHING_PATTERN_ERROR:
        return rb_eNoMatchingPatternError;
      case IBF_OBJECT_CLASS_TYPE_ERROR:
        return rb_eTypeError;
      case IBF_OBJECT_CLASS_NO_MATCHING_PATTERN_KEY_ERROR:
        return rb_eNoMatchingPatternKeyError;
    }
    rb_raise(rb_eArgError, "ibf_load_object_class: unknown class (%d)", (int)cindex);
}
static void
ibf_dump_object_float(struct ibf_dump *dump, VALUE obj)
{
    double dbl = rb_float_value_inline(obj);
    (void)((__extension__(_Alignof(double)) > 1 ? ibf_dump_align(dump, __extension__(_Alignof(double))) : (void)0), (double *)(VALUE)ibf_dump_write(dump, (&dbl), sizeof(double) * (1)));
}
static VALUE
ibf_load_object_float(const struct ibf_load *load, const struct ibf_object_header *header, ibf_offset_t offset)
{
    const double *dblp = (const double *) ibf_load_check_offset(load, ((((offset) - 1) / (__extension__(_Alignof(double))) + 1) * (__extension__(_Alignof(double)))));
    return rb_float_new_inline(*dblp);
}
static void
ibf_dump_object_string(struct ibf_dump *dump, VALUE obj)
{
    long encindex = (long)rb_enc_get_index(obj);
    long len = RSTRING_LEN(obj);
    const char *ptr = RSTRING_PTR(obj);
    if (encindex > RUBY_ENCINDEX_BUILTIN_MAX) {
        rb_encoding *enc = rb_enc_from_index((int)encindex);
        const char *enc_name = rb_enc_name(enc);
        encindex = RUBY_ENCINDEX_BUILTIN_MAX + ibf_dump_object(dump, ((__builtin_constant_p(enc_name) ? rbimpl_str_new_cstr : rb_str_new_cstr) (enc_name)));
    }
    ibf_dump_write_small_value(dump, encindex);
    ibf_dump_write_small_value(dump, len);
    ibf_dump_write(dump, (ptr), sizeof(char) * (len));
}
static VALUE
ibf_load_object_string(const struct ibf_load *load, const struct ibf_object_header *header, ibf_offset_t offset)
{
    ibf_offset_t reading_pos = offset;
    int encindex = (int)ibf_load_small_value(load, &reading_pos);
    const long len = (long)ibf_load_small_value(load, &reading_pos);
    const char *ptr = load->current_buffer->buff + reading_pos;
    if (encindex > RUBY_ENCINDEX_BUILTIN_MAX) {
        VALUE enc_name_str = ibf_load_object(load, encindex - RUBY_ENCINDEX_BUILTIN_MAX);
        encindex = rb_enc_find_index(RSTRING_PTR(enc_name_str));
    }
    VALUE str;
    if (header->frozen && !header->internal) {
        str = rb_enc_literal_str(ptr, len, rb_enc_from_index(encindex));
    }
    else {
        str = ((__builtin_constant_p(ptr) && __builtin_constant_p(len) ? rb_enc_str_new_static: rb_enc_str_new) ((ptr), (len), (rb_enc_from_index(encindex))));
        if (header->internal) rb_obj_hide(str);
        if (header->frozen) str = rb_fstring(str);
    }
    return str;
}
static void
ibf_dump_object_regexp(struct ibf_dump *dump, VALUE obj)
{
    VALUE srcstr = RREGEXP_SRC(obj);
    struct ibf_object_regexp regexp;
    regexp.option = (char)rb_reg_options(obj);
    regexp.srcstr = (long)ibf_dump_object(dump, srcstr);
    ibf_dump_write_byte(dump, (unsigned char)regexp.option);
    ibf_dump_write_small_value(dump, regexp.srcstr);
}
static VALUE
ibf_load_object_regexp(const struct ibf_load *load, const struct ibf_object_header *header, ibf_offset_t offset)
{
    struct ibf_object_regexp regexp;
    regexp.option = ibf_load_byte(load, &offset);
    regexp.srcstr = ibf_load_small_value(load, &offset);
    VALUE srcstr = ibf_load_object(load, regexp.srcstr);
    VALUE reg = rb_reg_compile(srcstr, (int)regexp.option, ((void *)0), 0);
    if (header->internal) rb_obj_hide(reg);
    if (header->frozen) rb_obj_freeze(reg);
    return reg;
}
static void
ibf_dump_object_array(struct ibf_dump *dump, VALUE obj)
{
    long i, len = rb_array_len(obj);
    ibf_dump_write_small_value(dump, len);
    for (i=0; i<len; i++) {
        long index = (long)ibf_dump_object(dump, RARRAY_AREF(obj, i));
        ibf_dump_write_small_value(dump, index);
    }
}
static VALUE
ibf_load_object_array(const struct ibf_load *load, const struct ibf_object_header *header, ibf_offset_t offset)
{
    ibf_offset_t reading_pos = offset;
    const long len = (long)ibf_load_small_value(load, &reading_pos);
    VALUE ary = header->internal ? rb_ary_hidden_new(len) : rb_ary_new_capa(len);
    int i;
    for (i=0; i<len; i++) {
        const VALUE index = ibf_load_small_value(load, &reading_pos);
        rb_ary_push(ary, ibf_load_object(load, index));
    }
    if (header->frozen) rb_ary_freeze(ary);
    return ary;
}
static int
ibf_dump_object_hash_i(st_data_t key, st_data_t val, st_data_t ptr)
{
    struct ibf_dump *dump = (struct ibf_dump *)ptr;
    VALUE key_index = ibf_dump_object(dump, (VALUE)key);
    VALUE val_index = ibf_dump_object(dump, (VALUE)val);
    ibf_dump_write_small_value(dump, key_index);
    ibf_dump_write_small_value(dump, val_index);
    return ST_CONTINUE;
}
static void
ibf_dump_object_hash(struct ibf_dump *dump, VALUE obj)
{
    long len = RHASH_SIZE(obj);
    ibf_dump_write_small_value(dump, (VALUE)len);
    if (len > 0) rb_hash_foreach(obj, ibf_dump_object_hash_i, (VALUE)dump);
}
static VALUE
ibf_load_object_hash(const struct ibf_load *load, const struct ibf_object_header *header, ibf_offset_t offset)
{
    long len = (long)ibf_load_small_value(load, &offset);
    VALUE obj = rb_hash_new_with_size(len);
    int i;
    for (i = 0; i < len; i++) {
        VALUE key_index = ibf_load_small_value(load, &offset);
        VALUE val_index = ibf_load_small_value(load, &offset);
        VALUE key = ibf_load_object(load, key_index);
        VALUE val = ibf_load_object(load, val_index);
        rb_hash_aset(obj, key, val);
    }
    rb_hash_rehash(obj);
    if (header->internal) rb_obj_hide(obj);
    if (header->frozen) rb_obj_freeze(obj);
    return obj;
}
static void
ibf_dump_object_struct(struct ibf_dump *dump, VALUE obj)
{
    if (rb_obj_is_kind_of(obj, rb_cRange)) {
        struct ibf_object_struct_range range;
        VALUE beg, end;
        memset(&(range), 0, sizeof(range));
        range.len = 3;
        range.class_index = 0;
        rb_range_values(obj, &beg, &end, &range.excl);
        range.beg = (long)ibf_dump_object(dump, beg);
        range.end = (long)ibf_dump_object(dump, end);
        (__extension__(_Alignof(struct ibf_object_struct_range)) > 1 ? ibf_dump_align(dump, __extension__(_Alignof(struct ibf_object_struct_range))) : (void)0);
        ibf_dump_write(dump, &(range), sizeof(range));
    }
    else {
        rb_raise(rb_eNotImpError, "ibf_dump_object_struct: unsupported class %""l""i" "\v",
                 rb_class_name(rb_class_of(obj)));
    }
}
static VALUE
ibf_load_object_struct(const struct ibf_load *load, const struct ibf_object_header *header, ibf_offset_t offset)
{
    const struct ibf_object_struct_range *range = (const struct ibf_object_struct_range *) ibf_load_check_offset(load, ((((offset) - 1) / (__extension__(_Alignof(struct ibf_object_struct_range))) + 1) * (__extension__(_Alignof(struct ibf_object_struct_range)))));
    VALUE beg = ibf_load_object(load, range->beg);
    VALUE end = ibf_load_object(load, range->end);
    VALUE obj = rb_range_new(beg, end, range->excl);
    if (header->internal) rb_obj_hide(obj);
    if (header->frozen) rb_obj_freeze(obj);
    return obj;
}
static void
ibf_dump_object_bignum(struct ibf_dump *dump, VALUE obj)
{
    ssize_t len = BIGNUM_LEN(obj);
    ssize_t slen = BIGNUM_SIGN(obj) > 0 ? len : len * -1;
    unsigned int *d = BIGNUM_DIGITS(obj);
    (void)((__extension__(_Alignof(ssize_t)) > 1 ? ibf_dump_align(dump, __extension__(_Alignof(ssize_t))) : (void)0), (ssize_t *)(VALUE)ibf_dump_write(dump, (&slen), sizeof(ssize_t) * (1)));
    ibf_dump_write(dump, (d), sizeof(unsigned int) * (len));
}
static VALUE
ibf_load_object_bignum(const struct ibf_load *load, const struct ibf_object_header *header, ibf_offset_t offset)
{
    const struct ibf_object_bignum *bignum = (const struct ibf_object_bignum *) ibf_load_check_offset(load, ((((offset) - 1) / (__extension__(_Alignof(struct ibf_object_bignum))) + 1) * (__extension__(_Alignof(struct ibf_object_bignum)))));
    int sign = bignum->slen > 0;
    ssize_t len = sign > 0 ? bignum->slen : -1 * bignum->slen;
    const int big_unpack_flags =
        0x02 |
        0x40;
    VALUE obj = rb_integer_unpack(bignum->digits, len, sizeof(unsigned int), 0,
                                  big_unpack_flags |
                                  (sign == 0 ? 0x200 : 0));
    if (header->internal) rb_obj_hide(obj);
    if (header->frozen) rb_obj_freeze(obj);
    return obj;
}
static void
ibf_dump_object_data(struct ibf_dump *dump, VALUE obj)
{
    if (rb_data_is_encoding(obj)) {
        rb_encoding *enc = rb_to_encoding(obj);
        const char *name = rb_enc_name(enc);
        long len = strlen(name) + 1;
        long data[2];
        data[0] = IBF_OBJECT_DATA_ENCODING;
        data[1] = len;
        (void)((__extension__(_Alignof(long)) > 1 ? ibf_dump_align(dump, __extension__(_Alignof(long))) : (void)0), (long *)(VALUE)ibf_dump_write(dump, (data), sizeof(long) * (2)));
        ibf_dump_write(dump, (name), sizeof(char) * (len));
    }
    else {
        ibf_dump_object_unsupported(dump, obj);
    }
}
static VALUE
ibf_load_object_data(const struct ibf_load *load, const struct ibf_object_header *header, ibf_offset_t offset)
{
    const long *body = (const long *) ibf_load_check_offset(load, ((((offset) - 1) / (__extension__(_Alignof(long))) + 1) * (__extension__(_Alignof(long)))));
    const enum ibf_object_data_type type = (enum ibf_object_data_type)body[0];
    const char *data = (const char *)&body[2];
    switch (type) {
      case IBF_OBJECT_DATA_ENCODING:
        {
            VALUE encobj = rb_enc_from_encoding(rb_enc_find(data));
            return encobj;
        }
    }
    return ibf_load_object_unsupported(load, header, offset);
}
static void
ibf_dump_object_complex_rational(struct ibf_dump *dump, VALUE obj)
{
    long data[2];
    data[0] = (long)ibf_dump_object(dump, ((struct RComplex *)(obj))->real);
    data[1] = (long)ibf_dump_object(dump, ((struct RComplex *)(obj))->imag);
    (void)((__extension__(_Alignof(long)) > 1 ? ibf_dump_align(dump, __extension__(_Alignof(long))) : (void)0), (long *)(VALUE)ibf_dump_write(dump, (data), sizeof(long) * (2)));
}
static VALUE
ibf_load_object_complex_rational(const struct ibf_load *load, const struct ibf_object_header *header, ibf_offset_t offset)
{
    const struct ibf_object_complex_rational *nums = (const struct ibf_object_complex_rational *) ibf_load_check_offset(load, ((((offset) - 1) / (__extension__(_Alignof(struct ibf_object_complex_rational))) + 1) * (__extension__(_Alignof(struct ibf_object_complex_rational)))));
    VALUE a = ibf_load_object(load, nums->a);
    VALUE b = ibf_load_object(load, nums->b);
    VALUE obj = header->type == RUBY_T_COMPLEX ?
      rb_complex_new(a, b) : rb_rational_new(a, b);
    if (header->internal) rb_obj_hide(obj);
    if (header->frozen) rb_obj_freeze(obj);
    return obj;
}
static void
ibf_dump_object_symbol(struct ibf_dump *dump, VALUE obj)
{
    ibf_dump_object_string(dump, rb_sym2str(obj));
}
static VALUE
ibf_load_object_symbol(const struct ibf_load *load, const struct ibf_object_header *header, ibf_offset_t offset)
{
    ibf_offset_t reading_pos = offset;
    int encindex = (int)ibf_load_small_value(load, &reading_pos);
    const long len = (long)ibf_load_small_value(load, &reading_pos);
    const char *ptr = load->current_buffer->buff + reading_pos;
    if (encindex > RUBY_ENCINDEX_BUILTIN_MAX) {
        VALUE enc_name_str = ibf_load_object(load, encindex - RUBY_ENCINDEX_BUILTIN_MAX);
        encindex = rb_enc_find_index(RSTRING_PTR(enc_name_str));
    }
    ID id = rb_intern3(ptr, len, rb_enc_from_index(encindex));
    return rb_id2sym(id);
}
typedef void (*ibf_dump_object_function)(struct ibf_dump *dump, VALUE obj);
static const ibf_dump_object_function dump_object_functions[RUBY_T_MASK+1] = {
    ibf_dump_object_unsupported,
    ibf_dump_object_unsupported,
    ibf_dump_object_class,
    ibf_dump_object_unsupported,
    ibf_dump_object_float,
    ibf_dump_object_string,
    ibf_dump_object_regexp,
    ibf_dump_object_array,
    ibf_dump_object_hash,
    ibf_dump_object_struct,
    ibf_dump_object_bignum,
    ibf_dump_object_unsupported,
    ibf_dump_object_data,
    ibf_dump_object_unsupported,
    ibf_dump_object_complex_rational,
    ibf_dump_object_complex_rational,
    ibf_dump_object_unsupported,
    ibf_dump_object_unsupported,
    ibf_dump_object_unsupported,
    ibf_dump_object_unsupported,
    ibf_dump_object_symbol,
    ibf_dump_object_unsupported,
    ibf_dump_object_unsupported,
    ibf_dump_object_unsupported,
    ibf_dump_object_unsupported,
    ibf_dump_object_unsupported,
    ibf_dump_object_unsupported,
    ibf_dump_object_unsupported,
    ibf_dump_object_unsupported,
    ibf_dump_object_unsupported,
    ibf_dump_object_unsupported,
    ibf_dump_object_unsupported,
};
static void
ibf_dump_object_object_header(struct ibf_dump *dump, const struct ibf_object_header header)
{
    unsigned char byte =
        (header.type << 0) |
        (header.special_const << 5) |
        (header.frozen << 6) |
        (header.internal << 7);
    ibf_dump_write(dump, &(byte), sizeof(byte));
}
static struct ibf_object_header
ibf_load_object_object_header(const struct ibf_load *load, ibf_offset_t *offset)
{
    unsigned char byte = ibf_load_byte(load, offset);
    struct ibf_object_header header;
    header.type = (byte >> 0) & 0x1f;
    header.special_const = (byte >> 5) & 0x01;
    header.frozen = (byte >> 6) & 0x01;
    header.internal = (byte >> 7) & 0x01;
    return header;
}
static ibf_offset_t
ibf_dump_object_object(struct ibf_dump *dump, VALUE obj)
{
    struct ibf_object_header obj_header;
    ibf_offset_t current_offset;
    memset(&(obj_header), 0, sizeof(obj_header));
    obj_header.type = ((int)rb_type(obj));
    (__extension__(_Alignof(ibf_offset_t)) > 1 ? ibf_dump_align(dump, __extension__(_Alignof(ibf_offset_t))) : (void)0);
    current_offset = ibf_dump_pos(dump);
    if (RB_SPECIAL_CONST_P(obj) &&
        ! (RB_SYMBOL_P(obj) ||
           RB_FLOAT_TYPE_P(obj))) {
        obj_header.special_const = 1;
        obj_header.frozen = 1;
        obj_header.internal = 1;
        ibf_dump_object_object_header(dump, obj_header);
        ibf_dump_write_small_value(dump, obj);
    }
    else {
        obj_header.internal = RB_SPECIAL_CONST_P(obj) ? 0 : (RBASIC_CLASS(obj) == 0) ? 1 : 0;
        obj_header.special_const = 0;
        obj_header.frozen = RB_FL_TEST(obj, ((VALUE)RUBY_FL_FREEZE)) ? 1 : 0;
        ibf_dump_object_object_header(dump, obj_header);
        (*dump_object_functions[obj_header.type])(dump, obj);
    }
    return current_offset;
}
typedef VALUE (*ibf_load_object_function)(const struct ibf_load *load, const struct ibf_object_header *header, ibf_offset_t offset);
static const ibf_load_object_function load_object_functions[RUBY_T_MASK+1] = {
    ibf_load_object_unsupported,
    ibf_load_object_unsupported,
    ibf_load_object_class,
    ibf_load_object_unsupported,
    ibf_load_object_float,
    ibf_load_object_string,
    ibf_load_object_regexp,
    ibf_load_object_array,
    ibf_load_object_hash,
    ibf_load_object_struct,
    ibf_load_object_bignum,
    ibf_load_object_unsupported,
    ibf_load_object_data,
    ibf_load_object_unsupported,
    ibf_load_object_complex_rational,
    ibf_load_object_complex_rational,
    ibf_load_object_unsupported,
    ibf_load_object_unsupported,
    ibf_load_object_unsupported,
    ibf_load_object_unsupported,
    ibf_load_object_symbol,
    ibf_load_object_unsupported,
    ibf_load_object_unsupported,
    ibf_load_object_unsupported,
    ibf_load_object_unsupported,
    ibf_load_object_unsupported,
    ibf_load_object_unsupported,
    ibf_load_object_unsupported,
    ibf_load_object_unsupported,
    ibf_load_object_unsupported,
    ibf_load_object_unsupported,
    ibf_load_object_unsupported,
};
static VALUE
ibf_load_object(const struct ibf_load *load, VALUE object_index)
{
    if (object_index == 0) {
        return ((VALUE)RUBY_Qnil);
    }
    else {
        VALUE obj = pinned_list_fetch(load->current_buffer->obj_list, (long)object_index);
        if (!obj) {
            ibf_offset_t *offsets = (ibf_offset_t *)(load->current_buffer->obj_list_offset + load->current_buffer->buff);
            ibf_offset_t offset = offsets[object_index];
            const struct ibf_object_header header = ibf_load_object_object_header(load, &offset);
            if (offset >= load->current_buffer->size) {
                rb_raise(rb_eIndexError, "object offset out of range: %u", offset);
            }
            if (header.special_const) {
                ibf_offset_t reading_pos = offset;
                obj = ibf_load_small_value(load, &reading_pos);
            }
            else {
                obj = (*load_object_functions[header.type])(load, &header, offset);
            }
            pinned_list_store(load->current_buffer->obj_list, (long)object_index, obj);
        }
        return obj;
    }
}
struct ibf_dump_object_list_arg
{
    struct ibf_dump *dump;
    VALUE offset_list;
};
static int
ibf_dump_object_list_i(st_data_t key, st_data_t val, st_data_t ptr)
{
    VALUE obj = (VALUE)key;
    struct ibf_dump_object_list_arg *args = (struct ibf_dump_object_list_arg *)ptr;
    ibf_offset_t offset = ibf_dump_object_object(args->dump, obj);
    rb_ary_push(args->offset_list, rb_uint2num_inline(offset));
    return ST_CONTINUE;
}
static void
ibf_dump_object_list(struct ibf_dump *dump, ibf_offset_t *obj_list_offset, unsigned int *obj_list_size)
{
    st_table *obj_table = dump->current_buffer->obj_table;
    VALUE offset_list = rb_ary_hidden_new(obj_table->num_entries);
    struct ibf_dump_object_list_arg args;
    args.dump = dump;
    args.offset_list = offset_list;
    rb_st_foreach(obj_table, ibf_dump_object_list_i, (st_data_t)&args);
    (__extension__(_Alignof(ibf_offset_t)) > 1 ? ibf_dump_align(dump, __extension__(_Alignof(ibf_offset_t))) : (void)0);
    *obj_list_offset = ibf_dump_pos(dump);
    st_index_t size = obj_table->num_entries;
    st_index_t i;
    for (i=0; i<size; i++) {
        ibf_offset_t offset = RB_NUM2UINT(RARRAY_AREF(offset_list, i));
        ibf_dump_write(dump, &(offset), sizeof(offset));
    }
    *obj_list_size = (unsigned int)size;
}
static void
ibf_dump_mark(void *ptr)
{
    struct ibf_dump *dump = (struct ibf_dump *)ptr;
    rb_gc_mark(dump->global_buffer.str);
    rb_mark_set(dump->global_buffer.obj_table);
    rb_mark_set(dump->iseq_table);
}
static void
ibf_dump_free(void *ptr)
{
    struct ibf_dump *dump = (struct ibf_dump *)ptr;
    if (dump->global_buffer.obj_table) {
        rb_st_free_table(dump->global_buffer.obj_table);
        dump->global_buffer.obj_table = 0;
    }
    if (dump->iseq_table) {
        rb_st_free_table(dump->iseq_table);
        dump->iseq_table = 0;
    }
}
static size_t
ibf_dump_memsize(const void *ptr)
{
    struct ibf_dump *dump = (struct ibf_dump *)ptr;
    size_t size = 0;
    if (dump->iseq_table) size += rb_st_memsize(dump->iseq_table);
    if (dump->global_buffer.obj_table) size += rb_st_memsize(dump->global_buffer.obj_table);
    return size;
}
static const rb_data_type_t ibf_dump_type = {
    "ibf_dump",
    {ibf_dump_mark, ibf_dump_free, ibf_dump_memsize,},
    0, 0, RUBY_TYPED_FREE_IMMEDIATELY | RUBY_TYPED_EMBEDDABLE
};
static void
ibf_dump_setup(struct ibf_dump *dump, VALUE dumper_obj)
{
    dump->global_buffer.obj_table = ((void *)0);
    dump->iseq_table = ((void *)0);
    (rb_obj_write((VALUE)(dumper_obj), (VALUE *)(&dump->global_buffer.str), (VALUE)(((__builtin_constant_p(0) && __builtin_constant_p(0) ? rb_str_new_static : rb_str_new) ((0), (0)))), "compile.c", 14453));
    dump->global_buffer.obj_table = ibf_dump_object_table_new();
    dump->iseq_table = rb_st_init_numtable();
    dump->current_buffer = &dump->global_buffer;
}
VALUE
rb_iseq_ibf_dump(const rb_iseq_t *iseq, VALUE opt)
{
    struct ibf_dump *dump;
    struct ibf_header header = {{0}};
    VALUE dump_obj;
    VALUE str;
    if (((iseq)->body)->parent_iseq != ((void *)0) ||
        ((iseq)->body)->local_iseq != iseq) {
        rb_raise(rb_eRuntimeError, "should be top of iseq");
    }
    if (RB_TEST(((iseq)->body)->variable.coverage)) {
        rb_raise(rb_eRuntimeError, "should not compile with coverage");
    }
    dump_obj = __extension__({ VALUE data_struct_obj = rb_data_typed_object_zalloc(0, sizeof(struct ibf_dump), &ibf_dump_type); (dump) = (struct ibf_dump *)RTYPEDDATA_GET_DATA(data_struct_obj); ((void)(dump)); data_struct_obj; });
    ibf_dump_setup(dump, dump_obj);
    ibf_dump_write(dump, &header, sizeof(header));
    ibf_dump_iseq(dump, iseq);
    header.magic[0] = 'Y';
    header.magic[1] = 'A';
    header.magic[2] = 'R';
    header.magic[3] = 'B';
    header.major_version = ((unsigned int)ruby_api_version[0]);
    header.minor_version = ((unsigned int)ruby_api_version[1]);
    header.endian = IBF_ENDIAN_MARK;
    header.wordsize = (uint8_t)8;
    ibf_dump_iseq_list(dump, &header);
    ibf_dump_object_list(dump, &header.global_object_list_offset, &header.global_object_list_size);
    header.size = ibf_dump_pos(dump);
    if (RB_TEST(opt)) {
        VALUE opt_str = opt;
        const char *ptr = rb_string_value_ptr(&(opt_str));
        header.extra_size = RSTRING_LENINT(opt_str);
        ibf_dump_write(dump, ptr, header.extra_size);
    }
    else {
        header.extra_size = 0;
    }
    ibf_dump_overwrite(dump, &header, sizeof(header), 0);
    str = dump->global_buffer.str;
    (*__extension__ ({ volatile VALUE *rb_gc_guarded_ptr = &(dump_obj); __asm__("" : : "m"(rb_gc_guarded_ptr)); rb_gc_guarded_ptr; }));
    return str;
}
static const ibf_offset_t *
ibf_iseq_list(const struct ibf_load *load)
{
    return (const ibf_offset_t *)(load->global_buffer.buff + load->header->iseq_list_offset);
}
void
rb_ibf_load_iseq_complete(rb_iseq_t *iseq)
{
    struct ibf_load *load = (((struct RTypedData *)(iseq->aux.loader.obj))->data);
    rb_iseq_t *prev_src_iseq = load->iseq;
    ibf_offset_t offset = ibf_iseq_list(load)[iseq->aux.loader.index];
    load->iseq = iseq;
    ibf_load_iseq_each(load, iseq, offset);
    ISEQ_COMPILE_DATA_CLEAR(iseq);
    RB_FL_UNSET((VALUE)iseq, ((VALUE)RUBY_FL_USER5));
    rb_iseq_init_trace(iseq);
    load->iseq = prev_src_iseq;
}
static rb_iseq_t *
ibf_load_iseq(const struct ibf_load *load, const rb_iseq_t *index_iseq)
{
    int iseq_index = (int)(VALUE)index_iseq;
    if (iseq_index == -1) {
        return ((void *)0);
    }
    else {
        VALUE iseqv = pinned_list_fetch(load->iseq_list, iseq_index);
        if (iseqv) {
            return (rb_iseq_t *)iseqv;
        }
        else {
            rb_iseq_t *iseq = iseq_imemo_alloc();
            RB_FL_SET((VALUE)iseq, ((VALUE)RUBY_FL_USER5));
            iseq->aux.loader.obj = load->loader_obj;
            iseq->aux.loader.index = iseq_index;
            pinned_list_store(load->iseq_list, iseq_index, (VALUE)iseq);
            if (!0 || rb_current_vm()->builtin_function_table) {
                rb_ibf_load_iseq_complete(iseq);
            }
            return iseq;
        }
    }
}
static void
ibf_load_setup_bytes(struct ibf_load *load, VALUE loader_obj, const char *bytes, size_t size)
{
    struct ibf_header *header = (struct ibf_header *)bytes;
    load->loader_obj = loader_obj;
    load->global_buffer.buff = bytes;
    load->header = header;
    load->global_buffer.size = header->size;
    load->global_buffer.obj_list_offset = header->global_object_list_offset;
    load->global_buffer.obj_list_size = header->global_object_list_size;
    (rb_obj_write((VALUE)(loader_obj), (VALUE *)(&load->iseq_list), (VALUE)(pinned_list_new(header->iseq_list_size)), "compile.c", 14606));
    (rb_obj_write((VALUE)(loader_obj), (VALUE *)(&load->global_buffer.obj_list), (VALUE)(pinned_list_new(load->global_buffer.obj_list_size)), "compile.c", 14607));
    load->iseq = ((void *)0);
    load->current_buffer = &load->global_buffer;
    if (size < header->size) {
        rb_raise(rb_eRuntimeError, "broken binary format");
    }
    if (strncmp(header->magic, "YARB", 4) != 0) {
        rb_raise(rb_eRuntimeError, "unknown binary format");
    }
    if (header->major_version != ((unsigned int)ruby_api_version[0]) ||
        header->minor_version != ((unsigned int)ruby_api_version[1])) {
        rb_raise(rb_eRuntimeError, "unmatched version file (%u.%u for %u.%u)",
                 header->major_version, header->minor_version, ((unsigned int)ruby_api_version[0]), ((unsigned int)ruby_api_version[1]));
    }
    if (header->endian != IBF_ENDIAN_MARK) {
        rb_raise(rb_eRuntimeError, "unmatched endian: %c", header->endian);
    }
    if (header->wordsize != 8) {
        rb_raise(rb_eRuntimeError, "unmatched word size: %d", header->wordsize);
    }
    if (header->iseq_list_offset % __extension__(_Alignof(ibf_offset_t))) {
        rb_raise(rb_eArgError, "unaligned iseq list offset: %u",
                 header->iseq_list_offset);
    }
    if (load->global_buffer.obj_list_offset % __extension__(_Alignof(ibf_offset_t))) {
        rb_raise(rb_eArgError, "unaligned object list offset: %u",
                 load->global_buffer.obj_list_offset);
    }
}
static void
ibf_load_setup(struct ibf_load *load, VALUE loader_obj, VALUE str)
{
    rb_string_value(&(str));
    if (RSTRING_LENINT(str) < (int)sizeof(struct ibf_header)) {
        rb_raise(rb_eRuntimeError, "broken binary format");
    }
    if (0) {
        str = ((__builtin_constant_p(RSTRING_PTR(str)) && __builtin_constant_p(RSTRING_LEN(str)) ? rb_str_new_static : rb_str_new) ((RSTRING_PTR(str)), (RSTRING_LEN(str))));
    }
    ibf_load_setup_bytes(load, loader_obj, RSTRING_PTR(str), RSTRING_LEN(str));
    (rb_obj_write((VALUE)(loader_obj), (VALUE *)(&load->str), (VALUE)(str), "compile.c", 14653));
}
static void
ibf_loader_mark(void *ptr)
{
    struct ibf_load *load = (struct ibf_load *)ptr;
    rb_gc_mark(load->str);
    rb_gc_mark(load->iseq_list);
    rb_gc_mark(load->global_buffer.obj_list);
}
static void
ibf_loader_free(void *ptr)
{
    struct ibf_load *load = (struct ibf_load *)ptr;
    ruby_xfree(load);
}
static size_t
ibf_loader_memsize(const void *ptr)
{
    return sizeof(struct ibf_load);
}
static const rb_data_type_t ibf_load_type = {
    "ibf_loader",
    {ibf_loader_mark, ibf_loader_free, ibf_loader_memsize,},
    0, 0, RUBY_TYPED_WB_PROTECTED | RUBY_TYPED_FREE_IMMEDIATELY
};
const rb_iseq_t *
rb_iseq_ibf_load(VALUE str)
{
    struct ibf_load *load;
    rb_iseq_t *iseq;
    VALUE loader_obj = __extension__({ VALUE data_struct_obj = rb_data_typed_object_zalloc(0, sizeof(struct ibf_load), &ibf_load_type); (load) = (struct ibf_load *)RTYPEDDATA_GET_DATA(data_struct_obj); ((void)(load)); data_struct_obj; });
    ibf_load_setup(load, loader_obj, str);
    iseq = ibf_load_iseq(load, 0);
    (*__extension__ ({ volatile VALUE *rb_gc_guarded_ptr = &(loader_obj); __asm__("" : : "m"(rb_gc_guarded_ptr)); rb_gc_guarded_ptr; }));
    return iseq;
}
const rb_iseq_t *
rb_iseq_ibf_load_bytes(const char *bytes, size_t size)
{
    struct ibf_load *load;
    rb_iseq_t *iseq;
    VALUE loader_obj = __extension__({ VALUE data_struct_obj = rb_data_typed_object_zalloc(0, sizeof(struct ibf_load), &ibf_load_type); (load) = (struct ibf_load *)RTYPEDDATA_GET_DATA(data_struct_obj); ((void)(load)); data_struct_obj; });
    ibf_load_setup_bytes(load, loader_obj, bytes, size);
    iseq = ibf_load_iseq(load, 0);
    (*__extension__ ({ volatile VALUE *rb_gc_guarded_ptr = &(loader_obj); __asm__("" : : "m"(rb_gc_guarded_ptr)); rb_gc_guarded_ptr; }));
    return iseq;
}
VALUE
rb_iseq_ibf_load_extra_data(VALUE str)
{
    struct ibf_load *load;
    VALUE loader_obj = __extension__({ VALUE data_struct_obj = rb_data_typed_object_zalloc(0, sizeof(struct ibf_load), &ibf_load_type); (load) = (struct ibf_load *)RTYPEDDATA_GET_DATA(data_struct_obj); ((void)(load)); data_struct_obj; });
    VALUE extra_str;
    ibf_load_setup(load, loader_obj, str);
    extra_str = ((__builtin_constant_p(load->global_buffer.buff + load->header->size) && __builtin_constant_p(load->header->extra_size) ? rb_str_new_static : rb_str_new) ((load->global_buffer.buff + load->header->size), (load->header->extra_size)));
    (*__extension__ ({ volatile VALUE *rb_gc_guarded_ptr = &(loader_obj); __asm__("" : : "m"(rb_gc_guarded_ptr)); rb_gc_guarded_ptr; }));
    return extra_str;
}
typedef struct {
    int32_t line;
    uint32_t node_id;
} pm_node_location_t;
static void
pm_iseq_add_getlocal(rb_iseq_t *iseq, LINK_ANCHOR *const seq, int line, int node_id, int idx, int level)
{
    if (iseq_local_block_param_p(iseq, idx, level)) {
        ADD_ELEM(seq, (LINK_ELEMENT *) new_insn_body(iseq, line, node_id, YARVINSN_getblockparam, 2, __builtin_choose_expr( __builtin_constant_p((idx) + ( 3) - 1), ((VALUE)((idx) + ( 3) - 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((idx) + ( 3) - 1)), __builtin_choose_expr( __builtin_constant_p(level), ((VALUE)(level)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(level))));
    }
    else {
        ADD_ELEM(seq, (LINK_ELEMENT *) new_insn_body(iseq, line, node_id, YARVINSN_getlocal, 2, __builtin_choose_expr( __builtin_constant_p((idx) + ( 3) - 1), ((VALUE)((idx) + ( 3) - 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((idx) + ( 3) - 1)), __builtin_choose_expr( __builtin_constant_p(level), ((VALUE)(level)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(level))));
    }
    if (level > 0) access_outer_variables(iseq, level, iseq_lvar_id(iseq, idx, level), ((VALUE)RUBY_Qfalse));
}
static void
pm_iseq_add_setlocal(rb_iseq_t *iseq, LINK_ANCHOR *const seq, int line, int node_id, int idx, int level)
{
    if (iseq_local_block_param_p(iseq, idx, level)) {
        ADD_ELEM(seq, (LINK_ELEMENT *) new_insn_body(iseq, line, node_id, YARVINSN_setblockparam, 2, __builtin_choose_expr( __builtin_constant_p((idx) + ( 3) - 1), ((VALUE)((idx) + ( 3) - 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((idx) + ( 3) - 1)), __builtin_choose_expr( __builtin_constant_p(level), ((VALUE)(level)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(level))));
    }
    else {
        ADD_ELEM(seq, (LINK_ELEMENT *) new_insn_body(iseq, line, node_id, YARVINSN_setlocal, 2, __builtin_choose_expr( __builtin_constant_p((idx) + ( 3) - 1), ((VALUE)((idx) + ( 3) - 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((idx) + ( 3) - 1)), __builtin_choose_expr( __builtin_constant_p(level), ((VALUE)(level)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(level))));
    }
    if (level > 0) access_outer_variables(iseq, level, iseq_lvar_id(iseq, idx, level), ((VALUE)RUBY_Qtrue));
}
static int
pm_node_line_number(const pm_parser_t *parser, const pm_node_t *node)
{
    return (int) pm_newline_list_line(&parser->newline_list, node->location.start, parser->start_line);
}
static int
pm_location_line_number(const pm_parser_t *parser, const pm_location_t *location) {
    return (int) pm_newline_list_line(&parser->newline_list, location->start, parser->start_line);
}
static VALUE
parse_integer_value(const pm_integer_t *integer)
{
    VALUE result;
    if (integer->values == ((void *)0)) {
        result = rb_uint2num_inline(integer->value);
    }
    else {
        VALUE string = ((__builtin_constant_p(((void *)0)) && __builtin_constant_p(integer->length * 8) ? rb_str_new_static : rb_str_new) ((((void *)0)), (integer->length * 8)));
        unsigned char *bytes = (unsigned char *) RSTRING_PTR(string);
        size_t offset = integer->length * 8;
        for (size_t value_index = 0; value_index < integer->length; value_index++) {
            uint32_t value = integer->values[value_index];
            for (int index = 0; index < 8; index++) {
                int byte = (value >> (4 * index)) & 0xf;
                bytes[--offset] = byte < 10 ? byte + '0' : byte - 10 + 'a';
            }
        }
        result = rb_funcall(string, (__builtin_constant_p("to_i") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("to_i")); }) : (rb_intern)("to_i")), 1, rb_uint2num_inline(16));
    }
    if (integer->negative) {
        result = rb_funcall(result, (__builtin_constant_p("-@") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("-@")); }) : (rb_intern)("-@")), 0);
    }
    return result;
}
static inline VALUE
parse_integer(const pm_integer_node_t *node)
{
    return parse_integer_value(&node->value);
}
static VALUE
parse_float(const pm_float_node_t *node)
{
    return rb_float_new_inline(node->value);
}
static VALUE
parse_rational(const pm_rational_node_t *node)
{
    VALUE numerator = parse_integer_value(&node->numerator);
    VALUE denominator = parse_integer_value(&node->denominator);
    return rb_rational_new(numerator, denominator);
}
static VALUE
parse_imaginary(const pm_imaginary_node_t *node)
{
    VALUE imaginary_part;
    switch (((enum pm_node_type) (node->numeric)->type)) {
      case PM_FLOAT_NODE: {
        imaginary_part = parse_float((const pm_float_node_t *) node->numeric);
        break;
      }
      case PM_INTEGER_NODE: {
        imaginary_part = parse_integer((const pm_integer_node_t *) node->numeric);
        break;
      }
      case PM_RATIONAL_NODE: {
        imaginary_part = parse_rational((const pm_rational_node_t *) node->numeric);
        break;
      }
      default:
        rb_bug("Unexpected numeric type on imaginary number %s\n", pm_node_type_to_str(((enum pm_node_type) (node->numeric)->type)));
    }
    return rb_complex_raw(__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)), imaginary_part);
}
static inline VALUE
parse_string(const pm_scope_node_t *scope_node, const pm_string_t *string)
{
    return ((__builtin_constant_p((const char *) pm_string_source(string)) && __builtin_constant_p(pm_string_length(string)) ? rb_enc_str_new_static: rb_enc_str_new) (((const char *) pm_string_source(string)), (pm_string_length(string)), (scope_node->encoding)));
}
static inline VALUE
parse_string_encoded(const pm_node_t *node, const pm_string_t *string, rb_encoding *default_encoding)
{
    rb_encoding *encoding;
    if (node->flags & PM_ENCODING_FLAGS_FORCED_BINARY_ENCODING) {
        encoding = rb_ascii8bit_encoding();
    }
    else if (node->flags & PM_ENCODING_FLAGS_FORCED_UTF8_ENCODING) {
        encoding = rb_utf8_encoding();
    }
    else {
        encoding = default_encoding;
    }
    return ((__builtin_constant_p((const char *) pm_string_source(string)) && __builtin_constant_p(pm_string_length(string)) ? rb_enc_str_new_static: rb_enc_str_new) (((const char *) pm_string_source(string)), (pm_string_length(string)), (encoding)));
}
static inline VALUE
parse_static_literal_string(rb_iseq_t *iseq, const pm_scope_node_t *scope_node, const pm_node_t *node, const pm_string_t *string)
{
    rb_encoding *encoding;
    if (node->flags & PM_STRING_FLAGS_FORCED_BINARY_ENCODING) {
        encoding = rb_ascii8bit_encoding();
    }
    else if (node->flags & PM_STRING_FLAGS_FORCED_UTF8_ENCODING) {
        encoding = rb_utf8_encoding();
    }
    else {
        encoding = scope_node->encoding;
    }
    VALUE value = rb_enc_literal_str((const char *) pm_string_source(string), pm_string_length(string), encoding);
    rb_enc_str_coderange(value);
    if (ISEQ_COMPILE_DATA(iseq)->option->debug_frozen_string_literal || RB_TEST((*rb_ruby_debug_ptr()))) {
        int line_number = pm_node_line_number(scope_node->parser, node);
        value = rb_str_with_debug_created_info(value, rb_iseq_path(iseq), line_number);
    }
    return value;
}
static inline ID
parse_string_symbol(const pm_scope_node_t *scope_node, const pm_symbol_node_t *symbol)
{
    rb_encoding *encoding;
    if (symbol->base.flags & PM_SYMBOL_FLAGS_FORCED_UTF8_ENCODING) {
        encoding = rb_utf8_encoding();
    }
    else if (symbol->base.flags & PM_SYMBOL_FLAGS_FORCED_BINARY_ENCODING) {
        encoding = rb_ascii8bit_encoding();
    }
    else if (symbol->base.flags & PM_SYMBOL_FLAGS_FORCED_US_ASCII_ENCODING) {
        encoding = rb_usascii_encoding();
    }
    else {
        encoding = scope_node->encoding;
    }
    return rb_intern3((const char *) pm_string_source(&symbol->unescaped), pm_string_length(&symbol->unescaped), encoding);
}
static int
pm_optimizable_range_item_p(const pm_node_t *node)
{
    return (!node || (((enum pm_node_type) (node)->type) == (PM_INTEGER_NODE)) || (((enum pm_node_type) (node)->type) == (PM_NIL_NODE)));
}
static VALUE
parse_regexp_error(rb_iseq_t *iseq, int32_t line_number, const char *fmt, ...)
{
    va_list args;
    __builtin_va_start(args,fmt);
    VALUE error = rb_syntax_error_append(((VALUE)RUBY_Qnil), rb_iseq_path(iseq), line_number, -1, ((void *)0), "%" "l""i" "\v", args);
    __builtin_va_end(args);
    rb_exc_raise(error);
}
static VALUE
parse_regexp_string_part(rb_iseq_t *iseq, const pm_scope_node_t *scope_node, const pm_node_t *node, const pm_string_t *unescaped, rb_encoding *implicit_regexp_encoding, rb_encoding *explicit_regexp_encoding)
{
    rb_encoding *encoding;
    if (explicit_regexp_encoding != ((void *)0)) {
        encoding = explicit_regexp_encoding;
    }
    else if (node->flags & PM_STRING_FLAGS_FORCED_BINARY_ENCODING) {
        encoding = rb_ascii8bit_encoding();
    }
    else if (node->flags & PM_STRING_FLAGS_FORCED_UTF8_ENCODING) {
        encoding = rb_utf8_encoding();
    }
    else {
        encoding = implicit_regexp_encoding;
    }
    VALUE string = ((__builtin_constant_p((const char *) pm_string_source(unescaped)) && __builtin_constant_p(pm_string_length(unescaped)) ? rb_enc_str_new_static: rb_enc_str_new) (((const char *) pm_string_source(unescaped)), (pm_string_length(unescaped)), (encoding)));
    VALUE error = rb_reg_check_preprocess(string);
    if (error != ((VALUE)RUBY_Qnil)) parse_regexp_error(iseq, pm_node_line_number(scope_node->parser, node), "%" "l""i" "\v", rb_obj_as_string(error));
    return string;
}
static VALUE
pm_static_literal_concat(rb_iseq_t *iseq, const pm_node_list_t *nodes, const pm_scope_node_t *scope_node, rb_encoding *implicit_regexp_encoding, rb_encoding *explicit_regexp_encoding, _Bool top)
{
    VALUE current = ((VALUE)RUBY_Qnil);
    for (size_t index = 0; index < nodes->size; index++) {
        const pm_node_t *part = nodes->nodes[index];
        VALUE string;
        switch (((enum pm_node_type) (part)->type)) {
          case PM_STRING_NODE:
            if (implicit_regexp_encoding != ((void *)0)) {
                if (top) {
                    string = parse_regexp_string_part(iseq, scope_node, part, &((const pm_string_node_t *) part)->unescaped, implicit_regexp_encoding, explicit_regexp_encoding);
                }
                else {
                    string = parse_string_encoded(part, &((const pm_string_node_t *) part)->unescaped, scope_node->encoding);
                    VALUE error = rb_reg_check_preprocess(string);
                    if (error != ((VALUE)RUBY_Qnil)) parse_regexp_error(iseq, pm_node_line_number(scope_node->parser, part), "%" "l""i" "\v", rb_obj_as_string(error));
                }
            }
            else {
                string = parse_string_encoded(part, &((const pm_string_node_t *) part)->unescaped, scope_node->encoding);
            }
            break;
          case PM_INTERPOLATED_STRING_NODE:
            string = pm_static_literal_concat(iseq, &((const pm_interpolated_string_node_t *) part)->parts, scope_node, implicit_regexp_encoding, explicit_regexp_encoding, 0);
            break;
          case PM_EMBEDDED_STATEMENTS_NODE: {
            const pm_embedded_statements_node_t *cast = (const pm_embedded_statements_node_t *) part;
            string = pm_static_literal_concat(iseq, &cast->statements->body, scope_node, implicit_regexp_encoding, explicit_regexp_encoding, 0);
            break;
          }
          default:
            ((void)0);
            return ((VALUE)RUBY_Qnil);
        }
        if (current != ((VALUE)RUBY_Qnil)) {
            current = rb_str_concat(current, string);
        }
        else {
            current = string;
        }
    }
    return top ? rb_fstring(current) : current;
}
static int
parse_regexp_flags(const pm_node_t *node)
{
    int flags = 0;
    if (((((pm_node_t *)(node))->flags & (PM_REGULAR_EXPRESSION_FLAGS_ASCII_8BIT)) != 0)) {
        flags |= 32;
    }
    if (((((pm_node_t *)(node))->flags & (PM_REGULAR_EXPRESSION_FLAGS_EUC_JP)) != 0)) {
        flags |= (16 | (((2) & 0xFF) << 8));
    }
    if (((((pm_node_t *)(node))->flags & (PM_REGULAR_EXPRESSION_FLAGS_WINDOWS_31J)) != 0)) {
        flags |= (16 | (((3) & 0xFF) << 8));
    }
    if (((((pm_node_t *)(node))->flags & (PM_REGULAR_EXPRESSION_FLAGS_UTF_8)) != 0)) {
        flags |= (16 | (((4) & 0xFF) << 8));
    }
    if (((((pm_node_t *)(node))->flags & (PM_REGULAR_EXPRESSION_FLAGS_IGNORE_CASE)) != 0)) {
        flags |= 1U;
    }
    if (((((pm_node_t *)(node))->flags & (PM_REGULAR_EXPRESSION_FLAGS_MULTI_LINE)) != 0)) {
        flags |= ((1U << 1) << 1);
    }
    if (((((pm_node_t *)(node))->flags & (PM_REGULAR_EXPRESSION_FLAGS_EXTENDED)) != 0)) {
        flags |= (1U << 1);
    }
    return flags;
}
static rb_encoding *
parse_regexp_encoding(const pm_scope_node_t *scope_node, const pm_node_t *node)
{
    if (((((pm_node_t *)(node))->flags & (PM_REGULAR_EXPRESSION_FLAGS_FORCED_BINARY_ENCODING)) != 0) || ((((pm_node_t *)(node))->flags & (PM_REGULAR_EXPRESSION_FLAGS_ASCII_8BIT)) != 0)) {
        return rb_ascii8bit_encoding();
    }
    else if (((((pm_node_t *)(node))->flags & (PM_REGULAR_EXPRESSION_FLAGS_UTF_8)) != 0)) {
        return rb_utf8_encoding();
    }
    else if (((((pm_node_t *)(node))->flags & (PM_REGULAR_EXPRESSION_FLAGS_EUC_JP)) != 0)) {
        return rb_enc_get_from_index(RUBY_ENCINDEX_EUC_JP);
    }
    else if (((((pm_node_t *)(node))->flags & (PM_REGULAR_EXPRESSION_FLAGS_WINDOWS_31J)) != 0)) {
        return rb_enc_get_from_index(RUBY_ENCINDEX_Windows_31J);
    }
    else {
        return ((void *)0);
    }
}
static VALUE
parse_regexp(rb_iseq_t *iseq, const pm_scope_node_t *scope_node, const pm_node_t *node, VALUE string)
{
    VALUE errinfo = rb_errinfo();
    int32_t line_number = pm_node_line_number(scope_node->parser, node);
    VALUE regexp = rb_reg_compile(string, parse_regexp_flags(node), (const char *) pm_string_source(&scope_node->parser->filepath), line_number);
    if (RB_NIL_P(regexp)) {
        VALUE message = rb_attr_get(rb_errinfo(), idMesg);
        rb_set_errinfo(errinfo);
        parse_regexp_error(iseq, line_number, "%" "l""i" "\v", message);
        return ((VALUE)RUBY_Qnil);
    }
    rb_obj_freeze(regexp);
    return regexp;
}
static inline VALUE
parse_regexp_literal(rb_iseq_t *iseq, const pm_scope_node_t *scope_node, const pm_node_t *node, const pm_string_t *unescaped)
{
    rb_encoding *regexp_encoding = parse_regexp_encoding(scope_node, node);
    if (regexp_encoding == ((void *)0)) regexp_encoding = scope_node->encoding;
    VALUE string = ((__builtin_constant_p((const char *) pm_string_source(unescaped)) && __builtin_constant_p(pm_string_length(unescaped)) ? rb_enc_str_new_static: rb_enc_str_new) (((const char *) pm_string_source(unescaped)), (pm_string_length(unescaped)), (regexp_encoding)));
    return parse_regexp(iseq, scope_node, node, string);
}
static inline VALUE
parse_regexp_concat(rb_iseq_t *iseq, const pm_scope_node_t *scope_node, const pm_node_t *node, const pm_node_list_t *parts)
{
    rb_encoding *explicit_regexp_encoding = parse_regexp_encoding(scope_node, node);
    rb_encoding *implicit_regexp_encoding = explicit_regexp_encoding != ((void *)0) ? explicit_regexp_encoding : scope_node->encoding;
    VALUE string = pm_static_literal_concat(iseq, parts, scope_node, implicit_regexp_encoding, explicit_regexp_encoding, 0);
    return parse_regexp(iseq, scope_node, node, string);
}
static void pm_compile_node(rb_iseq_t *iseq, const pm_node_t *node, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node);
static int
pm_interpolated_node_compile(rb_iseq_t *iseq, const pm_node_list_t *parts, const pm_node_location_t *node_location, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node, rb_encoding *implicit_regexp_encoding, rb_encoding *explicit_regexp_encoding)
{
    int stack_size = 0;
    size_t parts_size = parts->size;
    _Bool interpolated = 0;
    if (parts_size > 0) {
        VALUE current_string = ((VALUE)RUBY_Qnil);
        pm_node_location_t current_location = *node_location;
        for (size_t index = 0; index < parts_size; index++) {
            const pm_node_t *part = parts->nodes[index];
            if ((((enum pm_node_type) (part)->type) == (PM_STRING_NODE))) {
                const pm_string_node_t *string_node = (const pm_string_node_t *) part;
                VALUE string_value;
                if (implicit_regexp_encoding == ((void *)0)) {
                    string_value = parse_string_encoded(part, &string_node->unescaped, scope_node->encoding);
                }
                else {
                    string_value = parse_regexp_string_part(iseq, scope_node, (const pm_node_t *) string_node, &string_node->unescaped, implicit_regexp_encoding, explicit_regexp_encoding);
                }
                if (RB_TEST(current_string)) {
                    current_string = rb_str_concat(current_string, string_value);
                }
                else {
                    current_string = string_value;
                    if (index != 0) current_location = ((pm_node_location_t) { .line = pm_newline_list_line(&(scope_node->parser)->newline_list, ((const pm_node_t *) (part))->location.end, (scope_node->parser)->start_line), .node_id = ((const pm_node_t *) (part))->node_id });
                }
            }
            else {
                interpolated = 1;
                if (
                    (((enum pm_node_type) (part)->type) == (PM_EMBEDDED_STATEMENTS_NODE)) &&
                    ((const pm_embedded_statements_node_t *) part)->statements != ((void *)0) &&
                    ((const pm_embedded_statements_node_t *) part)->statements->body.size == 1 &&
                    (((enum pm_node_type) (((const pm_embedded_statements_node_t *) part)->statements->body.nodes[0])->type) == (PM_STRING_NODE))
                ) {
                    const pm_string_node_t *string_node = (const pm_string_node_t *) ((const pm_embedded_statements_node_t *) part)->statements->body.nodes[0];
                    VALUE string_value;
                    if (implicit_regexp_encoding == ((void *)0)) {
                        string_value = parse_string_encoded(part, &string_node->unescaped, scope_node->encoding);
                    }
                    else {
                        string_value = parse_regexp_string_part(iseq, scope_node, (const pm_node_t *) string_node, &string_node->unescaped, implicit_regexp_encoding, explicit_regexp_encoding);
                    }
                    if (RB_TEST(current_string)) {
                        current_string = rb_str_concat(current_string, string_value);
                    }
                    else {
                        current_string = string_value;
                        current_location = ((pm_node_location_t) { .line = pm_newline_list_line(&(scope_node->parser)->newline_list, ((const pm_node_t *) (part))->location.start, (scope_node->parser)->start_line), .node_id = ((const pm_node_t *) (part))->node_id });
                    }
                }
                else {
                    if (!RB_TEST(current_string)) {
                        rb_encoding *encoding;
                        if (implicit_regexp_encoding != ((void *)0)) {
                            if (explicit_regexp_encoding != ((void *)0)) {
                                encoding = explicit_regexp_encoding;
                            }
                            else if (scope_node->parser->encoding == (&pm_encodings[PM_ENCODING_US_ASCII])) {
                                encoding = rb_ascii8bit_encoding();
                            }
                            else {
                                encoding = implicit_regexp_encoding;
                            }
                        }
                        else {
                            encoding = scope_node->encoding;
                        }
                        if (parts_size == 1) {
                            current_string = ((__builtin_constant_p(((void *)0)) && __builtin_constant_p(0) ? rb_enc_str_new_static: rb_enc_str_new) ((((void *)0)), (0), (encoding)));
                        }
                    }
                    if (RB_TEST(current_string)) {
                        VALUE operand = rb_fstring(current_string);
                        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (current_location).line, (int) (current_location).node_id, YARVINSN_putobject, 1, (VALUE)(operand)));
                        stack_size++;
                    }
                    pm_compile_node(iseq, (part), ret, 0, scope_node);
                    const pm_node_location_t current_location = ((pm_node_location_t) { .line = pm_newline_list_line(&(scope_node->parser)->newline_list, ((const pm_node_t *) (part))->location.start, (scope_node->parser)->start_line), .node_id = ((const pm_node_t *) (part))->node_id });
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (current_location).line, (int) (current_location).node_id, YARVINSN_dup, 0));
                    {
                        const struct rb_callinfo *callinfo = new_callinfo(iseq, idTo_s, 0, (0x01 << VM_CALL_FCALL_bit) | (0x01 << VM_CALL_ARGS_SIMPLE_bit), ((void *)0), 0);
                        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (current_location).line, (int) (current_location).node_id, YARVINSN_objtostring, 1, (VALUE)(callinfo)));
                    }
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (current_location).line, (int) (current_location).node_id, YARVINSN_anytostring, 0));
                    current_string = ((VALUE)RUBY_Qnil);
                    stack_size++;
                }
            }
        }
        if (RB_TEST(current_string)) {
            current_string = rb_fstring(current_string);
            if (stack_size == 0 && interpolated) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (current_location).line, (int) (current_location).node_id, YARVINSN_putstring, 1, (VALUE)(current_string)));
            }
            else {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (current_location).line, (int) (current_location).node_id, YARVINSN_putobject, 1, (VALUE)(current_string)));
            }
            current_string = ((VALUE)RUBY_Qnil);
            stack_size++;
        }
    }
    else {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*node_location).line, (int) (*node_location).node_id, YARVINSN_putnil, 0));
    }
    return stack_size;
}
static void
pm_compile_regexp_dynamic(rb_iseq_t *iseq, const pm_node_t *node, const pm_node_list_t *parts, const pm_node_location_t *node_location, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node)
{
    rb_encoding *explicit_regexp_encoding = parse_regexp_encoding(scope_node, node);
    rb_encoding *implicit_regexp_encoding = explicit_regexp_encoding != ((void *)0) ? explicit_regexp_encoding : scope_node->encoding;
    int length = pm_interpolated_node_compile(iseq, parts, node_location, ret, popped, scope_node, implicit_regexp_encoding, explicit_regexp_encoding);
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*node_location).line, (int) (*node_location).node_id, YARVINSN_toregexp, 2, (VALUE)(__builtin_choose_expr( __builtin_constant_p(parse_regexp_flags(node) & 0xFF), ((VALUE)(parse_regexp_flags(node) & 0xFF)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(parse_regexp_flags(node) & 0xFF))), (VALUE)(__builtin_choose_expr( __builtin_constant_p(length), ((VALUE)(length)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(length)))));
}
static VALUE
pm_source_file_value(const pm_source_file_node_t *node, const pm_scope_node_t *scope_node)
{
    const pm_string_t *filepath = &node->filepath;
    size_t length = pm_string_length(filepath);
    if (length > 0) {
        rb_encoding *filepath_encoding = scope_node->filepath_encoding != ((void *)0) ? scope_node->filepath_encoding : rb_utf8_encoding();
        return rb_enc_interned_str((const char *) pm_string_source(filepath), length, filepath_encoding);
    }
    else {
        return rb_fstring_new(("<compiled>"), ((sizeof("<compiled>" "") / sizeof("<compiled>" ""[0])) - 1));
    }
}
static VALUE
pm_static_literal_string(rb_iseq_t *iseq, VALUE string, int line_number)
{
    if (ISEQ_COMPILE_DATA(iseq)->option->debug_frozen_string_literal || RB_TEST((*rb_ruby_debug_ptr()))) {
        return rb_str_with_debug_created_info(string, rb_iseq_path(iseq), line_number);
    }
    else {
        return rb_fstring(string);
    }
}
static VALUE
pm_static_literal_value(rb_iseq_t *iseq, const pm_node_t *node, const pm_scope_node_t *scope_node)
{
    ((void)0);
    switch (((enum pm_node_type) (node)->type)) {
      case PM_ARRAY_NODE: {
        const pm_array_node_t *cast = (const pm_array_node_t *) node;
        const pm_node_list_t *elements = &cast->elements;
        VALUE value = rb_ary_hidden_new(elements->size);
        for (size_t index = 0; index < elements->size; index++) {
            rb_ary_push(value, pm_static_literal_value(iseq, elements->nodes[index], scope_node));
        }
        rb_obj_freeze_inline(value);
        return value;
      }
      case PM_FALSE_NODE:
        return ((VALUE)RUBY_Qfalse);
      case PM_FLOAT_NODE:
        return parse_float((const pm_float_node_t *) node);
      case PM_HASH_NODE: {
        const pm_hash_node_t *cast = (const pm_hash_node_t *) node;
        const pm_node_list_t *elements = &cast->elements;
        VALUE array = rb_ary_hidden_new(elements->size * 2);
        for (size_t index = 0; index < elements->size; index++) {
            ((void)0);
            const pm_assoc_node_t *cast = (const pm_assoc_node_t *) elements->nodes[index];
            VALUE pair[2] = { pm_static_literal_value(iseq, cast->key, scope_node), pm_static_literal_value(iseq, cast->value, scope_node) };
            rb_ary_cat(array, pair, 2);
        }
        VALUE value = rb_hash_new_with_size(elements->size);
        rb_hash_bulk_insert(rb_array_len(array), rb_array_const_ptr(array), value);
        value = rb_obj_hide(value);
        rb_obj_freeze_inline(value);
        return value;
      }
      case PM_IMAGINARY_NODE:
        return parse_imaginary((const pm_imaginary_node_t *) node);
      case PM_INTEGER_NODE:
        return parse_integer((const pm_integer_node_t *) node);
      case PM_INTERPOLATED_MATCH_LAST_LINE_NODE: {
        const pm_interpolated_match_last_line_node_t *cast = (const pm_interpolated_match_last_line_node_t *) node;
        return parse_regexp_concat(iseq, scope_node, (const pm_node_t *) cast, &cast->parts);
      }
      case PM_INTERPOLATED_REGULAR_EXPRESSION_NODE: {
        const pm_interpolated_regular_expression_node_t *cast = (const pm_interpolated_regular_expression_node_t *) node;
        return parse_regexp_concat(iseq, scope_node, (const pm_node_t *) cast, &cast->parts);
      }
      case PM_INTERPOLATED_STRING_NODE: {
        VALUE string = pm_static_literal_concat(iseq, &((const pm_interpolated_string_node_t *) node)->parts, scope_node, ((void *)0), ((void *)0), 0);
        int line_number = pm_node_line_number(scope_node->parser, node);
        return pm_static_literal_string(iseq, string, line_number);
      }
      case PM_INTERPOLATED_SYMBOL_NODE: {
        const pm_interpolated_symbol_node_t *cast = (const pm_interpolated_symbol_node_t *) node;
        VALUE string = pm_static_literal_concat(iseq, &cast->parts, scope_node, ((void *)0), ((void *)0), 1);
        return rb_id2sym(rb_intern_str(string));
      }
      case PM_MATCH_LAST_LINE_NODE: {
        const pm_match_last_line_node_t *cast = (const pm_match_last_line_node_t *) node;
        return parse_regexp_literal(iseq, scope_node, (const pm_node_t *) cast, &cast->unescaped);
      }
      case PM_NIL_NODE:
        return ((VALUE)RUBY_Qnil);
      case PM_RATIONAL_NODE:
        return parse_rational((const pm_rational_node_t *) node);
      case PM_REGULAR_EXPRESSION_NODE: {
        const pm_regular_expression_node_t *cast = (const pm_regular_expression_node_t *) node;
        return parse_regexp_literal(iseq, scope_node, (const pm_node_t *) cast, &cast->unescaped);
      }
      case PM_SOURCE_ENCODING_NODE:
        return rb_enc_from_encoding(scope_node->encoding);
      case PM_SOURCE_FILE_NODE: {
        const pm_source_file_node_t *cast = (const pm_source_file_node_t *) node;
        return pm_source_file_value(cast, scope_node);
      }
      case PM_SOURCE_LINE_NODE:
        return __builtin_choose_expr( __builtin_constant_p(pm_node_line_number(scope_node->parser, node)), ((VALUE)(pm_node_line_number(scope_node->parser, node))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(pm_node_line_number(scope_node->parser, node)));
      case PM_STRING_NODE: {
        const pm_string_node_t *cast = (const pm_string_node_t *) node;
        return parse_static_literal_string(iseq, scope_node, node, &cast->unescaped);
      }
      case PM_SYMBOL_NODE:
        return rb_id2sym(parse_string_symbol(scope_node, (const pm_symbol_node_t *) node));
      case PM_TRUE_NODE:
        return ((VALUE)RUBY_Qtrue);
      default:
        rb_bug("Don't have a literal value for node type %s", pm_node_type_to_str(((enum pm_node_type) (node)->type)));
        return ((VALUE)RUBY_Qfalse);
    }
}
static rb_code_location_t
pm_code_location(const pm_scope_node_t *scope_node, const pm_node_t *node)
{
    const pm_line_column_t start_location = pm_newline_list_line_column(&(scope_node->parser)->newline_list, ((const pm_node_t *) (node))->location.start, (scope_node->parser)->start_line);
    const pm_line_column_t end_location = pm_newline_list_line_column(&(scope_node->parser)->newline_list, ((const pm_node_t *) (node))->location.end, (scope_node->parser)->start_line);
    return (rb_code_location_t) {
        .beg_pos = { .lineno = start_location.line, .column = start_location.column },
        .end_pos = { .lineno = end_location.line, .column = end_location.column }
    };
}
static void
pm_compile_branch_condition(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const pm_node_t *cond,
                         LABEL *then_label, LABEL *else_label, _Bool popped, pm_scope_node_t *scope_node);
static void
pm_compile_logical(rb_iseq_t *iseq, LINK_ANCHOR *const ret, pm_node_t *cond, LABEL *then_label, LABEL *else_label, _Bool popped, pm_scope_node_t *scope_node)
{
    const pm_node_location_t location = ((pm_node_location_t) { .line = pm_newline_list_line(&(scope_node->parser)->newline_list, ((const pm_node_t *) (cond))->location.start, (scope_node->parser)->start_line), .node_id = ((const pm_node_t *) (cond))->node_id });
    LINK_ANCHOR seq[1] = {{{ISEQ_ELEMENT_ANCHOR,},&seq[0].anchor}};
    LABEL *label = new_label_body(iseq, (location.line));
    if (!then_label) then_label = label;
    else if (!else_label) else_label = label;
    pm_compile_branch_condition(iseq, seq, cond, then_label, else_label, popped, scope_node);
    if (LIST_INSN_SIZE_ONE(seq)) {
        INSN *insn = (INSN *) ELEM_FIRST_INSN(FIRST_ELEMENT(seq));
        if (insn->insn_id == YARVINSN_jump && (LABEL *)(insn->operands[0]) == label) return;
    }
    if (!label->refcnt) {
        if (popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
    }
    else {
        ADD_ELEM((seq), (LINK_ELEMENT *) (label));
    }
    APPEND_LIST((ret), (seq));
    return;
}
static void
pm_compile_flip_flop_bound(rb_iseq_t *iseq, const pm_node_t *node, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node)
{
    const pm_node_location_t location = { .line = ((iseq)->body)->location.first_lineno, .node_id = -1 };
    if ((((enum pm_node_type) (node)->type) == (PM_INTEGER_NODE))) {
        pm_compile_node(iseq, (node), ret, 0, scope_node);
        VALUE operand = rb_id2sym((__builtin_constant_p("$.") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("$.")); }) : (rb_intern)("$.")));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_getglobal, 1, (VALUE)(operand)));
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((idEq)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
        if (popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
    }
    else {
        pm_compile_node(iseq, (node), ret, popped, scope_node);
    }
}
static void
pm_compile_flip_flop(const pm_flip_flop_node_t *flip_flop_node, LABEL *else_label, LABEL *then_label, rb_iseq_t *iseq, const int lineno, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node)
{
    const pm_node_location_t location = { .line = ((iseq)->body)->location.first_lineno, .node_id = -1 };
    LABEL *lend = new_label_body(iseq, (location.line));
    int again = !(flip_flop_node->base.flags & PM_RANGE_FLAGS_EXCLUDE_END);
    rb_num_t count = ISEQ_FLIP_CNT_INCREMENT(((iseq)->body)->local_iseq) + VM_SVAR_FLIPFLOP_START;
    VALUE key = __builtin_choose_expr( __builtin_constant_p(count), ((VALUE)(count)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(count));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_getspecial, 2, (VALUE)(key), (VALUE)(__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))));
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchif, 1, (VALUE)(lend))), ((lend)->refcnt++));
    if (flip_flop_node->left) {
        pm_compile_flip_flop_bound(iseq, flip_flop_node->left, ret, popped, scope_node);
    }
    else {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
    }
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(else_label))), ((else_label)->refcnt++));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qtrue))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setspecial, 1, (VALUE)(key)));
    if (!again) {
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_jump, 1, (VALUE)(then_label))), ((then_label)->refcnt++));
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) (lend));
    if (flip_flop_node->right) {
        pm_compile_flip_flop_bound(iseq, flip_flop_node->right, ret, popped, scope_node);
    }
    else {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
    }
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(then_label))), ((then_label)->refcnt++));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qfalse))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setspecial, 1, (VALUE)(key)));
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_jump, 1, (VALUE)(then_label))), ((then_label)->refcnt++));
}
static void pm_compile_defined_expr(rb_iseq_t *iseq, const pm_node_t *node, const pm_node_location_t *node_location, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node, _Bool in_condition);
static void
pm_compile_branch_condition(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const pm_node_t *cond, LABEL *then_label, LABEL *else_label, _Bool popped, pm_scope_node_t *scope_node)
{
    const pm_node_location_t location = ((pm_node_location_t) { .line = pm_newline_list_line(&(scope_node->parser)->newline_list, ((const pm_node_t *) (cond))->location.start, (scope_node->parser)->start_line), .node_id = ((const pm_node_t *) (cond))->node_id });
again:
    switch (((enum pm_node_type) (cond)->type)) {
      case PM_AND_NODE: {
        const pm_and_node_t *cast = (const pm_and_node_t *) cond;
        pm_compile_logical(iseq, ret, cast->left, ((void *)0), else_label, popped, scope_node);
        cond = cast->right;
        goto again;
      }
      case PM_OR_NODE: {
        const pm_or_node_t *cast = (const pm_or_node_t *) cond;
        pm_compile_logical(iseq, ret, cast->left, then_label, ((void *)0), popped, scope_node);
        cond = cast->right;
        goto again;
      }
      case PM_FALSE_NODE:
      case PM_NIL_NODE:
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_jump, 1, (VALUE)(else_label))), ((else_label)->refcnt++));
        return;
      case PM_FLOAT_NODE:
      case PM_IMAGINARY_NODE:
      case PM_INTEGER_NODE:
      case PM_LAMBDA_NODE:
      case PM_RATIONAL_NODE:
      case PM_REGULAR_EXPRESSION_NODE:
      case PM_STRING_NODE:
      case PM_SYMBOL_NODE:
      case PM_TRUE_NODE:
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_jump, 1, (VALUE)(then_label))), ((then_label)->refcnt++));
        return;
      case PM_FLIP_FLOP_NODE:
        pm_compile_flip_flop((const pm_flip_flop_node_t *) cond, else_label, then_label, iseq, location.line, ret, popped, scope_node);
        return;
      case PM_DEFINED_NODE: {
        const pm_defined_node_t *cast = (const pm_defined_node_t *) cond;
        pm_compile_defined_expr(iseq, cast->value, &location, ret, popped, scope_node, 1);
        break;
      }
      default: {
        LINK_ANCHOR cond_seq[1] = {{{ISEQ_ELEMENT_ANCHOR,},&cond_seq[0].anchor}};
        pm_compile_node(iseq, cond, cond_seq, 0, scope_node);
        if (LIST_INSN_SIZE_ONE(cond_seq)) {
            INSN *insn = (INSN *) ELEM_FIRST_INSN(FIRST_ELEMENT(cond_seq));
            if (insn->insn_id == YARVINSN_putobject) {
                if (RB_TEST(insn->operands[0])) {
                    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_jump, 1, (VALUE)(then_label))), ((then_label)->refcnt++));
                    return;
                }
                else {
                    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_jump, 1, (VALUE)(else_label))), ((else_label)->refcnt++));
                    return;
                }
            }
        }
        APPEND_LIST((ret), (cond_seq));
        break;
      }
    }
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(else_label))), ((else_label)->refcnt++));
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_jump, 1, (VALUE)(then_label))), ((then_label)->refcnt++));
}
static void
pm_compile_conditional(rb_iseq_t *iseq, const pm_node_location_t *node_location, pm_node_type_t type, const pm_node_t *node, const pm_statements_node_t *statements, const pm_node_t *subsequent, const pm_node_t *predicate, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node)
{
    const pm_node_location_t location = *node_location;
    LABEL *then_label = new_label_body(iseq, (location.line));
    LABEL *else_label = new_label_body(iseq, (location.line));
    LABEL *end_label = ((void *)0);
    LINK_ANCHOR cond_seq[1] = {{{ISEQ_ELEMENT_ANCHOR,},&cond_seq[0].anchor}};
    pm_compile_branch_condition(iseq, cond_seq, predicate, then_label, else_label, 0, scope_node);
    APPEND_LIST((ret), (cond_seq));
    rb_code_location_t conditional_location = { 0 };
    VALUE branches = ((VALUE)RUBY_Qfalse);
    if (then_label->refcnt && else_label->refcnt && (((iseq)->body)->variable.coverage && RARRAY_AREF(((iseq)->body)->variable.coverage, 1))) {
        conditional_location = pm_code_location(scope_node, node);
        branches = decl_branch_base(iseq, (rb_int2inum((intptr_t)(void *)(node))), &conditional_location, type == PM_IF_NODE ? "if" : "unless");
    }
    if (then_label->refcnt) {
        ADD_ELEM((ret), (LINK_ELEMENT *) (then_label));
        LINK_ANCHOR then_seq[1] = {{{ISEQ_ELEMENT_ANCHOR,},&then_seq[0].anchor}};
        if (statements != ((void *)0)) {
            pm_compile_node(iseq, (const pm_node_t *) statements, then_seq, popped, scope_node);
        }
        else if (!popped) {
            do { int lineno = ISEQ_COMPILE_DATA(iseq)->last_line; if (lineno == 0) lineno = RB_FIX2INT(rb_iseq_first_lineno(iseq)); ADD_ELEM((then_seq), (LINK_ELEMENT *) new_insn_body(iseq, (lineno), (-1), YARVINSN_putnil, 0)); } while (0);
        }
        if (else_label->refcnt) {
            if ((((iseq)->body)->variable.coverage && RARRAY_AREF(((iseq)->body)->variable.coverage, 1))) {
                rb_code_location_t branch_location;
                if (statements != ((void *)0)) {
                    branch_location = pm_code_location(scope_node, (const pm_node_t *) statements);
                } else if (type == PM_IF_NODE) {
                    pm_line_column_t predicate_end = pm_newline_list_line_column(&(scope_node->parser)->newline_list, ((const pm_node_t *) (predicate))->location.end, (scope_node->parser)->start_line);
                    branch_location = (rb_code_location_t) {
                        .beg_pos = { .lineno = predicate_end.line, .column = predicate_end.column },
                        .end_pos = { .lineno = predicate_end.line, .column = predicate_end.column }
                    };
                } else {
                    branch_location = conditional_location;
                }
                add_trace_branch_coverage(iseq, ret, &branch_location, branch_location.beg_pos.column, 0, type == PM_IF_NODE ? "then" : "else", branches);
            }
            end_label = new_label_body(iseq, (location.line));
            (ADD_ELEM((then_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_jump, 1, (VALUE)(end_label))), ((end_label)->refcnt++));
            if (!popped) ADD_ELEM((then_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        }
        APPEND_LIST((ret), (then_seq));
    }
    if (else_label->refcnt) {
        ADD_ELEM((ret), (LINK_ELEMENT *) (else_label));
        LINK_ANCHOR else_seq[1] = {{{ISEQ_ELEMENT_ANCHOR,},&else_seq[0].anchor}};
        if (subsequent != ((void *)0)) {
            pm_compile_node(iseq, subsequent, else_seq, popped, scope_node);
        }
        else if (!popped) {
            do { int lineno = ISEQ_COMPILE_DATA(iseq)->last_line; if (lineno == 0) lineno = RB_FIX2INT(rb_iseq_first_lineno(iseq)); ADD_ELEM((else_seq), (LINK_ELEMENT *) new_insn_body(iseq, (lineno), (-1), YARVINSN_putnil, 0)); } while (0);
        }
        if (then_label->refcnt && (((iseq)->body)->variable.coverage && RARRAY_AREF(((iseq)->body)->variable.coverage, 1))) {
            rb_code_location_t branch_location;
            if (subsequent == ((void *)0)) {
                branch_location = conditional_location;
            } else if ((((enum pm_node_type) (subsequent)->type) == (PM_ELSE_NODE))) {
                const pm_else_node_t *else_node = (const pm_else_node_t *) subsequent;
                branch_location = pm_code_location(scope_node, else_node->statements != ((void *)0) ? ((const pm_node_t *) else_node->statements) : (const pm_node_t *) else_node);
            } else {
                branch_location = pm_code_location(scope_node, (const pm_node_t *) subsequent);
            }
            add_trace_branch_coverage(iseq, ret, &branch_location, branch_location.beg_pos.column, 1, type == PM_IF_NODE ? "else" : "then", branches);
        }
        APPEND_LIST((ret), (else_seq));
    }
    if (end_label) {
        ADD_ELEM((ret), (LINK_ELEMENT *) (end_label));
    }
    return;
}
static void
pm_compile_loop(rb_iseq_t *iseq, const pm_node_location_t *node_location, pm_node_flags_t flags, enum pm_node_type type, const pm_node_t *node, const pm_statements_node_t *statements, const pm_node_t *predicate, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node)
{
    const pm_node_location_t location = *node_location;
    LABEL *prev_start_label = ISEQ_COMPILE_DATA(iseq)->start_label;
    LABEL *prev_end_label = ISEQ_COMPILE_DATA(iseq)->end_label;
    LABEL *prev_redo_label = ISEQ_COMPILE_DATA(iseq)->redo_label;
    LABEL *next_label = ISEQ_COMPILE_DATA(iseq)->start_label = new_label_body(iseq, (location.line));
    LABEL *redo_label = ISEQ_COMPILE_DATA(iseq)->redo_label = new_label_body(iseq, (location.line));
    LABEL *break_label = ISEQ_COMPILE_DATA(iseq)->end_label = new_label_body(iseq, (location.line));
    LABEL *end_label = new_label_body(iseq, (location.line));
    LABEL *adjust_label = new_label_body(iseq, (location.line));
    LABEL *next_catch_label = new_label_body(iseq, (location.line));
    LABEL *tmp_label = ((void *)0);
    struct iseq_compile_data_ensure_node_stack enl;
    push_ensure_entry(iseq, &enl, ((void *)0), ((void *)0));
    if (flags & PM_LOOP_FLAGS_BEGIN_MODIFIER) {
        tmp_label = new_label_body(iseq, (location.line));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_jump, 1, (VALUE)(tmp_label))), ((tmp_label)->refcnt++));
    }
    else {
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_jump, 1, (VALUE)(next_label))), ((next_label)->refcnt++));
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) (adjust_label));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) (next_catch_label));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_jump, 1, (VALUE)(next_label))), ((next_label)->refcnt++));
    if (tmp_label) ADD_ELEM((ret), (LINK_ELEMENT *) (tmp_label));
    ADD_ELEM((ret), (LINK_ELEMENT *) (redo_label));
    if ((((iseq)->body)->variable.coverage && RARRAY_AREF(((iseq)->body)->variable.coverage, 1))) {
        rb_code_location_t loop_location = pm_code_location(scope_node, node);
        VALUE branches = decl_branch_base(iseq, (rb_int2inum((intptr_t)(void *)(node))), &loop_location, type == PM_WHILE_NODE ? "while" : "until");
        rb_code_location_t branch_location = statements != ((void *)0) ? pm_code_location(scope_node, (const pm_node_t *) statements) : loop_location;
        add_trace_branch_coverage(iseq, ret, &branch_location, branch_location.beg_pos.column, 0, "body", branches);
    }
    if (statements != ((void *)0)) pm_compile_node(iseq, ((const pm_node_t *) statements), ret, 1, scope_node);
    ADD_ELEM((ret), (LINK_ELEMENT *) (next_label));
    if (type == PM_WHILE_NODE) {
        pm_compile_branch_condition(iseq, ret, predicate, redo_label, end_label, popped, scope_node);
    }
    else if (type == PM_UNTIL_NODE) {
        pm_compile_branch_condition(iseq, ret, predicate, end_label, redo_label, popped, scope_node);
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) (end_label));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_adjust_body(iseq, (adjust_label), -1));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) (break_label));
    if (popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
    do { VALUE _e = __extension__ ({ const VALUE args_to_new_ary[] = {((CATCH_TYPE_BREAK)), (VALUE)((redo_label)) | 1, (VALUE)((break_label)) | 1, (VALUE)((((void *)0))), (VALUE)((break_label)) | 1}; if (__builtin_constant_p(5)) { __extension__ _Static_assert(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))) == (5), "rb_ary_new_from_args" ": " "numberof(args_to_new_ary) == (5)"); } rb_ary_new_from_values(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))), args_to_new_ary); }); (((redo_label)) ? ((((redo_label))->refcnt++), ((redo_label))->unremovable=1) : 0); (((break_label))->refcnt++); (((break_label))->refcnt++); if (RB_NIL_P(ISEQ_COMPILE_DATA(iseq)->catch_table_ary)) (rb_obj_write((VALUE)(iseq), (VALUE *)(&ISEQ_COMPILE_DATA(iseq)->catch_table_ary), (VALUE)(rb_ary_hidden_new(3)), "prism_compile.c", 1202)); rb_ary_push(ISEQ_COMPILE_DATA(iseq)->catch_table_ary, freeze_hide_obj(_e)); } while (0);
    do { VALUE _e = __extension__ ({ const VALUE args_to_new_ary[] = {((CATCH_TYPE_NEXT)), (VALUE)((redo_label)) | 1, (VALUE)((break_label)) | 1, (VALUE)((((void *)0))), (VALUE)((next_catch_label)) | 1}; if (__builtin_constant_p(5)) { __extension__ _Static_assert(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))) == (5), "rb_ary_new_from_args" ": " "numberof(args_to_new_ary) == (5)"); } rb_ary_new_from_values(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))), args_to_new_ary); }); (((redo_label)) ? ((((redo_label))->refcnt++), ((redo_label))->unremovable=1) : 0); (((break_label))->refcnt++); (((next_catch_label))->refcnt++); if (RB_NIL_P(ISEQ_COMPILE_DATA(iseq)->catch_table_ary)) (rb_obj_write((VALUE)(iseq), (VALUE *)(&ISEQ_COMPILE_DATA(iseq)->catch_table_ary), (VALUE)(rb_ary_hidden_new(3)), "prism_compile.c", 1203)); rb_ary_push(ISEQ_COMPILE_DATA(iseq)->catch_table_ary, freeze_hide_obj(_e)); } while (0);
    do { VALUE _e = __extension__ ({ const VALUE args_to_new_ary[] = {((CATCH_TYPE_REDO)), (VALUE)((redo_label)) | 1, (VALUE)((break_label)) | 1, (VALUE)((((void *)0))), (VALUE)((ISEQ_COMPILE_DATA(iseq)->redo_label)) | 1}; if (__builtin_constant_p(5)) { __extension__ _Static_assert(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))) == (5), "rb_ary_new_from_args" ": " "numberof(args_to_new_ary) == (5)"); } rb_ary_new_from_values(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))), args_to_new_ary); }); (((redo_label)) ? ((((redo_label))->refcnt++), ((redo_label))->unremovable=1) : 0); (((break_label))->refcnt++); (((ISEQ_COMPILE_DATA(iseq)->redo_label))->refcnt++); if (RB_NIL_P(ISEQ_COMPILE_DATA(iseq)->catch_table_ary)) (rb_obj_write((VALUE)(iseq), (VALUE *)(&ISEQ_COMPILE_DATA(iseq)->catch_table_ary), (VALUE)(rb_ary_hidden_new(3)), "prism_compile.c", 1204)); rb_ary_push(ISEQ_COMPILE_DATA(iseq)->catch_table_ary, freeze_hide_obj(_e)); } while (0);
    ISEQ_COMPILE_DATA(iseq)->start_label = prev_start_label;
    ISEQ_COMPILE_DATA(iseq)->end_label = prev_end_label;
    ISEQ_COMPILE_DATA(iseq)->redo_label = prev_redo_label;
    ISEQ_COMPILE_DATA(iseq)->ensure_node_stack = ISEQ_COMPILE_DATA(iseq)->ensure_node_stack->prev;
    return;
}
static pm_local_index_t
pm_lookup_local_index(rb_iseq_t *iseq, const pm_scope_node_t *scope_node, pm_constant_id_t constant_id, int start_depth)
{
    pm_local_index_t lindex = { 0 };
    st_data_t local_index;
    int level;
    for (level = 0; level < start_depth; level++) {
        scope_node = scope_node->previous;
    }
    while (!rb_st_lookup(scope_node->index_lookup_table, constant_id, &local_index)) {
        level++;
        if (scope_node->previous) {
            scope_node = scope_node->previous;
        }
        else {
            rb_bug("Local with constant_id %u does not exist", (unsigned int) constant_id);
        }
    }
    lindex.level = level;
    lindex.index = scope_node->local_table_for_iseq_size - (int) local_index;
    return lindex;
}
static ID
pm_constant_id_lookup(const pm_scope_node_t *scope_node, pm_constant_id_t constant_id)
{
    if (constant_id < 1 || constant_id > scope_node->parser->constant_pool.size) {
        rb_bug("constant_id out of range: %u", (unsigned int)constant_id);
    }
    return scope_node->constants[constant_id - 1];
}
static rb_iseq_t *
pm_new_child_iseq(rb_iseq_t *iseq, pm_scope_node_t *node, VALUE name, const rb_iseq_t *parent, enum rb_iseq_type type, int line_no)
{
    if(0)printf("[new_child_iseq]> ---------------------------------------\n");
    int isolated_depth = ISEQ_COMPILE_DATA(iseq)->isolated_depth;
    int error_state;
    rb_iseq_t *ret_iseq = pm_iseq_new_with_opt(node, name,
            rb_iseq_path(iseq), rb_iseq_realpath(iseq),
            line_no, parent,
            isolated_depth ? isolated_depth + 1 : 0,
            type, ISEQ_COMPILE_DATA(iseq)->option, &error_state);
    if (error_state) {
        ((void)0);
        rb_jump_tag(error_state);
    }
    if(0)printf("[new_child_iseq]< ---------------------------------------\n");
    return ret_iseq;
}
static int
pm_compile_class_path(rb_iseq_t *iseq, const pm_node_t *node, const pm_node_location_t *node_location, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node)
{
    if ((((enum pm_node_type) (node)->type) == (PM_CONSTANT_PATH_NODE))) {
        const pm_node_t *parent = ((const pm_constant_path_node_t *) node)->parent;
        if (parent) {
            pm_compile_node(iseq, (parent), ret, popped, scope_node);
            return 0x08;
        }
        else {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*node_location).line, (int) (*node_location).node_id, YARVINSN_putobject, 1, (VALUE)(rb_cObject)));
            return 0x08;
        }
    }
    else {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*node_location).line, (int) (*node_location).node_id, YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_CONST_BASE), ((VALUE)(VM_SPECIAL_OBJECT_CONST_BASE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_CONST_BASE)))));
        return 0;
    }
}
static void
pm_compile_call_and_or_write_node(rb_iseq_t *iseq, _Bool and_node, const pm_node_t *receiver, const pm_node_t *value, pm_constant_id_t write_name, pm_constant_id_t read_name, _Bool safe_nav, const pm_node_location_t *node_location, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node)
{
    const pm_node_location_t location = *node_location;
    LABEL *lfin = new_label_body(iseq, (location.line));
    LABEL *lcfin = new_label_body(iseq, (location.line));
    LABEL *lskip = ((void *)0);
    int flag = (((enum pm_node_type) (receiver)->type) == (PM_SELF_NODE)) ? (0x01 << VM_CALL_FCALL_bit) : 0;
    ID id_read_name = pm_constant_id_lookup(scope_node, read_name);
    pm_compile_node(iseq, (receiver), ret, 0, scope_node);
    if (safe_nav) {
        lskip = new_label_body(iseq, (location.line));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchnil, 1, (VALUE)(lskip))), ((lskip)->refcnt++));
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((id_read_name)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))), (((void *)0)), (VALUE)((VALUE)(__builtin_choose_expr( __builtin_constant_p(flag), ((VALUE)(flag)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(flag)))), (((void *)0))));
    if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
    if (and_node) {
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(lcfin))), ((lcfin)->refcnt++));
    }
    else {
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchif, 1, (VALUE)(lcfin))), ((lcfin)->refcnt++));
    }
    if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
    pm_compile_node(iseq, (value), ret, 0, scope_node);
    if (!popped) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_swap, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
    }
    ID id_write_name = pm_constant_id_lookup(scope_node, write_name);
    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((id_write_name)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)(__builtin_choose_expr( __builtin_constant_p(flag), ((VALUE)(flag)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(flag)))), (((void *)0))));
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_jump, 1, (VALUE)(lfin))), ((lfin)->refcnt++));
    ADD_ELEM((ret), (LINK_ELEMENT *) (lcfin));
    if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_swap, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) (lfin));
    if (lskip && popped) ADD_ELEM((ret), (LINK_ELEMENT *) (lskip));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
    if (lskip && !popped) ADD_ELEM((ret), (LINK_ELEMENT *) (lskip));
}
static void
pm_compile_hash_elements(rb_iseq_t *iseq, const pm_node_t *node, const pm_node_list_t *elements, _Bool argument, LINK_ANCHOR *const ret, pm_scope_node_t *scope_node)
{
    const pm_node_location_t location = ((pm_node_location_t) { .line = pm_newline_list_line(&(scope_node->parser)->newline_list, ((const pm_node_t *) (node))->location.start, (scope_node->parser)->start_line), .node_id = ((const pm_node_t *) (node))->node_id });
    const int max_stack_length = 0x100;
    const unsigned int min_tmp_hash_length = 0x800;
    int stack_length = 0;
    _Bool first_chunk = 1;
    _Bool static_literal = 0;
    LINK_ANCHOR anchor[1] = {{{ISEQ_ELEMENT_ANCHOR,},&anchor[0].anchor}};
    for (size_t index = 0; index < elements->size; index++) {
        const pm_node_t *element = elements->nodes[index];
        switch (((enum pm_node_type) (element)->type)) {
          case PM_ASSOC_NODE: {
            if (
                ((((pm_node_t *)(element))->flags & (PM_NODE_FLAG_STATIC_LITERAL)) != 0) && (
                    (!static_literal && ((index + min_tmp_hash_length) < elements->size)) ||
                    (first_chunk && stack_length == 0)
                )
            ) {
                size_t count = 1;
                while (index + count < elements->size && ((((pm_node_t *)(elements->nodes[index + count]))->flags & (PM_NODE_FLAG_STATIC_LITERAL)) != 0)) count++;
                if ((first_chunk && stack_length == 0) || count >= min_tmp_hash_length) {
                    VALUE ary = rb_ary_hidden_new(count);
                    for (size_t tmp_end = index + count; index < tmp_end; index++) {
                        const pm_assoc_node_t *assoc = (const pm_assoc_node_t *) elements->nodes[index];
                        VALUE elem[2] = {
                            pm_static_literal_value(iseq, assoc->key, scope_node),
                            pm_static_literal_value(iseq, assoc->value, scope_node)
                        };
                        rb_ary_cat(ary, elem, 2);
                    }
                    index --;
                    VALUE hash = rb_hash_new_with_size(rb_array_len(ary) / 2);
                    rb_hash_bulk_insert(rb_array_len(ary), rb_array_const_ptr(ary), hash);
                    hash = rb_obj_hide(hash);
                    rb_obj_freeze_inline(hash);
                    if (stack_length) { if (first_chunk) { APPEND_LIST((ret), (anchor)); ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_newhash, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(stack_length), ((VALUE)(stack_length)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(stack_length))))); first_chunk = 0; } else { ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE))))); ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_swap, 0)); APPEND_LIST((ret), (anchor)); ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((id_core_hash_merge_ptr)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(stack_length + 1), ((VALUE)(stack_length + 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(stack_length + 1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0)))); } ((anchor->last = &anchor->anchor)->next = ((void *)0)); stack_length = 0; };
                    if (first_chunk) {
                        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_duphash, 1, (VALUE)(hash)));
                        first_chunk = 0;
                    }
                    else {
                        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
                        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_swap, 0));
                        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(hash)));
                        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((id_core_hash_merge_kwd)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
                    }
                    break;
                }
                else {
                    static_literal = 1;
                }
            }
            else {
                static_literal = 0;
            }
            pm_compile_node(iseq, element, anchor, 0, scope_node);
            if ((stack_length += 2) >= max_stack_length) if (stack_length) { if (first_chunk) { APPEND_LIST((ret), (anchor)); ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_newhash, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(stack_length), ((VALUE)(stack_length)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(stack_length))))); first_chunk = 0; } else { ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE))))); ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_swap, 0)); APPEND_LIST((ret), (anchor)); ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((id_core_hash_merge_ptr)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(stack_length + 1), ((VALUE)(stack_length + 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(stack_length + 1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0)))); } ((anchor->last = &anchor->anchor)->next = ((void *)0)); stack_length = 0; };
            break;
          }
          case PM_ASSOC_SPLAT_NODE: {
            if (stack_length) { if (first_chunk) { APPEND_LIST((ret), (anchor)); ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_newhash, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(stack_length), ((VALUE)(stack_length)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(stack_length))))); first_chunk = 0; } else { ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE))))); ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_swap, 0)); APPEND_LIST((ret), (anchor)); ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((id_core_hash_merge_ptr)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(stack_length + 1), ((VALUE)(stack_length + 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(stack_length + 1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0)))); } ((anchor->last = &anchor->anchor)->next = ((void *)0)); stack_length = 0; };
            const pm_assoc_splat_node_t *assoc_splat = (const pm_assoc_splat_node_t *) element;
            _Bool empty_hash = assoc_splat->value != ((void *)0) && (
                ((((enum pm_node_type) (assoc_splat->value)->type) == (PM_HASH_NODE)) && ((const pm_hash_node_t *) assoc_splat->value)->elements.size == 0) ||
                (((enum pm_node_type) (assoc_splat->value)->type) == (PM_NIL_NODE))
            );
            _Bool first_element = first_chunk && stack_length == 0;
            _Bool last_element = index == elements->size - 1;
            _Bool only_element = first_element && last_element;
            if (empty_hash) {
                if (only_element && argument) {
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
                }
                else if (first_element) {
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_newhash, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))));
                }
            }
            else {
                if (only_element && argument) {
                    pm_compile_node(iseq, (element), ret, 0, scope_node);
                }
                else {
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
                    if (first_element) {
                        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_newhash, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))));
                    }
                    else {
                        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_swap, 0));
                    }
                    pm_compile_node(iseq, (element), ret, 0, scope_node);
                    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((id_core_hash_merge_kwd)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
                }
            }
            first_chunk = 0;
            static_literal = 0;
            break;
          }
          default:
            ((void)0);
            break;
        }
    }
    if (stack_length) { if (first_chunk) { APPEND_LIST((ret), (anchor)); ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_newhash, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(stack_length), ((VALUE)(stack_length)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(stack_length))))); first_chunk = 0; } else { ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE))))); ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_swap, 0)); APPEND_LIST((ret), (anchor)); ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((id_core_hash_merge_ptr)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(stack_length + 1), ((VALUE)(stack_length + 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(stack_length + 1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0)))); } ((anchor->last = &anchor->anchor)->next = ((void *)0)); stack_length = 0; };
}
static int
pm_setup_args_core(const pm_arguments_node_t *arguments_node, const pm_node_t *block, int *flags, const _Bool has_regular_blockarg, struct rb_callinfo_kwarg **kw_arg, int *dup_rest, rb_iseq_t *iseq, LINK_ANCHOR *const ret, pm_scope_node_t *scope_node, const pm_node_location_t *node_location)
{
    const pm_node_location_t location = *node_location;
    int orig_argc = 0;
    _Bool has_splat = 0;
    _Bool has_keyword_splat = 0;
    if (arguments_node == ((void *)0)) {
        if (*flags & (0x01 << VM_CALL_FCALL_bit)) {
            *flags |= (0x01 << VM_CALL_VCALL_bit);
        }
    }
    else {
        const pm_node_list_t *arguments = &arguments_node->arguments;
        has_keyword_splat = ((((pm_node_t *)(arguments_node))->flags & (PM_ARGUMENTS_NODE_FLAGS_CONTAINS_KEYWORD_SPLAT)) != 0);
        int post_splat_counter = 0;
        const pm_node_t *argument;
        for (size_t index = 0; index < (arguments)->size && ((argument) = (arguments)->nodes[index]); index++) {
            switch (((enum pm_node_type) (argument)->type)) {
              case PM_KEYWORD_HASH_NODE: {
                const pm_keyword_hash_node_t *keyword_arg = (const pm_keyword_hash_node_t *) argument;
                const pm_node_list_t *elements = &keyword_arg->elements;
                if (has_keyword_splat || has_splat) {
                    *flags |= (0x01 << VM_CALL_KW_SPLAT_bit);
                    has_keyword_splat = 1;
                    if (elements->size > 1 || !(elements->size == 1 && (((enum pm_node_type) (elements->nodes[0])->type) == (PM_ASSOC_SPLAT_NODE)))) {
                        *flags |= (0x01 << VM_CALL_KW_SPLAT_MUT_bit);
                        pm_compile_hash_elements(iseq, argument, elements, 1, ret, scope_node);
                    }
                    else if (*dup_rest & 2) {
                        *flags |= (0x01 << VM_CALL_KW_SPLAT_MUT_bit);
                        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
                        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_newhash, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))));
                        pm_compile_hash_elements(iseq, argument, elements, 1, ret, scope_node);
                        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((id_core_hash_merge_kwd)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
                    }
                    else {
                        pm_compile_hash_elements(iseq, argument, elements, 1, ret, scope_node);
                    }
                }
                else {
                    if (((((pm_node_t *)(keyword_arg))->flags & (PM_KEYWORD_HASH_NODE_FLAGS_SYMBOL_KEYS)) != 0)) {
                        VALUE stored_indices = rb_hash_new();
                        VALUE keyword_indices = rb_ary_new_capa(elements->size);
                        size_t size = 0;
                        for (size_t element_index = 0; element_index < elements->size; element_index++) {
                            const pm_assoc_node_t *assoc = (const pm_assoc_node_t *) elements->nodes[element_index];
                            VALUE keyword = pm_static_literal_value(iseq, assoc->key, scope_node);
                            VALUE stored_index = rb_hash_aref(stored_indices, keyword);
                            if (!RB_NIL_P(stored_index)) {
                                rb_ary_store(keyword_indices, rb_num2long_inline(stored_index), ((VALUE)RUBY_Qfalse));
                                size--;
                            }
                            rb_hash_aset(stored_indices, keyword, rb_ulong2num_inline(element_index));
                            rb_ary_store(keyword_indices, (long) element_index, ((VALUE)RUBY_Qtrue));
                            size++;
                        }
                        *kw_arg = rb_xmalloc_mul_add(size, sizeof(VALUE), sizeof(struct rb_callinfo_kwarg));
                        *flags |= (0x01 << VM_CALL_KWARG_bit);
                        VALUE *keywords = (*kw_arg)->keywords;
                        (*kw_arg)->references = 0;
                        (*kw_arg)->keyword_len = (int) size;
                        size_t keyword_index = 0;
                        for (size_t element_index = 0; element_index < elements->size; element_index++) {
                            const pm_assoc_node_t *assoc = (const pm_assoc_node_t *) elements->nodes[element_index];
                            _Bool popped = 1;
                            if (rb_ary_entry(keyword_indices, (long) element_index) == ((VALUE)RUBY_Qtrue)) {
                                keywords[keyword_index++] = pm_static_literal_value(iseq, assoc->key, scope_node);
                                popped = 0;
                            }
                            pm_compile_node(iseq, (assoc->value), ret, popped, scope_node);
                        }
                        ((void)0);
                    }
                    else {
                        orig_argc++;
                        *flags |= (0x01 << VM_CALL_KW_SPLAT_bit);
                        size_t size = elements->size;
                        if (size > 1) {
                            *flags |= (0x01 << VM_CALL_KW_SPLAT_MUT_bit);
                        }
                        for (size_t element_index = 0; element_index < size; element_index++) {
                            const pm_assoc_node_t *assoc = (const pm_assoc_node_t *) elements->nodes[element_index];
                            pm_compile_node(iseq, (assoc->key), ret, 0, scope_node);
                            pm_compile_node(iseq, (assoc->value), ret, 0, scope_node);
                        }
                        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_newhash, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(size * 2), ((VALUE)(size * 2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(size * 2)))));
                    }
                }
                break;
              }
              case PM_SPLAT_NODE: {
                *flags |= (0x01 << VM_CALL_ARGS_SPLAT_bit);
                const pm_splat_node_t *splat_node = (const pm_splat_node_t *) argument;
                if (splat_node->expression) {
                    pm_compile_node(iseq, (splat_node->expression), ret, 0, scope_node);
                }
                else {
                    pm_local_index_t index = pm_lookup_local_index(iseq, scope_node, ((pm_constant_id_t)(idMULT | ((pm_constant_id_t)(1 << 31)))), 0);
                    pm_iseq_add_getlocal(iseq, (ret), (int) (location).line, (int) (location).node_id, (index.index), (index.level));
                }
                _Bool first_splat = !has_splat;
                if (first_splat) {
                    if (index + 1 < arguments->size || has_regular_blockarg) {
                        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_splatarray, 1, (VALUE)((*dup_rest & 1) ? ((VALUE)RUBY_Qtrue) : ((VALUE)RUBY_Qfalse))));
                        if (*dup_rest & 1) *dup_rest &= ~1;
                    }
                    else {
                        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_splatarray, 1, (VALUE)(((VALUE)RUBY_Qfalse))));
                    }
                }
                else {
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_concattoarray, 0));
                }
                has_splat = 1;
                post_splat_counter = 0;
                break;
              }
              case PM_FORWARDING_ARGUMENTS_NODE: {
                if (((((iseq)->body)->local_iseq)->body)->param.flags.forwardable) {
                    *flags |= (0x01 << VM_CALL_FORWARDING_bit);
                    pm_local_index_t mult_local = pm_lookup_local_index(iseq, scope_node, ((pm_constant_id_t)(idDot3 | ((pm_constant_id_t)(1 << 31)))), 0);
                    pm_iseq_add_getlocal(iseq, (ret), (int) (location).line, (int) (location).node_id, (mult_local.index), (mult_local.level));
                    break;
                }
                orig_argc += 2;
                *flags |= (0x01 << VM_CALL_ARGS_SPLAT_bit) | (0x01 << VM_CALL_ARGS_SPLAT_MUT_bit) | (0x01 << VM_CALL_ARGS_BLOCKARG_bit) | (0x01 << VM_CALL_KW_SPLAT_bit);
                pm_local_index_t mult_local = pm_lookup_local_index(iseq, scope_node, ((pm_constant_id_t)(idMULT | ((pm_constant_id_t)(1 << 31)))), 0);
                pm_iseq_add_getlocal(iseq, (ret), (int) (location).line, (int) (location).node_id, (mult_local.index), (mult_local.level));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_splatarray, 1, (VALUE)(((VALUE)RUBY_Qtrue))));
                pm_local_index_t pow_local = pm_lookup_local_index(iseq, scope_node, ((pm_constant_id_t)(idPow | ((pm_constant_id_t)(1 << 31)))), 0);
                pm_iseq_add_getlocal(iseq, (ret), (int) (location).line, (int) (location).node_id, (pow_local.index), (pow_local.level));
                pm_local_index_t and_local = pm_lookup_local_index(iseq, scope_node, ((pm_constant_id_t)(idAnd | ((pm_constant_id_t)(1 << 31)))), 0);
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_getblockparamproxy, 2, (VALUE)(__builtin_choose_expr( __builtin_constant_p(and_local.index + ( 3) - 1), ((VALUE)(and_local.index + ( 3) - 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(and_local.index + ( 3) - 1))), (VALUE)(__builtin_choose_expr( __builtin_constant_p(and_local.level), ((VALUE)(and_local.level)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(and_local.level)))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_splatkw, 0));
                break;
              }
              default: {
                post_splat_counter++;
                pm_compile_node(iseq, (argument), ret, 0, scope_node);
                if (has_splat) {
                    if (index == arguments->size - 1) {
                        ((void)0);
                        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pushtoarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(post_splat_counter), ((VALUE)(post_splat_counter)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(post_splat_counter)))));
                    }
                    else {
                        pm_node_t *next_arg = arguments->nodes[index + 1];
                        switch (((enum pm_node_type) (next_arg)->type)) {
                          case PM_KEYWORD_HASH_NODE: {
                            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_newarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(post_splat_counter), ((VALUE)(post_splat_counter)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(post_splat_counter)))));
                            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_concatarray, 0));
                            break;
                          }
                          case PM_SPLAT_NODE: {
                            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_newarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(post_splat_counter), ((VALUE)(post_splat_counter)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(post_splat_counter)))));
                            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_concatarray, 0));
                            break;
                          }
                          default:
                            break;
                        }
                    }
                }
                else {
                    orig_argc++;
                }
              }
            }
        }
    }
    if (has_splat) orig_argc++;
    if (has_keyword_splat) orig_argc++;
    return orig_argc;
}
static inline _Bool
pm_setup_args_dup_rest_p(const pm_node_t *node)
{
    switch (((enum pm_node_type) (node)->type)) {
      case PM_BACK_REFERENCE_READ_NODE:
      case PM_CLASS_VARIABLE_READ_NODE:
      case PM_CONSTANT_PATH_NODE:
      case PM_CONSTANT_READ_NODE:
      case PM_FALSE_NODE:
      case PM_FLOAT_NODE:
      case PM_GLOBAL_VARIABLE_READ_NODE:
      case PM_IMAGINARY_NODE:
      case PM_INSTANCE_VARIABLE_READ_NODE:
      case PM_INTEGER_NODE:
      case PM_LAMBDA_NODE:
      case PM_LOCAL_VARIABLE_READ_NODE:
      case PM_NIL_NODE:
      case PM_NUMBERED_REFERENCE_READ_NODE:
      case PM_RATIONAL_NODE:
      case PM_REGULAR_EXPRESSION_NODE:
      case PM_SELF_NODE:
      case PM_STRING_NODE:
      case PM_SYMBOL_NODE:
      case PM_TRUE_NODE:
        return 0;
      case PM_IMPLICIT_NODE:
        return pm_setup_args_dup_rest_p(((const pm_implicit_node_t *) node)->value);
      default:
        return 1;
    }
}
static int
pm_setup_args(const pm_arguments_node_t *arguments_node, const pm_node_t *block, int *flags, struct rb_callinfo_kwarg **kw_arg, rb_iseq_t *iseq, LINK_ANCHOR *const ret, pm_scope_node_t *scope_node, const pm_node_location_t *node_location)
{
    int dup_rest = 1;
    const pm_node_list_t *arguments;
    size_t arguments_size;
    if (
        arguments_node != ((void *)0) &&
        (arguments = &arguments_node->arguments, arguments_size = arguments->size) >= 2 &&
        ((((pm_node_t *)(arguments_node))->flags & (PM_ARGUMENTS_NODE_FLAGS_CONTAINS_SPLAT)) != 0) &&
        !((((pm_node_t *)(arguments_node))->flags & (PM_ARGUMENTS_NODE_FLAGS_CONTAINS_MULTIPLE_SPLATS)) != 0) &&
        (((enum pm_node_type) (arguments->nodes[arguments_size - 1])->type) == (PM_KEYWORD_HASH_NODE))
    ) {
        dup_rest = 0;
        const pm_keyword_hash_node_t *keyword_hash = (const pm_keyword_hash_node_t *) arguments->nodes[arguments_size - 1];
        const pm_node_list_t *elements = &keyword_hash->elements;
        for (size_t index = 0; dup_rest == 0 && index < elements->size; index++) {
            const pm_node_t *element = elements->nodes[index];
            switch (((enum pm_node_type) (element)->type)) {
              case PM_ASSOC_NODE: {
                const pm_assoc_node_t *assoc = (const pm_assoc_node_t *) element;
                if (pm_setup_args_dup_rest_p(assoc->key) || pm_setup_args_dup_rest_p(assoc->value)) dup_rest = 1;
                break;
              }
              case PM_ASSOC_SPLAT_NODE: {
                const pm_assoc_splat_node_t *assoc = (const pm_assoc_splat_node_t *) element;
                if (assoc->value != ((void *)0) && pm_setup_args_dup_rest_p(assoc->value)) dup_rest = 1;
                break;
              }
              default:
                break;
            }
        }
    }
    int initial_dup_rest = dup_rest;
    int argc;
    if (block && (((enum pm_node_type) (block)->type) == (PM_BLOCK_ARGUMENT_NODE))) {
        _Bool regular_block_arg = 1;
        const pm_node_t *block_expr = ((const pm_block_argument_node_t *)block)->expression;
        if (block_expr && pm_setup_args_dup_rest_p(block_expr)) {
            dup_rest = 1 | 2;
            initial_dup_rest = dup_rest;
        }
        LINK_ANCHOR block_arg[1] = {{{ISEQ_ELEMENT_ANCHOR,},&block_arg[0].anchor}};
        pm_compile_node(iseq, block, block_arg, 0, scope_node);
        *flags |= (0x01 << VM_CALL_ARGS_BLOCKARG_bit);
        if (LIST_INSN_SIZE_ONE(block_arg)) {
            LINK_ELEMENT *elem = FIRST_ELEMENT(block_arg);
            if (((elem)->type == ISEQ_ELEMENT_INSN)) {
                INSN *iobj = (INSN *) elem;
                if (iobj->insn_id == YARVINSN_getblockparam) {
                    iobj->insn_id = YARVINSN_getblockparamproxy;
                }
                regular_block_arg = 0;
            }
        }
        argc = pm_setup_args_core(arguments_node, block, flags, regular_block_arg, kw_arg, &dup_rest, iseq, ret, scope_node, node_location);
        APPEND_LIST((ret), (block_arg));
    }
    else {
        argc = pm_setup_args_core(arguments_node, block, flags, 0, kw_arg, &dup_rest, iseq, ret, scope_node, node_location);
    }
    if (*flags & (0x01 << VM_CALL_ARGS_SPLAT_bit) && dup_rest != initial_dup_rest) {
        *flags |= (0x01 << VM_CALL_ARGS_SPLAT_MUT_bit);
    }
    return argc;
}
static void
pm_compile_index_operator_write_node(rb_iseq_t *iseq, const pm_index_operator_write_node_t *node, const pm_node_location_t *node_location, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node)
{
    const pm_node_location_t location = *node_location;
    if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
    pm_compile_node(iseq, (node->receiver), ret, 0, scope_node);
    int boff = (node->block == ((void *)0) ? 0 : 1);
    int flag = (((enum pm_node_type) (node->receiver)->type) == (PM_SELF_NODE)) ? (0x01 << VM_CALL_FCALL_bit) : 0;
    struct rb_callinfo_kwarg *keywords = ((void *)0);
    int argc = pm_setup_args(node->arguments, (const pm_node_t *) node->block, &flag, &keywords, iseq, ret, scope_node, node_location);
    if ((argc > 0 || boff) && (flag & (0x01 << VM_CALL_KW_SPLAT_bit))) {
        if (boff) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_splatkw, 0));
        }
        else {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_splatkw, 0));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        }
    }
    int dup_argn = argc + 1 + boff;
    int keyword_len = 0;
    if (keywords) {
        keyword_len = keywords->keyword_len;
        dup_argn += keyword_len;
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dupn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(dup_argn), ((VALUE)(dup_argn)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(dup_argn)))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, (idAREF), (VALUE)(__builtin_choose_expr( __builtin_constant_p(argc), ((VALUE)(argc)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(argc))), (((void *)0)), (VALUE)(__builtin_choose_expr( __builtin_constant_p(flag & ~((0x01 << VM_CALL_ARGS_SPLAT_MUT_bit) | (0x01 << VM_CALL_KW_SPLAT_MUT_bit))), ((VALUE)(flag & ~((0x01 << VM_CALL_ARGS_SPLAT_MUT_bit) | (0x01 << VM_CALL_KW_SPLAT_MUT_bit)))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(flag & ~((0x01 << VM_CALL_ARGS_SPLAT_MUT_bit) | (0x01 << VM_CALL_KW_SPLAT_MUT_bit))))), (keywords)));
    pm_compile_node(iseq, (node->value), ret, 0, scope_node);
    ID id_operator = pm_constant_id_lookup(scope_node, node->binary_operator);
    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((id_operator)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
    if (!popped) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(dup_argn + 1), ((VALUE)(dup_argn + 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(dup_argn + 1)))));
    }
    if (flag & (0x01 << VM_CALL_ARGS_SPLAT_bit)) {
        if (flag & (0x01 << VM_CALL_KW_SPLAT_bit)) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(2 + boff), ((VALUE)(2 + boff)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2 + boff)))));
            if (!(flag & (0x01 << VM_CALL_ARGS_SPLAT_MUT_bit))) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_splatarray, 1, (VALUE)(((VALUE)RUBY_Qtrue))));
                flag |= (0x01 << VM_CALL_ARGS_SPLAT_MUT_bit);
            }
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_swap, 0));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pushtoarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(2 + boff), ((VALUE)(2 + boff)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2 + boff)))));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        }
        else {
            if (boff > 0) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dupn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_swap, 0));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
            }
            if (!(flag & (0x01 << VM_CALL_ARGS_SPLAT_MUT_bit))) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_swap, 0));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_splatarray, 1, (VALUE)(((VALUE)RUBY_Qtrue))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_swap, 0));
                flag |= (0x01 << VM_CALL_ARGS_SPLAT_MUT_bit);
            }
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pushtoarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
            if (boff > 0) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
            }
        }
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, (idASET), (VALUE)(__builtin_choose_expr( __builtin_constant_p(argc), ((VALUE)(argc)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(argc))), (((void *)0)), (VALUE)(__builtin_choose_expr( __builtin_constant_p(flag), ((VALUE)(flag)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(flag))), (keywords)));
    }
    else if (flag & (0x01 << VM_CALL_KW_SPLAT_bit)) {
        if (boff > 0) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_swap, 0));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)))));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        }
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_swap, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, (idASET), (VALUE)(__builtin_choose_expr( __builtin_constant_p(argc + 1), ((VALUE)(argc + 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(argc + 1))), (((void *)0)), (VALUE)(__builtin_choose_expr( __builtin_constant_p(flag), ((VALUE)(flag)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(flag))), (keywords)));
    }
    else if (keyword_len) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_opt_reverse, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(keyword_len + boff + 2), ((VALUE)(keyword_len + boff + 2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(keyword_len + boff + 2)))));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_opt_reverse, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(keyword_len + boff + 1), ((VALUE)(keyword_len + boff + 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(keyword_len + boff + 1)))));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, (idASET), (VALUE)(__builtin_choose_expr( __builtin_constant_p(argc + 1), ((VALUE)(argc + 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(argc + 1))), (((void *)0)), (VALUE)(__builtin_choose_expr( __builtin_constant_p(flag), ((VALUE)(flag)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(flag))), (keywords)));
    }
    else {
        if (boff > 0) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_swap, 0));
        }
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, (idASET), (VALUE)(__builtin_choose_expr( __builtin_constant_p(argc + 1), ((VALUE)(argc + 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(argc + 1))), (((void *)0)), (VALUE)(__builtin_choose_expr( __builtin_constant_p(flag), ((VALUE)(flag)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(flag))), (keywords)));
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
}
static void
pm_compile_index_control_flow_write_node(rb_iseq_t *iseq, const pm_node_t *node, const pm_node_t *receiver, const pm_arguments_node_t *arguments, const pm_block_argument_node_t *block, const pm_node_t *value, const pm_node_location_t *node_location, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node)
{
    const pm_node_location_t location = *node_location;
    if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
    pm_compile_node(iseq, (receiver), ret, 0, scope_node);
    int boff = (block == ((void *)0) ? 0 : 1);
    int flag = (((enum pm_node_type) (receiver)->type) == (PM_SELF_NODE)) ? (0x01 << VM_CALL_FCALL_bit) : 0;
    struct rb_callinfo_kwarg *keywords = ((void *)0);
    int argc = pm_setup_args(arguments, (const pm_node_t *) block, &flag, &keywords, iseq, ret, scope_node, node_location);
    if ((argc > 0 || boff) && (flag & (0x01 << VM_CALL_KW_SPLAT_bit))) {
        if (boff) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_splatkw, 0));
        }
        else {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_splatkw, 0));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        }
    }
    int dup_argn = argc + 1 + boff;
    int keyword_len = 0;
    if (keywords) {
        keyword_len = keywords->keyword_len;
        dup_argn += keyword_len;
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dupn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(dup_argn), ((VALUE)(dup_argn)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(dup_argn)))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, (idAREF), (VALUE)(__builtin_choose_expr( __builtin_constant_p(argc), ((VALUE)(argc)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(argc))), (((void *)0)), (VALUE)(__builtin_choose_expr( __builtin_constant_p(flag & ~((0x01 << VM_CALL_ARGS_SPLAT_MUT_bit) | (0x01 << VM_CALL_KW_SPLAT_MUT_bit))), ((VALUE)(flag & ~((0x01 << VM_CALL_ARGS_SPLAT_MUT_bit) | (0x01 << VM_CALL_KW_SPLAT_MUT_bit)))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(flag & ~((0x01 << VM_CALL_ARGS_SPLAT_MUT_bit) | (0x01 << VM_CALL_KW_SPLAT_MUT_bit))))), (keywords)));
    LABEL *label = new_label_body(iseq, (location.line));
    LABEL *lfin = new_label_body(iseq, (location.line));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
    if ((((enum pm_node_type) (node)->type) == (PM_INDEX_AND_WRITE_NODE))) {
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(label))), ((label)->refcnt++));
    }
    else {
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchif, 1, (VALUE)(label))), ((label)->refcnt++));
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
    pm_compile_node(iseq, (value), ret, 0, scope_node);
    if (!popped) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(dup_argn + 1), ((VALUE)(dup_argn + 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(dup_argn + 1)))));
    }
    if (flag & (0x01 << VM_CALL_ARGS_SPLAT_bit)) {
        if (flag & (0x01 << VM_CALL_KW_SPLAT_bit)) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(2 + boff), ((VALUE)(2 + boff)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2 + boff)))));
            if (!(flag & (0x01 << VM_CALL_ARGS_SPLAT_MUT_bit))) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_splatarray, 1, (VALUE)(((VALUE)RUBY_Qtrue))));
                flag |= (0x01 << VM_CALL_ARGS_SPLAT_MUT_bit);
            }
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_swap, 0));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pushtoarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(2 + boff), ((VALUE)(2 + boff)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2 + boff)))));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        }
        else {
            if (boff > 0) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dupn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_swap, 0));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
            }
            if (!(flag & (0x01 << VM_CALL_ARGS_SPLAT_MUT_bit))) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_swap, 0));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_splatarray, 1, (VALUE)(((VALUE)RUBY_Qtrue))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_swap, 0));
                flag |= (0x01 << VM_CALL_ARGS_SPLAT_MUT_bit);
            }
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pushtoarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
            if (boff > 0) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
            }
        }
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, (idASET), (VALUE)(__builtin_choose_expr( __builtin_constant_p(argc), ((VALUE)(argc)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(argc))), (((void *)0)), (VALUE)(__builtin_choose_expr( __builtin_constant_p(flag), ((VALUE)(flag)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(flag))), (keywords)));
    }
    else if (flag & (0x01 << VM_CALL_KW_SPLAT_bit)) {
        if (boff > 0) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_swap, 0));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)))));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        }
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_swap, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, (idASET), (VALUE)(__builtin_choose_expr( __builtin_constant_p(argc + 1), ((VALUE)(argc + 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(argc + 1))), (((void *)0)), (VALUE)(__builtin_choose_expr( __builtin_constant_p(flag), ((VALUE)(flag)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(flag))), (keywords)));
    }
    else if (keyword_len) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_opt_reverse, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(keyword_len + boff + 1), ((VALUE)(keyword_len + boff + 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(keyword_len + boff + 1)))));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_opt_reverse, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(keyword_len + boff + 0), ((VALUE)(keyword_len + boff + 0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(keyword_len + boff + 0)))));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, (idASET), (VALUE)(__builtin_choose_expr( __builtin_constant_p(argc + 1), ((VALUE)(argc + 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(argc + 1))), (((void *)0)), (VALUE)(__builtin_choose_expr( __builtin_constant_p(flag), ((VALUE)(flag)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(flag))), (keywords)));
    }
    else {
        if (boff > 0) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_swap, 0));
        }
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, (idASET), (VALUE)(__builtin_choose_expr( __builtin_constant_p(argc + 1), ((VALUE)(argc + 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(argc + 1))), (((void *)0)), (VALUE)(__builtin_choose_expr( __builtin_constant_p(flag), ((VALUE)(flag)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(flag))), (keywords)));
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_jump, 1, (VALUE)(lfin))), ((lfin)->refcnt++));
    ADD_ELEM((ret), (LINK_ELEMENT *) (label));
    if (!popped) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(dup_argn + 1), ((VALUE)(dup_argn + 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(dup_argn + 1)))));
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_adjuststack, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(dup_argn + 1), ((VALUE)(dup_argn + 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(dup_argn + 1)))));
    ADD_ELEM((ret), (LINK_ELEMENT *) (lfin));
}
static int pm_compile_pattern(rb_iseq_t *iseq, pm_scope_node_t *scope_node, const pm_node_t *node, LINK_ANCHOR *const ret, LABEL *matched_label, LABEL *unmatched_label, _Bool in_single_pattern, _Bool in_alternation_pattern, _Bool use_deconstructed_cache, unsigned int base_index);
static int
pm_compile_pattern_generic_error(rb_iseq_t *iseq, pm_scope_node_t *scope_node, const pm_node_t *node, LINK_ANCHOR *const ret, VALUE message, unsigned int base_index)
{
    const pm_node_location_t location = ((pm_node_location_t) { .line = pm_newline_list_line(&(scope_node->parser)->newline_list, ((const pm_node_t *) (node))->location.start, (scope_node->parser)->start_line), .node_id = ((const pm_node_t *) (node))->node_id });
    LABEL *match_succeeded_label = new_label_body(iseq, (location.line));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchif, 1, (VALUE)(match_succeeded_label))), ((match_succeeded_label)->refcnt++));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(message)));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)))));
    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((id_core_sprintf)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(base_index + 1 + 1), ((VALUE)(base_index + 1 + 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(base_index + 1 + 1)))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qfalse))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(base_index + 2 + 2), ((VALUE)(base_index + 2 + 2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(base_index + 2 + 2)))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) (match_succeeded_label));
    return 1;
}
static int
pm_compile_pattern_length_error(rb_iseq_t *iseq, pm_scope_node_t *scope_node, const pm_node_t *node, LINK_ANCHOR *const ret, VALUE message, VALUE length, unsigned int base_index)
{
    const pm_node_location_t location = ((pm_node_location_t) { .line = pm_newline_list_line(&(scope_node->parser)->newline_list, ((const pm_node_t *) (node))->location.start, (scope_node->parser)->start_line), .node_id = ((const pm_node_t *) (node))->node_id });
    LABEL *match_succeeded_label = new_label_body(iseq, (location.line));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchif, 1, (VALUE)(match_succeeded_label))), ((match_succeeded_label)->refcnt++));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(message)));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((idLength)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(length)));
    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((id_core_sprintf)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(4), ((VALUE)(4)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(4)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(base_index + 1 + 1), ((VALUE)(base_index + 1 + 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(base_index + 1 + 1)))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qfalse))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(base_index + 2 + 2), ((VALUE)(base_index + 2 + 2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(base_index + 2 + 2)))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) (match_succeeded_label));
    return 1;
}
static int
pm_compile_pattern_eqq_error(rb_iseq_t *iseq, pm_scope_node_t *scope_node, const pm_node_t *node, LINK_ANCHOR *const ret, unsigned int base_index)
{
    const pm_node_location_t location = ((pm_node_location_t) { .line = pm_newline_list_line(&(scope_node->parser)->newline_list, ((const pm_node_t *) (node))->location.start, (scope_node->parser)->start_line), .node_id = ((const pm_node_t *) (node))->node_id });
    LABEL *match_succeeded_label = new_label_body(iseq, (location.line));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchif, 1, (VALUE)(match_succeeded_label))), ((match_succeeded_label)->refcnt++));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
    VALUE operand = rb_fstring_new(("%p === %p does not return true"), ((sizeof("%p === %p does not return true" "") / sizeof("%p === %p does not return true" ""[0])) - 1));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(operand)));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(5), ((VALUE)(5)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(5)))));
    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((id_core_sprintf)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(base_index + 1 + 1), ((VALUE)(base_index + 1 + 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(base_index + 1 + 1)))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qfalse))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(base_index + 2 + 2), ((VALUE)(base_index + 2 + 2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(base_index + 2 + 2)))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) (match_succeeded_label));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
    return 1;
}
static int
pm_compile_pattern_match(rb_iseq_t *iseq, pm_scope_node_t *scope_node, const pm_node_t *node, LINK_ANCHOR *const ret, LABEL *unmatched_label, _Bool in_single_pattern, _Bool in_alternation_pattern, _Bool use_deconstructed_cache, unsigned int base_index)
{
    LABEL *matched_label = new_label_body(iseq, (pm_node_line_number(scope_node->parser, node)));
    if (!(pm_compile_pattern(iseq, scope_node, node, ret, matched_label, unmatched_label, in_single_pattern, in_alternation_pattern, use_deconstructed_cache, base_index))) {((void)0);return 0;};
    ADD_ELEM((ret), (LINK_ELEMENT *) (matched_label));
    return 1;
}
static int
pm_compile_pattern_deconstruct(rb_iseq_t *iseq, pm_scope_node_t *scope_node, const pm_node_t *node, LINK_ANCHOR *const ret, LABEL *deconstruct_label, LABEL *match_failed_label, LABEL *deconstructed_label, LABEL *type_error_label, _Bool in_single_pattern, _Bool use_deconstructed_cache, unsigned int base_index)
{
    const pm_node_location_t location = ((pm_node_location_t) { .line = pm_newline_list_line(&(scope_node->parser)->newline_list, ((const pm_node_t *) (node))->location.start, (scope_node->parser)->start_line), .node_id = ((const pm_node_t *) (node))->node_id });
    if (use_deconstructed_cache) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(base_index + 0), ((VALUE)(base_index + 0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(base_index + 0)))));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchnil, 1, (VALUE)(deconstruct_label))), ((deconstruct_label)->refcnt++));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(base_index + 0), ((VALUE)(base_index + 0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(base_index + 0)))));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(match_failed_label))), ((match_failed_label)->refcnt++));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(base_index + 0 - 1), ((VALUE)(base_index + 0 - 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(base_index + 0 - 1)))));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_jump, 1, (VALUE)(deconstructed_label))), ((deconstructed_label)->refcnt++));
    }
    else {
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_jump, 1, (VALUE)(deconstruct_label))), ((deconstruct_label)->refcnt++));
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) (deconstruct_label));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
    VALUE operand = rb_id2sym((__builtin_constant_p("deconstruct") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("deconstruct")); }) : (rb_intern)("deconstruct")));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(operand)));
    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((idRespond_to)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
    if (use_deconstructed_cache) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(base_index + 0 + 1), ((VALUE)(base_index + 0 + 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(base_index + 0 + 1)))));
    }
    if (in_single_pattern) {
        if (!(pm_compile_pattern_generic_error(iseq, scope_node, node, ret, rb_fstring_new(("%p does not respond to #deconstruct"), ((sizeof("%p does not respond to #deconstruct" "") / sizeof("%p does not respond to #deconstruct" ""[0])) - 1)), base_index + 1))) {((void)0);return 0;};
    }
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(match_failed_label))), ((match_failed_label)->refcnt++));
    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, (((__builtin_constant_p("deconstruct") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("deconstruct")); }) : (rb_intern)("deconstruct")))), (VALUE)((__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
    if (use_deconstructed_cache) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(base_index + 0), ((VALUE)(base_index + 0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(base_index + 0)))));
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_checktype, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(RUBY_T_ARRAY), ((VALUE)(RUBY_T_ARRAY)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(RUBY_T_ARRAY)))));
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(type_error_label))), ((type_error_label)->refcnt++));
    ADD_ELEM((ret), (LINK_ELEMENT *) (deconstructed_label));
    return 1;
}
static int
pm_compile_pattern_constant(rb_iseq_t *iseq, pm_scope_node_t *scope_node, const pm_node_t *node, LINK_ANCHOR *const ret, LABEL *match_failed_label, _Bool in_single_pattern, unsigned int base_index)
{
    const pm_node_location_t location = ((pm_node_location_t) { .line = pm_newline_list_line(&(scope_node->parser)->newline_list, ((const pm_node_t *) (node))->location.start, (scope_node->parser)->start_line), .node_id = ((const pm_node_t *) (node))->node_id });
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
    pm_compile_node(iseq, (node), ret, 0, scope_node);
    if (in_single_pattern) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dupn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))));
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_checkmatch, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_CHECKMATCH_TYPE_CASE), ((VALUE)(VM_CHECKMATCH_TYPE_CASE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_CHECKMATCH_TYPE_CASE)))));
    if (in_single_pattern) {
        if (!(pm_compile_pattern_eqq_error(iseq, scope_node, node, ret, base_index + 3))) {((void)0);return 0;};
    }
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(match_failed_label))), ((match_failed_label)->refcnt++));
    return 1;
}
static void
pm_compile_pattern_error_handler(rb_iseq_t *iseq, const pm_scope_node_t *scope_node, const pm_node_t *node, LINK_ANCHOR *const ret, LABEL *done_label, _Bool popped)
{
    const pm_node_location_t location = ((pm_node_location_t) { .line = pm_newline_list_line(&(scope_node->parser)->newline_list, ((const pm_node_t *) (node))->location.start, (scope_node->parser)->start_line), .node_id = ((const pm_node_t *) (node))->node_id });
    LABEL *key_error_label = new_label_body(iseq, (location.line));
    LABEL *cleanup_label = new_label_body(iseq, (location.line));
    struct rb_callinfo_kwarg *kw_arg = rb_xmalloc_mul_add(2, sizeof(VALUE), sizeof(struct rb_callinfo_kwarg));
    kw_arg->references = 0;
    kw_arg->keyword_len = 2;
    kw_arg->keywords[0] = rb_id2sym((__builtin_constant_p("matchee") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("matchee")); }) : (rb_intern)("matchee")));
    kw_arg->keywords[1] = rb_id2sym((__builtin_constant_p("key") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("key")); }) : (rb_intern)("key")));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(2 + 2), ((VALUE)(2 + 2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2 + 2)))));
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchif, 1, (VALUE)(key_error_label))), ((key_error_label)->refcnt++));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(rb_eNoMatchingPatternError)));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
    {
        VALUE operand = rb_fstring_new(("%p: %s"), ((sizeof("%p: %s" "") / sizeof("%p: %s" ""[0])) - 1));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(operand)));
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(4), ((VALUE)(4)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(4)))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1 + 6), ((VALUE)(1 + 6)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1 + 6)))));
    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((id_core_sprintf)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((id_core_raise)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_jump, 1, (VALUE)(cleanup_label))), ((cleanup_label)->refcnt++));
    ADD_ELEM((ret), (LINK_ELEMENT *) (key_error_label));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(rb_eNoMatchingPatternKeyError)));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
    {
        VALUE operand = rb_fstring_new(("%p: %s"), ((sizeof("%p: %s" "") / sizeof("%p: %s" ""[0])) - 1));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(operand)));
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(4), ((VALUE)(4)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(4)))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1 + 6), ((VALUE)(1 + 6)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1 + 6)))));
    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((id_core_sprintf)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(3 + 4), ((VALUE)(3 + 4)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3 + 4)))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(4 + 5), ((VALUE)(4 + 5)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(4 + 5)))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((__builtin_constant_p("new") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("new")); }) : (rb_intern)("new"))), (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1))), (((void *)0)), (VALUE)(__builtin_choose_expr( __builtin_constant_p((0x01 << VM_CALL_KWARG_bit)), ((VALUE)((0x01 << VM_CALL_KWARG_bit))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((0x01 << VM_CALL_KWARG_bit)))), (kw_arg)));
    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((id_core_raise)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
    ADD_ELEM((ret), (LINK_ELEMENT *) (cleanup_label));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_adjuststack, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(7), ((VALUE)(7)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(7)))));
    if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_jump, 1, (VALUE)(done_label))), ((done_label)->refcnt++));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dupn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(5), ((VALUE)(5)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(5)))));
    if (popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
}
static int
pm_compile_pattern(rb_iseq_t *iseq, pm_scope_node_t *scope_node, const pm_node_t *node, LINK_ANCHOR *const ret, LABEL *matched_label, LABEL *unmatched_label, _Bool in_single_pattern, _Bool in_alternation_pattern, _Bool use_deconstructed_cache, unsigned int base_index)
{
    const pm_node_location_t location = ((pm_node_location_t) { .line = pm_newline_list_line(&(scope_node->parser)->newline_list, ((const pm_node_t *) (node))->location.start, (scope_node->parser)->start_line), .node_id = ((const pm_node_t *) (node))->node_id });
    switch (((enum pm_node_type) (node)->type)) {
      case PM_ARRAY_PATTERN_NODE: {
        const pm_array_pattern_node_t *cast = (const pm_array_pattern_node_t *) node;
        const size_t requireds_size = cast->requireds.size;
        const size_t posts_size = cast->posts.size;
        const size_t minimum_size = requireds_size + posts_size;
        _Bool rest_named = 0;
        _Bool use_rest_size = 0;
        if (cast->rest != ((void *)0)) {
            rest_named = ((((enum pm_node_type) (cast->rest)->type) == (PM_SPLAT_NODE)) && ((const pm_splat_node_t *) cast->rest)->expression != ((void *)0));
            use_rest_size = (rest_named || (!rest_named && posts_size > 0));
        }
        LABEL *match_failed_label = new_label_body(iseq, (location.line));
        LABEL *type_error_label = new_label_body(iseq, (location.line));
        LABEL *deconstruct_label = new_label_body(iseq, (location.line));
        LABEL *deconstructed_label = new_label_body(iseq, (location.line));
        if (use_rest_size) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_swap, 0));
            base_index++;
        }
        if (cast->constant != ((void *)0)) {
            if (!(pm_compile_pattern_constant(iseq, scope_node, cast->constant, ret, match_failed_label, in_single_pattern, base_index))) {((void)0);return 0;};
        }
        if (!(pm_compile_pattern_deconstruct(iseq, scope_node, node, ret, deconstruct_label, match_failed_label, deconstructed_label, type_error_label, in_single_pattern, use_deconstructed_cache, base_index))) {((void)0);return 0;};
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((idLength)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(minimum_size), ((VALUE)(minimum_size)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(minimum_size)))));
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((cast->rest == ((void *)0) ? idEq : idGE)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
        if (in_single_pattern) {
            VALUE message = cast->rest == ((void *)0) ? rb_fstring_new(("%p length mismatch (given %p, expected %p)"), ((sizeof("%p length mismatch (given %p, expected %p)" "") / sizeof("%p length mismatch (given %p, expected %p)" ""[0])) - 1)) : rb_fstring_new(("%p length mismatch (given %p, expected %p+)"), ((sizeof("%p length mismatch (given %p, expected %p+)" "") / sizeof("%p length mismatch (given %p, expected %p+)" ""[0])) - 1));
            if (!(pm_compile_pattern_length_error(iseq, scope_node, node, ret, message, __builtin_choose_expr( __builtin_constant_p(minimum_size), ((VALUE)(minimum_size)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(minimum_size)), base_index + 1))) {((void)0);return 0;};
        }
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(match_failed_label))), ((match_failed_label)->refcnt++));
        for (size_t index = 0; index < requireds_size; index++) {
            const pm_node_t *required = cast->requireds.nodes[index];
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(index), ((VALUE)(index)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(index)))));
            ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((idAREF)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
            if (!(pm_compile_pattern_match(iseq, scope_node, required, ret, match_failed_label, in_single_pattern, in_alternation_pattern, 0, base_index + 1))) {((void)0);return 0;};
        }
        if (cast->rest != ((void *)0)) {
            if (rest_named) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(requireds_size), ((VALUE)(requireds_size)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(requireds_size)))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
                ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((idLength)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(minimum_size), ((VALUE)(minimum_size)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(minimum_size)))));
                ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((idMINUS)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(4), ((VALUE)(4)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(4)))));
                ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((idAREF)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
                if (!(pm_compile_pattern_match(iseq, scope_node, ((const pm_splat_node_t *) cast->rest)->expression, ret, match_failed_label, in_single_pattern, in_alternation_pattern, 0, base_index + 1))) {((void)0);return 0;};
            }
            else if (posts_size > 0) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
                ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((idLength)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(minimum_size), ((VALUE)(minimum_size)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(minimum_size)))));
                ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((idMINUS)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
            }
        }
        for (size_t index = 0; index < posts_size; index++) {
            const pm_node_t *post = cast->posts.nodes[index];
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(requireds_size + index), ((VALUE)(requireds_size + index)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(requireds_size + index)))));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)))));
            ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((idPLUS)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
            ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((idAREF)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
            if (!(pm_compile_pattern_match(iseq, scope_node, post, ret, match_failed_label, in_single_pattern, in_alternation_pattern, 0, base_index + 1))) {((void)0);return 0;};
        }
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        if (use_rest_size) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        }
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_jump, 1, (VALUE)(matched_label))), ((matched_label)->refcnt++));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
        if (use_rest_size) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
        }
        ADD_ELEM((ret), (LINK_ELEMENT *) (type_error_label));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(rb_eTypeError)));
        {
            VALUE operand = rb_fstring_new(("deconstruct must return Array"), ((sizeof("deconstruct must return Array" "") / sizeof("deconstruct must return Array" ""[0])) - 1));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(operand)));
        }
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((id_core_raise)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) (match_failed_label));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        if (use_rest_size) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        }
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_jump, 1, (VALUE)(unmatched_label))), ((unmatched_label)->refcnt++));
        break;
      }
      case PM_FIND_PATTERN_NODE: {
        const pm_find_pattern_node_t *cast = (const pm_find_pattern_node_t *) node;
        const size_t size = cast->requireds.size;
        LABEL *match_failed_label = new_label_body(iseq, (location.line));
        LABEL *type_error_label = new_label_body(iseq, (location.line));
        LABEL *deconstruct_label = new_label_body(iseq, (location.line));
        LABEL *deconstructed_label = new_label_body(iseq, (location.line));
        if (cast->constant) {
            if (!(pm_compile_pattern_constant(iseq, scope_node, cast->constant, ret, match_failed_label, in_single_pattern, base_index))) {((void)0);return 0;};
        }
        if (!(pm_compile_pattern_deconstruct(iseq, scope_node, node, ret, deconstruct_label, match_failed_label, deconstructed_label, type_error_label, in_single_pattern, use_deconstructed_cache, base_index))) {((void)0);return 0;};
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((idLength)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(size), ((VALUE)(size)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(size)))));
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((idGE)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
        if (in_single_pattern) {
            if (!(pm_compile_pattern_length_error(iseq, scope_node, node, ret, rb_fstring_new(("%p length mismatch (given %p, expected %p+)"), ((sizeof("%p length mismatch (given %p, expected %p+)" "") / sizeof("%p length mismatch (given %p, expected %p+)" ""[0])) - 1)), __builtin_choose_expr( __builtin_constant_p(size), ((VALUE)(size)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(size)), base_index + 1))) {((void)0);return 0;};
        }
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(match_failed_label))), ((match_failed_label)->refcnt++));
        {
            LABEL *while_begin_label = new_label_body(iseq, (location.line));
            LABEL *next_loop_label = new_label_body(iseq, (location.line));
            LABEL *find_succeeded_label = new_label_body(iseq, (location.line));
            LABEL *find_failed_label = new_label_body(iseq, (location.line));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
            ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((idLength)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(size), ((VALUE)(size)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(size)))));
            ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((idMINUS)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))));
            ADD_ELEM((ret), (LINK_ELEMENT *) (while_begin_label));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))));
            ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((idLE)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
            (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(find_failed_label))), ((find_failed_label)->refcnt++));
            for (size_t index = 0; index < size; index++) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
                if (index != 0) {
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(index), ((VALUE)(index)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(index)))));
                    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((idPLUS)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
                }
                ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((idAREF)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
                if (!(pm_compile_pattern_match(iseq, scope_node, cast->requireds.nodes[index], ret, next_loop_label, in_single_pattern, in_alternation_pattern, 0, base_index + 4))) {((void)0);return 0;};
            }
            const pm_splat_node_t *left = cast->left;
            if (left->expression != ((void *)0)) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))));
                ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((idAREF)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
                if (!(pm_compile_pattern_match(iseq, scope_node, left->expression, ret, find_failed_label, in_single_pattern, in_alternation_pattern, 0, base_index + 4))) {((void)0);return 0;};
            }
            ((void)0);
            const pm_splat_node_t *right = (const pm_splat_node_t *) cast->right;
            if (right->expression != ((void *)0)) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(size), ((VALUE)(size)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(size)))));
                ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((idPLUS)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)))));
                ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((idAREF)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
                pm_compile_pattern_match(iseq, scope_node, right->expression, ret, find_failed_label, in_single_pattern, in_alternation_pattern, 0, base_index + 4);
            }
            (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_jump, 1, (VALUE)(find_succeeded_label))), ((find_succeeded_label)->refcnt++));
            ADD_ELEM((ret), (LINK_ELEMENT *) (next_loop_label));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
            ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((idPLUS)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
            (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_jump, 1, (VALUE)(while_begin_label))), ((while_begin_label)->refcnt++));
            ADD_ELEM((ret), (LINK_ELEMENT *) (find_failed_label));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_adjuststack, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)))));
            if (in_single_pattern) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
                {
                    VALUE operand = rb_fstring_new(("%p does not match to find pattern"), ((sizeof("%p does not match to find pattern" "") / sizeof("%p does not match to find pattern" ""[0])) - 1));
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(operand)));
                }
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))));
                ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((id_core_sprintf)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(base_index + 1 + 1), ((VALUE)(base_index + 1 + 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(base_index + 1 + 1)))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qfalse))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(base_index + 2 + 2), ((VALUE)(base_index + 2 + 2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(base_index + 2 + 2)))));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
            }
            (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_jump, 1, (VALUE)(match_failed_label))), ((match_failed_label)->refcnt++));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dupn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)))));
            ADD_ELEM((ret), (LINK_ELEMENT *) (find_succeeded_label));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_adjuststack, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)))));
        }
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_jump, 1, (VALUE)(matched_label))), ((matched_label)->refcnt++));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) (type_error_label));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(rb_eTypeError)));
        {
            VALUE operand = rb_fstring_new(("deconstruct must return Array"), ((sizeof("deconstruct must return Array" "") / sizeof("deconstruct must return Array" ""[0])) - 1));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(operand)));
        }
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((id_core_raise)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) (match_failed_label));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_jump, 1, (VALUE)(unmatched_label))), ((unmatched_label)->refcnt++));
        break;
      }
      case PM_HASH_PATTERN_NODE: {
        const pm_hash_pattern_node_t *cast = (const pm_hash_pattern_node_t *) node;
        _Bool has_rest = cast->rest != ((void *)0) && !((((enum pm_node_type) (cast->rest)->type) == (PM_ASSOC_SPLAT_NODE)) && ((const pm_assoc_splat_node_t *) cast->rest)->value == ((void *)0));
        _Bool has_keys = cast->elements.size > 0 || cast->rest != ((void *)0);
        LABEL *match_failed_label = new_label_body(iseq, (location.line));
        LABEL *type_error_label = new_label_body(iseq, (location.line));
        VALUE keys = ((VALUE)RUBY_Qnil);
        if (has_keys && !has_rest) {
            keys = rb_ary_new_capa(cast->elements.size);
            for (size_t index = 0; index < cast->elements.size; index++) {
                const pm_node_t *element = cast->elements.nodes[index];
                ((void)0);
                const pm_node_t *key = ((const pm_assoc_node_t *) element)->key;
                ((void)0);
                VALUE symbol = rb_id2sym(parse_string_symbol(scope_node, (const pm_symbol_node_t *) key));
                rb_ary_push(keys, symbol);
            }
        }
        if (cast->constant) {
            if (!(pm_compile_pattern_constant(iseq, scope_node, cast->constant, ret, match_failed_label, in_single_pattern, base_index))) {((void)0);return 0;};
        }
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
        {
            VALUE operand = rb_id2sym((__builtin_constant_p("deconstruct_keys") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("deconstruct_keys")); }) : (rb_intern)("deconstruct_keys")));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(operand)));
        }
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((idRespond_to)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
        if (in_single_pattern) {
            if (!(pm_compile_pattern_generic_error(iseq, scope_node, node, ret, rb_fstring_new(("%p does not respond to #deconstruct_keys"), ((sizeof("%p does not respond to #deconstruct_keys" "") / sizeof("%p does not respond to #deconstruct_keys" ""[0])) - 1)), base_index + 1))) {((void)0);return 0;};
        }
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(match_failed_label))), ((match_failed_label)->refcnt++));
        if (RB_NIL_P(keys)) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
        }
        else {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_duparray, 1, (VALUE)(keys)));
            (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(rb_obj_hide(keys)), "prism_compile.c", 2814));
        }
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, (((__builtin_constant_p("deconstruct_keys") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("deconstruct_keys")); }) : (rb_intern)("deconstruct_keys")))), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_checktype, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(RUBY_T_HASH), ((VALUE)(RUBY_T_HASH)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(RUBY_T_HASH)))));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(type_error_label))), ((type_error_label)->refcnt++));
        if (has_rest) {
            ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, (((__builtin_constant_p("dup") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("dup")); }) : (rb_intern)("dup")))), (VALUE)((__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
        }
        if (has_keys) {
            LINK_ANCHOR match_values[1] = {{{ISEQ_ELEMENT_ANCHOR,},&match_values[0].anchor}};
            for (size_t index = 0; index < cast->elements.size; index++) {
                const pm_node_t *element = cast->elements.nodes[index];
                ((void)0);
                const pm_assoc_node_t *assoc = (const pm_assoc_node_t *) element;
                const pm_node_t *key = assoc->key;
                ((void)0);
                VALUE symbol = rb_id2sym(parse_string_symbol(scope_node, (const pm_symbol_node_t *) key));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(symbol)));
                ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, (((__builtin_constant_p("key?") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("key?")); }) : (rb_intern)("key?")))), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
                if (in_single_pattern) {
                    LABEL *match_succeeded_label = new_label_body(iseq, (location.line));
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
                    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchif, 1, (VALUE)(match_succeeded_label))), ((match_succeeded_label)->refcnt++));
                    {
                        VALUE operand = rb_str_freeze(rb_sprintf("key not found: %+""l""i" "\v", symbol));
                        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(operand)));
                    }
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(base_index + 1 + 2), ((VALUE)(base_index + 1 + 2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(base_index + 1 + 2)))));
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qtrue))));
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(base_index + 2 + 3), ((VALUE)(base_index + 2 + 3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(base_index + 2 + 3)))));
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)))));
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(base_index + 3 + 4), ((VALUE)(base_index + 3 + 4)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(base_index + 3 + 4)))));
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(symbol)));
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(base_index + 4 + 5), ((VALUE)(base_index + 4 + 5)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(base_index + 4 + 5)))));
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_adjuststack, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(4), ((VALUE)(4)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(4)))));
                    ADD_ELEM((ret), (LINK_ELEMENT *) (match_succeeded_label));
                }
                (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(match_failed_label))), ((match_failed_label)->refcnt++));
                ADD_ELEM((match_values), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
                ADD_ELEM((match_values), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(symbol)));
                ADD_ELEM(((match_values)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((has_rest ? (__builtin_constant_p("delete") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("delete")); }) : (rb_intern)("delete")) : idAREF)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
                const pm_node_t *value = assoc->value;
                if ((((enum pm_node_type) (value)->type) == (PM_IMPLICIT_NODE))) {
                    value = ((const pm_implicit_node_t *) value)->value;
                }
                if (!(pm_compile_pattern_match(iseq, scope_node, value, match_values, match_failed_label, in_single_pattern, in_alternation_pattern, 0, base_index + 1))) {((void)0);return 0;};
            }
            APPEND_LIST((ret), (match_values));
        }
        else {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
            ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((idEmptyP)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
            if (in_single_pattern) {
                if (!(pm_compile_pattern_generic_error(iseq, scope_node, node, ret, rb_fstring_new(("%p is not empty"), ((sizeof("%p is not empty" "") / sizeof("%p is not empty" ""[0])) - 1)), base_index + 1))) {((void)0);return 0;};
            }
            (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(match_failed_label))), ((match_failed_label)->refcnt++));
        }
        if (has_rest) {
            switch (((enum pm_node_type) (cast->rest)->type)) {
              case PM_NO_KEYWORDS_PARAMETER_NODE: {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
                ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((idEmptyP)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
                if (in_single_pattern) {
                    pm_compile_pattern_generic_error(iseq, scope_node, node, ret, rb_fstring_new(("rest of %p is not empty"), ((sizeof("rest of %p is not empty" "") / sizeof("rest of %p is not empty" ""[0])) - 1)), base_index + 1);
                }
                (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(match_failed_label))), ((match_failed_label)->refcnt++));
                break;
              }
              case PM_ASSOC_SPLAT_NODE: {
                const pm_assoc_splat_node_t *splat = (const pm_assoc_splat_node_t *) cast->rest;
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
                pm_compile_pattern_match(iseq, scope_node, splat->value, ret, match_failed_label, in_single_pattern, in_alternation_pattern, 0, base_index + 1);
                break;
              }
              default:
                rb_bug("unreachable");
                break;
            }
        }
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_jump, 1, (VALUE)(matched_label))), ((matched_label)->refcnt++));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) (type_error_label));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(rb_eTypeError)));
        {
            VALUE operand = rb_fstring_new(("deconstruct_keys must return Hash"), ((sizeof("deconstruct_keys must return Hash" "") / sizeof("deconstruct_keys must return Hash" ""[0])) - 1));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(operand)));
        }
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((id_core_raise)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) (match_failed_label));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_jump, 1, (VALUE)(unmatched_label))), ((unmatched_label)->refcnt++));
        break;
      }
      case PM_CAPTURE_PATTERN_NODE: {
        const pm_capture_pattern_node_t *cast = (const pm_capture_pattern_node_t *) node;
        LABEL *match_failed_label = new_label_body(iseq, (location.line));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
        if (!(pm_compile_pattern_match(iseq, scope_node, cast->value, ret, match_failed_label, in_single_pattern, in_alternation_pattern, use_deconstructed_cache, base_index + 1))) {((void)0);return 0;};
        if (!(pm_compile_pattern(iseq, scope_node, (const pm_node_t *) cast->target, ret, matched_label, match_failed_label, in_single_pattern, in_alternation_pattern, 0, base_index))) {((void)0);return 0;};
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) (match_failed_label));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_jump, 1, (VALUE)(unmatched_label))), ((unmatched_label)->refcnt++));
        break;
      }
      case PM_LOCAL_VARIABLE_TARGET_NODE: {
        const pm_local_variable_target_node_t *cast = (const pm_local_variable_target_node_t *) node;
        pm_local_index_t index = pm_lookup_local_index(iseq, scope_node, cast->name, cast->depth);
        if (in_alternation_pattern) {
            ID id = pm_constant_id_lookup(scope_node, cast->name);
            const char *name = rb_id2name(id);
            if (name && strlen(name) > 0 && name[0] != '_') {
                append_compile_error(iseq, location.line, "illegal variable in alternative pattern (%""l""i" "\v"")", rb_id2str(id));
                return 0;
            }
        }
        pm_iseq_add_setlocal(iseq, (ret), (int) (location).line, (int) (location).node_id, (index.index), (index.level));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_jump, 1, (VALUE)(matched_label))), ((matched_label)->refcnt++));
        break;
      }
      case PM_ALTERNATION_PATTERN_NODE: {
        const pm_alternation_pattern_node_t *cast = (const pm_alternation_pattern_node_t *) node;
        LABEL *matched_left_label = new_label_body(iseq, (location.line));
        LABEL *unmatched_left_label = new_label_body(iseq, (location.line));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
        if (!(pm_compile_pattern(iseq, scope_node, cast->left, ret, matched_left_label, unmatched_left_label, in_single_pattern, 1, 1, base_index + 1))) {((void)0);return 0;};
        ADD_ELEM((ret), (LINK_ELEMENT *) (matched_left_label));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_jump, 1, (VALUE)(matched_label))), ((matched_label)->refcnt++));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) (unmatched_left_label));
        if (!(pm_compile_pattern(iseq, scope_node, cast->right, ret, matched_label, unmatched_label, in_single_pattern, 1, 1, base_index))) {((void)0);return 0;};
        break;
      }
      case PM_PARENTHESES_NODE:
        return pm_compile_pattern(iseq, scope_node, ((const pm_parentheses_node_t *) node)->body, ret, matched_label, unmatched_label, in_single_pattern, in_alternation_pattern, use_deconstructed_cache, base_index);
      case PM_PINNED_EXPRESSION_NODE:
        node = ((const pm_pinned_expression_node_t *) node)->expression;
      case PM_ARRAY_NODE:
      case PM_CLASS_VARIABLE_READ_NODE:
      case PM_CONSTANT_PATH_NODE:
      case PM_CONSTANT_READ_NODE:
      case PM_FALSE_NODE:
      case PM_FLOAT_NODE:
      case PM_GLOBAL_VARIABLE_READ_NODE:
      case PM_IMAGINARY_NODE:
      case PM_INSTANCE_VARIABLE_READ_NODE:
      case PM_INTEGER_NODE:
      case PM_INTERPOLATED_REGULAR_EXPRESSION_NODE:
      case PM_INTERPOLATED_STRING_NODE:
      case PM_INTERPOLATED_SYMBOL_NODE:
      case PM_INTERPOLATED_X_STRING_NODE:
      case PM_LAMBDA_NODE:
      case PM_LOCAL_VARIABLE_READ_NODE:
      case PM_NIL_NODE:
      case PM_SOURCE_ENCODING_NODE:
      case PM_SOURCE_FILE_NODE:
      case PM_SOURCE_LINE_NODE:
      case PM_RANGE_NODE:
      case PM_RATIONAL_NODE:
      case PM_REGULAR_EXPRESSION_NODE:
      case PM_SELF_NODE:
      case PM_STRING_NODE:
      case PM_SYMBOL_NODE:
      case PM_TRUE_NODE:
      case PM_X_STRING_NODE: {
        pm_compile_node(iseq, (node), ret, 0, scope_node);
        if (in_single_pattern) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dupn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))));
        }
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_checkmatch, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_CHECKMATCH_TYPE_CASE), ((VALUE)(VM_CHECKMATCH_TYPE_CASE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_CHECKMATCH_TYPE_CASE)))));
        if (in_single_pattern) {
            pm_compile_pattern_eqq_error(iseq, scope_node, node, ret, base_index + 2);
        }
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchif, 1, (VALUE)(matched_label))), ((matched_label)->refcnt++));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_jump, 1, (VALUE)(unmatched_label))), ((unmatched_label)->refcnt++));
        break;
      }
      case PM_PINNED_VARIABLE_NODE: {
        const pm_pinned_variable_node_t *cast = (const pm_pinned_variable_node_t *) node;
        if (!(pm_compile_pattern(iseq, scope_node, cast->variable, ret, matched_label, unmatched_label, in_single_pattern, in_alternation_pattern, 1, base_index))) {((void)0);return 0;};
        break;
      }
      case PM_IF_NODE:
      case PM_UNLESS_NODE: {
        const pm_node_t *predicate;
        const pm_node_t *statement;
        if ((((enum pm_node_type) (node)->type) == (PM_IF_NODE))) {
            const pm_if_node_t *cast = (const pm_if_node_t *) node;
            predicate = cast->predicate;
            ((void)0);
            statement = cast->statements->body.nodes[0];
        }
        else {
            const pm_unless_node_t *cast = (const pm_unless_node_t *) node;
            predicate = cast->predicate;
            ((void)0);
            statement = cast->statements->body.nodes[0];
        }
        if (!(pm_compile_pattern_match(iseq, scope_node, statement, ret, unmatched_label, in_single_pattern, in_alternation_pattern, use_deconstructed_cache, base_index))) {((void)0);return 0;};
        pm_compile_node(iseq, (predicate), ret, 0, scope_node);
        if (in_single_pattern) {
            LABEL *match_succeeded_label = new_label_body(iseq, (location.line));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
            if ((((enum pm_node_type) (node)->type) == (PM_IF_NODE))) {
                (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchif, 1, (VALUE)(match_succeeded_label))), ((match_succeeded_label)->refcnt++));
            }
            else {
                (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(match_succeeded_label))), ((match_succeeded_label)->refcnt++));
            }
            {
                VALUE operand = rb_fstring_new(("guard clause does not return true"), ((sizeof("guard clause does not return true" "") / sizeof("guard clause does not return true" ""[0])) - 1));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(operand)));
            }
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(base_index + 1 + 1), ((VALUE)(base_index + 1 + 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(base_index + 1 + 1)))));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qfalse))));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(base_index + 2 + 2), ((VALUE)(base_index + 2 + 2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(base_index + 2 + 2)))));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
            ADD_ELEM((ret), (LINK_ELEMENT *) (match_succeeded_label));
        }
        if ((((enum pm_node_type) (node)->type) == (PM_IF_NODE))) {
            (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(unmatched_label))), ((unmatched_label)->refcnt++));
        }
        else {
            (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchif, 1, (VALUE)(unmatched_label))), ((unmatched_label)->refcnt++));
        }
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_jump, 1, (VALUE)(matched_label))), ((matched_label)->refcnt++));
        break;
      }
      default:
        rb_bug("Unexpected node type in pattern matching expression: %s", pm_node_type_to_str(((enum pm_node_type) (node)->type)));
        break;
    }
    return 1;
}
void
pm_scope_node_init(const pm_node_t *node, pm_scope_node_t *scope, pm_scope_node_t *previous)
{
    memset(scope, 0, sizeof(pm_scope_node_t));
    scope->base.type = PM_SCOPE_NODE;
    scope->base.location.start = node->location.start;
    scope->base.location.end = node->location.end;
    scope->previous = previous;
    scope->ast_node = (pm_node_t *) node;
    if (previous) {
        scope->parser = previous->parser;
        scope->encoding = previous->encoding;
        scope->filepath_encoding = previous->filepath_encoding;
        scope->constants = previous->constants;
        scope->coverage_enabled = previous->coverage_enabled;
        scope->script_lines = previous->script_lines;
    }
    switch (((enum pm_node_type) (node)->type)) {
      case PM_BLOCK_NODE: {
        const pm_block_node_t *cast = (const pm_block_node_t *) node;
        scope->body = cast->body;
        scope->locals = cast->locals;
        scope->parameters = cast->parameters;
        break;
      }
      case PM_CLASS_NODE: {
        const pm_class_node_t *cast = (const pm_class_node_t *) node;
        scope->body = cast->body;
        scope->locals = cast->locals;
        break;
      }
      case PM_DEF_NODE: {
        const pm_def_node_t *cast = (const pm_def_node_t *) node;
        scope->parameters = (pm_node_t *) cast->parameters;
        scope->body = cast->body;
        scope->locals = cast->locals;
        break;
      }
      case PM_ENSURE_NODE: {
        const pm_ensure_node_t *cast = (const pm_ensure_node_t *) node;
        scope->body = (pm_node_t *) node;
        if (cast->statements != ((void *)0)) {
            scope->base.location.start = cast->statements->base.location.start;
            scope->base.location.end = cast->statements->base.location.end;
        }
        break;
      }
      case PM_FOR_NODE: {
        const pm_for_node_t *cast = (const pm_for_node_t *) node;
        scope->body = (pm_node_t *) cast->statements;
        break;
      }
      case PM_INTERPOLATED_REGULAR_EXPRESSION_NODE: {
        ((void)0);
        scope->body = (pm_node_t *) node;
        break;
      }
      case PM_LAMBDA_NODE: {
        const pm_lambda_node_t *cast = (const pm_lambda_node_t *) node;
        scope->parameters = cast->parameters;
        scope->body = cast->body;
        scope->locals = cast->locals;
        if (cast->parameters != ((void *)0)) {
            scope->base.location.start = cast->parameters->location.start;
        }
        else {
            scope->base.location.start = cast->operator_loc.end;
        }
        break;
      }
      case PM_MODULE_NODE: {
        const pm_module_node_t *cast = (const pm_module_node_t *) node;
        scope->body = cast->body;
        scope->locals = cast->locals;
        break;
      }
      case PM_POST_EXECUTION_NODE: {
        const pm_post_execution_node_t *cast = (const pm_post_execution_node_t *) node;
        scope->body = (pm_node_t *) cast->statements;
        break;
      }
      case PM_PROGRAM_NODE: {
        const pm_program_node_t *cast = (const pm_program_node_t *) node;
        scope->body = (pm_node_t *) cast->statements;
        scope->locals = cast->locals;
        break;
      }
      case PM_RESCUE_NODE: {
        const pm_rescue_node_t *cast = (const pm_rescue_node_t *) node;
        scope->body = (pm_node_t *) cast->statements;
        break;
      }
      case PM_RESCUE_MODIFIER_NODE: {
        const pm_rescue_modifier_node_t *cast = (const pm_rescue_modifier_node_t *) node;
        scope->body = (pm_node_t *) cast->rescue_expression;
        break;
      }
      case PM_SINGLETON_CLASS_NODE: {
        const pm_singleton_class_node_t *cast = (const pm_singleton_class_node_t *) node;
        scope->body = cast->body;
        scope->locals = cast->locals;
        break;
      }
      case PM_STATEMENTS_NODE: {
        const pm_statements_node_t *cast = (const pm_statements_node_t *) node;
        scope->body = (pm_node_t *) cast;
        break;
      }
      default:
        rb_bug("unreachable");
        break;
    }
}
void
pm_scope_node_destroy(pm_scope_node_t *scope_node)
{
    if (scope_node->index_lookup_table) {
        rb_st_free_table(scope_node->index_lookup_table);
    }
}
static void
pm_compile_retry_end_label(rb_iseq_t *iseq, LINK_ANCHOR *const ret, LABEL *retry_end_l)
{
    INSN *iobj;
    LINK_ELEMENT *last_elem = LAST_ELEMENT(ret);
    iobj = ((last_elem)->type == ISEQ_ELEMENT_INSN) ? (INSN*) last_elem : (INSN*) get_prev_insn((INSN*) last_elem);
    while (!((((INSN*)(iobj))->insn_id) == YARVINSN_send) && !((((INSN*)(iobj))->insn_id) == YARVINSN_invokesuper) && !((((INSN*)(iobj))->insn_id) == YARVINSN_sendforward) && !((((INSN*)(iobj))->insn_id) == YARVINSN_invokesuperforward)) {
        iobj = (INSN*) get_prev_insn(iobj);
    }
    ELEM_INSERT_NEXT(&iobj->link, (LINK_ELEMENT*) retry_end_l);
    if (&iobj->link == LAST_ELEMENT(ret)) {
        ret->last = (LINK_ELEMENT*) retry_end_l;
    }
}
static const char *
pm_iseq_builtin_function_name(const pm_scope_node_t *scope_node, const pm_node_t *receiver, ID method_id)
{
    const char *name = rb_id2name(method_id);
    static const char prefix[] = "__builtin_";
    const size_t prefix_len = sizeof(prefix) - 1;
    if (receiver == ((void *)0)) {
        if ((__builtin_expect(!!(strncmp(prefix, name, prefix_len) == 0), 0))) {
            return &name[prefix_len];
        }
    }
    else if ((((enum pm_node_type) (receiver)->type) == (PM_CALL_NODE))) {
        if (((((pm_node_t *)(receiver))->flags & (PM_CALL_NODE_FLAGS_VARIABLE_CALL)) != 0)) {
            const pm_call_node_t *cast = (const pm_call_node_t *) receiver;
            if (pm_constant_id_lookup(scope_node, cast->name) == rb_intern_const("__builtin")) {
                return name;
            }
        }
    }
    else if ((((enum pm_node_type) (receiver)->type) == (PM_CONSTANT_READ_NODE))) {
        const pm_constant_read_node_t *cast = (const pm_constant_read_node_t *) receiver;
        if (pm_constant_id_lookup(scope_node, cast->name) == rb_intern_const("Primitive")) {
            return name;
        }
    }
    return ((void *)0);
}
static int
pm_compile_builtin_attr(rb_iseq_t *iseq, const pm_scope_node_t *scope_node, const pm_arguments_node_t *arguments, const pm_node_location_t *node_location)
{
    if (arguments == ((void *)0)) {
        append_compile_error(iseq, node_location->line, "attr!: no argument");
        return 0;
    }
    const pm_node_t *argument;
    for (size_t index = 0; index < (&arguments->arguments)->size && ((argument) = (&arguments->arguments)->nodes[index]); index++) {
        if (!(((enum pm_node_type) (argument)->type) == (PM_SYMBOL_NODE))) {
            append_compile_error(iseq, node_location->line, "non symbol argument to attr!: %s", pm_node_type_to_str(((enum pm_node_type) (argument)->type)));
            return 0;
        }
        VALUE symbol = pm_static_literal_value(iseq, argument, scope_node);
        VALUE string = rb_sym2str(symbol);
        if (strcmp(RSTRING_PTR(string), "leaf") == 0) {
            ((iseq)->body)->builtin_attrs |= BUILTIN_ATTR_LEAF;
        }
        else if (strcmp(RSTRING_PTR(string), "inline_block") == 0) {
            ((iseq)->body)->builtin_attrs |= BUILTIN_ATTR_INLINE_BLOCK;
        }
        else if (strcmp(RSTRING_PTR(string), "use_block") == 0) {
            iseq_set_use_block(iseq);
        }
        else if (strcmp(RSTRING_PTR(string), "c_trace") == 0) {
            ((iseq)->body)->builtin_attrs |= BUILTIN_ATTR_C_TRACE;
        }
        else {
            append_compile_error(iseq, node_location->line, "unknown argument to attr!: %s", RSTRING_PTR(string));
            return 0;
        }
    }
    return 1;
}
static int
pm_compile_builtin_arg(rb_iseq_t *iseq, LINK_ANCHOR *const ret, const pm_scope_node_t *scope_node, const pm_arguments_node_t *arguments, const pm_node_location_t *node_location, int popped)
{
    if (arguments == ((void *)0)) {
        append_compile_error(iseq, node_location->line, "arg!: no argument");
        return 0;
    }
    if (arguments->arguments.size != 1) {
        append_compile_error(iseq, node_location->line, "arg!: too many argument");
        return 0;
    }
    const pm_node_t *argument = arguments->arguments.nodes[0];
    if (!(((enum pm_node_type) (argument)->type) == (PM_SYMBOL_NODE))) {
        append_compile_error(iseq, node_location->line, "non symbol argument to arg!: %s", pm_node_type_to_str(((enum pm_node_type) (argument)->type)));
        return 0;
    }
    if (!popped) {
        ID name = parse_string_symbol(scope_node, ((const pm_symbol_node_t *) argument));
        int index = ((((iseq)->body)->local_iseq)->body)->local_table_size - get_local_var_idx(iseq, name);
        if(0)printf("id: %s idx: %d\n", rb_id2name(name), index);
        pm_iseq_add_getlocal(iseq, (ret), (int) (*node_location).line, (int) (*node_location).node_id, (index), (get_lvar_level(iseq)));
    }
    return 1;
}
static int
pm_compile_builtin_mandatory_only_method(rb_iseq_t *iseq, pm_scope_node_t *scope_node, const pm_call_node_t *call_node, const pm_node_location_t *node_location)
{
    const pm_node_t *ast_node = scope_node->ast_node;
    if (!(((enum pm_node_type) (ast_node)->type) == (PM_DEF_NODE))) {
        rb_bug("mandatory_only?: not in method definition");
        return 0;
    }
    const pm_def_node_t *def_node = (const pm_def_node_t *) ast_node;
    const pm_parameters_node_t *parameters_node = def_node->parameters;
    if (parameters_node == ((void *)0)) {
        rb_bug("mandatory_only?: in method definition with no parameters");
        return 0;
    }
    const pm_node_t *body_node = def_node->body;
    if (body_node == ((void *)0) || !(((enum pm_node_type) (body_node)->type) == (PM_STATEMENTS_NODE)) || (((const pm_statements_node_t *) body_node)->body.size != 1) || !(((enum pm_node_type) (((const pm_statements_node_t *) body_node)->body.nodes[0])->type) == (PM_IF_NODE))) {
        rb_bug("mandatory_only?: not in method definition with plain statements");
        return 0;
    }
    const pm_if_node_t *if_node = (const pm_if_node_t *) ((const pm_statements_node_t *) body_node)->body.nodes[0];
    if (if_node->predicate != ((const pm_node_t *) call_node)) {
        rb_bug("mandatory_only?: can't find mandatory node");
        return 0;
    }
    pm_parameters_node_t parameters = {
        .base = parameters_node->base,
        .requireds = parameters_node->requireds
    };
    const pm_def_node_t def = {
        .base = def_node->base,
        .name = def_node->name,
        .receiver = def_node->receiver,
        .parameters = &parameters,
        .body = (pm_node_t *) if_node->statements,
        .locals = {
            .ids = def_node->locals.ids,
            .size = parameters_node->requireds.size,
            .capacity = def_node->locals.capacity
        }
    };
    pm_scope_node_t next_scope_node;
    pm_scope_node_init(&def.base, &next_scope_node, scope_node);
    int error_state;
    ((iseq)->body)->mandatory_only_iseq = pm_iseq_new_with_opt(
        &next_scope_node,
        rb_iseq_base_label(iseq),
        rb_iseq_path(iseq),
        rb_iseq_realpath(iseq),
        node_location->line,
        ((void *)0),
        0,
        ISEQ_TYPE_METHOD,
        ISEQ_COMPILE_DATA(iseq)->option,
        &error_state
    );
    if (error_state) {
        ((void)0);
        rb_jump_tag(error_state);
    }
    pm_scope_node_destroy(&next_scope_node);
    return 1;
}
static int
pm_compile_builtin_function_call(rb_iseq_t *iseq, LINK_ANCHOR *const ret, pm_scope_node_t *scope_node, const pm_call_node_t *call_node, const pm_node_location_t *node_location, int popped, const rb_iseq_t *parent_block, const char *builtin_func)
{
    const pm_arguments_node_t *arguments = call_node->arguments;
    if (parent_block != ((void *)0)) {
        append_compile_error(iseq, node_location->line, "should not call builtins here.");
        return 0;
    }
    char inline_func[sizeof("_bi") + ((((sizeof(int)) * 8) * 3010 + 9998) / 9999)];
    _Bool cconst = 0;
retry:;
    const struct rb_builtin_function *bf = iseq_builtin_function_lookup(iseq, builtin_func);
    if (bf == ((void *)0)) {
        if (strcmp("cstmt!", builtin_func) == 0 || strcmp("cexpr!", builtin_func) == 0) {
        }
        else if (strcmp("cconst!", builtin_func) == 0) {
            cconst = 1;
        }
        else if (strcmp("cinit!", builtin_func) == 0) {
            return 1;
        }
        else if (strcmp("attr!", builtin_func) == 0) {
            return pm_compile_builtin_attr(iseq, scope_node, arguments, node_location);
        }
        else if (strcmp("arg!", builtin_func) == 0) {
            return pm_compile_builtin_arg(iseq, ret, scope_node, arguments, node_location, popped);
        }
        else if (strcmp("mandatory_only?", builtin_func) == 0) {
            if (popped) {
                rb_bug("mandatory_only? should be in if condition");
            }
            else if (!LIST_INSN_SIZE_ZERO(ret)) {
                rb_bug("mandatory_only? should be put on top");
            }
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*node_location).line, (int) (*node_location).node_id, YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qfalse))));
            return pm_compile_builtin_mandatory_only_method(iseq, scope_node, call_node, node_location);
        }
        else if (1) {
            rb_bug("can't find builtin function:%s", builtin_func);
        }
        else {
            append_compile_error(iseq, node_location->line, "can't find builtin function:%s", builtin_func);
            return 0;
        }
        int inline_index = node_location->line;
        ruby_snprintf(inline_func, sizeof(inline_func), "_bi" "%d", inline_index);
        builtin_func = inline_func;
        arguments = ((void *)0);
        goto retry;
    }
    if (cconst) {
        typedef VALUE(*builtin_func0)(void *, VALUE);
        VALUE const_val = (*(builtin_func0)(uintptr_t)bf->func_ptr)(((void *)0), ((VALUE)RUBY_Qnil));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*node_location).line, (int) (*node_location).node_id, YARVINSN_putobject, 1, (VALUE)(const_val)));
        return 1;
    }
    LINK_ANCHOR args_seq[1] = {{{ISEQ_ELEMENT_ANCHOR,},&args_seq[0].anchor}};
    int flags = 0;
    struct rb_callinfo_kwarg *keywords = ((void *)0);
    int argc = pm_setup_args(arguments, call_node->block, &flags, &keywords, iseq, args_seq, scope_node, node_location);
    if (argc != bf->argc) {
        append_compile_error(iseq, node_location->line, "argc is not match for builtin function:%s (expect %d but %d)", builtin_func, bf->argc, argc);
        return 0;
    }
    unsigned int start_index;
    if (delegate_call_p(iseq, argc, args_seq, &start_index)) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*node_location).line, (int) (*node_location).node_id, YARVINSN_opt_invokebuiltin_delegate, 2, (VALUE)(bf), (VALUE)(__builtin_choose_expr( __builtin_constant_p(start_index), ((VALUE)(start_index)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(start_index)))));
    }
    else {
        APPEND_LIST((ret), (args_seq));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*node_location).line, (int) (*node_location).node_id, YARVINSN_invokebuiltin, 1, (VALUE)(bf)));
    }
    if (popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*node_location).line, (int) (*node_location).node_id, YARVINSN_pop, 0));
    return 1;
}
static void
pm_compile_call(rb_iseq_t *iseq, const pm_call_node_t *call_node, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node, ID method_id, LABEL *start)
{
    const pm_location_t *message_loc = &call_node->message_loc;
    if (message_loc->start == ((void *)0)) message_loc = &call_node->base.location;
    const pm_node_location_t location = ((pm_node_location_t) { .line = pm_newline_list_line(&(scope_node->parser)->newline_list, (message_loc)->start, (scope_node->parser)->start_line), .node_id = call_node->base.node_id });
    LABEL *else_label = new_label_body(iseq, (location.line));
    LABEL *end_label = new_label_body(iseq, (location.line));
    LABEL *retry_end_l = new_label_body(iseq, (location.line));
    VALUE branches = ((VALUE)RUBY_Qfalse);
    rb_code_location_t code_location = { 0 };
    int node_id = location.node_id;
    if (((((pm_node_t *)(call_node))->flags & (PM_CALL_NODE_FLAGS_SAFE_NAVIGATION)) != 0)) {
        if ((((iseq)->body)->variable.coverage && RARRAY_AREF(((iseq)->body)->variable.coverage, 1))) {
            const uint8_t *cursors[3] = {
                call_node->closing_loc.end,
                call_node->arguments == ((void *)0) ? ((void *)0) : call_node->arguments->base.location.end,
                call_node->message_loc.end
            };
            const uint8_t *end_cursor = cursors[0];
            end_cursor = (end_cursor == ((void *)0) || cursors[1] == ((void *)0)) ? cursors[1] : (end_cursor > cursors[1] ? end_cursor : cursors[1]);
            end_cursor = (end_cursor == ((void *)0) || cursors[2] == ((void *)0)) ? cursors[2] : (end_cursor > cursors[2] ? end_cursor : cursors[2]);
            if (!end_cursor) end_cursor = call_node->closing_loc.end;
            const pm_line_column_t start_location = pm_newline_list_line_column(&(scope_node->parser)->newline_list, ((const pm_node_t *) (call_node))->location.start, (scope_node->parser)->start_line);
            const pm_line_column_t end_location = pm_newline_list_line_column(&scope_node->parser->newline_list, end_cursor, scope_node->parser->start_line);
            code_location = (rb_code_location_t) {
                .beg_pos = { .lineno = start_location.line, .column = start_location.column },
                .end_pos = { .lineno = end_location.line, .column = end_location.column }
            };
            branches = decl_branch_base(iseq, (rb_int2inum((intptr_t)(void *)(call_node))), &code_location, "&.");
        }
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchnil, 1, (VALUE)(else_label))), ((else_label)->refcnt++));
        add_trace_branch_coverage(iseq, ret, &code_location, node_id, 0, "then", branches);
    }
    int flags = 0;
    struct rb_callinfo_kwarg *kw_arg = ((void *)0);
    int orig_argc = pm_setup_args(call_node->arguments, call_node->block, &flags, &kw_arg, iseq, ret, scope_node, &location);
    const rb_iseq_t *previous_block = ISEQ_COMPILE_DATA(iseq)->current_block;
    const rb_iseq_t *block_iseq = ((void *)0);
    if (call_node->block != ((void *)0) && (((enum pm_node_type) (call_node->block)->type) == (PM_BLOCK_NODE))) {
        pm_scope_node_t next_scope_node;
        pm_scope_node_init(call_node->block, &next_scope_node, scope_node);
        block_iseq = pm_new_child_iseq(iseq, (&next_scope_node), rb_fstring(make_name_for_block(iseq)), iseq, (ISEQ_TYPE_BLOCK), (pm_node_line_number(scope_node->parser, call_node->block)));
        pm_scope_node_destroy(&next_scope_node);
        ISEQ_COMPILE_DATA(iseq)->current_block = block_iseq;
    }
    else {
        if (((((pm_node_t *)(call_node))->flags & (PM_CALL_NODE_FLAGS_VARIABLE_CALL)) != 0)) {
            flags |= (0x01 << VM_CALL_VCALL_bit);
        }
        if (!flags) {
            flags |= (0x01 << VM_CALL_ARGS_SIMPLE_bit);
        }
    }
    if (((((pm_node_t *)(call_node))->flags & (PM_CALL_NODE_FLAGS_IGNORE_VISIBILITY)) != 0)) {
        flags |= (0x01 << VM_CALL_FCALL_bit);
    }
    if (!popped && ((((pm_node_t *)(call_node))->flags & (PM_CALL_NODE_FLAGS_ATTRIBUTE_WRITE)) != 0)) {
        if (flags & (0x01 << VM_CALL_ARGS_BLOCKARG_bit)) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
            if (flags & (0x01 << VM_CALL_ARGS_SPLAT_bit)) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(-1), ((VALUE)(-1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(-1)))));
                ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((idAREF)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)(__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))), (((void *)0))));
            }
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(orig_argc + 3), ((VALUE)(orig_argc + 3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(orig_argc + 3)))));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        }
        else if (flags & (0x01 << VM_CALL_ARGS_SPLAT_bit)) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(-1), ((VALUE)(-1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(-1)))));
            ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((idAREF)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)(__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))), (((void *)0))));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(orig_argc + 2), ((VALUE)(orig_argc + 2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(orig_argc + 2)))));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        }
        else {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(orig_argc + 1), ((VALUE)(orig_argc + 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(orig_argc + 1)))));
        }
    }
    if ((flags & (0x01 << VM_CALL_KW_SPLAT_bit)) && (flags & (0x01 << VM_CALL_ARGS_BLOCKARG_bit)) && !(flags & (0x01 << VM_CALL_KW_SPLAT_MUT_bit))) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_splatkw, 0));
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, (method_id), (VALUE)(__builtin_choose_expr( __builtin_constant_p(orig_argc), ((VALUE)(orig_argc)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(orig_argc))), (block_iseq), (VALUE)(__builtin_choose_expr( __builtin_constant_p(flags), ((VALUE)(flags)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(flags))), (kw_arg)));
    if (block_iseq && ((block_iseq)->body)->catch_table) {
        pm_compile_retry_end_label(iseq, ret, retry_end_l);
        do { VALUE _e = __extension__ ({ const VALUE args_to_new_ary[] = {((CATCH_TYPE_BREAK)), (VALUE)((start)) | 1, (VALUE)((retry_end_l)) | 1, (VALUE)((block_iseq)), (VALUE)((retry_end_l)) | 1}; if (__builtin_constant_p(5)) { __extension__ _Static_assert(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))) == (5), "rb_ary_new_from_args" ": " "numberof(args_to_new_ary) == (5)"); } rb_ary_new_from_values(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))), args_to_new_ary); }); (((start)) ? ((((start))->refcnt++), ((start))->unremovable=1) : 0); (((retry_end_l))->refcnt++); (((retry_end_l))->refcnt++); if (RB_NIL_P(ISEQ_COMPILE_DATA(iseq)->catch_table_ary)) (rb_obj_write((VALUE)(iseq), (VALUE *)(&ISEQ_COMPILE_DATA(iseq)->catch_table_ary), (VALUE)(rb_ary_hidden_new(3)), "prism_compile.c", 3703)); rb_ary_push(ISEQ_COMPILE_DATA(iseq)->catch_table_ary, freeze_hide_obj(_e)); } while (0);
    }
    if (((((pm_node_t *)(call_node))->flags & (PM_CALL_NODE_FLAGS_SAFE_NAVIGATION)) != 0)) {
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_jump, 1, (VALUE)(end_label))), ((end_label)->refcnt++));
        ADD_ELEM((ret), (LINK_ELEMENT *) (else_label));
        add_trace_branch_coverage(iseq, ret, &code_location, node_id, 1, "else", branches);
        ADD_ELEM((ret), (LINK_ELEMENT *) (end_label));
    }
    if (((((pm_node_t *)(call_node))->flags & (PM_CALL_NODE_FLAGS_ATTRIBUTE_WRITE)) != 0) && !popped) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
    }
    if (popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
    ISEQ_COMPILE_DATA(iseq)->current_block = previous_block;
}
static void
pm_compile_defined_expr0(rb_iseq_t *iseq, const pm_node_t *node, const pm_node_location_t *node_location, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node, _Bool in_condition, LABEL **lfinish, _Bool explicit_receiver)
{
    enum defined_type dtype = DEFINED_NOT_DEFINED;
    const pm_node_location_t location = *node_location;
    switch (((enum pm_node_type) (node)->type)) {
      case PM_ARGUMENTS_NODE: {
        const pm_arguments_node_t *cast = (const pm_arguments_node_t *) node;
        const pm_node_list_t *arguments = &cast->arguments;
        for (size_t idx = 0; idx < arguments->size; idx++) {
            const pm_node_t *argument = arguments->nodes[idx];
            pm_compile_defined_expr0(iseq, argument, node_location, ret, popped, scope_node, in_condition, lfinish, explicit_receiver);
            if (!lfinish[1]) {
                lfinish[1] = new_label_body(iseq, (location.line));
            }
            (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(lfinish[1]))), ((lfinish[1])->refcnt++));
        }
        dtype = DEFINED_TRUE;
        break;
      }
      case PM_NIL_NODE:
        dtype = DEFINED_NIL;
        break;
      case PM_PARENTHESES_NODE: {
        const pm_parentheses_node_t *cast = (const pm_parentheses_node_t *) node;
        if (cast->body == ((void *)0)) {
            dtype = DEFINED_NIL;
        }
        else if ((((enum pm_node_type) (cast->body)->type) == (PM_STATEMENTS_NODE)) && ((const pm_statements_node_t *) cast->body)->body.size == 1) {
            pm_compile_defined_expr0(iseq, ((const pm_statements_node_t *) cast->body)->body.nodes[0], node_location, ret, popped, scope_node, in_condition, lfinish, explicit_receiver);
            return;
        }
        else {
            dtype = DEFINED_EXPR;
        }
        break;
      }
      case PM_SELF_NODE:
        dtype = DEFINED_SELF;
        break;
      case PM_TRUE_NODE:
        dtype = DEFINED_TRUE;
        break;
      case PM_FALSE_NODE:
        dtype = DEFINED_FALSE;
        break;
      case PM_ARRAY_NODE: {
        const pm_array_node_t *cast = (const pm_array_node_t *) node;
        if (cast->elements.size > 0 && !lfinish[1]) {
            lfinish[1] = new_label_body(iseq, (location.line));
        }
        for (size_t index = 0; index < cast->elements.size; index++) {
            pm_compile_defined_expr0(iseq, cast->elements.nodes[index], node_location, ret, popped, scope_node, 1, lfinish, 0);
            (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(lfinish[1]))), ((lfinish[1])->refcnt++));
        }
        dtype = DEFINED_EXPR;
        break;
      }
      case PM_HASH_NODE:
      case PM_KEYWORD_HASH_NODE: {
        const pm_node_list_t *elements;
        if ((((enum pm_node_type) (node)->type) == (PM_HASH_NODE))) {
            elements = &((const pm_hash_node_t *) node)->elements;
        }
        else {
            elements = &((const pm_keyword_hash_node_t *) node)->elements;
        }
        if (elements->size > 0 && !lfinish[1]) {
            lfinish[1] = new_label_body(iseq, (location.line));
        }
        for (size_t index = 0; index < elements->size; index++) {
            const pm_node_t *element = elements->nodes[index];
            switch (((enum pm_node_type) (element)->type)) {
              case PM_ASSOC_NODE: {
                const pm_assoc_node_t *assoc = (const pm_assoc_node_t *) element;
                pm_compile_defined_expr0(iseq, assoc->key, node_location, ret, popped, scope_node, 1, lfinish, 0);
                (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(lfinish[1]))), ((lfinish[1])->refcnt++));
                pm_compile_defined_expr0(iseq, assoc->value, node_location, ret, popped, scope_node, 1, lfinish, 0);
                (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(lfinish[1]))), ((lfinish[1])->refcnt++));
                break;
              }
              case PM_ASSOC_SPLAT_NODE: {
                const pm_assoc_splat_node_t *assoc_splat = (const pm_assoc_splat_node_t *) element;
                pm_compile_defined_expr0(iseq, assoc_splat->value, node_location, ret, popped, scope_node, 1, lfinish, 0);
                (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(lfinish[1]))), ((lfinish[1])->refcnt++));
                break;
              }
              default:
                rb_bug("unexpected node type in hash node: %s", pm_node_type_to_str(((enum pm_node_type) (element)->type)));
                break;
            }
        }
        dtype = DEFINED_EXPR;
        break;
      }
      case PM_SPLAT_NODE: {
        const pm_splat_node_t *cast = (const pm_splat_node_t *) node;
        pm_compile_defined_expr0(iseq, cast->expression, node_location, ret, popped, scope_node, in_condition, lfinish, 0);
        if (!lfinish[1]) {
            lfinish[1] = new_label_body(iseq, (location.line));
        }
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(lfinish[1]))), ((lfinish[1])->refcnt++));
        dtype = DEFINED_EXPR;
        break;
      }
      case PM_IMPLICIT_NODE: {
        const pm_implicit_node_t *cast = (const pm_implicit_node_t *) node;
        pm_compile_defined_expr0(iseq, cast->value, node_location, ret, popped, scope_node, in_condition, lfinish, explicit_receiver);
        return;
      }
      case PM_AND_NODE:
      case PM_BEGIN_NODE:
      case PM_BREAK_NODE:
      case PM_CASE_NODE:
      case PM_CASE_MATCH_NODE:
      case PM_CLASS_NODE:
      case PM_DEF_NODE:
      case PM_DEFINED_NODE:
      case PM_FLOAT_NODE:
      case PM_FOR_NODE:
      case PM_IF_NODE:
      case PM_IMAGINARY_NODE:
      case PM_INTEGER_NODE:
      case PM_INTERPOLATED_REGULAR_EXPRESSION_NODE:
      case PM_INTERPOLATED_STRING_NODE:
      case PM_INTERPOLATED_SYMBOL_NODE:
      case PM_INTERPOLATED_X_STRING_NODE:
      case PM_LAMBDA_NODE:
      case PM_MATCH_PREDICATE_NODE:
      case PM_MATCH_REQUIRED_NODE:
      case PM_MATCH_WRITE_NODE:
      case PM_MODULE_NODE:
      case PM_NEXT_NODE:
      case PM_OR_NODE:
      case PM_RANGE_NODE:
      case PM_RATIONAL_NODE:
      case PM_REDO_NODE:
      case PM_REGULAR_EXPRESSION_NODE:
      case PM_RETRY_NODE:
      case PM_RETURN_NODE:
      case PM_SINGLETON_CLASS_NODE:
      case PM_SOURCE_ENCODING_NODE:
      case PM_SOURCE_FILE_NODE:
      case PM_SOURCE_LINE_NODE:
      case PM_STRING_NODE:
      case PM_SYMBOL_NODE:
      case PM_UNLESS_NODE:
      case PM_UNTIL_NODE:
      case PM_WHILE_NODE:
      case PM_X_STRING_NODE:
        dtype = DEFINED_EXPR;
        break;
      case PM_LOCAL_VARIABLE_READ_NODE:
        dtype = DEFINED_LVAR;
        break;
      case PM_INSTANCE_VARIABLE_READ_NODE: {
        const pm_instance_variable_read_node_t *cast = (const pm_instance_variable_read_node_t *) node;
        ID name = pm_constant_id_lookup(scope_node, cast->name);
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_definedivar, 3, (VALUE)(rb_id2sym(name)), (VALUE)(get_ivar_ic_value(iseq, name)), (VALUE)((in_condition ? ((VALUE)RUBY_Qtrue) : rb_iseq_defined_string(DEFINED_IVAR)))));
        return;
      }
      case PM_BACK_REFERENCE_READ_NODE: {
        const char *char_ptr = (const char *) (node->location.start + 1);
        ID backref_val = __builtin_choose_expr( __builtin_constant_p(rb_intern2(char_ptr, 1)), ((VALUE)(rb_intern2(char_ptr, 1))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(rb_intern2(char_ptr, 1))) << 1 | 1;
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_defined, 3, (VALUE)(__builtin_choose_expr( __builtin_constant_p(DEFINED_REF), ((VALUE)(DEFINED_REF)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(DEFINED_REF))), (VALUE)(backref_val), (VALUE)((in_condition ? ((VALUE)RUBY_Qtrue) : rb_iseq_defined_string(DEFINED_GVAR)))));
        return;
      }
      case PM_NUMBERED_REFERENCE_READ_NODE: {
        uint32_t reference_number = ((const pm_numbered_reference_read_node_t *) node)->number;
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_defined, 3, (VALUE)(__builtin_choose_expr( __builtin_constant_p(DEFINED_REF), ((VALUE)(DEFINED_REF)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(DEFINED_REF))), (VALUE)(__builtin_choose_expr( __builtin_constant_p(reference_number << 1), ((VALUE)(reference_number << 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(reference_number << 1))), (VALUE)((in_condition ? ((VALUE)RUBY_Qtrue) : rb_iseq_defined_string(DEFINED_GVAR)))));
        return;
      }
      case PM_GLOBAL_VARIABLE_READ_NODE: {
        const pm_global_variable_read_node_t *cast = (const pm_global_variable_read_node_t *) node;
        VALUE name = rb_id2sym(pm_constant_id_lookup(scope_node, cast->name));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_defined, 3, (VALUE)(__builtin_choose_expr( __builtin_constant_p(DEFINED_GVAR), ((VALUE)(DEFINED_GVAR)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(DEFINED_GVAR))), (VALUE)(name), (VALUE)((in_condition ? ((VALUE)RUBY_Qtrue) : rb_iseq_defined_string(DEFINED_GVAR)))));
        return;
      }
      case PM_CLASS_VARIABLE_READ_NODE: {
        const pm_class_variable_read_node_t *cast = (const pm_class_variable_read_node_t *) node;
        VALUE name = rb_id2sym(pm_constant_id_lookup(scope_node, cast->name));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_defined, 3, (VALUE)(__builtin_choose_expr( __builtin_constant_p(DEFINED_CVAR), ((VALUE)(DEFINED_CVAR)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(DEFINED_CVAR))), (VALUE)(name), (VALUE)((in_condition ? ((VALUE)RUBY_Qtrue) : rb_iseq_defined_string(DEFINED_CVAR)))));
        return;
      }
      case PM_CONSTANT_READ_NODE: {
        const pm_constant_read_node_t *cast = (const pm_constant_read_node_t *) node;
        VALUE name = rb_id2sym(pm_constant_id_lookup(scope_node, cast->name));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_defined, 3, (VALUE)(__builtin_choose_expr( __builtin_constant_p(DEFINED_CONST), ((VALUE)(DEFINED_CONST)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(DEFINED_CONST))), (VALUE)(name), (VALUE)((in_condition ? ((VALUE)RUBY_Qtrue) : rb_iseq_defined_string(DEFINED_CONST)))));
        return;
      }
      case PM_CONSTANT_PATH_NODE: {
        const pm_constant_path_node_t *cast = (const pm_constant_path_node_t *) node;
        VALUE name = rb_id2sym(pm_constant_id_lookup(scope_node, cast->name));
        if (cast->parent != ((void *)0)) {
            if (!lfinish[1]) lfinish[1] = new_label_body(iseq, (location.line));
            pm_compile_defined_expr0(iseq, cast->parent, node_location, ret, popped, scope_node, 1, lfinish, 0);
            (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(lfinish[1]))), ((lfinish[1])->refcnt++));
            pm_compile_node(iseq, (cast->parent), ret, popped, scope_node);
        }
        else {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(rb_cObject)));
        }
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_defined, 3, (VALUE)(__builtin_choose_expr( __builtin_constant_p(DEFINED_CONST_FROM), ((VALUE)(DEFINED_CONST_FROM)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(DEFINED_CONST_FROM))), (VALUE)(name), (VALUE)((in_condition ? ((VALUE)RUBY_Qtrue) : rb_iseq_defined_string(DEFINED_CONST)))));
        return;
      }
      case PM_CALL_NODE: {
        const pm_call_node_t *cast = ((const pm_call_node_t *) node);
        if (cast->block != ((void *)0) && (((enum pm_node_type) (cast->block)->type) == (PM_BLOCK_NODE))) {
            dtype = DEFINED_EXPR;
            break;
        }
        ID method_id = pm_constant_id_lookup(scope_node, cast->name);
        if (cast->receiver || cast->arguments) {
            if (!lfinish[1]) lfinish[1] = new_label_body(iseq, (location.line));
            if (!lfinish[2]) lfinish[2] = new_label_body(iseq, (location.line));
        }
        if (cast->arguments) {
            pm_compile_defined_expr0(iseq, (const pm_node_t *) cast->arguments, node_location, ret, popped, scope_node, 1, lfinish, 0);
            (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(lfinish[1]))), ((lfinish[1])->refcnt++));
        }
        if (cast->receiver) {
            pm_compile_defined_expr0(iseq, cast->receiver, node_location, ret, popped, scope_node, 1, lfinish, 1);
            if ((((enum pm_node_type) (cast->receiver)->type) == (PM_CALL_NODE))) {
                (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(lfinish[2]))), ((lfinish[2])->refcnt++));
                const pm_call_node_t *receiver = (const pm_call_node_t *) cast->receiver;
                ID method_id = pm_constant_id_lookup(scope_node, receiver->name);
                pm_compile_call(iseq, receiver, ret, popped, scope_node, method_id, ((void *)0));
            }
            else {
                (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(lfinish[1]))), ((lfinish[1])->refcnt++));
                pm_compile_node(iseq, (cast->receiver), ret, popped, scope_node);
            }
            if (explicit_receiver) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_defined, 3, (VALUE)(__builtin_choose_expr( __builtin_constant_p(DEFINED_METHOD), ((VALUE)(DEFINED_METHOD)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(DEFINED_METHOD))), (VALUE)(rb_id2sym(method_id)), (VALUE)((in_condition ? ((VALUE)RUBY_Qtrue) : rb_iseq_defined_string(DEFINED_METHOD)))));
        }
        else {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putself, 0));
            if (explicit_receiver) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_defined, 3, (VALUE)(__builtin_choose_expr( __builtin_constant_p(DEFINED_FUNC), ((VALUE)(DEFINED_FUNC)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(DEFINED_FUNC))), (VALUE)(rb_id2sym(method_id)), (VALUE)((in_condition ? ((VALUE)RUBY_Qtrue) : rb_iseq_defined_string(DEFINED_METHOD)))));
        }
        return;
      }
      case PM_YIELD_NODE:
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_defined, 3, (VALUE)(__builtin_choose_expr( __builtin_constant_p(DEFINED_YIELD), ((VALUE)(DEFINED_YIELD)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(DEFINED_YIELD))), (VALUE)(0), (VALUE)((in_condition ? ((VALUE)RUBY_Qtrue) : rb_iseq_defined_string(DEFINED_YIELD)))));
        iseq_set_use_block(((iseq)->body)->local_iseq);
        return;
      case PM_SUPER_NODE:
      case PM_FORWARDING_SUPER_NODE:
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_defined, 3, (VALUE)(__builtin_choose_expr( __builtin_constant_p(DEFINED_ZSUPER), ((VALUE)(DEFINED_ZSUPER)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(DEFINED_ZSUPER))), (VALUE)(0), (VALUE)((in_condition ? ((VALUE)RUBY_Qtrue) : rb_iseq_defined_string(DEFINED_ZSUPER)))));
        return;
      case PM_CALL_AND_WRITE_NODE:
      case PM_CALL_OPERATOR_WRITE_NODE:
      case PM_CALL_OR_WRITE_NODE:
      case PM_CONSTANT_WRITE_NODE:
      case PM_CONSTANT_OPERATOR_WRITE_NODE:
      case PM_CONSTANT_AND_WRITE_NODE:
      case PM_CONSTANT_OR_WRITE_NODE:
      case PM_CONSTANT_PATH_AND_WRITE_NODE:
      case PM_CONSTANT_PATH_OPERATOR_WRITE_NODE:
      case PM_CONSTANT_PATH_OR_WRITE_NODE:
      case PM_CONSTANT_PATH_WRITE_NODE:
      case PM_GLOBAL_VARIABLE_WRITE_NODE:
      case PM_GLOBAL_VARIABLE_OPERATOR_WRITE_NODE:
      case PM_GLOBAL_VARIABLE_AND_WRITE_NODE:
      case PM_GLOBAL_VARIABLE_OR_WRITE_NODE:
      case PM_CLASS_VARIABLE_WRITE_NODE:
      case PM_CLASS_VARIABLE_OPERATOR_WRITE_NODE:
      case PM_CLASS_VARIABLE_AND_WRITE_NODE:
      case PM_CLASS_VARIABLE_OR_WRITE_NODE:
      case PM_INDEX_AND_WRITE_NODE:
      case PM_INDEX_OPERATOR_WRITE_NODE:
      case PM_INDEX_OR_WRITE_NODE:
      case PM_INSTANCE_VARIABLE_WRITE_NODE:
      case PM_INSTANCE_VARIABLE_OPERATOR_WRITE_NODE:
      case PM_INSTANCE_VARIABLE_AND_WRITE_NODE:
      case PM_INSTANCE_VARIABLE_OR_WRITE_NODE:
      case PM_LOCAL_VARIABLE_WRITE_NODE:
      case PM_LOCAL_VARIABLE_OPERATOR_WRITE_NODE:
      case PM_LOCAL_VARIABLE_AND_WRITE_NODE:
      case PM_LOCAL_VARIABLE_OR_WRITE_NODE:
      case PM_MULTI_WRITE_NODE:
        dtype = DEFINED_ASGN;
        break;
      default:
        rb_bug("Unsupported node %s", pm_node_type_to_str(((enum pm_node_type) (node)->type)));
    }
    ((void)0);
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)((in_condition ? ((VALUE)RUBY_Qtrue) : rb_iseq_defined_string(dtype)))));
}
static void
pm_defined_expr(rb_iseq_t *iseq, const pm_node_t *node, const pm_node_location_t *node_location, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node, _Bool in_condition, LABEL **lfinish, _Bool explicit_receiver)
{
    LINK_ELEMENT *lcur = ret->last;
    pm_compile_defined_expr0(iseq, node, node_location, ret, popped, scope_node, in_condition, lfinish, 0);
    if (lfinish[1]) {
        LABEL *lstart = new_label_body(iseq, (node_location->line));
        LABEL *lend = new_label_body(iseq, (node_location->line));
        struct rb_iseq_new_with_callback_callback_func *ifunc =
            rb_iseq_new_with_callback_new_callback(build_defined_rescue_iseq, ((void *)0));
        const rb_iseq_t *rescue = new_child_iseq_with_callback(
            iseq,
            ifunc,
            rb_str_concat(((__builtin_constant_p("defined guard in ") ? rbimpl_str_new_cstr : rb_str_new_cstr) ("defined guard in ")), ((iseq)->body)->location.label),
            iseq,
            ISEQ_TYPE_RESCUE,
            0
        );
        lstart->rescued = LABEL_RESCUE_BEG;
        lend->rescued = LABEL_RESCUE_END;
        APPEND_ELEM((ret), (lcur), (LINK_ELEMENT *) (lstart));
        ADD_ELEM((ret), (LINK_ELEMENT *) (lend));
        do { VALUE _e = __extension__ ({ const VALUE args_to_new_ary[] = {((CATCH_TYPE_RESCUE)), (VALUE)((lstart)) | 1, (VALUE)((lend)) | 1, (VALUE)((rescue)), (VALUE)((lfinish[1])) | 1}; if (__builtin_constant_p(5)) { __extension__ _Static_assert(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))) == (5), "rb_ary_new_from_args" ": " "numberof(args_to_new_ary) == (5)"); } rb_ary_new_from_values(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))), args_to_new_ary); }); (((lstart)) ? ((((lstart))->refcnt++), ((lstart))->unremovable=1) : 0); (((lend))->refcnt++); (((lfinish[1]))->refcnt++); if (RB_NIL_P(ISEQ_COMPILE_DATA(iseq)->catch_table_ary)) (rb_obj_write((VALUE)(iseq), (VALUE *)(&ISEQ_COMPILE_DATA(iseq)->catch_table_ary), (VALUE)(rb_ary_hidden_new(3)), "prism_compile.c", 4107)); rb_ary_push(ISEQ_COMPILE_DATA(iseq)->catch_table_ary, freeze_hide_obj(_e)); } while (0);
    }
}
static void
pm_compile_defined_expr(rb_iseq_t *iseq, const pm_node_t *node, const pm_node_location_t *node_location, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node, _Bool in_condition)
{
    LABEL *lfinish[3];
    LINK_ELEMENT *last = ret->last;
    lfinish[0] = new_label_body(iseq, (node_location->line));
    lfinish[1] = 0;
    lfinish[2] = 0;
    if (!popped) {
        pm_defined_expr(iseq, node, node_location, ret, popped, scope_node, in_condition, lfinish, 0);
    }
    if (lfinish[1]) {
        ELEM_INSERT_NEXT(last, &new_insn_body(iseq, node_location->line, node_location->node_id, YARVINSN_putnil, 0)->link);
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*node_location).line, (int) (*node_location).node_id, YARVINSN_swap, 0));
        if (lfinish[2]) ADD_ELEM((ret), (LINK_ELEMENT *) (lfinish[2]));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*node_location).line, (int) (*node_location).node_id, YARVINSN_pop, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) (lfinish[1]));
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) (lfinish[0]));
}
static void
pm_add_ensure_iseq(LINK_ANCHOR *const ret, rb_iseq_t *iseq, int is_return, pm_scope_node_t *scope_node)
{
    ((void)0);
    struct iseq_compile_data_ensure_node_stack *enlp =
        ISEQ_COMPILE_DATA(iseq)->ensure_node_stack;
    struct iseq_compile_data_ensure_node_stack *prev_enlp = enlp;
    LINK_ANCHOR ensure[1] = {{{ISEQ_ELEMENT_ANCHOR,},&ensure[0].anchor}};
    while (enlp) {
        if (enlp->erange != ((void *)0)) {
            LINK_ANCHOR ensure_part[1] = {{{ISEQ_ELEMENT_ANCHOR,},&ensure_part[0].anchor}};
            LABEL *lstart = new_label_body(iseq, (0));
            LABEL *lend = new_label_body(iseq, (0));
            add_ensure_range(iseq, enlp->erange, lstart, lend);
            ISEQ_COMPILE_DATA(iseq)->ensure_node_stack = enlp->prev;
            ADD_ELEM((ensure_part), (LINK_ELEMENT *) (lstart));
            _Bool popped = 1;
            pm_compile_node(iseq, ((const pm_node_t *) enlp->ensure_node), ensure_part, popped, scope_node);
            ADD_ELEM((ensure_part), (LINK_ELEMENT *) (lend));
            APPEND_LIST((ensure), (ensure_part));
        }
        else {
            if (!is_return) {
                break;
            }
        }
        enlp = enlp->prev;
    }
    ISEQ_COMPILE_DATA(iseq)->ensure_node_stack = prev_enlp;
    APPEND_LIST((ret), (ensure));
}
struct pm_local_table_insert_ctx {
    pm_scope_node_t *scope_node;
    rb_ast_id_table_t *local_table_for_iseq;
    int local_index;
};
static int
pm_local_table_insert_func(st_data_t *key, st_data_t *value, st_data_t arg, int existing)
{
    if (!existing) {
        pm_constant_id_t constant_id = (pm_constant_id_t) *key;
        struct pm_local_table_insert_ctx * ctx = (struct pm_local_table_insert_ctx *) arg;
        pm_scope_node_t *scope_node = ctx->scope_node;
        rb_ast_id_table_t *local_table_for_iseq = ctx->local_table_for_iseq;
        int local_index = ctx->local_index;
        ID local = pm_constant_id_lookup(scope_node, constant_id);
        local_table_for_iseq->ids[local_index] = local;
        *value = (st_data_t)local_index;
        ctx->local_index++;
    }
    return ST_CONTINUE;
}
static void
pm_insert_local_index(pm_constant_id_t constant_id, int local_index, st_table *index_lookup_table, rb_ast_id_table_t *local_table_for_iseq, pm_scope_node_t *scope_node)
{
    ((void)0);
    ID local = pm_constant_id_lookup(scope_node, constant_id);
    local_table_for_iseq->ids[local_index] = local;
    rb_st_insert(index_lookup_table, (st_data_t) constant_id, (st_data_t) local_index);
}
static void
pm_insert_local_special(ID local_name, int local_index, st_table *index_lookup_table, rb_ast_id_table_t *local_table_for_iseq)
{
    local_table_for_iseq->ids[local_index] = local_name;
    rb_st_insert(index_lookup_table, (st_data_t) (local_name | ((pm_constant_id_t)(1 << 31))), (st_data_t) local_index);
}
static int
pm_compile_destructured_param_locals(const pm_multi_target_node_t *node, st_table *index_lookup_table, rb_ast_id_table_t *local_table_for_iseq, pm_scope_node_t *scope_node, int local_index)
{
    for (size_t index = 0; index < node->lefts.size; index++) {
        const pm_node_t *left = node->lefts.nodes[index];
        if ((((enum pm_node_type) (left)->type) == (PM_REQUIRED_PARAMETER_NODE))) {
            if (!((((pm_node_t *)(left))->flags & (PM_PARAMETER_FLAGS_REPEATED_PARAMETER)) != 0)) {
                pm_insert_local_index(((const pm_required_parameter_node_t *) left)->name, local_index, index_lookup_table, local_table_for_iseq, scope_node);
                local_index++;
            }
        }
        else {
            ((void)0);
            local_index = pm_compile_destructured_param_locals((const pm_multi_target_node_t *) left, index_lookup_table, local_table_for_iseq, scope_node, local_index);
        }
    }
    if (node->rest != ((void *)0) && (((enum pm_node_type) (node->rest)->type) == (PM_SPLAT_NODE))) {
        const pm_splat_node_t *rest = (const pm_splat_node_t *) node->rest;
        if (rest->expression != ((void *)0)) {
            ((void)0);
            if (!((((pm_node_t *)(rest->expression))->flags & (PM_PARAMETER_FLAGS_REPEATED_PARAMETER)) != 0)) {
                pm_insert_local_index(((const pm_required_parameter_node_t *) rest->expression)->name, local_index, index_lookup_table, local_table_for_iseq, scope_node);
                local_index++;
            }
        }
    }
    for (size_t index = 0; index < node->rights.size; index++) {
        const pm_node_t *right = node->rights.nodes[index];
        if ((((enum pm_node_type) (right)->type) == (PM_REQUIRED_PARAMETER_NODE))) {
            if (!((((pm_node_t *)(right))->flags & (PM_PARAMETER_FLAGS_REPEATED_PARAMETER)) != 0)) {
                pm_insert_local_index(((const pm_required_parameter_node_t *) right)->name, local_index, index_lookup_table, local_table_for_iseq, scope_node);
                local_index++;
            }
        }
        else {
            ((void)0);
            local_index = pm_compile_destructured_param_locals((const pm_multi_target_node_t *) right, index_lookup_table, local_table_for_iseq, scope_node, local_index);
        }
    }
    return local_index;
}
static inline void
pm_compile_destructured_param_write(rb_iseq_t *iseq, const pm_required_parameter_node_t *node, LINK_ANCHOR *const ret, const pm_scope_node_t *scope_node)
{
    const pm_node_location_t location = ((pm_node_location_t) { .line = pm_newline_list_line(&(scope_node->parser)->newline_list, ((const pm_node_t *) (node))->location.start, (scope_node->parser)->start_line), .node_id = ((const pm_node_t *) (node))->node_id });
    pm_local_index_t index = pm_lookup_local_index(iseq, scope_node, node->name, 0);
    pm_iseq_add_setlocal(iseq, (ret), (int) (location).line, (int) (location).node_id, (index.index), (index.level));
}
static void
pm_compile_destructured_param_writes(rb_iseq_t *iseq, const pm_multi_target_node_t *node, LINK_ANCHOR *const ret, const pm_scope_node_t *scope_node)
{
    const pm_node_location_t location = ((pm_node_location_t) { .line = pm_newline_list_line(&(scope_node->parser)->newline_list, ((const pm_node_t *) (node))->location.start, (scope_node->parser)->start_line), .node_id = ((const pm_node_t *) (node))->node_id });
    _Bool has_rest = (node->rest && (((enum pm_node_type) (node->rest)->type) == (PM_SPLAT_NODE)) && (((const pm_splat_node_t *) node->rest)->expression) != ((void *)0));
    _Bool has_rights = node->rights.size > 0;
    int flag = (has_rest || has_rights) ? 1 : 0;
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_expandarray, 2, (VALUE)(__builtin_choose_expr( __builtin_constant_p(node->lefts.size), ((VALUE)(node->lefts.size)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(node->lefts.size))), (VALUE)(__builtin_choose_expr( __builtin_constant_p(flag), ((VALUE)(flag)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(flag)))));
    for (size_t index = 0; index < node->lefts.size; index++) {
        const pm_node_t *left = node->lefts.nodes[index];
        if ((((enum pm_node_type) (left)->type) == (PM_REQUIRED_PARAMETER_NODE))) {
            pm_compile_destructured_param_write(iseq, (const pm_required_parameter_node_t *) left, ret, scope_node);
        }
        else {
            ((void)0);
            pm_compile_destructured_param_writes(iseq, (const pm_multi_target_node_t *) left, ret, scope_node);
        }
    }
    if (has_rest) {
        if (has_rights) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_expandarray, 2, (VALUE)(__builtin_choose_expr( __builtin_constant_p(node->rights.size), ((VALUE)(node->rights.size)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(node->rights.size))), (VALUE)(__builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)))));
        }
        const pm_node_t *rest = ((const pm_splat_node_t *) node->rest)->expression;
        ((void)0);
        pm_compile_destructured_param_write(iseq, (const pm_required_parameter_node_t *) rest, ret, scope_node);
    }
    if (has_rights) {
        if (!has_rest) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_expandarray, 2, (VALUE)(__builtin_choose_expr( __builtin_constant_p(node->rights.size), ((VALUE)(node->rights.size)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(node->rights.size))), (VALUE)(__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))));
        }
        for (size_t index = 0; index < node->rights.size; index++) {
            const pm_node_t *right = node->rights.nodes[index];
            if ((((enum pm_node_type) (right)->type) == (PM_REQUIRED_PARAMETER_NODE))) {
                pm_compile_destructured_param_write(iseq, (const pm_required_parameter_node_t *) right, ret, scope_node);
            }
            else {
                ((void)0);
                pm_compile_destructured_param_writes(iseq, (const pm_multi_target_node_t *) right, ret, scope_node);
            }
        }
    }
}
typedef struct pm_multi_target_state_node {
    INSN *topn;
    size_t stack_index;
    size_t stack_size;
    size_t position;
    struct pm_multi_target_state_node *next;
} pm_multi_target_state_node_t;
typedef struct {
    size_t stack_size;
    size_t position;
    pm_multi_target_state_node_t *head;
    pm_multi_target_state_node_t *tail;
} pm_multi_target_state_t;
static void
pm_multi_target_state_push(pm_multi_target_state_t *state, INSN *topn, size_t stack_size)
{
    pm_multi_target_state_node_t *node = ((pm_multi_target_state_node_t *)ruby_xmalloc(sizeof(pm_multi_target_state_node_t)));
    node->topn = topn;
    node->stack_index = state->stack_size + 1;
    node->stack_size = stack_size;
    node->position = state->position;
    node->next = ((void *)0);
    if (state->head == ((void *)0)) {
        state->head = node;
        state->tail = node;
    }
    else {
        state->tail->next = node;
        state->tail = node;
    }
    state->stack_size += stack_size;
}
static void
pm_multi_target_state_update(pm_multi_target_state_t *state)
{
    if (state->stack_size == 0) return;
    pm_multi_target_state_node_t *current = state->head;
    pm_multi_target_state_node_t *previous;
    while (current != ((void *)0)) {
        VALUE offset = __builtin_choose_expr( __builtin_constant_p(state->stack_size - current->stack_index + current->position), ((VALUE)(state->stack_size - current->stack_index + current->position)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(state->stack_size - current->stack_index + current->position));
        current->topn->operands[0] = offset;
        if (current->stack_size > 1) {
            INSN *insn = current->topn;
            for (size_t index = 1; index < current->stack_size; index += 1) {
                LINK_ELEMENT *element = get_next_insn(insn);
                ((void)0);
                insn = (INSN *) element;
                ((void)0);
                insn->operands[0] = offset;
            }
        }
        previous = current;
        current = current->next;
        ruby_xfree(previous);
    }
}
static void
pm_compile_multi_target_node(rb_iseq_t *iseq, const pm_node_t *node, LINK_ANCHOR *const parents, LINK_ANCHOR *const writes, LINK_ANCHOR *const cleanup, pm_scope_node_t *scope_node, pm_multi_target_state_t *state);
static void
pm_compile_target_node(rb_iseq_t *iseq, const pm_node_t *node, LINK_ANCHOR *const parents, LINK_ANCHOR *const writes, LINK_ANCHOR *const cleanup, pm_scope_node_t *scope_node, pm_multi_target_state_t *state)
{
    const pm_node_location_t location = ((pm_node_location_t) { .line = pm_newline_list_line(&(scope_node->parser)->newline_list, ((const pm_node_t *) (node))->location.start, (scope_node->parser)->start_line), .node_id = ((const pm_node_t *) (node))->node_id });
    switch (((enum pm_node_type) (node)->type)) {
      case PM_LOCAL_VARIABLE_TARGET_NODE: {
        const pm_local_variable_target_node_t *cast = (const pm_local_variable_target_node_t *) node;
        pm_local_index_t index = pm_lookup_local_index(iseq, scope_node, cast->name, cast->depth);
        pm_iseq_add_setlocal(iseq, (writes), (int) (location).line, (int) (location).node_id, (index.index), (index.level));
        break;
      }
      case PM_CLASS_VARIABLE_TARGET_NODE: {
        const pm_class_variable_target_node_t *cast = (const pm_class_variable_target_node_t *) node;
        ID name = pm_constant_id_lookup(scope_node, cast->name);
        VALUE operand = rb_id2sym(name);
        ADD_ELEM((writes), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setclassvariable, 2, (VALUE)(operand), (VALUE)(get_cvar_ic_value(iseq, name))));
        break;
      }
      case PM_CONSTANT_TARGET_NODE: {
        const pm_constant_target_node_t *cast = (const pm_constant_target_node_t *) node;
        ID name = pm_constant_id_lookup(scope_node, cast->name);
        VALUE operand = rb_id2sym(name);
        ADD_ELEM((writes), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_CONST_BASE), ((VALUE)(VM_SPECIAL_OBJECT_CONST_BASE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_CONST_BASE)))));
        ADD_ELEM((writes), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setconstant, 1, (VALUE)(operand)));
        break;
      }
      case PM_GLOBAL_VARIABLE_TARGET_NODE: {
        const pm_global_variable_target_node_t *cast = (const pm_global_variable_target_node_t *) node;
        ID name = pm_constant_id_lookup(scope_node, cast->name);
        VALUE operand = rb_id2sym(name);
        ADD_ELEM((writes), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setglobal, 1, (VALUE)(operand)));
        break;
      }
      case PM_INSTANCE_VARIABLE_TARGET_NODE: {
        const pm_instance_variable_target_node_t *cast = (const pm_instance_variable_target_node_t *) node;
        ID name = pm_constant_id_lookup(scope_node, cast->name);
        VALUE operand = rb_id2sym(name);
        ADD_ELEM((writes), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setinstancevariable, 2, (VALUE)(operand), (VALUE)(get_ivar_ic_value(iseq, name))));
        break;
      }
      case PM_CONSTANT_PATH_TARGET_NODE: {
        const pm_constant_path_target_node_t *cast = (const pm_constant_path_target_node_t *) node;
        ID name = pm_constant_id_lookup(scope_node, cast->name);
        if (cast->parent != ((void *)0)) {
            pm_compile_node(iseq, cast->parent, parents, 0, scope_node);
        }
        else {
            ADD_ELEM((parents), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(rb_cObject)));
        }
        if (state == ((void *)0)) {
            ADD_ELEM((writes), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_swap, 0));
        }
        else {
            ADD_ELEM((writes), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
            pm_multi_target_state_push(state, (INSN *) LAST_ELEMENT(writes), 1);
        }
        VALUE operand = rb_id2sym(name);
        ADD_ELEM((writes), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setconstant, 1, (VALUE)(operand)));
        if (state != ((void *)0)) {
            ADD_ELEM((cleanup), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        }
        break;
      }
      case PM_CALL_TARGET_NODE: {
        const pm_call_target_node_t *cast = (const pm_call_target_node_t *) node;
        ID method_id = pm_constant_id_lookup(scope_node, cast->name);
        pm_compile_node(iseq, cast->receiver, parents, 0, scope_node);
        LABEL *safe_label = ((void *)0);
        if (((((pm_node_t *)(cast))->flags & (PM_CALL_NODE_FLAGS_SAFE_NAVIGATION)) != 0)) {
            safe_label = new_label_body(iseq, (location.line));
            ADD_ELEM((parents), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
            (ADD_ELEM((parents), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchnil, 1, (VALUE)(safe_label))), ((safe_label)->refcnt++));
        }
        if (state != ((void *)0)) {
            ADD_ELEM((writes), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
            pm_multi_target_state_push(state, (INSN *) LAST_ELEMENT(writes), 1);
            ADD_ELEM((writes), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_swap, 0));
        }
        int flags = (0x01 << VM_CALL_ARGS_SIMPLE_bit);
        if (((((pm_node_t *)(cast))->flags & (PM_CALL_NODE_FLAGS_IGNORE_VISIBILITY)) != 0)) flags |= (0x01 << VM_CALL_FCALL_bit);
        ADD_ELEM(((writes)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((method_id)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)(__builtin_choose_expr( __builtin_constant_p(flags), ((VALUE)(flags)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(flags)))), (((void *)0))));
        if (safe_label != ((void *)0) && state == ((void *)0)) ADD_ELEM((writes), (LINK_ELEMENT *) (safe_label));
        ADD_ELEM((writes), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        if (safe_label != ((void *)0) && state != ((void *)0)) ADD_ELEM((writes), (LINK_ELEMENT *) (safe_label));
        if (state != ((void *)0)) {
            ADD_ELEM((cleanup), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        }
        break;
      }
      case PM_INDEX_TARGET_NODE: {
        const pm_index_target_node_t *cast = (const pm_index_target_node_t *) node;
        pm_compile_node(iseq, cast->receiver, parents, 0, scope_node);
        int flags = 0;
        struct rb_callinfo_kwarg *kwargs = ((void *)0);
        int argc = pm_setup_args(cast->arguments, (const pm_node_t *) cast->block, &flags, &kwargs, iseq, parents, scope_node, &location);
        if (state != ((void *)0)) {
            ADD_ELEM((writes), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(argc + 1), ((VALUE)(argc + 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(argc + 1)))));
            pm_multi_target_state_push(state, (INSN *) LAST_ELEMENT(writes), argc + 1);
            if (argc == 0) {
                ADD_ELEM((writes), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_swap, 0));
            }
            else {
                for (int index = 0; index < argc; index++) {
                    ADD_ELEM((writes), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(argc + 1), ((VALUE)(argc + 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(argc + 1)))));
                }
                ADD_ELEM((writes), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(argc + 1), ((VALUE)(argc + 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(argc + 1)))));
            }
        }
        int ci_argc = argc + 1;
        if (flags & (0x01 << VM_CALL_ARGS_SPLAT_bit)) {
            ci_argc--;
            ADD_ELEM((writes), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_newarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
            ADD_ELEM((writes), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_concatarray, 0));
        }
        ADD_ELEM((writes), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, (idASET), (VALUE)(rb_int2num_inline(ci_argc)), (((void *)0)), (VALUE)(__builtin_choose_expr( __builtin_constant_p(flags), ((VALUE)(flags)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(flags))), (kwargs)));
        ADD_ELEM((writes), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        if (state != ((void *)0)) {
            if (argc != 0) {
                ADD_ELEM((writes), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
            }
            for (int index = 0; index < argc + 1; index++) {
                ADD_ELEM((cleanup), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
            }
        }
        break;
      }
      case PM_MULTI_TARGET_NODE: {
        size_t before_position;
        if (state != ((void *)0)) {
            before_position = state->position;
            state->position--;
        }
        pm_compile_multi_target_node(iseq, node, parents, writes, cleanup, scope_node, state);
        if (state != ((void *)0)) state->position = before_position;
        break;
      }
      default:
        rb_bug("Unexpected node type: %s", pm_node_type_to_str(((enum pm_node_type) (node)->type)));
        break;
    }
}
static void
pm_compile_multi_target_node(rb_iseq_t *iseq, const pm_node_t *node, LINK_ANCHOR *const parents, LINK_ANCHOR *const writes, LINK_ANCHOR *const cleanup, pm_scope_node_t *scope_node, pm_multi_target_state_t *state)
{
    const pm_node_location_t location = ((pm_node_location_t) { .line = pm_newline_list_line(&(scope_node->parser)->newline_list, ((const pm_node_t *) (node))->location.start, (scope_node->parser)->start_line), .node_id = ((const pm_node_t *) (node))->node_id });
    const pm_node_list_t *lefts;
    const pm_node_t *rest;
    const pm_node_list_t *rights;
    switch (((enum pm_node_type) (node)->type)) {
      case PM_MULTI_TARGET_NODE: {
        const pm_multi_target_node_t *cast = (const pm_multi_target_node_t *) node;
        lefts = &cast->lefts;
        rest = cast->rest;
        rights = &cast->rights;
        break;
      }
      case PM_MULTI_WRITE_NODE: {
        const pm_multi_write_node_t *cast = (const pm_multi_write_node_t *) node;
        lefts = &cast->lefts;
        rest = cast->rest;
        rights = &cast->rights;
        break;
      }
      default:
        rb_bug("Unsupported node %s", pm_node_type_to_str(((enum pm_node_type) (node)->type)));
        break;
    }
    _Bool has_rest = (rest != ((void *)0)) && (((enum pm_node_type) (rest)->type) == (PM_SPLAT_NODE)) && ((const pm_splat_node_t *) rest)->expression != ((void *)0);
    _Bool has_posts = rights->size > 0;
    ADD_ELEM((writes), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_expandarray, 2, (VALUE)(__builtin_choose_expr( __builtin_constant_p(lefts->size), ((VALUE)(lefts->size)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(lefts->size))), (VALUE)(__builtin_choose_expr( __builtin_constant_p((has_rest || has_posts) ? 1 : 0), ((VALUE)((has_rest || has_posts) ? 1 : 0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((has_rest || has_posts) ? 1 : 0)))));
    pm_multi_target_state_t target_state = { 0 };
    if (state == ((void *)0)) state = &target_state;
    size_t base_position = state->position;
    size_t splat_position = (has_rest || has_posts) ? 1 : 0;
    for (size_t index = 0; index < lefts->size; index++) {
        const pm_node_t *target = lefts->nodes[index];
        state->position = lefts->size - index + splat_position + base_position;
        pm_compile_target_node(iseq, target, parents, writes, cleanup, scope_node, state);
    }
    if (has_rest) {
        const pm_node_t *target = ((const pm_splat_node_t *) rest)->expression;
        state->position = 1 + rights->size + base_position;
        if (has_posts) {
            ADD_ELEM((writes), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_expandarray, 2, (VALUE)(__builtin_choose_expr( __builtin_constant_p(rights->size), ((VALUE)(rights->size)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(rights->size))), (VALUE)(__builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)))));
        }
        pm_compile_target_node(iseq, target, parents, writes, cleanup, scope_node, state);
    }
    if (has_posts) {
        if (!has_rest && rest != ((void *)0)) {
            ADD_ELEM((writes), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_expandarray, 2, (VALUE)(__builtin_choose_expr( __builtin_constant_p(rights->size), ((VALUE)(rights->size)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(rights->size))), (VALUE)(__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))));
        }
        for (size_t index = 0; index < rights->size; index++) {
            const pm_node_t *target = rights->nodes[index];
            state->position = rights->size - index + base_position;
            pm_compile_target_node(iseq, target, parents, writes, cleanup, scope_node, state);
        }
    }
}
static void
pm_compile_for_node_index(rb_iseq_t *iseq, const pm_node_t *node, LINK_ANCHOR *const ret, pm_scope_node_t *scope_node)
{
    const pm_node_location_t location = ((pm_node_location_t) { .line = pm_newline_list_line(&(scope_node->parser)->newline_list, ((const pm_node_t *) (node))->location.start, (scope_node->parser)->start_line), .node_id = ((const pm_node_t *) (node))->node_id });
    switch (((enum pm_node_type) (node)->type)) {
      case PM_LOCAL_VARIABLE_TARGET_NODE: {
        pm_iseq_add_getlocal(iseq, (ret), (int) (location).line, (int) (location).node_id, (1), (0));
        pm_compile_target_node(iseq, node, ret, ret, ret, scope_node, ((void *)0));
        break;
      }
      case PM_CLASS_VARIABLE_TARGET_NODE:
      case PM_CONSTANT_TARGET_NODE:
      case PM_GLOBAL_VARIABLE_TARGET_NODE:
      case PM_INSTANCE_VARIABLE_TARGET_NODE:
      case PM_CONSTANT_PATH_TARGET_NODE:
      case PM_CALL_TARGET_NODE:
      case PM_INDEX_TARGET_NODE: {
        LINK_ANCHOR writes[1] = {{{ISEQ_ELEMENT_ANCHOR,},&writes[0].anchor}};
        LINK_ANCHOR cleanup[1] = {{{ISEQ_ELEMENT_ANCHOR,},&cleanup[0].anchor}};
        pm_multi_target_state_t state = { 0 };
        state.position = 1;
        pm_compile_target_node(iseq, node, ret, writes, cleanup, scope_node, &state);
        pm_iseq_add_getlocal(iseq, (ret), (int) (location).line, (int) (location).node_id, (1), (0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_expandarray, 2, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1))), (VALUE)(__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))));
        APPEND_LIST((ret), (writes));
        APPEND_LIST((ret), (cleanup));
        pm_multi_target_state_update(&state);
        break;
      }
      case PM_MULTI_TARGET_NODE: {
        LINK_ANCHOR writes[1] = {{{ISEQ_ELEMENT_ANCHOR,},&writes[0].anchor}};
        LINK_ANCHOR cleanup[1] = {{{ISEQ_ELEMENT_ANCHOR,},&cleanup[0].anchor}};
        pm_compile_target_node(iseq, node, ret, writes, cleanup, scope_node, ((void *)0));
        LABEL *not_single = new_label_body(iseq, (location.line));
        LABEL *not_ary = new_label_body(iseq, (location.line));
        pm_iseq_add_getlocal(iseq, (ret), (int) (location).line, (int) (location).node_id, (1), (0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((idLength)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p((0x01 << VM_CALL_FCALL_bit)), ((VALUE)((0x01 << VM_CALL_FCALL_bit))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((0x01 << VM_CALL_FCALL_bit)))), (((void *)0))));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((idEq)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p((0x01 << VM_CALL_FCALL_bit)), ((VALUE)((0x01 << VM_CALL_FCALL_bit))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((0x01 << VM_CALL_FCALL_bit)))), (((void *)0))));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(not_single))), ((not_single)->refcnt++));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))));
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((idAREF)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p((0x01 << VM_CALL_FCALL_bit)), ((VALUE)((0x01 << VM_CALL_FCALL_bit))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((0x01 << VM_CALL_FCALL_bit)))), (((void *)0))));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(rb_cArray)));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_swap, 0));
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, (((__builtin_constant_p("try_convert") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("try_convert")); }) : (rb_intern)("try_convert")))), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p((0x01 << VM_CALL_FCALL_bit)), ((VALUE)((0x01 << VM_CALL_FCALL_bit))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((0x01 << VM_CALL_FCALL_bit)))), (((void *)0))));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(not_ary))), ((not_ary)->refcnt++));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_swap, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) (not_ary));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) (not_single));
        APPEND_LIST((ret), (writes));
        APPEND_LIST((ret), (cleanup));
        break;
      }
      default:
        rb_bug("Unexpected node type for index in for node: %s", pm_node_type_to_str(((enum pm_node_type) (node)->type)));
        break;
    }
}
static void
pm_compile_rescue(rb_iseq_t *iseq, const pm_begin_node_t *cast, const pm_node_location_t *node_location, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node)
{
    const pm_parser_t *parser = scope_node->parser;
    LABEL *lstart = new_label_body(iseq, (node_location->line));
    LABEL *lend = new_label_body(iseq, (node_location->line));
    LABEL *lcont = new_label_body(iseq, (node_location->line));
    pm_scope_node_t rescue_scope_node;
    pm_scope_node_init((const pm_node_t *) cast->rescue_clause, &rescue_scope_node, scope_node);
    rb_iseq_t *rescue_iseq = pm_new_child_iseq(iseq, (&rescue_scope_node), rb_fstring(rb_str_concat(((__builtin_constant_p("rescue in ") ? rbimpl_str_new_cstr : rb_str_new_cstr) ("rescue in ")), ((iseq)->body)->location.label)), iseq, (ISEQ_TYPE_RESCUE), (pm_node_line_number(parser, (const pm_node_t *) cast->rescue_clause)));
    pm_scope_node_destroy(&rescue_scope_node);
    lstart->rescued = LABEL_RESCUE_BEG;
    lend->rescued = LABEL_RESCUE_END;
    ADD_ELEM((ret), (LINK_ELEMENT *) (lstart));
    _Bool prev_in_rescue = ISEQ_COMPILE_DATA(iseq)->in_rescue;
    ISEQ_COMPILE_DATA(iseq)->in_rescue = 1;
    if (cast->statements != ((void *)0)) {
        pm_compile_node(iseq, ((const pm_node_t *) cast->statements), ret, 0, scope_node);
    }
    else {
        const pm_node_location_t location = ((pm_node_location_t) { .line = pm_newline_list_line(&(parser)->newline_list, ((const pm_node_t *) (cast->rescue_clause))->location.start, (parser)->start_line), .node_id = ((const pm_node_t *) (cast->rescue_clause))->node_id });
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
    }
    ISEQ_COMPILE_DATA(iseq)->in_rescue = prev_in_rescue;
    ADD_ELEM((ret), (LINK_ELEMENT *) (lend));
    if (cast->else_clause != ((void *)0)) {
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*node_location).line, (int) (*node_location).node_id, YARVINSN_pop, 0));
        pm_compile_node(iseq, ((const pm_node_t *) cast->else_clause), ret, popped, scope_node);
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*node_location).line, (int) (*node_location).node_id, YARVINSN_nop, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) (lcont));
    if (popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*node_location).line, (int) (*node_location).node_id, YARVINSN_pop, 0));
    do { VALUE _e = __extension__ ({ const VALUE args_to_new_ary[] = {((CATCH_TYPE_RESCUE)), (VALUE)((lstart)) | 1, (VALUE)((lend)) | 1, (VALUE)((rescue_iseq)), (VALUE)((lcont)) | 1}; if (__builtin_constant_p(5)) { __extension__ _Static_assert(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))) == (5), "rb_ary_new_from_args" ": " "numberof(args_to_new_ary) == (5)"); } rb_ary_new_from_values(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))), args_to_new_ary); }); (((lstart)) ? ((((lstart))->refcnt++), ((lstart))->unremovable=1) : 0); (((lend))->refcnt++); (((lcont))->refcnt++); if (RB_NIL_P(ISEQ_COMPILE_DATA(iseq)->catch_table_ary)) (rb_obj_write((VALUE)(iseq), (VALUE *)(&ISEQ_COMPILE_DATA(iseq)->catch_table_ary), (VALUE)(rb_ary_hidden_new(3)), "prism_compile.c", 4953)); rb_ary_push(ISEQ_COMPILE_DATA(iseq)->catch_table_ary, freeze_hide_obj(_e)); } while (0);
    do { VALUE _e = __extension__ ({ const VALUE args_to_new_ary[] = {((CATCH_TYPE_RETRY)), (VALUE)((lend)) | 1, (VALUE)((lcont)) | 1, (VALUE)((((void *)0))), (VALUE)((lstart)) | 1}; if (__builtin_constant_p(5)) { __extension__ _Static_assert(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))) == (5), "rb_ary_new_from_args" ": " "numberof(args_to_new_ary) == (5)"); } rb_ary_new_from_values(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))), args_to_new_ary); }); (((lend)) ? ((((lend))->refcnt++), ((lend))->unremovable=1) : 0); (((lcont))->refcnt++); (((lstart))->refcnt++); if (RB_NIL_P(ISEQ_COMPILE_DATA(iseq)->catch_table_ary)) (rb_obj_write((VALUE)(iseq), (VALUE *)(&ISEQ_COMPILE_DATA(iseq)->catch_table_ary), (VALUE)(rb_ary_hidden_new(3)), "prism_compile.c", 4954)); rb_ary_push(ISEQ_COMPILE_DATA(iseq)->catch_table_ary, freeze_hide_obj(_e)); } while (0);
}
static void
pm_compile_ensure(rb_iseq_t *iseq, const pm_begin_node_t *cast, const pm_node_location_t *node_location, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node)
{
    const pm_parser_t *parser = scope_node->parser;
    const pm_statements_node_t *statements = cast->ensure_clause->statements;
    pm_node_location_t location;
    if (statements != ((void *)0)) {
        location = ((pm_node_location_t) { .line = pm_newline_list_line(&(parser)->newline_list, ((const pm_node_t *) (statements))->location.start, (parser)->start_line), .node_id = ((const pm_node_t *) (statements))->node_id });
    }
    else {
        location = *node_location;
    }
    LABEL *lstart = new_label_body(iseq, (location.line));
    LABEL *lend = new_label_body(iseq, (location.line));
    LABEL *lcont = new_label_body(iseq, (location.line));
    struct ensure_range er;
    struct iseq_compile_data_ensure_node_stack enl;
    struct ensure_range *erange;
    LINK_ANCHOR ensr[1] = {{{ISEQ_ELEMENT_ANCHOR,},&ensr[0].anchor}};
    if (statements != ((void *)0)) {
        pm_compile_node(iseq, (const pm_node_t *) statements, ensr, 1, scope_node);
    }
    LINK_ELEMENT *last = ensr->last;
    _Bool last_leave = last && ((last)->type == ISEQ_ELEMENT_INSN) && ((((INSN*)(last))->insn_id) == YARVINSN_leave);
    er.begin = lstart;
    er.end = lend;
    er.next = 0;
    push_ensure_entry(iseq, &enl, &er, (void *) cast->ensure_clause);
    ADD_ELEM((ret), (LINK_ELEMENT *) (lstart));
    if (cast->rescue_clause != ((void *)0)) {
        pm_compile_rescue(iseq, cast, node_location, ret, popped | last_leave, scope_node);
    }
    else if (cast->statements != ((void *)0)) {
        pm_compile_node(iseq, (const pm_node_t *) cast->statements, ret, popped | last_leave, scope_node);
    }
    else if (!(popped | last_leave)) {
        do { int lineno = ISEQ_COMPILE_DATA(iseq)->last_line; if (lineno == 0) lineno = RB_FIX2INT(rb_iseq_first_lineno(iseq)); ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (lineno), (-1), YARVINSN_putnil, 0)); } while (0);
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) (lend));
    APPEND_LIST((ret), (ensr));
    if (!popped && last_leave) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*node_location).line, (int) (*node_location).node_id, YARVINSN_putnil, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) (lcont));
    if (last_leave) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*node_location).line, (int) (*node_location).node_id, YARVINSN_pop, 0));
    pm_scope_node_t next_scope_node;
    pm_scope_node_init((const pm_node_t *) cast->ensure_clause, &next_scope_node, scope_node);
    rb_iseq_t *child_iseq = pm_new_child_iseq(iseq, (&next_scope_node), rb_fstring(rb_str_concat(((__builtin_constant_p("ensure in ") ? rbimpl_str_new_cstr : rb_str_new_cstr) ("ensure in ")), ((iseq)->body)->location.label)), iseq, (ISEQ_TYPE_ENSURE), (location.line));
    pm_scope_node_destroy(&next_scope_node);
    erange = ISEQ_COMPILE_DATA(iseq)->ensure_node_stack->erange;
    if (lstart->link.next != &lend->link) {
        while (erange) {
            do { VALUE _e = __extension__ ({ const VALUE args_to_new_ary[] = {((CATCH_TYPE_ENSURE)), (VALUE)((erange->begin)) | 1, (VALUE)((erange->end)) | 1, (VALUE)((child_iseq)), (VALUE)((lcont)) | 1}; if (__builtin_constant_p(5)) { __extension__ _Static_assert(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))) == (5), "rb_ary_new_from_args" ": " "numberof(args_to_new_ary) == (5)"); } rb_ary_new_from_values(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))), args_to_new_ary); }); (((erange->begin)) ? ((((erange->begin))->refcnt++), ((erange->begin))->unremovable=1) : 0); (((erange->end))->refcnt++); (((lcont))->refcnt++); if (RB_NIL_P(ISEQ_COMPILE_DATA(iseq)->catch_table_ary)) (rb_obj_write((VALUE)(iseq), (VALUE *)(&ISEQ_COMPILE_DATA(iseq)->catch_table_ary), (VALUE)(rb_ary_hidden_new(3)), "prism_compile.c", 5024)); rb_ary_push(ISEQ_COMPILE_DATA(iseq)->catch_table_ary, freeze_hide_obj(_e)); } while (0);
            erange = erange->next;
        }
    }
    ISEQ_COMPILE_DATA(iseq)->ensure_node_stack = enl.prev;
}
static inline _Bool
pm_opt_str_freeze_p(const rb_iseq_t *iseq, const pm_call_node_t *node)
{
    return (
        !((((pm_node_t *)(node))->flags & (PM_CALL_NODE_FLAGS_SAFE_NAVIGATION)) != 0) &&
        node->receiver != ((void *)0) &&
        (((enum pm_node_type) (node->receiver)->type) == (PM_STRING_NODE)) &&
        node->arguments == ((void *)0) &&
        node->block == ((void *)0) &&
        ISEQ_COMPILE_DATA(iseq)->option->specialized_instruction
    );
}
static inline _Bool
pm_opt_aref_with_p(const rb_iseq_t *iseq, const pm_call_node_t *node)
{
    return (
        !((((pm_node_t *)(node))->flags & (PM_CALL_NODE_FLAGS_SAFE_NAVIGATION)) != 0) &&
        node->arguments != ((void *)0) &&
        (((enum pm_node_type) ((const pm_node_t *) node->arguments)->type) == (PM_ARGUMENTS_NODE)) &&
        ((const pm_arguments_node_t *) node->arguments)->arguments.size == 1 &&
        (((enum pm_node_type) (((const pm_arguments_node_t *) node->arguments)->arguments.nodes[0])->type) == (PM_STRING_NODE)) &&
        node->block == ((void *)0) &&
        !((((pm_node_t *)(((const pm_arguments_node_t *) node->arguments)->arguments.nodes[0]))->flags & (PM_STRING_FLAGS_FROZEN)) != 0) &&
        ISEQ_COMPILE_DATA(iseq)->option->specialized_instruction
    );
}
static inline _Bool
pm_opt_aset_with_p(const rb_iseq_t *iseq, const pm_call_node_t *node)
{
    return (
        !((((pm_node_t *)(node))->flags & (PM_CALL_NODE_FLAGS_SAFE_NAVIGATION)) != 0) &&
        node->arguments != ((void *)0) &&
        (((enum pm_node_type) ((const pm_node_t *) node->arguments)->type) == (PM_ARGUMENTS_NODE)) &&
        ((const pm_arguments_node_t *) node->arguments)->arguments.size == 2 &&
        (((enum pm_node_type) (((const pm_arguments_node_t *) node->arguments)->arguments.nodes[0])->type) == (PM_STRING_NODE)) &&
        node->block == ((void *)0) &&
        !((((pm_node_t *)(((const pm_arguments_node_t *) node->arguments)->arguments.nodes[0]))->flags & (PM_STRING_FLAGS_FROZEN)) != 0) &&
        ISEQ_COMPILE_DATA(iseq)->option->specialized_instruction
    );
}
static void
pm_compile_constant_read(rb_iseq_t *iseq, VALUE name, const pm_location_t *name_loc, uint32_t node_id, LINK_ANCHOR *const ret, const pm_scope_node_t *scope_node)
{
    const pm_node_location_t location = ((pm_node_location_t) { .line = pm_newline_list_line(&(scope_node->parser)->newline_list, (name_loc)->start, (scope_node->parser)->start_line), .node_id = node_id });
    if (ISEQ_COMPILE_DATA(iseq)->option->inline_const_cache) {
        ((iseq)->body)->ic_size++;
        VALUE segments = __extension__ ({ const VALUE args_to_new_ary[] = {name}; if (__builtin_constant_p(1)) { __extension__ _Static_assert(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))) == (1), "rb_ary_new_from_args" ": " "numberof(args_to_new_ary) == (1)"); } rb_ary_new_from_values(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))), args_to_new_ary); });
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_opt_getconstant_path, 1, (VALUE)(segments)));
    }
    else {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qtrue))));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_getconstant, 1, (VALUE)(name)));
    }
}
static VALUE
pm_constant_path_parts(const pm_node_t *node, const pm_scope_node_t *scope_node)
{
    VALUE parts = rb_ary_new();
    while (1) {
        switch (((enum pm_node_type) (node)->type)) {
          case PM_CONSTANT_READ_NODE: {
            const pm_constant_read_node_t *cast = (const pm_constant_read_node_t *) node;
            VALUE name = rb_id2sym(pm_constant_id_lookup(scope_node, cast->name));
            rb_ary_unshift(parts, name);
            return parts;
          }
          case PM_CONSTANT_PATH_NODE: {
            const pm_constant_path_node_t *cast = (const pm_constant_path_node_t *) node;
            VALUE name = rb_id2sym(pm_constant_id_lookup(scope_node, cast->name));
            rb_ary_unshift(parts, name);
            if (cast->parent == ((void *)0)) {
                rb_ary_unshift(parts, rb_id2sym(idNULL));
                return parts;
            }
            node = cast->parent;
            break;
          }
          default:
            return ((VALUE)RUBY_Qnil);
        }
    }
}
static void
pm_compile_constant_path(rb_iseq_t *iseq, const pm_node_t *node, LINK_ANCHOR *const prefix, LINK_ANCHOR *const body, _Bool popped, pm_scope_node_t *scope_node)
{
    const pm_node_location_t location = ((pm_node_location_t) { .line = pm_newline_list_line(&(scope_node->parser)->newline_list, ((const pm_node_t *) (node))->location.start, (scope_node->parser)->start_line), .node_id = ((const pm_node_t *) (node))->node_id });
    switch (((enum pm_node_type) (node)->type)) {
      case PM_CONSTANT_READ_NODE: {
        const pm_constant_read_node_t *cast = (const pm_constant_read_node_t *) node;
        VALUE name = rb_id2sym(pm_constant_id_lookup(scope_node, cast->name));
        ADD_ELEM((body), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qtrue))));
        ADD_ELEM((body), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_getconstant, 1, (VALUE)(name)));
        break;
      }
      case PM_CONSTANT_PATH_NODE: {
        const pm_constant_path_node_t *cast = (const pm_constant_path_node_t *) node;
        VALUE name = rb_id2sym(pm_constant_id_lookup(scope_node, cast->name));
        if (cast->parent == ((void *)0)) {
            ADD_ELEM((body), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
            ADD_ELEM((body), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(rb_cObject)));
            ADD_ELEM((body), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qtrue))));
            ADD_ELEM((body), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_getconstant, 1, (VALUE)(name)));
        }
        else {
            pm_compile_constant_path(iseq, cast->parent, prefix, body, 0, scope_node);
            ADD_ELEM((body), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qfalse))));
            ADD_ELEM((body), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_getconstant, 1, (VALUE)(name)));
        }
        break;
      }
      default:
        pm_compile_node(iseq, (node), prefix, popped, scope_node);
        break;
    }
}
static VALUE
pm_compile_shareable_constant_literal(rb_iseq_t *iseq, const pm_node_t *node, const pm_scope_node_t *scope_node)
{
    switch (((enum pm_node_type) (node)->type)) {
      case PM_TRUE_NODE:
      case PM_FALSE_NODE:
      case PM_NIL_NODE:
      case PM_SYMBOL_NODE:
      case PM_REGULAR_EXPRESSION_NODE:
      case PM_SOURCE_LINE_NODE:
      case PM_INTEGER_NODE:
      case PM_FLOAT_NODE:
      case PM_RATIONAL_NODE:
      case PM_IMAGINARY_NODE:
      case PM_SOURCE_ENCODING_NODE:
        return pm_static_literal_value(iseq, node, scope_node);
      case PM_STRING_NODE:
        return parse_static_literal_string(iseq, scope_node, node, &((const pm_string_node_t *) node)->unescaped);
      case PM_SOURCE_FILE_NODE:
        return pm_source_file_value((const pm_source_file_node_t *) node, scope_node);
      case PM_ARRAY_NODE: {
        const pm_array_node_t *cast = (const pm_array_node_t *) node;
        VALUE result = rb_ary_new_capa(cast->elements.size);
        for (size_t index = 0; index < cast->elements.size; index++) {
            VALUE element = pm_compile_shareable_constant_literal(iseq, cast->elements.nodes[index], scope_node);
            if (element == ((VALUE)RUBY_Qundef)) return ((VALUE)RUBY_Qundef);
            rb_ary_push(result, element);
        }
        return rb_ractor_make_shareable(result);
      }
      case PM_HASH_NODE: {
        const pm_hash_node_t *cast = (const pm_hash_node_t *) node;
        VALUE result = rb_hash_new_capa(cast->elements.size);
        for (size_t index = 0; index < cast->elements.size; index++) {
            const pm_node_t *element = cast->elements.nodes[index];
            if (!(((enum pm_node_type) (element)->type) == (PM_ASSOC_NODE))) return ((VALUE)RUBY_Qundef);
            const pm_assoc_node_t *assoc = (const pm_assoc_node_t *) element;
            VALUE key = pm_compile_shareable_constant_literal(iseq, assoc->key, scope_node);
            if (key == ((VALUE)RUBY_Qundef)) return ((VALUE)RUBY_Qundef);
            VALUE value = pm_compile_shareable_constant_literal(iseq, assoc->value, scope_node);
            if (value == ((VALUE)RUBY_Qundef)) return ((VALUE)RUBY_Qundef);
            rb_hash_aset(result, key, value);
        }
        return rb_ractor_make_shareable(result);
      }
      default:
        return ((VALUE)RUBY_Qundef);
    }
}
static void
pm_compile_shareable_constant_value(rb_iseq_t *iseq, const pm_node_t *node, const pm_node_flags_t shareability, VALUE path, LINK_ANCHOR *const ret, pm_scope_node_t *scope_node, _Bool top)
{
    VALUE literal = pm_compile_shareable_constant_literal(iseq, node, scope_node);
    if (literal != ((VALUE)RUBY_Qundef)) {
        const pm_node_location_t location = ((pm_node_location_t) { .line = pm_newline_list_line(&(scope_node->parser)->newline_list, ((const pm_node_t *) (node))->location.start, (scope_node->parser)->start_line), .node_id = ((const pm_node_t *) (node))->node_id });
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(literal)));
        return;
    }
    const pm_node_location_t location = ((pm_node_location_t) { .line = pm_newline_list_line(&(scope_node->parser)->newline_list, ((const pm_node_t *) (node))->location.start, (scope_node->parser)->start_line), .node_id = ((const pm_node_t *) (node))->node_id });
    switch (((enum pm_node_type) (node)->type)) {
      case PM_ARRAY_NODE: {
        const pm_array_node_t *cast = (const pm_array_node_t *) node;
        if (top) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
        }
        for (size_t index = 0; index < cast->elements.size; index++) {
            pm_compile_shareable_constant_value(iseq, cast->elements.nodes[index], shareability, path, ret, scope_node, 0);
        }
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_newarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(cast->elements.size), ((VALUE)(cast->elements.size)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(cast->elements.size)))));
        if (top) {
            ID method_id = (shareability & PM_SHAREABLE_CONSTANT_NODE_FLAGS_EXPERIMENTAL_COPY) ? (__builtin_constant_p("make_shareable_copy") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("make_shareable_copy")); }) : (rb_intern)("make_shareable_copy")) : (__builtin_constant_p("make_shareable") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("make_shareable")); }) : (rb_intern)("make_shareable"));
            ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((method_id)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)(__builtin_choose_expr( __builtin_constant_p((0x01 << VM_CALL_ARGS_SIMPLE_bit)), ((VALUE)((0x01 << VM_CALL_ARGS_SIMPLE_bit))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((0x01 << VM_CALL_ARGS_SIMPLE_bit))))), (((void *)0))));
        }
        return;
      }
      case PM_HASH_NODE: {
        const pm_hash_node_t *cast = (const pm_hash_node_t *) node;
        if (top) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
        }
        for (size_t index = 0; index < cast->elements.size; index++) {
            const pm_node_t *element = cast->elements.nodes[index];
            if (!(((enum pm_node_type) (element)->type) == (PM_ASSOC_NODE))) {
                append_compile_error(iseq, location.line, "Ractor constant writes do not support **");
            }
            const pm_assoc_node_t *assoc = (const pm_assoc_node_t *) element;
            pm_compile_shareable_constant_value(iseq, assoc->key, shareability, path, ret, scope_node, 0);
            pm_compile_shareable_constant_value(iseq, assoc->value, shareability, path, ret, scope_node, 0);
        }
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_newhash, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(cast->elements.size * 2), ((VALUE)(cast->elements.size * 2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(cast->elements.size * 2)))));
        if (top) {
            ID method_id = (shareability & PM_SHAREABLE_CONSTANT_NODE_FLAGS_EXPERIMENTAL_COPY) ? (__builtin_constant_p("make_shareable_copy") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("make_shareable_copy")); }) : (rb_intern)("make_shareable_copy")) : (__builtin_constant_p("make_shareable") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("make_shareable")); }) : (rb_intern)("make_shareable"));
            ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((method_id)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)(__builtin_choose_expr( __builtin_constant_p((0x01 << VM_CALL_ARGS_SIMPLE_bit)), ((VALUE)((0x01 << VM_CALL_ARGS_SIMPLE_bit))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((0x01 << VM_CALL_ARGS_SIMPLE_bit))))), (((void *)0))));
        }
        return;
      }
      default: {
        LINK_ANCHOR value_seq[1] = {{{ISEQ_ELEMENT_ANCHOR,},&value_seq[0].anchor}};
        pm_compile_node(iseq, node, value_seq, 0, scope_node);
        if ((((enum pm_node_type) (node)->type) == (PM_INTERPOLATED_STRING_NODE))) {
            ADD_ELEM(((value_seq)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((idUMinus)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))), (((void *)0)), (VALUE)((VALUE)(__builtin_choose_expr( __builtin_constant_p((0x01 << VM_CALL_ARGS_SIMPLE_bit)), ((VALUE)((0x01 << VM_CALL_ARGS_SIMPLE_bit))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((0x01 << VM_CALL_ARGS_SIMPLE_bit))))), (((void *)0))));
        }
        if (shareability & PM_SHAREABLE_CONSTANT_NODE_FLAGS_LITERAL) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
            APPEND_LIST((ret), (value_seq));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(path)));
            ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, (((__builtin_constant_p("ensure_shareable") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("ensure_shareable")); }) : (rb_intern)("ensure_shareable")))), (VALUE)((__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))), (((void *)0)), (VALUE)((VALUE)(__builtin_choose_expr( __builtin_constant_p((0x01 << VM_CALL_ARGS_SIMPLE_bit)), ((VALUE)((0x01 << VM_CALL_ARGS_SIMPLE_bit))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((0x01 << VM_CALL_ARGS_SIMPLE_bit))))), (((void *)0))));
        }
        else if (shareability & PM_SHAREABLE_CONSTANT_NODE_FLAGS_EXPERIMENTAL_COPY) {
            if (top) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
            APPEND_LIST((ret), (value_seq));
            if (top) ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, (((__builtin_constant_p("make_shareable_copy") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("make_shareable_copy")); }) : (rb_intern)("make_shareable_copy")))), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)(__builtin_choose_expr( __builtin_constant_p((0x01 << VM_CALL_ARGS_SIMPLE_bit)), ((VALUE)((0x01 << VM_CALL_ARGS_SIMPLE_bit))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((0x01 << VM_CALL_ARGS_SIMPLE_bit))))), (((void *)0))));
        }
        else if (shareability & PM_SHAREABLE_CONSTANT_NODE_FLAGS_EXPERIMENTAL_EVERYTHING) {
            if (top) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
            APPEND_LIST((ret), (value_seq));
            if (top) ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, (((__builtin_constant_p("make_shareable") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("make_shareable")); }) : (rb_intern)("make_shareable")))), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)(__builtin_choose_expr( __builtin_constant_p((0x01 << VM_CALL_ARGS_SIMPLE_bit)), ((VALUE)((0x01 << VM_CALL_ARGS_SIMPLE_bit))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((0x01 << VM_CALL_ARGS_SIMPLE_bit))))), (((void *)0))));
        }
        break;
      }
    }
}
static void
pm_compile_constant_write_node(rb_iseq_t *iseq, const pm_constant_write_node_t *node, const pm_node_flags_t shareability, const pm_node_location_t *node_location, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node)
{
    const pm_node_location_t location = *node_location;
    ID name_id = pm_constant_id_lookup(scope_node, node->name);
    if (shareability != 0) {
        pm_compile_shareable_constant_value(iseq, node->value, shareability, rb_id2str(name_id), ret, scope_node, 1);
    }
    else {
        pm_compile_node(iseq, (node->value), ret, 0, scope_node);
    }
    if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_CONST_BASE), ((VALUE)(VM_SPECIAL_OBJECT_CONST_BASE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_CONST_BASE)))));
    VALUE operand = rb_id2sym(name_id);
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setconstant, 1, (VALUE)(operand)));
}
static void
pm_compile_constant_and_write_node(rb_iseq_t *iseq, const pm_constant_and_write_node_t *node, const pm_node_flags_t shareability, const pm_node_location_t *node_location, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node)
{
    const pm_node_location_t location = *node_location;
    VALUE name = rb_id2sym(pm_constant_id_lookup(scope_node, node->name));
    LABEL *end_label = new_label_body(iseq, (location.line));
    pm_compile_constant_read(iseq, name, &node->name_loc, location.node_id, ret, scope_node);
    if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(end_label))), ((end_label)->refcnt++));
    if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
    if (shareability != 0) {
        pm_compile_shareable_constant_value(iseq, node->value, shareability, name, ret, scope_node, 1);
    }
    else {
        pm_compile_node(iseq, (node->value), ret, 0, scope_node);
    }
    if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_CONST_BASE), ((VALUE)(VM_SPECIAL_OBJECT_CONST_BASE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_CONST_BASE)))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setconstant, 1, (VALUE)(name)));
    ADD_ELEM((ret), (LINK_ELEMENT *) (end_label));
}
static void
pm_compile_constant_or_write_node(rb_iseq_t *iseq, const pm_constant_or_write_node_t *node, const pm_node_flags_t shareability, const pm_node_location_t *node_location, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node)
{
    const pm_node_location_t location = *node_location;
    VALUE name = rb_id2sym(pm_constant_id_lookup(scope_node, node->name));
    LABEL *set_label = new_label_body(iseq, (location.line));
    LABEL *end_label = new_label_body(iseq, (location.line));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_defined, 3, (VALUE)(__builtin_choose_expr( __builtin_constant_p(DEFINED_CONST), ((VALUE)(DEFINED_CONST)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(DEFINED_CONST))), (VALUE)(name), (VALUE)(((VALUE)RUBY_Qtrue))));
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(set_label))), ((set_label)->refcnt++));
    pm_compile_constant_read(iseq, name, &node->name_loc, location.node_id, ret, scope_node);
    if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchif, 1, (VALUE)(end_label))), ((end_label)->refcnt++));
    if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) (set_label));
    if (shareability != 0) {
        pm_compile_shareable_constant_value(iseq, node->value, shareability, name, ret, scope_node, 1);
    }
    else {
        pm_compile_node(iseq, (node->value), ret, 0, scope_node);
    }
    if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_CONST_BASE), ((VALUE)(VM_SPECIAL_OBJECT_CONST_BASE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_CONST_BASE)))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setconstant, 1, (VALUE)(name)));
    ADD_ELEM((ret), (LINK_ELEMENT *) (end_label));
}
static void
pm_compile_constant_operator_write_node(rb_iseq_t *iseq, const pm_constant_operator_write_node_t *node, const pm_node_flags_t shareability, const pm_node_location_t *node_location, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node)
{
    const pm_node_location_t location = *node_location;
    VALUE name = rb_id2sym(pm_constant_id_lookup(scope_node, node->name));
    ID method_id = pm_constant_id_lookup(scope_node, node->binary_operator);
    pm_compile_constant_read(iseq, name, &node->name_loc, location.node_id, ret, scope_node);
    if (shareability != 0) {
        pm_compile_shareable_constant_value(iseq, node->value, shareability, name, ret, scope_node, 1);
    }
    else {
        pm_compile_node(iseq, (node->value), ret, 0, scope_node);
    }
    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((method_id)), (VALUE)((rb_int2num_inline(1))), (((void *)0)), (VALUE)((VALUE)(__builtin_choose_expr( __builtin_constant_p((0x01 << VM_CALL_ARGS_SIMPLE_bit)), ((VALUE)((0x01 << VM_CALL_ARGS_SIMPLE_bit))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((0x01 << VM_CALL_ARGS_SIMPLE_bit))))), (((void *)0))));
    if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_CONST_BASE), ((VALUE)(VM_SPECIAL_OBJECT_CONST_BASE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_CONST_BASE)))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setconstant, 1, (VALUE)(name)));
}
static VALUE
pm_constant_path_path(const pm_constant_path_node_t *node, const pm_scope_node_t *scope_node)
{
    VALUE parts = rb_ary_new();
    rb_ary_push(parts, rb_id2str(pm_constant_id_lookup(scope_node, node->name)));
    const pm_node_t *current = node->parent;
    while (current != ((void *)0) && (((enum pm_node_type) (current)->type) == (PM_CONSTANT_PATH_NODE))) {
        const pm_constant_path_node_t *cast = (const pm_constant_path_node_t *) current;
        rb_ary_unshift(parts, rb_id2str(pm_constant_id_lookup(scope_node, cast->name)));
        current = cast->parent;
    }
    if (current == ((void *)0)) {
        rb_ary_unshift(parts, rb_id2str(idNULL));
    }
    else if ((((enum pm_node_type) (current)->type) == (PM_CONSTANT_READ_NODE))) {
        rb_ary_unshift(parts, rb_id2str(pm_constant_id_lookup(scope_node, ((const pm_constant_read_node_t *) current)->name)));
    }
    else {
        rb_ary_unshift(parts, ((__builtin_constant_p("...") ? rbimpl_str_new_cstr : rb_str_new_cstr) ("...")));
    }
    return rb_ary_join(parts, ((__builtin_constant_p("::") ? rbimpl_str_new_cstr : rb_str_new_cstr) ("::")));
}
static void
pm_compile_constant_path_write_node(rb_iseq_t *iseq, const pm_constant_path_write_node_t *node, const pm_node_flags_t shareability, const pm_node_location_t *node_location, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node)
{
    const pm_node_location_t location = *node_location;
    const pm_constant_path_node_t *target = node->target;
    VALUE name = rb_id2sym(pm_constant_id_lookup(scope_node, target->name));
    if (target->parent) {
        pm_compile_node(iseq, ((const pm_node_t *) target->parent), ret, 0, scope_node);
    }
    else {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(rb_cObject)));
    }
    if (shareability != 0) {
        pm_compile_shareable_constant_value(iseq, node->value, shareability, pm_constant_path_path(node->target, scope_node), ret, scope_node, 1);
    }
    else {
        pm_compile_node(iseq, (node->value), ret, 0, scope_node);
    }
    if (!popped) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_swap, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_swap, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setconstant, 1, (VALUE)(name)));
}
static void
pm_compile_constant_path_and_write_node(rb_iseq_t *iseq, const pm_constant_path_and_write_node_t *node, const pm_node_flags_t shareability, const pm_node_location_t *node_location, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node)
{
    const pm_node_location_t location = *node_location;
    const pm_constant_path_node_t *target = node->target;
    VALUE name = rb_id2sym(pm_constant_id_lookup(scope_node, target->name));
    LABEL *lfin = new_label_body(iseq, (location.line));
    if (target->parent) {
        pm_compile_node(iseq, (target->parent), ret, 0, scope_node);
    }
    else {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(rb_cObject)));
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qtrue))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_getconstant, 1, (VALUE)(name)));
    if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(lfin))), ((lfin)->refcnt++));
    if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
    if (shareability != 0) {
        pm_compile_shareable_constant_value(iseq, node->value, shareability, pm_constant_path_path(node->target, scope_node), ret, scope_node, 1);
    }
    else {
        pm_compile_node(iseq, (node->value), ret, 0, scope_node);
    }
    if (popped) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
    }
    else {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dupn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_swap, 0));
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setconstant, 1, (VALUE)(name)));
    ADD_ELEM((ret), (LINK_ELEMENT *) (lfin));
    if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_swap, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
}
static void
pm_compile_constant_path_or_write_node(rb_iseq_t *iseq, const pm_constant_path_or_write_node_t *node, const pm_node_flags_t shareability, const pm_node_location_t *node_location, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node)
{
    const pm_node_location_t location = *node_location;
    const pm_constant_path_node_t *target = node->target;
    VALUE name = rb_id2sym(pm_constant_id_lookup(scope_node, target->name));
    LABEL *lassign = new_label_body(iseq, (location.line));
    LABEL *lfin = new_label_body(iseq, (location.line));
    if (target->parent) {
        pm_compile_node(iseq, (target->parent), ret, 0, scope_node);
    }
    else {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(rb_cObject)));
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_defined, 3, (VALUE)(__builtin_choose_expr( __builtin_constant_p(DEFINED_CONST_FROM), ((VALUE)(DEFINED_CONST_FROM)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(DEFINED_CONST_FROM))), (VALUE)(name), (VALUE)(((VALUE)RUBY_Qtrue))));
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(lassign))), ((lassign)->refcnt++));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qtrue))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_getconstant, 1, (VALUE)(name)));
    if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchif, 1, (VALUE)(lfin))), ((lfin)->refcnt++));
    if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) (lassign));
    if (shareability != 0) {
        pm_compile_shareable_constant_value(iseq, node->value, shareability, pm_constant_path_path(node->target, scope_node), ret, scope_node, 1);
    }
    else {
        pm_compile_node(iseq, (node->value), ret, 0, scope_node);
    }
    if (popped) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
    }
    else {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dupn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_swap, 0));
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setconstant, 1, (VALUE)(name)));
    ADD_ELEM((ret), (LINK_ELEMENT *) (lfin));
    if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_swap, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
}
static void
pm_compile_constant_path_operator_write_node(rb_iseq_t *iseq, const pm_constant_path_operator_write_node_t *node, const pm_node_flags_t shareability, const pm_node_location_t *node_location, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node)
{
    const pm_node_location_t location = *node_location;
    const pm_constant_path_node_t *target = node->target;
    ID method_id = pm_constant_id_lookup(scope_node, node->binary_operator);
    VALUE name = rb_id2sym(pm_constant_id_lookup(scope_node, target->name));
    if (target->parent) {
        pm_compile_node(iseq, (target->parent), ret, 0, scope_node);
    }
    else {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(rb_cObject)));
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qtrue))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_getconstant, 1, (VALUE)(name)));
    if (shareability != 0) {
        pm_compile_shareable_constant_value(iseq, node->value, shareability, pm_constant_path_path(node->target, scope_node), ret, scope_node, 1);
    }
    else {
        pm_compile_node(iseq, (node->value), ret, 0, scope_node);
    }
    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((method_id)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p((0x01 << VM_CALL_FCALL_bit)), ((VALUE)((0x01 << VM_CALL_FCALL_bit))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((0x01 << VM_CALL_FCALL_bit)))), (((void *)0))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_swap, 0));
    if (!popped) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_swap, 0));
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setconstant, 1, (VALUE)(name)));
}
static inline void
pm_compile_scope_node(rb_iseq_t *iseq, pm_scope_node_t *scope_node, const pm_node_location_t *node_location, LINK_ANCHOR *const ret, _Bool popped)
{
    const pm_node_location_t location = *node_location;
    struct rb_iseq_constant_body *body = ((iseq)->body);
    pm_constant_id_list_t *locals = &scope_node->locals;
    pm_parameters_node_t *parameters_node = ((void *)0);
    pm_node_list_t *keywords_list = ((void *)0);
    pm_node_list_t *optionals_list = ((void *)0);
    pm_node_list_t *posts_list = ((void *)0);
    pm_node_list_t *requireds_list = ((void *)0);
    pm_node_list_t *block_locals = ((void *)0);
    _Bool trailing_comma = 0;
    if ((((enum pm_node_type) (scope_node->ast_node)->type) == (PM_CLASS_NODE)) || (((enum pm_node_type) (scope_node->ast_node)->type) == (PM_MODULE_NODE))) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_trace_body(iseq, (0x0002), 0));
    }
    if (scope_node->parameters != ((void *)0)) {
        switch (((enum pm_node_type) (scope_node->parameters)->type)) {
          case PM_BLOCK_PARAMETERS_NODE: {
            pm_block_parameters_node_t *cast = (pm_block_parameters_node_t *) scope_node->parameters;
            parameters_node = cast->parameters;
            block_locals = &cast->locals;
            if (parameters_node) {
                if (parameters_node->rest && (((enum pm_node_type) (parameters_node->rest)->type) == (PM_IMPLICIT_REST_NODE))) {
                    trailing_comma = 1;
                }
            }
            break;
          }
          case PM_PARAMETERS_NODE: {
            parameters_node = (pm_parameters_node_t *) scope_node->parameters;
            break;
          }
          case PM_NUMBERED_PARAMETERS_NODE: {
            uint32_t maximum = ((const pm_numbered_parameters_node_t *) scope_node->parameters)->maximum;
            body->param.lead_num = maximum;
            body->param.flags.ambiguous_param0 = maximum == 1;
            break;
          }
          case PM_IT_PARAMETERS_NODE:
            body->param.lead_num = 1;
            body->param.flags.ambiguous_param0 = 1;
            break;
          default:
            rb_bug("Unexpected node type for parameters: %s", pm_node_type_to_str(((enum pm_node_type) (scope_node->parameters)->type)));
        }
    }
    struct rb_iseq_param_keyword *keyword = ((void *)0);
    if (parameters_node) {
        optionals_list = &parameters_node->optionals;
        requireds_list = &parameters_node->requireds;
        keywords_list = &parameters_node->keywords;
        posts_list = &parameters_node->posts;
    }
    else if (scope_node->parameters && ((((enum pm_node_type) (scope_node->parameters)->type) == (PM_NUMBERED_PARAMETERS_NODE)) || (((enum pm_node_type) (scope_node->parameters)->type) == (PM_IT_PARAMETERS_NODE)))) {
        body->param.opt_num = 0;
    }
    else {
        body->param.lead_num = 0;
        body->param.opt_num = 0;
    }
    size_t locals_size = locals->size;
    st_table *index_lookup_table = rb_st_init_numtable();
    int table_size = (int) locals_size;
    if ((((enum pm_node_type) (scope_node->ast_node)->type) == (PM_FOR_NODE))) table_size++;
    if (keywords_list && keywords_list->size) {
        table_size++;
    }
    if (requireds_list) {
        for (size_t i = 0; i < requireds_list->size; i++) {
            pm_node_t *required = requireds_list->nodes[i];
            if ((((enum pm_node_type) (required)->type) == (PM_MULTI_TARGET_NODE))) {
                table_size++;
            }
            else if ((((enum pm_node_type) (required)->type) == (PM_REQUIRED_PARAMETER_NODE))) {
                if (((((pm_node_t *)(required))->flags & (PM_PARAMETER_FLAGS_REPEATED_PARAMETER)) != 0)) {
                    table_size++;
                }
            }
        }
    }
    if (scope_node->parameters != ((void *)0) && (((enum pm_node_type) (scope_node->parameters)->type) == (PM_IT_PARAMETERS_NODE))) {
        table_size++;
    }
    if (optionals_list && optionals_list->size) {
        for (size_t i = 0; i < optionals_list->size; i++) {
            pm_node_t * node = optionals_list->nodes[i];
            if (((((pm_node_t *)(node))->flags & (PM_PARAMETER_FLAGS_REPEATED_PARAMETER)) != 0)) {
                table_size++;
            }
        }
    }
    if (parameters_node) {
        if (parameters_node->rest) {
            if (!((((enum pm_node_type) (parameters_node->rest)->type) == (PM_IMPLICIT_REST_NODE)))) {
                if (!((const pm_rest_parameter_node_t *) parameters_node->rest)->name || ((((pm_node_t *)(parameters_node->rest))->flags & (PM_PARAMETER_FLAGS_REPEATED_PARAMETER)) != 0)) {
                    table_size++;
                }
            }
        }
        if (parameters_node->keyword_rest) {
            if ((((enum pm_node_type) (parameters_node->keyword_rest)->type) == (PM_FORWARDING_PARAMETER_NODE))) {
                if (requireds_list->size == 0 && optionals_list->size == 0 && keywords_list->size == 0) {
                    ((iseq)->body)->param.flags.use_block = 1;
                    ((iseq)->body)->param.flags.forwardable = 1;
                    table_size += 1;
                }
                else {
                    table_size += 4;
                }
            }
            else {
                const pm_keyword_rest_parameter_node_t *kw_rest = (const pm_keyword_rest_parameter_node_t *) parameters_node->keyword_rest;
                if (!kw_rest->name || ((((pm_node_t *)(kw_rest))->flags & (PM_PARAMETER_FLAGS_REPEATED_PARAMETER)) != 0)) {
                    table_size++;
                }
            }
        }
    }
    if (posts_list) {
        for (size_t i = 0; i < posts_list->size; i++) {
            pm_node_t *required = posts_list->nodes[i];
            if ((((enum pm_node_type) (required)->type) == (PM_MULTI_TARGET_NODE)) || ((((pm_node_t *)(required))->flags & (PM_PARAMETER_FLAGS_REPEATED_PARAMETER)) != 0)) {
                table_size++;
            }
        }
    }
    if (keywords_list && keywords_list->size) {
        for (size_t i = 0; i < keywords_list->size; i++) {
            pm_node_t *keyword_parameter_node = keywords_list->nodes[i];
            if (((((pm_node_t *)(keyword_parameter_node))->flags & (PM_PARAMETER_FLAGS_REPEATED_PARAMETER)) != 0)) {
                table_size++;
            }
        }
    }
    if (parameters_node && parameters_node->block) {
        const pm_block_parameter_node_t *block_node = (const pm_block_parameter_node_t *) parameters_node->block;
        if (((((pm_node_t *)(block_node))->flags & (PM_PARAMETER_FLAGS_REPEATED_PARAMETER)) != 0) || !block_node->name) {
            table_size++;
        }
    }
    VALUE idtmp = 0;
    rb_ast_id_table_t *local_table_for_iseq = ((sizeof(rb_ast_id_table_t) + table_size * sizeof(ID)) < 1024 ? ((idtmp) = 0, __builtin_alloca (sizeof(rb_ast_id_table_t) + table_size * sizeof(ID))) : rb_alloc_tmp_buffer(&(idtmp), (sizeof(rb_ast_id_table_t) + table_size * sizeof(ID))));
    local_table_for_iseq->size = table_size;
    int local_index = 0;
    if (requireds_list && requireds_list->size) {
        for (size_t i = 0; i < requireds_list->size; i++, local_index++) {
            ID local;
            pm_node_t *required = requireds_list->nodes[i];
            switch (((enum pm_node_type) (required)->type)) {
              case PM_MULTI_TARGET_NODE: {
                local = rb_make_temporary_id(local_index);
                local_table_for_iseq->ids[local_index] = local;
                break;
              }
              case PM_REQUIRED_PARAMETER_NODE: {
                const pm_required_parameter_node_t *param = (const pm_required_parameter_node_t *) required;
                if (((((pm_node_t *)(required))->flags & (PM_PARAMETER_FLAGS_REPEATED_PARAMETER)) != 0)) {
                    ID local = pm_constant_id_lookup(scope_node, param->name);
                    local_table_for_iseq->ids[local_index] = local;
                }
                else {
                    pm_insert_local_index(param->name, local_index, index_lookup_table, local_table_for_iseq, scope_node);
                }
                break;
              }
              default:
                rb_bug("Unsupported node in requireds in parameters %s", pm_node_type_to_str(((enum pm_node_type) (required)->type)));
            }
        }
        body->param.lead_num = (int) requireds_list->size;
        body->param.flags.has_lead = 1;
    }
    if (scope_node->parameters != ((void *)0) && (((enum pm_node_type) (scope_node->parameters)->type) == (PM_IT_PARAMETERS_NODE))) {
        ID local = rb_make_temporary_id(local_index);
        local_table_for_iseq->ids[local_index++] = local;
    }
    if (optionals_list && optionals_list->size) {
        body->param.opt_num = (int) optionals_list->size;
        body->param.flags.has_opt = 1;
        for (size_t i = 0; i < optionals_list->size; i++, local_index++) {
            pm_node_t * node = optionals_list->nodes[i];
            pm_constant_id_t name = ((const pm_optional_parameter_node_t *) node)->name;
            if (((((pm_node_t *)(node))->flags & (PM_PARAMETER_FLAGS_REPEATED_PARAMETER)) != 0)) {
                ID local = pm_constant_id_lookup(scope_node, name);
                local_table_for_iseq->ids[local_index] = local;
            }
            else {
                pm_insert_local_index(name, local_index, index_lookup_table, local_table_for_iseq, scope_node);
            }
        }
    }
    if (parameters_node && parameters_node->rest) {
        body->param.rest_start = local_index;
        if (!((((enum pm_node_type) (parameters_node->rest)->type) == (PM_IMPLICIT_REST_NODE)))) {
            body->param.flags.has_rest = 1;
            ((void)0);
            pm_constant_id_t name = ((const pm_rest_parameter_node_t *) parameters_node->rest)->name;
            if (name) {
                if (((((pm_node_t *)(parameters_node->rest))->flags & (PM_PARAMETER_FLAGS_REPEATED_PARAMETER)) != 0)) {
                    ID local = pm_constant_id_lookup(scope_node, name);
                    local_table_for_iseq->ids[local_index] = local;
                }
                else {
                    pm_insert_local_index(name, local_index, index_lookup_table, local_table_for_iseq, scope_node);
                }
            }
            else {
                body->param.flags.anon_rest = 1;
                pm_insert_local_special(idMULT, local_index, index_lookup_table, local_table_for_iseq);
            }
            local_index++;
        }
    }
    if (posts_list && posts_list->size) {
        body->param.post_num = (int) posts_list->size;
        body->param.post_start = local_index;
        body->param.flags.has_post = 1;
        for (size_t i = 0; i < posts_list->size; i++, local_index++) {
            ID local;
            const pm_node_t *post_node = posts_list->nodes[i];
            switch (((enum pm_node_type) (post_node)->type)) {
              case PM_MULTI_TARGET_NODE: {
                local = rb_make_temporary_id(local_index);
                local_table_for_iseq->ids[local_index] = local;
                break;
              }
              case PM_REQUIRED_PARAMETER_NODE: {
                const pm_required_parameter_node_t *param = (const pm_required_parameter_node_t *) post_node;
                if (((((pm_node_t *)(param))->flags & (PM_PARAMETER_FLAGS_REPEATED_PARAMETER)) != 0)) {
                    ID local = pm_constant_id_lookup(scope_node, param->name);
                    local_table_for_iseq->ids[local_index] = local;
                }
                else {
                    pm_insert_local_index(param->name, local_index, index_lookup_table, local_table_for_iseq, scope_node);
                }
                break;
              }
              default:
                rb_bug("Unsupported node in posts in parameters %s", pm_node_type_to_str(((enum pm_node_type) (post_node)->type)));
            }
        }
    }
    if (keywords_list && keywords_list->size) {
        keyword = ((struct rb_iseq_param_keyword *)ruby_xcalloc((1), sizeof(struct rb_iseq_param_keyword)));
        keyword->num = (int) keywords_list->size;
        const VALUE default_values = rb_ary_hidden_new(1);
        const VALUE complex_mark = rb_str_tmp_new(0);
        for (size_t i = 0; i < keywords_list->size; i++) {
            pm_node_t *keyword_parameter_node = keywords_list->nodes[i];
            pm_constant_id_t name;
            if ((((enum pm_node_type) (keyword_parameter_node)->type) == (PM_REQUIRED_KEYWORD_PARAMETER_NODE))) {
                name = ((const pm_required_keyword_parameter_node_t *) keyword_parameter_node)->name;
                keyword->required_num++;
                ID local = pm_constant_id_lookup(scope_node, name);
                if (((((pm_node_t *)(keyword_parameter_node))->flags & (PM_PARAMETER_FLAGS_REPEATED_PARAMETER)) != 0)) {
                    local_table_for_iseq->ids[local_index] = local;
                }
                else {
                    pm_insert_local_index(name, local_index, index_lookup_table, local_table_for_iseq, scope_node);
                }
                local_index++;
            }
        }
        for (size_t i = 0; i < keywords_list->size; i++) {
            pm_node_t *keyword_parameter_node = keywords_list->nodes[i];
            pm_constant_id_t name;
            if ((((enum pm_node_type) (keyword_parameter_node)->type) == (PM_OPTIONAL_KEYWORD_PARAMETER_NODE))) {
                const pm_optional_keyword_parameter_node_t *cast = ((const pm_optional_keyword_parameter_node_t *) keyword_parameter_node);
                pm_node_t *value = cast->value;
                name = cast->name;
                if (((((pm_node_t *)(value))->flags & (PM_NODE_FLAG_STATIC_LITERAL)) != 0) && !((((enum pm_node_type) (value)->type) == (PM_ARRAY_NODE)) || (((enum pm_node_type) (value)->type) == (PM_HASH_NODE)) || (((enum pm_node_type) (value)->type) == (PM_RANGE_NODE)))) {
                    rb_ary_push(default_values, pm_static_literal_value(iseq, value, scope_node));
                }
                else {
                    rb_ary_push(default_values, complex_mark);
                }
                ID local = pm_constant_id_lookup(scope_node, name);
                if (((((pm_node_t *)(keyword_parameter_node))->flags & (PM_PARAMETER_FLAGS_REPEATED_PARAMETER)) != 0)) {
                    local_table_for_iseq->ids[local_index] = local;
                }
                else {
                    pm_insert_local_index(name, local_index, index_lookup_table, local_table_for_iseq, scope_node);
                }
                local_index++;
            }
        }
        if (rb_array_len(default_values)) {
            VALUE *dvs = ((VALUE *)ruby_xmalloc2((rb_array_len(default_values)), sizeof(VALUE)));
            for (int i = 0; i < rb_array_len(default_values); i++) {
                VALUE dv = RARRAY_AREF(default_values, i);
                if (dv == complex_mark) dv = ((VALUE)RUBY_Qundef);
                (rb_obj_write((VALUE)(iseq), (VALUE *)(&dvs[i]), (VALUE)(dv), "prism_compile.c", 6123));
            }
            keyword->default_values = dvs;
        }
        keyword->bits_start = local_index;
        ID local = rb_make_temporary_id(local_index);
        local_table_for_iseq->ids[local_index] = local;
        local_index++;
        body->param.keyword = keyword;
        body->param.flags.has_kw = 1;
    }
    if (body->type == ISEQ_TYPE_BLOCK && local_index == 1 && requireds_list && requireds_list->size == 1 && !trailing_comma) {
        body->param.flags.ambiguous_param0 = 1;
    }
    if (parameters_node) {
        if (parameters_node->keyword_rest) {
            switch (((enum pm_node_type) (parameters_node->keyword_rest)->type)) {
              case PM_NO_KEYWORDS_PARAMETER_NODE: {
                body->param.flags.accepts_no_kwarg = 1;
                break;
              }
              case PM_KEYWORD_REST_PARAMETER_NODE: {
                const pm_keyword_rest_parameter_node_t *kw_rest_node = (const pm_keyword_rest_parameter_node_t *) parameters_node->keyword_rest;
                if (!body->param.flags.has_kw) {
                    body->param.keyword = keyword = ((struct rb_iseq_param_keyword *)ruby_xcalloc((1), sizeof(struct rb_iseq_param_keyword)));
                }
                keyword->rest_start = local_index;
                body->param.flags.has_kwrest = 1;
                pm_constant_id_t constant_id = kw_rest_node->name;
                if (constant_id) {
                    if (((((pm_node_t *)(kw_rest_node))->flags & (PM_PARAMETER_FLAGS_REPEATED_PARAMETER)) != 0)) {
                        ID local = pm_constant_id_lookup(scope_node, constant_id);
                        local_table_for_iseq->ids[local_index] = local;
                    }
                    else {
                        pm_insert_local_index(constant_id, local_index, index_lookup_table, local_table_for_iseq, scope_node);
                    }
                }
                else {
                    body->param.flags.anon_kwrest = 1;
                    pm_insert_local_special(idPow, local_index, index_lookup_table, local_table_for_iseq);
                }
                local_index++;
                break;
              }
              case PM_FORWARDING_PARAMETER_NODE: {
                if (!((iseq)->body)->param.flags.forwardable) {
                    body->param.rest_start = local_index;
                    body->param.flags.has_rest = 1;
                    body->param.flags.anon_rest = 1;
                    pm_insert_local_special(idMULT, local_index++, index_lookup_table, local_table_for_iseq);
                    ((void)0);
                    body->param.flags.has_kw = 0;
                    body->param.flags.has_kwrest = 1;
                    body->param.flags.anon_kwrest = 1;
                    body->param.keyword = keyword = ((struct rb_iseq_param_keyword *)ruby_xcalloc((1), sizeof(struct rb_iseq_param_keyword)));
                    keyword->rest_start = local_index;
                    pm_insert_local_special(idPow, local_index++, index_lookup_table, local_table_for_iseq);
                    body->param.block_start = local_index;
                    body->param.flags.has_block = 1;
                    pm_insert_local_special(idAnd, local_index++, index_lookup_table, local_table_for_iseq);
                }
                pm_insert_local_special(idDot3, local_index++, index_lookup_table, local_table_for_iseq);
                break;
              }
              default:
                rb_bug("node type %s not expected as keyword_rest", pm_node_type_to_str(((enum pm_node_type) (parameters_node->keyword_rest)->type)));
            }
        }
        if (parameters_node->block) {
            body->param.block_start = local_index;
            body->param.flags.has_block = 1;
            iseq_set_use_block(iseq);
            pm_constant_id_t name = ((const pm_block_parameter_node_t *) parameters_node->block)->name;
            if (name) {
                if (((((pm_node_t *)(parameters_node->block))->flags & (PM_PARAMETER_FLAGS_REPEATED_PARAMETER)) != 0)) {
                    ID local = pm_constant_id_lookup(scope_node, name);
                    local_table_for_iseq->ids[local_index] = local;
                }
                else {
                    pm_insert_local_index(name, local_index, index_lookup_table, local_table_for_iseq, scope_node);
                }
            }
            else {
                pm_insert_local_special(idAnd, local_index, index_lookup_table, local_table_for_iseq);
            }
            local_index++;
        }
    }
    if (requireds_list && requireds_list->size) {
        for (size_t i = 0; i < requireds_list->size; i++) {
            const pm_node_t *required = requireds_list->nodes[i];
            if ((((enum pm_node_type) (required)->type) == (PM_MULTI_TARGET_NODE))) {
                local_index = pm_compile_destructured_param_locals((const pm_multi_target_node_t *) required, index_lookup_table, local_table_for_iseq, scope_node, local_index);
            }
        }
    }
    if (posts_list && posts_list->size) {
        for (size_t i = 0; i < posts_list->size; i++) {
            const pm_node_t *post = posts_list->nodes[i];
            if ((((enum pm_node_type) (post)->type) == (PM_MULTI_TARGET_NODE))) {
                local_index = pm_compile_destructured_param_locals((const pm_multi_target_node_t *) post, index_lookup_table, local_table_for_iseq, scope_node, local_index);
            }
        }
    }
    if ((((enum pm_node_type) (scope_node->ast_node)->type) == (PM_FOR_NODE))) {
        if ((((enum pm_node_type) (((const pm_for_node_t *) scope_node->ast_node)->index)->type) == (PM_LOCAL_VARIABLE_TARGET_NODE))) {
            body->param.lead_num++;
        }
        else {
            body->param.rest_start = local_index;
            body->param.flags.has_rest = 1;
        }
        ID local = rb_make_temporary_id(local_index);
        local_table_for_iseq->ids[local_index] = local;
        local_index++;
    }
    if (scope_node->parameters && (((enum pm_node_type) (scope_node->parameters)->type) == (PM_NUMBERED_PARAMETERS_NODE))) {
        int maximum = ((const pm_numbered_parameters_node_t *) scope_node->parameters)->maximum;
        ((void)0);
        for (int i = 0; i < maximum; i++, local_index++) {
            const uint8_t param_name[] = { '_', '1' + i };
            pm_constant_id_t constant_id = pm_constant_pool_find(&scope_node->parser->constant_pool, param_name, 2);
            ((void)0);
            pm_insert_local_index(constant_id, local_index, index_lookup_table, local_table_for_iseq, scope_node);
        }
        body->param.lead_num = maximum;
        body->param.flags.has_lead = 1;
    }
    if (block_locals && block_locals->size) {
        for (size_t i = 0; i < block_locals->size; i++, local_index++) {
            pm_constant_id_t constant_id = ((const pm_block_local_variable_node_t *) block_locals->nodes[i])->name;
            pm_insert_local_index(constant_id, local_index, index_lookup_table, local_table_for_iseq, scope_node);
        }
    }
    if (scope_node->locals.size) {
        for (size_t i = 0; i < scope_node->locals.size; i++) {
            pm_constant_id_t constant_id = locals->ids[i];
            if (constant_id) {
                struct pm_local_table_insert_ctx ctx;
                ctx.scope_node = scope_node;
                ctx.local_table_for_iseq = local_table_for_iseq;
                ctx.local_index = local_index;
                rb_st_update(index_lookup_table, (st_data_t)constant_id, pm_local_table_insert_func, (st_data_t)&ctx);
                local_index = ctx.local_index;
            }
        }
    }
    if (scope_node->index_lookup_table) {
        rb_st_free_table(scope_node->index_lookup_table);
    }
    scope_node->index_lookup_table = index_lookup_table;
    iseq_calc_param_size(iseq);
    if (((iseq)->body)->param.flags.forwardable) {
        ((iseq)->body)->param.size += 1;
    }
    iseq_set_local_table(iseq, local_table_for_iseq, 0);
    scope_node->local_table_for_iseq_size = local_table_for_iseq->size;
    if (keyword != ((void *)0)) {
        size_t keyword_start_index = keyword->bits_start - keyword->num;
        keyword->table = (ID *)&((iseq)->body)->local_table[keyword_start_index];
    }
    if (optionals_list && optionals_list->size) {
        LABEL **opt_table = (LABEL **) ((VALUE *)ruby_xmalloc2((optionals_list->size + 1), sizeof(VALUE)));
        LABEL *label;
        for (size_t i = 0; i < optionals_list->size; i++) {
            label = new_label_body(iseq, (location.line));
            opt_table[i] = label;
            ADD_ELEM((ret), (LINK_ELEMENT *) (label));
            pm_node_t *optional_node = optionals_list->nodes[i];
            pm_compile_node(iseq, (optional_node), ret, 0, scope_node);
        }
        label = new_label_body(iseq, (location.line));
        opt_table[optionals_list->size] = label;
        ADD_ELEM((ret), (LINK_ELEMENT *) (label));
        body->param.opt_table = (const VALUE *) opt_table;
    }
    if (keywords_list && keywords_list->size) {
        size_t optional_index = 0;
        for (size_t i = 0; i < keywords_list->size; i++) {
            pm_node_t *keyword_parameter_node = keywords_list->nodes[i];
            pm_constant_id_t name;
            switch (((enum pm_node_type) (keyword_parameter_node)->type)) {
              case PM_OPTIONAL_KEYWORD_PARAMETER_NODE: {
                const pm_optional_keyword_parameter_node_t *cast = ((const pm_optional_keyword_parameter_node_t *) keyword_parameter_node);
                pm_node_t *value = cast->value;
                name = cast->name;
                if (!((((pm_node_t *)(value))->flags & (PM_NODE_FLAG_STATIC_LITERAL)) != 0) || ((((enum pm_node_type) (value)->type) == (PM_ARRAY_NODE)) || (((enum pm_node_type) (value)->type) == (PM_HASH_NODE)) || (((enum pm_node_type) (value)->type) == (PM_RANGE_NODE)))) {
                    LABEL *end_label = new_label_body(iseq, (location.line));
                    pm_local_index_t index = pm_lookup_local_index(iseq, scope_node, name, 0);
                    int kw_bits_idx = table_size - body->param.keyword->bits_start;
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_checkkeyword, 2, (VALUE)(__builtin_choose_expr( __builtin_constant_p(kw_bits_idx + ( 3) - 1), ((VALUE)(kw_bits_idx + ( 3) - 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(kw_bits_idx + ( 3) - 1))), (VALUE)(__builtin_choose_expr( __builtin_constant_p(optional_index), ((VALUE)(optional_index)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(optional_index)))));
                    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchif, 1, (VALUE)(end_label))), ((end_label)->refcnt++));
                    pm_compile_node(iseq, (value), ret, popped, scope_node);
                    pm_iseq_add_setlocal(iseq, (ret), (int) (location).line, (int) (location).node_id, (index.index), (index.level));
                    ADD_ELEM((ret), (LINK_ELEMENT *) (end_label));
                }
                optional_index++;
                break;
              }
              case PM_REQUIRED_KEYWORD_PARAMETER_NODE:
                break;
              default:
                rb_bug("Unexpected keyword parameter node type %s", pm_node_type_to_str(((enum pm_node_type) (keyword_parameter_node)->type)));
            }
        }
    }
    if (requireds_list && requireds_list->size) {
        for (size_t i = 0; i < requireds_list->size; i++) {
            const pm_node_t *required = requireds_list->nodes[i];
            if ((((enum pm_node_type) (required)->type) == (PM_MULTI_TARGET_NODE))) {
                pm_iseq_add_getlocal(iseq, (ret), (int) (location).line, (int) (location).node_id, (table_size - (int)i), (0));
                pm_compile_destructured_param_writes(iseq, (const pm_multi_target_node_t *) required, ret, scope_node);
            }
        }
    }
    if (posts_list && posts_list->size) {
        for (size_t i = 0; i < posts_list->size; i++) {
            const pm_node_t *post = posts_list->nodes[i];
            if ((((enum pm_node_type) (post)->type) == (PM_MULTI_TARGET_NODE))) {
                pm_iseq_add_getlocal(iseq, (ret), (int) (location).line, (int) (location).node_id, (table_size - body->param.post_start - (int) i), (0));
                pm_compile_destructured_param_writes(iseq, (const pm_multi_target_node_t *) post, ret, scope_node);
            }
        }
    }
    switch (body->type) {
      case ISEQ_TYPE_PLAIN: {
        ((void)0);
        const pm_interpolated_regular_expression_node_t *cast = (const pm_interpolated_regular_expression_node_t *) scope_node->ast_node;
        pm_compile_regexp_dynamic(iseq, (const pm_node_t *) cast, &cast->parts, &location, ret, popped, scope_node);
        break;
      }
      case ISEQ_TYPE_BLOCK: {
        LABEL *start = ISEQ_COMPILE_DATA(iseq)->start_label = new_label_body(iseq, (0));
        LABEL *end = ISEQ_COMPILE_DATA(iseq)->end_label = new_label_body(iseq, (0));
        const pm_node_location_t block_location = { .line = body->location.first_lineno, .node_id = -1 };
        start->rescued = LABEL_RESCUE_BEG;
        end->rescued = LABEL_RESCUE_END;
        if ((((enum pm_node_type) (scope_node->ast_node)->type) == (PM_FOR_NODE))) {
            pm_compile_for_node_index(iseq, ((const pm_for_node_t *) scope_node->ast_node)->index, ret, scope_node);
        }
        ADD_ELEM((ret), (LINK_ELEMENT *) new_trace_body(iseq, (0x0100), 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (block_location).line, (int) (block_location).node_id, YARVINSN_nop, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) (start));
        if (scope_node->body != ((void *)0)) {
            switch (((enum pm_node_type) (scope_node->ast_node)->type)) {
              case PM_POST_EXECUTION_NODE: {
                const pm_post_execution_node_t *cast = (const pm_post_execution_node_t *) scope_node->ast_node;
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (block_location).line, (int) (block_location).node_id, YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
                pm_scope_node_t next_scope_node;
                pm_scope_node_init((const pm_node_t *) cast->statements, &next_scope_node, scope_node);
                const rb_iseq_t *block = pm_new_child_iseq(iseq, (&next_scope_node), rb_fstring(make_name_for_block(body->parent_iseq)), iseq, (ISEQ_TYPE_BLOCK), (location.line));
                pm_scope_node_destroy(&next_scope_node);
                ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (block_location).line, (int) (block_location).node_id, ((id_core_set_postexe)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))), ((block)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p((0x01 << VM_CALL_FCALL_bit)), ((VALUE)((0x01 << VM_CALL_FCALL_bit))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((0x01 << VM_CALL_FCALL_bit)))), (((void *)0))));
                break;
              }
              case PM_INTERPOLATED_REGULAR_EXPRESSION_NODE: {
                const pm_interpolated_regular_expression_node_t *cast = (const pm_interpolated_regular_expression_node_t *) scope_node->ast_node;
                pm_compile_regexp_dynamic(iseq, (const pm_node_t *) cast, &cast->parts, &location, ret, popped, scope_node);
                break;
              }
              default:
                pm_compile_node(iseq, scope_node->body, ret, popped, scope_node);
                break;
            }
        }
        else {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (block_location).line, (int) (block_location).node_id, YARVINSN_putnil, 0));
        }
        ADD_ELEM((ret), (LINK_ELEMENT *) (end));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_trace_body(iseq, (0x0200), 0));
        ISEQ_COMPILE_DATA(iseq)->last_line = body->location.code_location.end_pos.lineno;
        do { VALUE _e = __extension__ ({ const VALUE args_to_new_ary[] = {((CATCH_TYPE_REDO)), (VALUE)((start)) | 1, (VALUE)((end)) | 1, (VALUE)((((void *)0))), (VALUE)((start)) | 1}; if (__builtin_constant_p(5)) { __extension__ _Static_assert(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))) == (5), "rb_ary_new_from_args" ": " "numberof(args_to_new_ary) == (5)"); } rb_ary_new_from_values(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))), args_to_new_ary); }); (((start)) ? ((((start))->refcnt++), ((start))->unremovable=1) : 0); (((end))->refcnt++); (((start))->refcnt++); if (RB_NIL_P(ISEQ_COMPILE_DATA(iseq)->catch_table_ary)) (rb_obj_write((VALUE)(iseq), (VALUE *)(&ISEQ_COMPILE_DATA(iseq)->catch_table_ary), (VALUE)(rb_ary_hidden_new(3)), "prism_compile.c", 6525)); rb_ary_push(ISEQ_COMPILE_DATA(iseq)->catch_table_ary, freeze_hide_obj(_e)); } while (0);
        do { VALUE _e = __extension__ ({ const VALUE args_to_new_ary[] = {((CATCH_TYPE_NEXT)), (VALUE)((start)) | 1, (VALUE)((end)) | 1, (VALUE)((((void *)0))), (VALUE)((end)) | 1}; if (__builtin_constant_p(5)) { __extension__ _Static_assert(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))) == (5), "rb_ary_new_from_args" ": " "numberof(args_to_new_ary) == (5)"); } rb_ary_new_from_values(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))), args_to_new_ary); }); (((start)) ? ((((start))->refcnt++), ((start))->unremovable=1) : 0); (((end))->refcnt++); (((end))->refcnt++); if (RB_NIL_P(ISEQ_COMPILE_DATA(iseq)->catch_table_ary)) (rb_obj_write((VALUE)(iseq), (VALUE *)(&ISEQ_COMPILE_DATA(iseq)->catch_table_ary), (VALUE)(rb_ary_hidden_new(3)), "prism_compile.c", 6526)); rb_ary_push(ISEQ_COMPILE_DATA(iseq)->catch_table_ary, freeze_hide_obj(_e)); } while (0);
        break;
      }
      case ISEQ_TYPE_ENSURE: {
        const pm_node_location_t statements_location = (scope_node->body != ((void *)0) ? ((pm_node_location_t) { .line = pm_newline_list_line(&(scope_node->parser)->newline_list, ((const pm_node_t *) (scope_node->body))->location.start, (scope_node->parser)->start_line), .node_id = ((const pm_node_t *) (scope_node->body))->node_id }) : location);
        iseq_set_exception_local_table(iseq);
        if (scope_node->body != ((void *)0)) {
            pm_compile_node(iseq, ((const pm_node_t *) scope_node->body), ret, 1, scope_node);
        }
        pm_iseq_add_getlocal(iseq, (ret), (int) (statements_location).line, (int) (statements_location).node_id, (1), (0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (statements_location).line, (int) (statements_location).node_id, YARVINSN_throw, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))));
        return;
      }
      case ISEQ_TYPE_METHOD: {
        ISEQ_COMPILE_DATA(iseq)->root_node = (const void *) scope_node->body;
        ADD_ELEM((ret), (LINK_ELEMENT *) new_trace_body(iseq, (0x0008), 0));
        if (scope_node->body) {
            pm_compile_node(iseq, ((const pm_node_t *) scope_node->body), ret, popped, scope_node);
        }
        else {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
        }
        ISEQ_COMPILE_DATA(iseq)->root_node = (const void *) scope_node->body;
        ADD_ELEM((ret), (LINK_ELEMENT *) new_trace_body(iseq, (0x0010), 0));
        ISEQ_COMPILE_DATA(iseq)->last_line = body->location.code_location.end_pos.lineno;
        break;
      }
      case ISEQ_TYPE_RESCUE: {
        iseq_set_exception_local_table(iseq);
        if ((((enum pm_node_type) (scope_node->ast_node)->type) == (PM_RESCUE_MODIFIER_NODE))) {
            LABEL *lab = new_label_body(iseq, (location.line));
            LABEL *rescue_end = new_label_body(iseq, (location.line));
            pm_iseq_add_getlocal(iseq, (ret), (int) (location).line, (int) (location).node_id, ((1)), (0));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(rb_eStandardError)));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_checkmatch, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_CHECKMATCH_TYPE_RESCUE), ((VALUE)(VM_CHECKMATCH_TYPE_RESCUE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_CHECKMATCH_TYPE_RESCUE)))));
            (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchif, 1, (VALUE)(lab))), ((lab)->refcnt++));
            (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_jump, 1, (VALUE)(rescue_end))), ((rescue_end)->refcnt++));
            ADD_ELEM((ret), (LINK_ELEMENT *) (lab));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_trace_body(iseq, (0x4000), 0));
            pm_compile_node(iseq, ((const pm_node_t *) scope_node->body), ret, popped, scope_node);
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_leave, 0));
            ADD_ELEM((ret), (LINK_ELEMENT *) (rescue_end));
            pm_iseq_add_getlocal(iseq, (ret), (int) (location).line, (int) (location).node_id, ((1)), (0));
        }
        else {
            pm_compile_node(iseq, ((const pm_node_t *) scope_node->ast_node), ret, popped, scope_node);
        }
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_throw, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))));
        return;
      }
      default:
        if (scope_node->body) {
            pm_compile_node(iseq, ((const pm_node_t *) scope_node->body), ret, popped, scope_node);
        }
        else {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
        }
        break;
    }
    if ((((enum pm_node_type) (scope_node->ast_node)->type) == (PM_CLASS_NODE)) || (((enum pm_node_type) (scope_node->ast_node)->type) == (PM_MODULE_NODE))) {
        const pm_node_location_t end_location = ((pm_node_location_t) { .line = pm_newline_list_line(&(scope_node->parser)->newline_list, ((const pm_node_t *) (scope_node->ast_node))->location.end, (scope_node->parser)->start_line), .node_id = ((const pm_node_t *) (scope_node->ast_node))->node_id });
        ADD_ELEM((ret), (LINK_ELEMENT *) new_trace_body(iseq, (0x0004), 0));
        ISEQ_COMPILE_DATA(iseq)->last_line = end_location.line;
    }
    if (!(((enum pm_node_type) (scope_node->ast_node)->type) == (PM_ENSURE_NODE))) {
        const pm_node_location_t location = { .line = ISEQ_COMPILE_DATA(iseq)->last_line, .node_id = -1 };
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_leave, 0));
    }
}
static inline void
pm_compile_alias_global_variable_node(rb_iseq_t *iseq, const pm_alias_global_variable_node_t *node, const pm_node_location_t *location, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node)
{
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
    {
        const pm_location_t *name_loc = &node->new_name->location;
        VALUE operand = rb_id2sym(rb_intern3((const char *) name_loc->start, name_loc->end - name_loc->start, scope_node->encoding));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putobject, 1, (VALUE)(operand)));
    }
    {
        const pm_location_t *name_loc = &node->old_name->location;
        VALUE operand = rb_id2sym(rb_intern3((const char *) name_loc->start, name_loc->end - name_loc->start, scope_node->encoding));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putobject, 1, (VALUE)(operand)));
    }
    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (*location).line, (int) (*location).node_id, ((id_core_set_variable_alias)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
    if (popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_pop, 0));
}
static inline void
pm_compile_alias_method_node(rb_iseq_t *iseq, const pm_alias_method_node_t *node, const pm_node_location_t *location, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node)
{
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_CBASE), ((VALUE)(VM_SPECIAL_OBJECT_CBASE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_CBASE)))));
    pm_compile_node(iseq, (node->new_name), ret, 0, scope_node);
    pm_compile_node(iseq, (node->old_name), ret, 0, scope_node);
    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (*location).line, (int) (*location).node_id, ((id_core_set_method_alias)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
    if (popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_pop, 0));
}
static inline void
pm_compile_and_node(rb_iseq_t *iseq, const pm_and_node_t *node, const pm_node_location_t *location, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node)
{
    LABEL *end_label = new_label_body(iseq, (location->line));
    pm_compile_node(iseq, (node->left), ret, 0, scope_node);
    if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_dup, 0));
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_branchunless, 1, (VALUE)(end_label))), ((end_label)->refcnt++));
    if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_pop, 0));
    pm_compile_node(iseq, (node->right), ret, popped, scope_node);
    ADD_ELEM((ret), (LINK_ELEMENT *) (end_label));
}
static inline void
pm_compile_array_node(rb_iseq_t *iseq, const pm_node_t *node, const pm_node_list_t *elements, const pm_node_location_t *location, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node)
{
    if (((((pm_node_t *)(node))->flags & (PM_NODE_FLAG_STATIC_LITERAL)) != 0)) {
        if (!popped) {
            if (elements->size) {
                VALUE value = pm_static_literal_value(iseq, node, scope_node);
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_duparray, 1, (VALUE)(value)));
            }
            else {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_newarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))));
            }
        }
        return;
    }
    const int max_new_array_size = 0x100;
    const unsigned int min_tmp_array_size = 0x40;
    int new_array_size = 0;
    _Bool first_chunk = 1;
    _Bool static_literal = 0;
    for (size_t index = 0; index < elements->size; index++) {
        const pm_node_t *element = elements->nodes[index];
        if ((((enum pm_node_type) (element)->type) == (PM_SPLAT_NODE))) {
            if (new_array_size) { if (first_chunk) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_newarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(new_array_size), ((VALUE)(new_array_size)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(new_array_size))))); else ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_pushtoarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(new_array_size), ((VALUE)(new_array_size)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(new_array_size))))); first_chunk = 0; new_array_size = 0; };
            const pm_splat_node_t *splat_element = (const pm_splat_node_t *) element;
            if (splat_element->expression) {
                pm_compile_node(iseq, (splat_element->expression), ret, 0, scope_node);
            }
            else {
                pm_local_index_t index = pm_lookup_local_index(iseq, scope_node, ((pm_constant_id_t)(idMULT | ((pm_constant_id_t)(1 << 31)))), 0);
                pm_iseq_add_getlocal(iseq, (ret), (int) (*location).line, (int) (*location).node_id, (index.index), (index.level));
            }
            if (first_chunk) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_splatarray, 1, (VALUE)(((VALUE)RUBY_Qtrue))));
                first_chunk = 0;
            }
            else {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_concattoarray, 0));
            }
            static_literal = 0;
        }
        else if ((((enum pm_node_type) (element)->type) == (PM_KEYWORD_HASH_NODE))) {
            if (new_array_size == 0 && first_chunk) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_newarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))));
                first_chunk = 0;
            }
            else {
                if (new_array_size) { if (first_chunk) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_newarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(new_array_size), ((VALUE)(new_array_size)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(new_array_size))))); else ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_pushtoarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(new_array_size), ((VALUE)(new_array_size)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(new_array_size))))); first_chunk = 0; new_array_size = 0; };
            }
            const pm_keyword_hash_node_t *keyword_hash = (const pm_keyword_hash_node_t *) element;
            pm_compile_hash_elements(iseq, element, &keyword_hash->elements, 0, ret, scope_node);
            size_t splats = 0;
            while (splats < keyword_hash->elements.size && (((enum pm_node_type) (keyword_hash->elements.nodes[splats])->type) == (PM_ASSOC_SPLAT_NODE))) splats++;
            if (keyword_hash->elements.size == splats) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_pushtoarraykwsplat, 0));
            }
            else {
                new_array_size++;
            }
        }
        else if (
            ((((pm_node_t *)(element))->flags & (PM_NODE_FLAG_STATIC_LITERAL)) != 0) &&
            !((((enum pm_node_type) (element)->type) == (PM_ARRAY_NODE)) || (((enum pm_node_type) (element)->type) == (PM_HASH_NODE)) || (((enum pm_node_type) (element)->type) == (PM_RANGE_NODE))) &&
            !static_literal &&
            ((index + min_tmp_array_size) < elements->size)
        ) {
            size_t right_index = index + 1;
            while (
                right_index < elements->size &&
                ((((pm_node_t *)(elements->nodes[right_index]))->flags & (PM_NODE_FLAG_STATIC_LITERAL)) != 0) &&
                !((((enum pm_node_type) (elements->nodes[right_index])->type) == (PM_ARRAY_NODE)) || (((enum pm_node_type) (elements->nodes[right_index])->type) == (PM_HASH_NODE)) || (((enum pm_node_type) (elements->nodes[right_index])->type) == (PM_RANGE_NODE)))
            ) right_index++;
            size_t tmp_array_size = right_index - index;
            if (tmp_array_size >= min_tmp_array_size) {
                VALUE tmp_array = rb_ary_hidden_new(tmp_array_size);
                for (; tmp_array_size; tmp_array_size--)
                    rb_ary_push(tmp_array, pm_static_literal_value(iseq, elements->nodes[index++], scope_node));
                index--;
                rb_obj_freeze_inline(tmp_array);
                if (new_array_size) { if (first_chunk) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_newarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(new_array_size), ((VALUE)(new_array_size)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(new_array_size))))); else ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_pushtoarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(new_array_size), ((VALUE)(new_array_size)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(new_array_size))))); first_chunk = 0; new_array_size = 0; };
                if (first_chunk) {
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_duparray, 1, (VALUE)(tmp_array)));
                    first_chunk = 0;
                }
                else {
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putobject, 1, (VALUE)(tmp_array)));
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_concattoarray, 0));
                }
            }
            else {
                pm_compile_node(iseq, (element), ret, 0, scope_node);
                if (++new_array_size >= max_new_array_size) if (new_array_size) { if (first_chunk) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_newarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(new_array_size), ((VALUE)(new_array_size)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(new_array_size))))); else ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_pushtoarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(new_array_size), ((VALUE)(new_array_size)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(new_array_size))))); first_chunk = 0; new_array_size = 0; };
                static_literal = 1;
            }
        } else {
            pm_compile_node(iseq, (element), ret, 0, scope_node);
            if (++new_array_size >= max_new_array_size) if (new_array_size) { if (first_chunk) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_newarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(new_array_size), ((VALUE)(new_array_size)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(new_array_size))))); else ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_pushtoarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(new_array_size), ((VALUE)(new_array_size)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(new_array_size))))); first_chunk = 0; new_array_size = 0; };
            static_literal = 0;
        }
    }
    if (new_array_size) { if (first_chunk) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_newarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(new_array_size), ((VALUE)(new_array_size)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(new_array_size))))); else ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_pushtoarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(new_array_size), ((VALUE)(new_array_size)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(new_array_size))))); first_chunk = 0; new_array_size = 0; };
    if (popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_pop, 0));
}
static inline void
pm_compile_break_node(rb_iseq_t *iseq, const pm_break_node_t *node, const pm_node_location_t *location, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node)
{
    unsigned long throw_flag = 0;
    if (ISEQ_COMPILE_DATA(iseq)->redo_label != 0 && can_add_ensure_iseq(iseq)) {
        LABEL *splabel = new_label_body(iseq, (0));
        ADD_ELEM((ret), (LINK_ELEMENT *) (splabel));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_adjust_body(iseq, (ISEQ_COMPILE_DATA(iseq)->redo_label), (int) (*location).line));
        if (node->arguments != ((void *)0)) {
            pm_compile_node(iseq, ((const pm_node_t *) node->arguments), ret, 0, scope_node);
        }
        else {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putnil, 0));
        }
        pm_add_ensure_iseq(ret, iseq, 0, scope_node);
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_jump, 1, (VALUE)(ISEQ_COMPILE_DATA(iseq)->end_label))), ((ISEQ_COMPILE_DATA(iseq)->end_label)->refcnt++));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_adjust_body(iseq, (splabel), -1));
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putnil, 0));
    }
    else {
        const rb_iseq_t *ip = iseq;
        while (ip) {
            if (!ISEQ_COMPILE_DATA(ip)) {
                ip = 0;
                break;
            }
            if (ISEQ_COMPILE_DATA(ip)->redo_label != 0) {
                throw_flag = VM_THROW_NO_ESCAPE_FLAG;
            }
            else if (((ip)->body)->type == ISEQ_TYPE_BLOCK) {
                throw_flag = 0;
            }
            else if (((ip)->body)->type == ISEQ_TYPE_EVAL) {
                append_compile_error(iseq, location->line, "Invalid break");
                return;
            }
            else {
                ip = ((ip)->body)->parent_iseq;
                continue;
            }
            if (node->arguments != ((void *)0)) {
                pm_compile_node(iseq, ((const pm_node_t *) node->arguments), ret, 0, scope_node);
            }
            else {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putnil, 0));
            }
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_throw, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(throw_flag | RUBY_TAG_BREAK), ((VALUE)(throw_flag | RUBY_TAG_BREAK)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(throw_flag | RUBY_TAG_BREAK)))));
            if (popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_pop, 0));
            return;
        }
        append_compile_error(iseq, location->line, "Invalid break");
    }
}
static inline void
pm_compile_call_node(rb_iseq_t *iseq, const pm_call_node_t *node, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node)
{
    ID method_id = pm_constant_id_lookup(scope_node, node->name);
    const pm_location_t *message_loc = &node->message_loc;
    if (message_loc->start == ((void *)0)) message_loc = &node->base.location;
    const pm_node_location_t location = ((pm_node_location_t) { .line = pm_newline_list_line(&(scope_node->parser)->newline_list, (message_loc)->start, (scope_node->parser)->start_line), .node_id = node->base.node_id });
    const char *builtin_func;
    if ((__builtin_expect(!!(iseq_has_builtin_function_table(iseq)), 0)) && (builtin_func = pm_iseq_builtin_function_name(scope_node, node->receiver, method_id)) != ((void *)0)) {
        pm_compile_builtin_function_call(iseq, ret, scope_node, node, &location, popped, ISEQ_COMPILE_DATA(iseq)->current_block, builtin_func);
        return;
    }
    LABEL *start = new_label_body(iseq, (location.line));
    if (node->block) ADD_ELEM((ret), (LINK_ELEMENT *) (start));
    switch (method_id) {
      case idUMinus: {
        if (pm_opt_str_freeze_p(iseq, node)) {
            VALUE value = parse_static_literal_string(iseq, scope_node, node->receiver, &((const pm_string_node_t * ) node->receiver)->unescaped);
            const struct rb_callinfo *callinfo = new_callinfo(iseq, idUMinus, 0, 0, ((void *)0), 0);
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_opt_str_uminus, 2, (VALUE)(value), (VALUE)(callinfo)));
            return;
        }
        break;
      }
      case idFreeze: {
        if (pm_opt_str_freeze_p(iseq, node)) {
            VALUE value = parse_static_literal_string(iseq, scope_node, node->receiver, &((const pm_string_node_t * ) node->receiver)->unescaped);
            const struct rb_callinfo *callinfo = new_callinfo(iseq, idFreeze, 0, 0, ((void *)0), 0);
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_opt_str_freeze, 2, (VALUE)(value), (VALUE)(callinfo)));
            return;
        }
        break;
      }
      case idAREF: {
        if (pm_opt_aref_with_p(iseq, node)) {
            const pm_string_node_t *string = (const pm_string_node_t *) ((const pm_arguments_node_t *) node->arguments)->arguments.nodes[0];
            VALUE value = parse_static_literal_string(iseq, scope_node, (const pm_node_t *) string, &string->unescaped);
            pm_compile_node(iseq, (node->receiver), ret, 0, scope_node);
            const struct rb_callinfo *callinfo = new_callinfo(iseq, idAREF, 1, 0, ((void *)0), 0);
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_opt_aref_with, 2, (VALUE)(value), (VALUE)(callinfo)));
            if (popped) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
            }
            return;
        }
        break;
      }
      case idASET: {
        if (pm_opt_aset_with_p(iseq, node)) {
            const pm_string_node_t *string = (const pm_string_node_t *) ((const pm_arguments_node_t *) node->arguments)->arguments.nodes[0];
            VALUE value = parse_static_literal_string(iseq, scope_node, (const pm_node_t *) string, &string->unescaped);
            pm_compile_node(iseq, (node->receiver), ret, 0, scope_node);
            pm_compile_node(iseq, (((const pm_arguments_node_t *) node->arguments)->arguments.nodes[1]), ret, 0, scope_node);
            if (!popped) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_swap, 0));
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
            }
            const struct rb_callinfo *callinfo = new_callinfo(iseq, idASET, 2, 0, ((void *)0), 0);
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_opt_aset_with, 2, (VALUE)(value), (VALUE)(callinfo)));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
            return;
        }
        break;
      }
    }
    if (((((pm_node_t *)(node))->flags & (PM_CALL_NODE_FLAGS_ATTRIBUTE_WRITE)) != 0) && !popped) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
    }
    if (node->receiver == ((void *)0)) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putself, 0));
    }
    else {
        if (method_id == idCall && (((enum pm_node_type) (node->receiver)->type) == (PM_LOCAL_VARIABLE_READ_NODE))) {
            const pm_local_variable_read_node_t *read_node_cast = (const pm_local_variable_read_node_t *) node->receiver;
            uint32_t node_id = node->receiver->node_id;
            int idx, level;
            if (iseq_block_param_id_p(iseq, pm_constant_id_lookup(scope_node, read_node_cast->name), &idx, &level)) {
                ADD_ELEM(ret, (LINK_ELEMENT *) new_insn_body(iseq, location.line, node_id, YARVINSN_getblockparamproxy, 2, __builtin_choose_expr( __builtin_constant_p((idx) + ( 3) - 1), ((VALUE)((idx) + ( 3) - 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((idx) + ( 3) - 1)), __builtin_choose_expr( __builtin_constant_p(level), ((VALUE)(level)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(level))));
            }
            else {
                pm_compile_node(iseq, (node->receiver), ret, 0, scope_node);
            }
        }
        else {
            pm_compile_node(iseq, (node->receiver), ret, 0, scope_node);
        }
    }
    pm_compile_call(iseq, node, ret, popped, scope_node, method_id, start);
    return;
}
static inline void
pm_compile_call_operator_write_node(rb_iseq_t *iseq, const pm_call_operator_write_node_t *node, const pm_node_location_t *location, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node)
{
    int flag = 0;
    if (((((pm_node_t *)(node))->flags & (PM_CALL_NODE_FLAGS_IGNORE_VISIBILITY)) != 0)) {
        flag = (0x01 << VM_CALL_FCALL_bit);
    }
    pm_compile_node(iseq, (node->receiver), ret, 0, scope_node);
    LABEL *safe_label = ((void *)0);
    if (((((pm_node_t *)(node))->flags & (PM_CALL_NODE_FLAGS_SAFE_NAVIGATION)) != 0)) {
        safe_label = new_label_body(iseq, (location->line));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_dup, 0));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_branchnil, 1, (VALUE)(safe_label))), ((safe_label)->refcnt++));
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_dup, 0));
    ID id_read_name = pm_constant_id_lookup(scope_node, node->read_name);
    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (*location).line, (int) (*location).node_id, ((id_read_name)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))), (((void *)0)), (VALUE)((VALUE)(__builtin_choose_expr( __builtin_constant_p(flag), ((VALUE)(flag)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(flag)))), (((void *)0))));
    pm_compile_node(iseq, (node->value), ret, 0, scope_node);
    ID id_operator = pm_constant_id_lookup(scope_node, node->binary_operator);
    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (*location).line, (int) (*location).node_id, ((id_operator)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
    if (!popped) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_swap, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
    }
    ID id_write_name = pm_constant_id_lookup(scope_node, node->write_name);
    ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (*location).line, (int) (*location).node_id, ((id_write_name)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)(__builtin_choose_expr( __builtin_constant_p(flag), ((VALUE)(flag)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(flag)))), (((void *)0))));
    if (safe_label != ((void *)0) && popped) ADD_ELEM((ret), (LINK_ELEMENT *) (safe_label));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_pop, 0));
    if (safe_label != ((void *)0) && !popped) ADD_ELEM((ret), (LINK_ELEMENT *) (safe_label));
}
static VALUE
pm_compile_case_node_dispatch(rb_iseq_t *iseq, VALUE dispatch, const pm_node_t *node, LABEL *label, const pm_scope_node_t *scope_node)
{
    VALUE key = ((VALUE)RUBY_Qundef);
    switch (((enum pm_node_type) (node)->type)) {
      case PM_FLOAT_NODE: {
        key = pm_static_literal_value(iseq, node, scope_node);
        double intptr;
        if (modf(rb_float_value_inline(key), &intptr) == 0.0) {
            key = ((((intptr) < (0x7fffffffffffffffL / 2) + 1) && ((intptr) >= ((-0x7fffffffffffffffL - 1L) / 2))) ? RB_INT2FIX((long) intptr) : rb_dbl2big(intptr));
        }
        break;
      }
      case PM_FALSE_NODE:
      case PM_INTEGER_NODE:
      case PM_NIL_NODE:
      case PM_SOURCE_FILE_NODE:
      case PM_SOURCE_LINE_NODE:
      case PM_SYMBOL_NODE:
      case PM_TRUE_NODE:
        key = pm_static_literal_value(iseq, node, scope_node);
        break;
      case PM_STRING_NODE: {
        const pm_string_node_t *cast = (const pm_string_node_t *) node;
        key = parse_static_literal_string(iseq, scope_node, node, &cast->unescaped);
        break;
      }
      default:
        return ((VALUE)RUBY_Qundef);
    }
    if (RB_NIL_P(rb_hash_lookup(dispatch, key))) {
        rb_hash_aset(dispatch, key, ((VALUE) label) | 1);
    }
    return dispatch;
}
static inline void
pm_compile_case_node(rb_iseq_t *iseq, const pm_case_node_t *cast, const pm_node_location_t *node_location, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node)
{
    const pm_parser_t *parser = scope_node->parser;
    const pm_node_location_t location = *node_location;
    const pm_node_list_t *conditions = &cast->conditions;
    LINK_ANCHOR cond_seq[1] = {{{ISEQ_ELEMENT_ANCHOR,},&cond_seq[0].anchor}};
    LINK_ANCHOR body_seq[1] = {{{ISEQ_ELEMENT_ANCHOR,},&body_seq[0].anchor}};
    LABEL *end_label = new_label_body(iseq, (location.line));
    if (cast->predicate == ((void *)0)) {
        VALUE branches = ((VALUE)RUBY_Qfalse);
        rb_code_location_t case_location = { 0 };
        int branch_id = 0;
        if ((((iseq)->body)->variable.coverage && RARRAY_AREF(((iseq)->body)->variable.coverage, 1))) {
            case_location = pm_code_location(scope_node, (const pm_node_t *) cast);
            branches = decl_branch_base(iseq, (rb_int2inum((intptr_t)(void *)(cast))), &case_location, "case");
        }
        for (size_t clause_index = 0; clause_index < conditions->size; clause_index++) {
            const pm_when_node_t *clause = (const pm_when_node_t *) conditions->nodes[clause_index];
            const pm_node_list_t *conditions = &clause->conditions;
            int clause_lineno = pm_node_line_number(parser, (const pm_node_t *) clause);
            LABEL *label = new_label_body(iseq, (clause_lineno));
            ADD_ELEM((body_seq), (LINK_ELEMENT *) (label));
            if ((((iseq)->body)->variable.coverage && RARRAY_AREF(((iseq)->body)->variable.coverage, 1))) {
                rb_code_location_t branch_location = pm_code_location(scope_node, clause->statements != ((void *)0) ? ((const pm_node_t *) clause->statements) : ((const pm_node_t *) clause));
                add_trace_branch_coverage(iseq, body_seq, &branch_location, branch_location.beg_pos.column, branch_id++, "when", branches);
            }
            if (clause->statements != ((void *)0)) {
                pm_compile_node(iseq, (const pm_node_t *) clause->statements, body_seq, popped, scope_node);
            }
            else if (!popped) {
                do { int lineno = ISEQ_COMPILE_DATA(iseq)->last_line; if (lineno == 0) lineno = RB_FIX2INT(rb_iseq_first_lineno(iseq)); ADD_ELEM((body_seq), (LINK_ELEMENT *) new_insn_body(iseq, (lineno), (-1), YARVINSN_putnil, 0)); } while (0);
            }
            (ADD_ELEM((body_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_jump, 1, (VALUE)(end_label))), ((end_label)->refcnt++));
            for (size_t condition_index = 0; condition_index < conditions->size; condition_index++) {
                const pm_node_t *condition = conditions->nodes[condition_index];
                if ((((enum pm_node_type) (condition)->type) == (PM_SPLAT_NODE))) {
                    pm_node_location_t cond_location = ((pm_node_location_t) { .line = pm_newline_list_line(&(parser)->newline_list, ((const pm_node_t *) (condition))->location.start, (parser)->start_line), .node_id = ((const pm_node_t *) (condition))->node_id });
                    ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int) (cond_location).line, (int) (cond_location).node_id, YARVINSN_putnil, 0));
                    pm_compile_node(iseq, condition, cond_seq, 0, scope_node);
                    ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int) (cond_location).line, (int) (cond_location).node_id, YARVINSN_checkmatch, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_CHECKMATCH_TYPE_WHEN | 0x04), ((VALUE)(VM_CHECKMATCH_TYPE_WHEN | 0x04)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_CHECKMATCH_TYPE_WHEN | 0x04)))));
                    (ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int) (cond_location).line, (int) (cond_location).node_id, YARVINSN_branchif, 1, (VALUE)(label))), ((label)->refcnt++));
                }
                else {
                    LABEL *next_label = new_label_body(iseq, (pm_node_line_number(parser, condition)));
                    pm_compile_branch_condition(iseq, cond_seq, condition, label, next_label, 0, scope_node);
                    ADD_ELEM((cond_seq), (LINK_ELEMENT *) (next_label));
                }
            }
        }
        if ((((iseq)->body)->variable.coverage && RARRAY_AREF(((iseq)->body)->variable.coverage, 1))) {
            rb_code_location_t branch_location;
            if (cast->else_clause == ((void *)0)) {
                branch_location = case_location;
            } else if (cast->else_clause->statements == ((void *)0)) {
                branch_location = pm_code_location(scope_node, (const pm_node_t *) cast->else_clause);
            } else {
                branch_location = pm_code_location(scope_node, (const pm_node_t *) cast->else_clause->statements);
            }
            add_trace_branch_coverage(iseq, cond_seq, &branch_location, branch_location.beg_pos.column, branch_id, "else", branches);
        }
        if (cast->else_clause != ((void *)0)) {
            pm_compile_node(iseq, (const pm_node_t *) cast->else_clause, cond_seq, popped, scope_node);
        }
        else if (!popped) {
            do { int lineno = ISEQ_COMPILE_DATA(iseq)->last_line; if (lineno == 0) lineno = RB_FIX2INT(rb_iseq_first_lineno(iseq)); ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (lineno), (-1), YARVINSN_putnil, 0)); } while (0);
        }
        (ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_jump, 1, (VALUE)(end_label))), ((end_label)->refcnt++));
        APPEND_LIST((ret), (cond_seq));
    }
    else {
        VALUE branches = ((VALUE)RUBY_Qfalse);
        rb_code_location_t case_location = { 0 };
        int branch_id = 0;
        if ((((iseq)->body)->variable.coverage && RARRAY_AREF(((iseq)->body)->variable.coverage, 1))) {
            case_location = pm_code_location(scope_node, (const pm_node_t *) cast);
            branches = decl_branch_base(iseq, (rb_int2inum((intptr_t)(void *)(cast))), &case_location, "case");
        }
        LABEL *else_label = new_label_body(iseq, (location.line));
        VALUE dispatch = ((VALUE)RUBY_Qundef);
        if (ISEQ_COMPILE_DATA(iseq)->option->specialized_instruction) {
            dispatch = rb_hash_new();
            rb_hash_tbl_raw(dispatch, "prism_compile.c", 7232)->type = &cdhash_type;
        }
        for (size_t clause_index = 0; clause_index < conditions->size; clause_index++) {
            const pm_when_node_t *clause = (const pm_when_node_t *) conditions->nodes[clause_index];
            pm_node_location_t clause_location = ((pm_node_location_t) { .line = pm_newline_list_line(&(parser)->newline_list, ((const pm_node_t *) ((const pm_node_t *) clause))->location.start, (parser)->start_line), .node_id = ((const pm_node_t *) ((const pm_node_t *) clause))->node_id });
            const pm_node_list_t *conditions = &clause->conditions;
            LABEL *label = new_label_body(iseq, (clause_location.line));
            for (size_t condition_index = 0; condition_index < conditions->size; condition_index++) {
                const pm_node_t *condition = conditions->nodes[condition_index];
                const pm_node_location_t condition_location = ((pm_node_location_t) { .line = pm_newline_list_line(&(parser)->newline_list, ((const pm_node_t *) (condition))->location.start, (parser)->start_line), .node_id = ((const pm_node_t *) (condition))->node_id });
                if (dispatch != ((VALUE)RUBY_Qundef)) {
                    dispatch = pm_compile_case_node_dispatch(iseq, dispatch, condition, label, scope_node);
                }
                if ((((enum pm_node_type) (condition)->type) == (PM_SPLAT_NODE))) {
                    ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int) (condition_location).line, (int) (condition_location).node_id, YARVINSN_dup, 0));
                    pm_compile_node(iseq, condition, cond_seq, 0, scope_node);
                    ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int) (condition_location).line, (int) (condition_location).node_id, YARVINSN_checkmatch, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_CHECKMATCH_TYPE_CASE | 0x04), ((VALUE)(VM_CHECKMATCH_TYPE_CASE | 0x04)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_CHECKMATCH_TYPE_CASE | 0x04)))));
                }
                else {
                    if ((((enum pm_node_type) (condition)->type) == (PM_STRING_NODE))) {
                        const pm_string_node_t *string = (const pm_string_node_t *) condition;
                        VALUE value = parse_static_literal_string(iseq, scope_node, condition, &string->unescaped);
                        ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int) (condition_location).line, (int) (condition_location).node_id, YARVINSN_putobject, 1, (VALUE)(value)));
                    }
                    else {
                        pm_compile_node(iseq, condition, cond_seq, 0, scope_node);
                    }
                    ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int) (condition_location).line, (int) (condition_location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
                    ADD_ELEM(((cond_seq)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (condition_location).line, (int) (condition_location).node_id, ((idEqq)), (VALUE)((rb_int2num_inline(1))), (((void *)0)), (VALUE)((VALUE)(__builtin_choose_expr( __builtin_constant_p((0x01 << VM_CALL_FCALL_bit) | (0x01 << VM_CALL_ARGS_SIMPLE_bit)), ((VALUE)((0x01 << VM_CALL_FCALL_bit) | (0x01 << VM_CALL_ARGS_SIMPLE_bit))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((0x01 << VM_CALL_FCALL_bit) | (0x01 << VM_CALL_ARGS_SIMPLE_bit))))), (((void *)0))));
                }
                (ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int) (condition_location).line, (int) (condition_location).node_id, YARVINSN_branchif, 1, (VALUE)(label))), ((label)->refcnt++));
            }
            ADD_ELEM((body_seq), (LINK_ELEMENT *) (label));
            ADD_ELEM((body_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int) (clause_location).line, (int) (clause_location).node_id, YARVINSN_pop, 0));
            if ((((iseq)->body)->variable.coverage && RARRAY_AREF(((iseq)->body)->variable.coverage, 1))) {
                rb_code_location_t branch_location = pm_code_location(scope_node, clause->statements != ((void *)0) ? ((const pm_node_t *) clause->statements) : ((const pm_node_t *) clause));
                add_trace_branch_coverage(iseq, body_seq, &branch_location, branch_location.beg_pos.column, branch_id++, "when", branches);
            }
            if (clause->statements != ((void *)0)) {
                pm_compile_node(iseq, (const pm_node_t *) clause->statements, body_seq, popped, scope_node);
            }
            else if (!popped) {
                do { int lineno = ISEQ_COMPILE_DATA(iseq)->last_line; if (lineno == 0) lineno = RB_FIX2INT(rb_iseq_first_lineno(iseq)); ADD_ELEM((body_seq), (LINK_ELEMENT *) new_insn_body(iseq, (lineno), (-1), YARVINSN_putnil, 0)); } while (0);
            }
            (ADD_ELEM((body_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int) (clause_location).line, (int) (clause_location).node_id, YARVINSN_jump, 1, (VALUE)(end_label))), ((end_label)->refcnt++));
        }
        pm_compile_node(iseq, (cast->predicate), ret, 0, scope_node);
        if (dispatch != ((VALUE)RUBY_Qundef)) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_opt_case_dispatch, 2, (VALUE)(dispatch), (VALUE)(else_label)));
            ((else_label)->refcnt++);
        }
        APPEND_LIST((ret), (cond_seq));
        ADD_ELEM((ret), (LINK_ELEMENT *) (else_label));
        if (cast->else_clause != ((void *)0)) {
            pm_node_location_t else_location = ((pm_node_location_t) { .line = pm_newline_list_line(&(parser)->newline_list, ((const pm_node_t *) (cast->else_clause->statements != ((void *)0) ? ((const pm_node_t *) cast->else_clause->statements) : ((const pm_node_t *) cast->else_clause)))->location.start, (parser)->start_line), .node_id = ((const pm_node_t *) (cast->else_clause->statements != ((void *)0) ? ((const pm_node_t *) cast->else_clause->statements) : ((const pm_node_t *) cast->else_clause)))->node_id });
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (else_location).line, (int) (else_location).node_id, YARVINSN_pop, 0));
            if ((((iseq)->body)->variable.coverage && RARRAY_AREF(((iseq)->body)->variable.coverage, 1))) {
                rb_code_location_t branch_location = pm_code_location(scope_node, cast->else_clause->statements != ((void *)0) ? ((const pm_node_t *) cast->else_clause->statements) : ((const pm_node_t *) cast->else_clause));
                add_trace_branch_coverage(iseq, ret, &branch_location, branch_location.beg_pos.column, branch_id, "else", branches);
            }
            pm_compile_node(iseq, ((const pm_node_t *) cast->else_clause), ret, popped, scope_node);
            (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (else_location).line, (int) (else_location).node_id, YARVINSN_jump, 1, (VALUE)(end_label))), ((end_label)->refcnt++));
        }
        else {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
            if ((((iseq)->body)->variable.coverage && RARRAY_AREF(((iseq)->body)->variable.coverage, 1))) {
                add_trace_branch_coverage(iseq, ret, &case_location, case_location.beg_pos.column, branch_id, "else", branches);
            }
            if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
            (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_jump, 1, (VALUE)(end_label))), ((end_label)->refcnt++));
        }
    }
    APPEND_LIST((ret), (body_seq));
    ADD_ELEM((ret), (LINK_ELEMENT *) (end_label));
}
static inline void
pm_compile_case_match_node(rb_iseq_t *iseq, const pm_case_match_node_t *node, const pm_node_location_t *location, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node)
{
    LINK_ANCHOR body_seq[1] = {{{ISEQ_ELEMENT_ANCHOR,},&body_seq[0].anchor}};
    LINK_ANCHOR cond_seq[1] = {{{ISEQ_ELEMENT_ANCHOR,},&cond_seq[0].anchor}};
    LABEL *end_label = new_label_body(iseq, (location->line));
    LABEL *else_label = new_label_body(iseq, (location->line));
    rb_code_location_t case_location = { 0 };
    VALUE branches = ((VALUE)RUBY_Qfalse);
    int branch_id = 0;
    if ((((iseq)->body)->variable.coverage && RARRAY_AREF(((iseq)->body)->variable.coverage, 1))) {
        case_location = pm_code_location(scope_node, (const pm_node_t *) node);
        branches = decl_branch_base(iseq, (rb_int2inum((intptr_t)(void *)(node))), &case_location, "case");
    }
    _Bool in_single_pattern = node->else_clause == ((void *)0) && node->conditions.size == 1;
    if (in_single_pattern) {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putnil, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putnil, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qfalse))));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putnil, 0));
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putnil, 0));
    pm_compile_node(iseq, (node->predicate), ret, 0, scope_node);
    for (size_t index = 0; index < node->conditions.size; index++) {
        const pm_node_t *condition = node->conditions.nodes[index];
        ((void)0);
        const pm_in_node_t *in_node = (const pm_in_node_t *) condition;
        const pm_node_location_t in_location = ((pm_node_location_t) { .line = pm_newline_list_line(&(scope_node->parser)->newline_list, ((const pm_node_t *) (in_node))->location.start, (scope_node->parser)->start_line), .node_id = ((const pm_node_t *) (in_node))->node_id });
        const pm_node_location_t pattern_location = ((pm_node_location_t) { .line = pm_newline_list_line(&(scope_node->parser)->newline_list, ((const pm_node_t *) (in_node->pattern))->location.start, (scope_node->parser)->start_line), .node_id = ((const pm_node_t *) (in_node->pattern))->node_id });
        if (branch_id) {
            ADD_ELEM((body_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int) (in_location).line, (int) (in_location).node_id, YARVINSN_putnil, 0));
        }
        LABEL *body_label = new_label_body(iseq, (in_location.line));
        ADD_ELEM((body_seq), (LINK_ELEMENT *) (body_label));
        ADD_ELEM((body_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int) (in_location).line, (int) (in_location).node_id, YARVINSN_adjuststack, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(in_single_pattern ? 6 : 2), ((VALUE)(in_single_pattern ? 6 : 2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(in_single_pattern ? 6 : 2)))));
        if ((((iseq)->body)->variable.coverage && RARRAY_AREF(((iseq)->body)->variable.coverage, 1))) {
            rb_code_location_t branch_location = pm_code_location(scope_node, in_node->statements != ((void *)0) ? ((const pm_node_t *) in_node->statements) : ((const pm_node_t *) in_node));
            add_trace_branch_coverage(iseq, body_seq, &branch_location, branch_location.beg_pos.column, branch_id++, "in", branches);
        }
        if (in_node->statements != ((void *)0)) {
            pm_compile_node(iseq, ((const pm_node_t *) in_node->statements), body_seq, popped, scope_node);
        }
        else if (!popped) {
            do { int lineno = ISEQ_COMPILE_DATA(iseq)->last_line; if (lineno == 0) lineno = RB_FIX2INT(rb_iseq_first_lineno(iseq)); ADD_ELEM((body_seq), (LINK_ELEMENT *) new_insn_body(iseq, (lineno), (-1), YARVINSN_putnil, 0)); } while (0);
        }
        (ADD_ELEM((body_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int) (in_location).line, (int) (in_location).node_id, YARVINSN_jump, 1, (VALUE)(end_label))), ((end_label)->refcnt++));
        LABEL *next_pattern_label = new_label_body(iseq, (pattern_location.line));
        ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int) (pattern_location).line, (int) (pattern_location).node_id, YARVINSN_dup, 0));
        pm_compile_pattern(iseq, scope_node, in_node->pattern, cond_seq, body_label, next_pattern_label, in_single_pattern, 0, 1, 2);
        ADD_ELEM((cond_seq), (LINK_ELEMENT *) (next_pattern_label));
        ((next_pattern_label) ? (((next_pattern_label)->refcnt++), (next_pattern_label)->unremovable=1) : 0);
    }
    if (node->else_clause != ((void *)0)) {
        const pm_else_node_t *else_node = node->else_clause;
        ADD_ELEM((cond_seq), (LINK_ELEMENT *) (else_label));
        ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_pop, 0));
        ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_pop, 0));
        if ((((iseq)->body)->variable.coverage && RARRAY_AREF(((iseq)->body)->variable.coverage, 1))) {
            rb_code_location_t branch_location = pm_code_location(scope_node, else_node->statements != ((void *)0) ? ((const pm_node_t *) else_node->statements) : ((const pm_node_t *) else_node));
            add_trace_branch_coverage(iseq, cond_seq, &branch_location, branch_location.beg_pos.column, branch_id, "else", branches);
        }
        pm_compile_node(iseq, ((const pm_node_t *) else_node), cond_seq, popped, scope_node);
        (ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_jump, 1, (VALUE)(end_label))), ((end_label)->refcnt++));
        ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putnil, 0));
        if (popped) ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putnil, 0));
    }
    else {
        ADD_ELEM((cond_seq), (LINK_ELEMENT *) (else_label));
        add_trace_branch_coverage(iseq, cond_seq, &case_location, case_location.beg_pos.column, branch_id, "else", branches);
        if (in_single_pattern) {
            pm_compile_pattern_error_handler(iseq, scope_node, (const pm_node_t *) node, cond_seq, end_label, popped);
        }
        else {
            ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
            ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putobject, 1, (VALUE)(rb_eNoMatchingPatternError)));
            ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_topn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))));
            ADD_ELEM(((cond_seq)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (*location).line, (int) (*location).node_id, ((id_core_raise)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
            ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_adjuststack, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(3), ((VALUE)(3)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(3)))));
            if (!popped) ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putnil, 0));
            (ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_jump, 1, (VALUE)(end_label))), ((end_label)->refcnt++));
            ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_dupn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))));
            if (popped) ADD_ELEM((cond_seq), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putnil, 0));
        }
    }
    APPEND_LIST((ret), (cond_seq));
    APPEND_LIST((ret), (body_seq));
    ADD_ELEM((ret), (LINK_ELEMENT *) (end_label));
}
static inline void
pm_compile_forwarding_super_node(rb_iseq_t *iseq, const pm_forwarding_super_node_t *node, const pm_node_location_t *location, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node)
{
    const rb_iseq_t *block = ((void *)0);
    const rb_iseq_t *previous_block = ((void *)0);
    LABEL *retry_label = ((void *)0);
    LABEL *retry_end_l = ((void *)0);
    if (node->block != ((void *)0)) {
        previous_block = ISEQ_COMPILE_DATA(iseq)->current_block;
        ISEQ_COMPILE_DATA(iseq)->current_block = ((void *)0);
        retry_label = new_label_body(iseq, (location->line));
        retry_end_l = new_label_body(iseq, (location->line));
        ADD_ELEM((ret), (LINK_ELEMENT *) (retry_label));
    }
    else {
        iseq_set_use_block(((iseq)->body)->local_iseq);
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putself, 0));
    int flag = (0x01 << VM_CALL_ZSUPER_bit) | (0x01 << VM_CALL_SUPER_bit) | (0x01 << VM_CALL_FCALL_bit);
    if (node->block != ((void *)0)) {
        pm_scope_node_t next_scope_node;
        pm_scope_node_init((const pm_node_t *) node->block, &next_scope_node, scope_node);
        ISEQ_COMPILE_DATA(iseq)->current_block = block = pm_new_child_iseq(iseq, (&next_scope_node), rb_fstring(make_name_for_block(iseq)), iseq, (ISEQ_TYPE_BLOCK), (location->line));
        pm_scope_node_destroy(&next_scope_node);
        (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)((VALUE) block), "prism_compile.c", 7536));
    }
    LINK_ANCHOR args[1] = {{{ISEQ_ELEMENT_ANCHOR,},&args[0].anchor}};
    struct rb_iseq_constant_body *const body = ((iseq)->body);
    const rb_iseq_t *local_iseq = body->local_iseq;
    const struct rb_iseq_constant_body *const local_body = ((local_iseq)->body);
    int argc = 0;
    int depth = get_lvar_level(iseq);
    if (((((iseq)->body)->local_iseq)->body)->param.flags.forwardable) {
        flag |= (0x01 << VM_CALL_FORWARDING_bit);
        pm_local_index_t mult_local = pm_lookup_local_index(iseq, scope_node, ((pm_constant_id_t)(idDot3 | ((pm_constant_id_t)(1 << 31)))), 0);
        pm_iseq_add_getlocal(iseq, (ret), (int) (*location).line, (int) (*location).node_id, (mult_local.index), (mult_local.level));
        const struct rb_callinfo *callinfo = new_callinfo(iseq, 0, 0, flag, ((void *)0), block != ((void *)0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_invokesuperforward, 2, (VALUE)(callinfo), (VALUE)(block)));
        if (popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_pop, 0));
        if (node->block) {
            ISEQ_COMPILE_DATA(iseq)->current_block = previous_block;
        }
        return;
    }
    if (local_body->param.flags.has_lead) {
        for (int i = 0; i < local_body->param.lead_num; i++) {
            int idx = local_body->local_table_size - i;
            pm_iseq_add_getlocal(iseq, (args), (int) (*location).line, (int) (*location).node_id, (idx), (depth));
        }
        argc += local_body->param.lead_num;
    }
    if (local_body->param.flags.has_opt) {
        for (int j = 0; j < local_body->param.opt_num; j++) {
            int idx = local_body->local_table_size - (argc + j);
            pm_iseq_add_getlocal(iseq, (args), (int) (*location).line, (int) (*location).node_id, (idx), (depth));
        }
        argc += local_body->param.opt_num;
    }
    if (local_body->param.flags.has_rest) {
        int idx = local_body->local_table_size - local_body->param.rest_start;
        pm_iseq_add_getlocal(iseq, (args), (int) (*location).line, (int) (*location).node_id, (idx), (depth));
        ADD_ELEM((args), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_splatarray, 1, (VALUE)(((VALUE)RUBY_Qfalse))));
        argc = local_body->param.rest_start + 1;
        flag |= (0x01 << VM_CALL_ARGS_SPLAT_bit);
    }
    if (local_body->param.flags.has_post) {
        int post_len = local_body->param.post_num;
        int post_start = local_body->param.post_start;
        int j = 0;
        for (; j < post_len; j++) {
            int idx = local_body->local_table_size - (post_start + j);
            pm_iseq_add_getlocal(iseq, (args), (int) (*location).line, (int) (*location).node_id, (idx), (depth));
        }
        if (local_body->param.flags.has_rest) {
            ADD_ELEM((args), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_newarray, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(j), ((VALUE)(j)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(j)))));
            ADD_ELEM((args), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_concatarray, 0));
        }
        else {
            argc = post_len + post_start;
        }
    }
    const struct rb_iseq_param_keyword *const local_keyword = local_body->param.keyword;
    if (local_body->param.flags.has_kw) {
        int local_size = local_body->local_table_size;
        argc++;
        ADD_ELEM((args), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
        if (local_body->param.flags.has_kwrest) {
            int idx = local_body->local_table_size - local_keyword->rest_start;
            pm_iseq_add_getlocal(iseq, (args), (int) (*location).line, (int) (*location).node_id, (idx), (depth));
            ((void)0);
            ADD_ELEM(((args)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (*location).line, (int) (*location).node_id, (((__builtin_constant_p("dup") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("dup")); }) : (rb_intern)("dup")))), (VALUE)((__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
        }
        else {
            ADD_ELEM((args), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_newhash, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))));
        }
        int i = 0;
        for (; i < local_keyword->num; ++i) {
            ID id = local_keyword->table[i];
            int idx = local_size - get_local_var_idx(local_iseq, id);
            {
                VALUE operand = rb_id2sym(id);
                ADD_ELEM((args), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putobject, 1, (VALUE)(operand)));
            }
            pm_iseq_add_getlocal(iseq, (args), (int) (*location).line, (int) (*location).node_id, (idx), (depth));
        }
        ADD_ELEM(((args)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (*location).line, (int) (*location).node_id, ((id_core_hash_merge_ptr)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(i * 2 + 1), ((VALUE)(i * 2 + 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(i * 2 + 1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
        flag |= (0x01 << VM_CALL_KW_SPLAT_bit)| (0x01 << VM_CALL_KW_SPLAT_MUT_bit);
    }
    else if (local_body->param.flags.has_kwrest) {
        int idx = local_body->local_table_size - local_keyword->rest_start;
        pm_iseq_add_getlocal(iseq, (args), (int) (*location).line, (int) (*location).node_id, (idx), (depth));
        argc++;
        flag |= (0x01 << VM_CALL_KW_SPLAT_bit);
    }
    APPEND_LIST((ret), (args));
    {
        const struct rb_callinfo *callinfo = new_callinfo(iseq, 0, argc, flag, ((void *)0), block != ((void *)0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_invokesuper, 2, (VALUE)(callinfo), (VALUE)(block)));
    }
    if (node->block != ((void *)0)) {
        pm_compile_retry_end_label(iseq, ret, retry_end_l);
        do { VALUE _e = __extension__ ({ const VALUE args_to_new_ary[] = {((CATCH_TYPE_BREAK)), (VALUE)((retry_label)) | 1, (VALUE)((retry_end_l)) | 1, (VALUE)((block)), (VALUE)((retry_end_l)) | 1}; if (__builtin_constant_p(5)) { __extension__ _Static_assert(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))) == (5), "rb_ary_new_from_args" ": " "numberof(args_to_new_ary) == (5)"); } rb_ary_new_from_values(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))), args_to_new_ary); }); (((retry_label)) ? ((((retry_label))->refcnt++), ((retry_label))->unremovable=1) : 0); (((retry_end_l))->refcnt++); (((retry_end_l))->refcnt++); if (RB_NIL_P(ISEQ_COMPILE_DATA(iseq)->catch_table_ary)) (rb_obj_write((VALUE)(iseq), (VALUE *)(&ISEQ_COMPILE_DATA(iseq)->catch_table_ary), (VALUE)(rb_ary_hidden_new(3)), "prism_compile.c", 7660)); rb_ary_push(ISEQ_COMPILE_DATA(iseq)->catch_table_ary, freeze_hide_obj(_e)); } while (0);
        ISEQ_COMPILE_DATA(iseq)->current_block = previous_block;
    }
    if (popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_pop, 0));
}
static inline void
pm_compile_match_required_node(rb_iseq_t *iseq, const pm_match_required_node_t *node, const pm_node_location_t *location, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node)
{
    LABEL *matched_label = new_label_body(iseq, (location->line));
    LABEL *unmatched_label = new_label_body(iseq, (location->line));
    LABEL *done_label = new_label_body(iseq, (location->line));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putnil, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putnil, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qfalse))));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putnil, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putnil, 0));
    pm_compile_node(iseq, (node->value), ret, 0, scope_node);
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_dup, 0));
    pm_compile_pattern(iseq, scope_node, node->pattern, ret, matched_label, unmatched_label, 1, 0, 1, 2);
    ADD_ELEM((ret), (LINK_ELEMENT *) (unmatched_label));
    pm_compile_pattern_error_handler(iseq, scope_node, (const pm_node_t *) node, ret, done_label, popped);
    ADD_ELEM((ret), (LINK_ELEMENT *) (matched_label));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_adjuststack, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(6), ((VALUE)(6)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(6)))));
    if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putnil, 0));
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_jump, 1, (VALUE)(done_label))), ((done_label)->refcnt++));
    ADD_ELEM((ret), (LINK_ELEMENT *) (done_label));
}
static inline void
pm_compile_match_write_node(rb_iseq_t *iseq, const pm_match_write_node_t *node, const pm_node_location_t *location, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node)
{
    LABEL *fail_label = new_label_body(iseq, (location->line));
    LABEL *end_label = new_label_body(iseq, (location->line));
    pm_compile_node(iseq, ((const pm_node_t *) node->call), ret, 0, scope_node);
    {
        VALUE operand = rb_id2sym(idBACKREF);
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_getglobal, 1, (VALUE)(operand)));
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_dup, 0));
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_branchunless, 1, (VALUE)(fail_label))), ((fail_label)->refcnt++));
    size_t targets_count = node->targets.size;
    if (targets_count == 1) {
        const pm_node_t *target = node->targets.nodes[0];
        ((void)0);
        const pm_local_variable_target_node_t *local_target = (const pm_local_variable_target_node_t *) target;
        pm_local_index_t index = pm_lookup_local_index(iseq, scope_node, local_target->name, local_target->depth);
        {
            VALUE operand = rb_id2sym(pm_constant_id_lookup(scope_node, local_target->name));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putobject, 1, (VALUE)(operand)));
        }
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (*location).line, (int) (*location).node_id, ((idAREF)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
        ADD_ELEM((ret), (LINK_ELEMENT *) (fail_label));
        pm_iseq_add_setlocal(iseq, (ret), (int) (*location).line, (int) (*location).node_id, (index.index), (index.level));
        if (popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_pop, 0));
        return;
    }
    LINK_ANCHOR fail_anchor[1] = {{{ISEQ_ELEMENT_ANCHOR,},&fail_anchor[0].anchor}};
    for (size_t targets_index = 0; targets_index < targets_count; targets_index++) {
        const pm_node_t *target = node->targets.nodes[targets_index];
        ((void)0);
        const pm_local_variable_target_node_t *local_target = (const pm_local_variable_target_node_t *) target;
        pm_local_index_t index = pm_lookup_local_index(iseq, scope_node, local_target->name, local_target->depth);
        if (((size_t) targets_index) < (targets_count - 1)) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_dup, 0));
        }
        {
            VALUE operand = rb_id2sym(pm_constant_id_lookup(scope_node, local_target->name));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putobject, 1, (VALUE)(operand)));
        }
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (*location).line, (int) (*location).node_id, ((idAREF)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1)))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
        pm_iseq_add_setlocal(iseq, (ret), (int) (*location).line, (int) (*location).node_id, (index.index), (index.level));
        ADD_ELEM((fail_anchor), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putnil, 0));
        pm_iseq_add_setlocal(iseq, (fail_anchor), (int) (*location).line, (int) (*location).node_id, (index.index), (index.level));
    }
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_jump, 1, (VALUE)(end_label))), ((end_label)->refcnt++));
    ADD_ELEM((ret), (LINK_ELEMENT *) (fail_label));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_pop, 0));
    APPEND_LIST((ret), (fail_anchor));
    ADD_ELEM((ret), (LINK_ELEMENT *) (end_label));
    if (popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_pop, 0));
}
static inline void
pm_compile_next_node(rb_iseq_t *iseq, const pm_next_node_t *node, const pm_node_location_t *location, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node)
{
    if (ISEQ_COMPILE_DATA(iseq)->redo_label != 0 && can_add_ensure_iseq(iseq)) {
        LABEL *splabel = new_label_body(iseq, (0));
        ADD_ELEM((ret), (LINK_ELEMENT *) (splabel));
        if (node->arguments) {
            pm_compile_node(iseq, ((const pm_node_t *) node->arguments), ret, 0, scope_node);
        }
        else {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putnil, 0));
        }
        pm_add_ensure_iseq(ret, iseq, 0, scope_node);
        ADD_ELEM((ret), (LINK_ELEMENT *) new_adjust_body(iseq, (ISEQ_COMPILE_DATA(iseq)->redo_label), (int) (*location).line));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_jump, 1, (VALUE)(ISEQ_COMPILE_DATA(iseq)->start_label))), ((ISEQ_COMPILE_DATA(iseq)->start_label)->refcnt++));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_adjust_body(iseq, (splabel), -1));
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putnil, 0));
    }
    else if (ISEQ_COMPILE_DATA(iseq)->end_label && can_add_ensure_iseq(iseq)) {
        LABEL *splabel = new_label_body(iseq, (0));
        ADD_ELEM((ret), (LINK_ELEMENT *) (splabel));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_adjust_body(iseq, (ISEQ_COMPILE_DATA(iseq)->start_label), (int) (*location).line));
        if (node->arguments != ((void *)0)) {
            pm_compile_node(iseq, ((const pm_node_t *) node->arguments), ret, 0, scope_node);
        }
        else {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putnil, 0));
        }
        pm_add_ensure_iseq(ret, iseq, 0, scope_node);
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_jump, 1, (VALUE)(ISEQ_COMPILE_DATA(iseq)->end_label))), ((ISEQ_COMPILE_DATA(iseq)->end_label)->refcnt++));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_adjust_body(iseq, (splabel), -1));
        splabel->unremovable = 0;
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putnil, 0));
    }
    else {
        const rb_iseq_t *ip = iseq;
        unsigned long throw_flag = 0;
        while (ip) {
            if (!ISEQ_COMPILE_DATA(ip)) {
                ip = 0;
                break;
            }
            throw_flag = VM_THROW_NO_ESCAPE_FLAG;
            if (ISEQ_COMPILE_DATA(ip)->redo_label != 0) {
                break;
            }
            else if (((ip)->body)->type == ISEQ_TYPE_BLOCK) {
                break;
            }
            else if (((ip)->body)->type == ISEQ_TYPE_EVAL) {
                append_compile_error(iseq, location->line, "Invalid next");
                return;
            }
            ip = ((ip)->body)->parent_iseq;
        }
        if (ip != 0) {
            if (node->arguments) {
                pm_compile_node(iseq, ((const pm_node_t *) node->arguments), ret, 0, scope_node);
            }
            else {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putnil, 0));
            }
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_throw, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(throw_flag | RUBY_TAG_NEXT), ((VALUE)(throw_flag | RUBY_TAG_NEXT)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(throw_flag | RUBY_TAG_NEXT)))));
            if (popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_pop, 0));
        }
        else {
            append_compile_error(iseq, location->line, "Invalid next");
        }
    }
}
static inline void
pm_compile_redo_node(rb_iseq_t *iseq, const pm_node_location_t *location, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node)
{
    if (ISEQ_COMPILE_DATA(iseq)->redo_label && can_add_ensure_iseq(iseq)) {
        LABEL *splabel = new_label_body(iseq, (0));
        ADD_ELEM((ret), (LINK_ELEMENT *) (splabel));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_adjust_body(iseq, (ISEQ_COMPILE_DATA(iseq)->redo_label), (int) (*location).line));
        pm_add_ensure_iseq(ret, iseq, 0, scope_node);
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_jump, 1, (VALUE)(ISEQ_COMPILE_DATA(iseq)->redo_label))), ((ISEQ_COMPILE_DATA(iseq)->redo_label)->refcnt++));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_adjust_body(iseq, (splabel), -1));
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putnil, 0));
    }
    else if (((iseq)->body)->type != ISEQ_TYPE_EVAL && ISEQ_COMPILE_DATA(iseq)->start_label && can_add_ensure_iseq(iseq)) {
        LABEL *splabel = new_label_body(iseq, (0));
        ADD_ELEM((ret), (LINK_ELEMENT *) (splabel));
        pm_add_ensure_iseq(ret, iseq, 0, scope_node);
        ADD_ELEM((ret), (LINK_ELEMENT *) new_adjust_body(iseq, (ISEQ_COMPILE_DATA(iseq)->start_label), (int) (*location).line));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_jump, 1, (VALUE)(ISEQ_COMPILE_DATA(iseq)->start_label))), ((ISEQ_COMPILE_DATA(iseq)->start_label)->refcnt++));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_adjust_body(iseq, (splabel), -1));
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putnil, 0));
    }
    else {
        const rb_iseq_t *ip = iseq;
        while (ip) {
            if (!ISEQ_COMPILE_DATA(ip)) {
                ip = 0;
                break;
            }
            if (ISEQ_COMPILE_DATA(ip)->redo_label != 0) {
                break;
            }
            else if (((ip)->body)->type == ISEQ_TYPE_BLOCK) {
                break;
            }
            else if (((ip)->body)->type == ISEQ_TYPE_EVAL) {
                append_compile_error(iseq, location->line, "Invalid redo");
                return;
            }
            ip = ((ip)->body)->parent_iseq;
        }
        if (ip != 0) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putnil, 0));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_throw, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_THROW_NO_ESCAPE_FLAG | RUBY_TAG_REDO), ((VALUE)(VM_THROW_NO_ESCAPE_FLAG | RUBY_TAG_REDO)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_THROW_NO_ESCAPE_FLAG | RUBY_TAG_REDO)))));
            if (popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_pop, 0));
        }
        else {
            append_compile_error(iseq, location->line, "Invalid redo");
        }
    }
}
static inline void
pm_compile_rescue_node(rb_iseq_t *iseq, const pm_rescue_node_t *node, const pm_node_location_t *location, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node)
{
    iseq_set_exception_local_table(iseq);
    LABEL *exception_match_label = new_label_body(iseq, (location->line));
    LABEL *rescue_end_label = new_label_body(iseq, (location->line));
    const pm_node_list_t *exceptions = &node->exceptions;
    if (exceptions->size > 0) {
        for (size_t index = 0; index < exceptions->size; index++) {
            pm_iseq_add_getlocal(iseq, (ret), (int) (*location).line, (int) (*location).node_id, ((1)), (0));
            pm_compile_node(iseq, (exceptions->nodes[index]), ret, popped, scope_node);
            int checkmatch_flags = VM_CHECKMATCH_TYPE_RESCUE;
            if ((((enum pm_node_type) (exceptions->nodes[index])->type) == (PM_SPLAT_NODE))) {
                checkmatch_flags |= 0x04;
            }
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_checkmatch, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(checkmatch_flags), ((VALUE)(checkmatch_flags)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(checkmatch_flags)))));
            (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_branchif, 1, (VALUE)(exception_match_label))), ((exception_match_label)->refcnt++));
        }
    }
    else {
        pm_iseq_add_getlocal(iseq, (ret), (int) (*location).line, (int) (*location).node_id, ((1)), (0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putobject, 1, (VALUE)(rb_eStandardError)));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_checkmatch, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_CHECKMATCH_TYPE_RESCUE), ((VALUE)(VM_CHECKMATCH_TYPE_RESCUE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_CHECKMATCH_TYPE_RESCUE)))));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_branchif, 1, (VALUE)(exception_match_label))), ((exception_match_label)->refcnt++));
    }
    (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_jump, 1, (VALUE)(rescue_end_label))), ((rescue_end_label)->refcnt++));
    ADD_ELEM((ret), (LINK_ELEMENT *) (exception_match_label));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_trace_body(iseq, (0x4000), 0));
    if (node->reference) {
        LINK_ANCHOR writes[1] = {{{ISEQ_ELEMENT_ANCHOR,},&writes[0].anchor}};
        LINK_ANCHOR cleanup[1] = {{{ISEQ_ELEMENT_ANCHOR,},&cleanup[0].anchor}};
        pm_compile_target_node(iseq, node->reference, ret, writes, cleanup, scope_node, ((void *)0));
        pm_iseq_add_getlocal(iseq, (ret), (int) (*location).line, (int) (*location).node_id, ((1)), (0));
        APPEND_LIST((ret), (writes));
        APPEND_LIST((ret), (cleanup));
    }
    if (node->statements != ((void *)0)) {
        LABEL *prev_end = ISEQ_COMPILE_DATA(iseq)->end_label;
        ISEQ_COMPILE_DATA(iseq)->end_label = ((void *)0);
        pm_compile_node(iseq, ((const pm_node_t *) node->statements), ret, popped, scope_node);
        ISEQ_COMPILE_DATA(iseq)->end_label = prev_end;
    }
    else {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putnil, 0));
    }
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_leave, 0));
    ADD_ELEM((ret), (LINK_ELEMENT *) (rescue_end_label));
    if (node->subsequent != ((void *)0)) {
        pm_compile_node(iseq, ((const pm_node_t *) node->subsequent), ret, popped, scope_node);
    }
    else {
        pm_iseq_add_getlocal(iseq, (ret), (int) (*location).line, (int) (*location).node_id, (1), (0));
    }
}
static inline void
pm_compile_return_node(rb_iseq_t *iseq, const pm_return_node_t *node, const pm_node_location_t *location, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node)
{
    const pm_arguments_node_t *arguments = node->arguments;
    enum rb_iseq_type type = ((iseq)->body)->type;
    LABEL *splabel = 0;
    const rb_iseq_t *parent_iseq = iseq;
    enum rb_iseq_type parent_type = ((parent_iseq)->body)->type;
    while (parent_type == ISEQ_TYPE_RESCUE || parent_type == ISEQ_TYPE_ENSURE) {
        if (!(parent_iseq = ((parent_iseq)->body)->parent_iseq)) break;
        parent_type = ((parent_iseq)->body)->type;
    }
    switch (parent_type) {
      case ISEQ_TYPE_TOP:
      case ISEQ_TYPE_MAIN:
        if (arguments) {
            rb_warn("argument of top-level return is ignored");
        }
        if (parent_iseq == iseq) {
            type = ISEQ_TYPE_METHOD;
        }
        break;
      default:
        break;
    }
    if (type == ISEQ_TYPE_METHOD) {
        splabel = new_label_body(iseq, (0));
        ADD_ELEM((ret), (LINK_ELEMENT *) (splabel));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_adjust_body(iseq, (0), (int) (*location).line));
    }
    if (arguments != ((void *)0)) {
        pm_compile_node(iseq, ((const pm_node_t *) arguments), ret, 0, scope_node);
    }
    else {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putnil, 0));
    }
    if (type == ISEQ_TYPE_METHOD && can_add_ensure_iseq(iseq)) {
        pm_add_ensure_iseq(ret, iseq, 1, scope_node);
        ADD_ELEM((ret), (LINK_ELEMENT *) new_trace_body(iseq, (0x0010), 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_leave, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_adjust_body(iseq, (splabel), -1));
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putnil, 0));
    }
    else {
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_throw, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(RUBY_TAG_RETURN), ((VALUE)(RUBY_TAG_RETURN)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(RUBY_TAG_RETURN)))));
        if (popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_pop, 0));
    }
}
static inline void
pm_compile_super_node(rb_iseq_t *iseq, const pm_super_node_t *node, const pm_node_location_t *location, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node)
{
    LINK_ANCHOR args[1] = {{{ISEQ_ELEMENT_ANCHOR,},&args[0].anchor}};
    LABEL *retry_label = new_label_body(iseq, (location->line));
    LABEL *retry_end_l = new_label_body(iseq, (location->line));
    const rb_iseq_t *previous_block = ISEQ_COMPILE_DATA(iseq)->current_block;
    const rb_iseq_t *current_block;
    ISEQ_COMPILE_DATA(iseq)->current_block = current_block = ((void *)0);
    ADD_ELEM((ret), (LINK_ELEMENT *) (retry_label));
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_putself, 0));
    int flags = 0;
    struct rb_callinfo_kwarg *keywords = ((void *)0);
    int argc = pm_setup_args(node->arguments, node->block, &flags, &keywords, iseq, ret, scope_node, location);
    _Bool is_forwardable = (node->arguments != ((void *)0)) && ((((pm_node_t *)(node->arguments))->flags & (PM_ARGUMENTS_NODE_FLAGS_CONTAINS_FORWARDING)) != 0);
    flags |= (0x01 << VM_CALL_SUPER_bit) | (0x01 << VM_CALL_FCALL_bit);
    if (node->block && (((enum pm_node_type) (node->block)->type) == (PM_BLOCK_NODE))) {
        pm_scope_node_t next_scope_node;
        pm_scope_node_init(node->block, &next_scope_node, scope_node);
        ISEQ_COMPILE_DATA(iseq)->current_block = current_block = pm_new_child_iseq(iseq, (&next_scope_node), rb_fstring(make_name_for_block(iseq)), iseq, (ISEQ_TYPE_BLOCK), (location->line));
        pm_scope_node_destroy(&next_scope_node);
    }
    if (!node->block) {
        iseq_set_use_block(((iseq)->body)->local_iseq);
    }
    if ((flags & (0x01 << VM_CALL_ARGS_BLOCKARG_bit)) && (flags & (0x01 << VM_CALL_KW_SPLAT_bit)) && !(flags & (0x01 << VM_CALL_KW_SPLAT_MUT_bit))) {
        ADD_ELEM((args), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_splatkw, 0));
    }
    APPEND_LIST((ret), (args));
    if (is_forwardable && ((((iseq)->body)->local_iseq)->body)->param.flags.forwardable) {
        flags |= (0x01 << VM_CALL_FORWARDING_bit);
        {
            const struct rb_callinfo *callinfo = new_callinfo(iseq, 0, argc, flags, keywords, current_block != ((void *)0));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_invokesuperforward, 2, (VALUE)(callinfo), (VALUE)(current_block)));
        }
    }
    else {
        {
            const struct rb_callinfo *callinfo = new_callinfo(iseq, 0, argc, flags, keywords, current_block != ((void *)0));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_invokesuper, 2, (VALUE)(callinfo), (VALUE)(current_block)));
        }
    }
    pm_compile_retry_end_label(iseq, ret, retry_end_l);
    if (popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_pop, 0));
    ISEQ_COMPILE_DATA(iseq)->current_block = previous_block;
    do { VALUE _e = __extension__ ({ const VALUE args_to_new_ary[] = {((CATCH_TYPE_BREAK)), (VALUE)((retry_label)) | 1, (VALUE)((retry_end_l)) | 1, (VALUE)((current_block)), (VALUE)((retry_end_l)) | 1}; if (__builtin_constant_p(5)) { __extension__ _Static_assert(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))) == (5), "rb_ary_new_from_args" ": " "numberof(args_to_new_ary) == (5)"); } rb_ary_new_from_values(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))), args_to_new_ary); }); (((retry_label)) ? ((((retry_label))->refcnt++), ((retry_label))->unremovable=1) : 0); (((retry_end_l))->refcnt++); (((retry_end_l))->refcnt++); if (RB_NIL_P(ISEQ_COMPILE_DATA(iseq)->catch_table_ary)) (rb_obj_write((VALUE)(iseq), (VALUE *)(&ISEQ_COMPILE_DATA(iseq)->catch_table_ary), (VALUE)(rb_ary_hidden_new(3)), "prism_compile.c", 8148)); rb_ary_push(ISEQ_COMPILE_DATA(iseq)->catch_table_ary, freeze_hide_obj(_e)); } while (0);
}
static inline void
pm_compile_yield_node(rb_iseq_t *iseq, const pm_yield_node_t *node, const pm_node_location_t *location, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node)
{
    switch (((((iseq)->body)->local_iseq)->body)->type) {
      case ISEQ_TYPE_TOP:
      case ISEQ_TYPE_MAIN:
      case ISEQ_TYPE_CLASS:
        append_compile_error(iseq, location->line, "Invalid yield");
        return;
      default: ;
    }
    int argc = 0;
    int flags = 0;
    struct rb_callinfo_kwarg *keywords = ((void *)0);
    if (node->arguments) {
        argc = pm_setup_args(node->arguments, ((void *)0), &flags, &keywords, iseq, ret, scope_node, location);
    }
    const struct rb_callinfo *callinfo = new_callinfo(iseq, 0, argc, flags, keywords, 0);
    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_invokeblock, 1, (VALUE)(callinfo)));
    iseq_set_use_block(((iseq)->body)->local_iseq);
    if (popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (*location).line, (int) (*location).node_id, YARVINSN_pop, 0));
    int level = 0;
    for (const rb_iseq_t *tmp_iseq = iseq; tmp_iseq != ((iseq)->body)->local_iseq; level++) {
        tmp_iseq = ((tmp_iseq)->body)->parent_iseq;
    }
    if (level > 0) access_outer_variables(iseq, level, (__builtin_constant_p("yield") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("yield")); }) : (rb_intern)("yield")), 1);
}
static void
pm_compile_node(rb_iseq_t *iseq, const pm_node_t *node, LINK_ANCHOR *const ret, _Bool popped, pm_scope_node_t *scope_node)
{
    const pm_parser_t *parser = scope_node->parser;
    const pm_node_location_t location = ((pm_node_location_t) { .line = pm_newline_list_line(&(parser)->newline_list, ((const pm_node_t *) (node))->location.start, (parser)->start_line), .node_id = ((const pm_node_t *) (node))->node_id });
    int lineno = (int) location.line;
    if ((((enum pm_node_type) (node)->type) == (PM_BEGIN_NODE)) && (((const pm_begin_node_t *) node)->statements == ((void *)0)) && (((const pm_begin_node_t *) node)->rescue_clause != ((void *)0))) {
        lineno = (int) pm_newline_list_line_column(&(parser)->newline_list, ((const pm_node_t *) (((const pm_begin_node_t *) node)->rescue_clause))->location.start, (parser)->start_line).line;
    }
    if (((((pm_node_t *)(node))->flags & (PM_NODE_FLAG_NEWLINE)) != 0) && ISEQ_COMPILE_DATA(iseq)->last_line != lineno) {
        int event = 0x0001;
        ISEQ_COMPILE_DATA(iseq)->last_line = lineno;
        if (((iseq)->body)->variable.coverage && RARRAY_AREF(((iseq)->body)->variable.coverage, 0)) {
            event |= 0x010000;
        }
        ADD_ELEM((ret), (LINK_ELEMENT *) new_trace_body(iseq, (event), 0));
    }
    switch (((enum pm_node_type) (node)->type)) {
      case PM_ALIAS_GLOBAL_VARIABLE_NODE:
        pm_compile_alias_global_variable_node(iseq, (const pm_alias_global_variable_node_t *) node, &location, ret, popped, scope_node);
        return;
      case PM_ALIAS_METHOD_NODE:
        pm_compile_alias_method_node(iseq, (const pm_alias_method_node_t *) node, &location, ret, popped, scope_node);
        return;
      case PM_AND_NODE:
        pm_compile_and_node(iseq, (const pm_and_node_t *) node, &location, ret, popped, scope_node);
        return;
      case PM_ARGUMENTS_NODE: {
        const pm_arguments_node_t *cast = (const pm_arguments_node_t *) node;
        const pm_node_list_t *elements = &cast->arguments;
        if (elements->size == 1) {
            pm_compile_node(iseq, (elements->nodes[0]), ret, popped, scope_node);
        }
        else {
            pm_compile_array_node(iseq, (const pm_node_t *) cast, elements, &location, ret, popped, scope_node);
        }
        return;
      }
      case PM_ARRAY_NODE: {
        const pm_array_node_t *cast = (const pm_array_node_t *) node;
        pm_compile_array_node(iseq, (const pm_node_t *) cast, &cast->elements, &location, ret, popped, scope_node);
        return;
      }
      case PM_ASSOC_NODE: {
        const pm_assoc_node_t *cast = (const pm_assoc_node_t *) node;
        pm_compile_node(iseq, (cast->key), ret, popped, scope_node);
        pm_compile_node(iseq, (cast->value), ret, popped, scope_node);
        return;
      }
      case PM_ASSOC_SPLAT_NODE: {
        const pm_assoc_splat_node_t *cast = (const pm_assoc_splat_node_t *) node;
        if (cast->value != ((void *)0)) {
            pm_compile_node(iseq, (cast->value), ret, popped, scope_node);
        }
        else if (!popped) {
            pm_local_index_t index = pm_lookup_local_index(iseq, scope_node, ((pm_constant_id_t)(idPow | ((pm_constant_id_t)(1 << 31)))), 0);
            pm_iseq_add_getlocal(iseq, (ret), (int) (location).line, (int) (location).node_id, (index.index), (index.level));
        }
        return;
      }
      case PM_BACK_REFERENCE_READ_NODE: {
        if (!popped) {
            char *char_ptr = (char *)(node->location.start) + 1;
            ID backref_val = __builtin_choose_expr( __builtin_constant_p(rb_intern2(char_ptr, 1)), ((VALUE)(rb_intern2(char_ptr, 1))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(rb_intern2(char_ptr, 1))) << 1 | 1;
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_getspecial, 2, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1))), (VALUE)(backref_val)));
        }
        return;
      }
      case PM_BEGIN_NODE: {
        const pm_begin_node_t *cast = (const pm_begin_node_t *) node;
        if (cast->ensure_clause) {
            pm_compile_ensure(iseq, cast, &location, ret, popped, scope_node);
        }
        else if (cast->rescue_clause) {
            pm_compile_rescue(iseq, cast, &location, ret, popped, scope_node);
        }
        else {
            if (cast->statements != ((void *)0)) {
                pm_compile_node(iseq, ((const pm_node_t *) cast->statements), ret, popped, scope_node);
            }
            else if (!popped) {
                do { int lineno = ISEQ_COMPILE_DATA(iseq)->last_line; if (lineno == 0) lineno = RB_FIX2INT(rb_iseq_first_lineno(iseq)); ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (lineno), (-1), YARVINSN_putnil, 0)); } while (0);
            }
        }
        return;
      }
      case PM_BLOCK_ARGUMENT_NODE: {
        const pm_block_argument_node_t *cast = (const pm_block_argument_node_t *) node;
        if (cast->expression != ((void *)0)) {
            pm_compile_node(iseq, (cast->expression), ret, popped, scope_node);
        }
        else {
            pm_local_index_t local_index = pm_lookup_local_index(iseq, scope_node, ((pm_constant_id_t)(idAnd | ((pm_constant_id_t)(1 << 31)))), 0);
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_getblockparamproxy, 2, (VALUE)(__builtin_choose_expr( __builtin_constant_p(local_index.index + ( 3) - 1), ((VALUE)(local_index.index + ( 3) - 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(local_index.index + ( 3) - 1))), (VALUE)(__builtin_choose_expr( __builtin_constant_p(local_index.level), ((VALUE)(local_index.level)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(local_index.level)))));
        }
        return;
      }
      case PM_BREAK_NODE:
        pm_compile_break_node(iseq, (const pm_break_node_t *) node, &location, ret, popped, scope_node);
        return;
      case PM_CALL_NODE:
        pm_compile_call_node(iseq, (const pm_call_node_t *) node, ret, popped, scope_node);
        return;
      case PM_CALL_AND_WRITE_NODE: {
        const pm_call_and_write_node_t *cast = (const pm_call_and_write_node_t *) node;
        pm_compile_call_and_or_write_node(iseq, 1, cast->receiver, cast->value, cast->write_name, cast->read_name, ((((pm_node_t *)(cast))->flags & (PM_CALL_NODE_FLAGS_SAFE_NAVIGATION)) != 0), &location, ret, popped, scope_node);
        return;
      }
      case PM_CALL_OR_WRITE_NODE: {
        const pm_call_or_write_node_t *cast = (const pm_call_or_write_node_t *) node;
        pm_compile_call_and_or_write_node(iseq, 0, cast->receiver, cast->value, cast->write_name, cast->read_name, ((((pm_node_t *)(cast))->flags & (PM_CALL_NODE_FLAGS_SAFE_NAVIGATION)) != 0), &location, ret, popped, scope_node);
        return;
      }
      case PM_CALL_OPERATOR_WRITE_NODE:
        pm_compile_call_operator_write_node(iseq, (const pm_call_operator_write_node_t *) node, &location, ret, popped, scope_node);
        return;
      case PM_CASE_NODE:
        pm_compile_case_node(iseq, (const pm_case_node_t *) node, &location, ret, popped, scope_node);
        return;
      case PM_CASE_MATCH_NODE:
        pm_compile_case_match_node(iseq, (const pm_case_match_node_t *) node, &location, ret, popped, scope_node);
        return;
      case PM_CLASS_NODE: {
        const pm_class_node_t *cast = (const pm_class_node_t *) node;
        ID class_id = pm_constant_id_lookup(scope_node, cast->name);
        VALUE class_name = rb_str_freeze(rb_sprintf("<class:%""l""i" "\v"">", rb_id2str(class_id)));
        pm_scope_node_t next_scope_node;
        pm_scope_node_init((const pm_node_t *) cast, &next_scope_node, scope_node);
        const rb_iseq_t *class_iseq = pm_new_child_iseq(iseq, (&next_scope_node), rb_fstring(class_name), iseq, (ISEQ_TYPE_CLASS), (location.line));
        pm_scope_node_destroy(&next_scope_node);
        const int flags = VM_DEFINECLASS_TYPE_CLASS |
            (cast->superclass ? 0x10 : 0) |
            pm_compile_class_path(iseq, cast->constant_path, &location, ret, 0, scope_node);
        if (cast->superclass) {
            pm_compile_node(iseq, (cast->superclass), ret, 0, scope_node);
        }
        else {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
        }
        {
            VALUE operand = rb_id2sym(class_id);
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_defineclass, 3, (VALUE)(operand), (VALUE)(class_iseq), (VALUE)(__builtin_choose_expr( __builtin_constant_p(flags), ((VALUE)(flags)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(flags)))));
        }
        (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)((VALUE)class_iseq), "prism_compile.c", 8441));
        if (popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        return;
      }
      case PM_CLASS_VARIABLE_AND_WRITE_NODE: {
        const pm_class_variable_and_write_node_t *cast = (const pm_class_variable_and_write_node_t *) node;
        LABEL *end_label = new_label_body(iseq, (location.line));
        ID name_id = pm_constant_id_lookup(scope_node, cast->name);
        VALUE name = rb_id2sym(name_id);
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_getclassvariable, 2, (VALUE)(name), (VALUE)(get_cvar_ic_value(iseq, name_id))));
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(end_label))), ((end_label)->refcnt++));
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        pm_compile_node(iseq, (cast->value), ret, 0, scope_node);
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setclassvariable, 2, (VALUE)(name), (VALUE)(get_cvar_ic_value(iseq, name_id))));
        ADD_ELEM((ret), (LINK_ELEMENT *) (end_label));
        return;
      }
      case PM_CLASS_VARIABLE_OPERATOR_WRITE_NODE: {
        const pm_class_variable_operator_write_node_t *cast = (const pm_class_variable_operator_write_node_t *) node;
        ID name_id = pm_constant_id_lookup(scope_node, cast->name);
        VALUE name = rb_id2sym(name_id);
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_getclassvariable, 2, (VALUE)(name), (VALUE)(get_cvar_ic_value(iseq, name_id))));
        pm_compile_node(iseq, (cast->value), ret, 0, scope_node);
        ID method_id = pm_constant_id_lookup(scope_node, cast->binary_operator);
        int flags = (0x01 << VM_CALL_ARGS_SIMPLE_bit);
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((method_id)), (VALUE)((rb_int2num_inline(1))), (((void *)0)), (VALUE)((VALUE)(__builtin_choose_expr( __builtin_constant_p(flags), ((VALUE)(flags)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(flags)))), (((void *)0))));
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setclassvariable, 2, (VALUE)(name), (VALUE)(get_cvar_ic_value(iseq, name_id))));
        return;
      }
      case PM_CLASS_VARIABLE_OR_WRITE_NODE: {
        const pm_class_variable_or_write_node_t *cast = (const pm_class_variable_or_write_node_t *) node;
        LABEL *end_label = new_label_body(iseq, (location.line));
        LABEL *start_label = new_label_body(iseq, (location.line));
        ID name_id = pm_constant_id_lookup(scope_node, cast->name);
        VALUE name = rb_id2sym(name_id);
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_defined, 3, (VALUE)(__builtin_choose_expr( __builtin_constant_p(DEFINED_CVAR), ((VALUE)(DEFINED_CVAR)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(DEFINED_CVAR))), (VALUE)(name), (VALUE)(((VALUE)RUBY_Qtrue))));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(start_label))), ((start_label)->refcnt++));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_getclassvariable, 2, (VALUE)(name), (VALUE)(get_cvar_ic_value(iseq, name_id))));
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchif, 1, (VALUE)(end_label))), ((end_label)->refcnt++));
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) (start_label));
        pm_compile_node(iseq, (cast->value), ret, 0, scope_node);
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setclassvariable, 2, (VALUE)(name), (VALUE)(get_cvar_ic_value(iseq, name_id))));
        ADD_ELEM((ret), (LINK_ELEMENT *) (end_label));
        return;
      }
      case PM_CLASS_VARIABLE_READ_NODE: {
        if (!popped) {
            const pm_class_variable_read_node_t *cast = (const pm_class_variable_read_node_t *) node;
            ID name = pm_constant_id_lookup(scope_node, cast->name);
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_getclassvariable, 2, (VALUE)(rb_id2sym(name)), (VALUE)(get_cvar_ic_value(iseq, name))));
        }
        return;
      }
      case PM_CLASS_VARIABLE_WRITE_NODE: {
        const pm_class_variable_write_node_t *cast = (const pm_class_variable_write_node_t *) node;
        pm_compile_node(iseq, (cast->value), ret, 0, scope_node);
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
        ID name = pm_constant_id_lookup(scope_node, cast->name);
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setclassvariable, 2, (VALUE)(rb_id2sym(name)), (VALUE)(get_cvar_ic_value(iseq, name))));
        return;
      }
      case PM_CONSTANT_PATH_NODE: {
        VALUE parts;
        if (ISEQ_COMPILE_DATA(iseq)->option->inline_const_cache && ((parts = pm_constant_path_parts(node, scope_node)) != ((VALUE)RUBY_Qnil))) {
            ((iseq)->body)->ic_size++;
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_opt_getconstant_path, 1, (VALUE)(parts)));
        }
        else {
            LINK_ANCHOR prefix[1] = {{{ISEQ_ELEMENT_ANCHOR,},&prefix[0].anchor}};
            LINK_ANCHOR body[1] = {{{ISEQ_ELEMENT_ANCHOR,},&body[0].anchor}};
            pm_compile_constant_path(iseq, node, prefix, body, popped, scope_node);
            if (LIST_INSN_SIZE_ZERO(prefix)) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
            }
            else {
                APPEND_LIST((ret), (prefix));
            }
            APPEND_LIST((ret), (body));
        }
        if (popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        return;
      }
      case PM_CONSTANT_PATH_AND_WRITE_NODE: {
        const pm_constant_path_and_write_node_t *cast = (const pm_constant_path_and_write_node_t *) node;
        pm_compile_constant_path_and_write_node(iseq, cast, 0, &location, ret, popped, scope_node);
        return;
      }
      case PM_CONSTANT_PATH_OR_WRITE_NODE: {
        const pm_constant_path_or_write_node_t *cast = (const pm_constant_path_or_write_node_t *) node;
        pm_compile_constant_path_or_write_node(iseq, cast, 0, &location, ret, popped, scope_node);
        return;
      }
      case PM_CONSTANT_PATH_OPERATOR_WRITE_NODE: {
        const pm_constant_path_operator_write_node_t *cast = (const pm_constant_path_operator_write_node_t *) node;
        pm_compile_constant_path_operator_write_node(iseq, cast, 0, &location, ret, popped, scope_node);
        return;
      }
      case PM_CONSTANT_PATH_WRITE_NODE: {
        const pm_constant_path_write_node_t *cast = (const pm_constant_path_write_node_t *) node;
        pm_compile_constant_path_write_node(iseq, cast, 0, &location, ret, popped, scope_node);
        return;
      }
      case PM_CONSTANT_READ_NODE: {
        const pm_constant_read_node_t *cast = (const pm_constant_read_node_t *) node;
        VALUE name = rb_id2sym(pm_constant_id_lookup(scope_node, cast->name));
        pm_compile_constant_read(iseq, name, &cast->base.location, location.node_id, ret, scope_node);
        if (popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        return;
      }
      case PM_CONSTANT_AND_WRITE_NODE: {
        const pm_constant_and_write_node_t *cast = (const pm_constant_and_write_node_t *) node;
        pm_compile_constant_and_write_node(iseq, cast, 0, &location, ret, popped, scope_node);
        return;
      }
      case PM_CONSTANT_OR_WRITE_NODE: {
        const pm_constant_or_write_node_t *cast = (const pm_constant_or_write_node_t *) node;
        pm_compile_constant_or_write_node(iseq, cast, 0, &location, ret, popped, scope_node);
        return;
      }
      case PM_CONSTANT_OPERATOR_WRITE_NODE: {
        const pm_constant_operator_write_node_t *cast = (const pm_constant_operator_write_node_t *) node;
        pm_compile_constant_operator_write_node(iseq, cast, 0, &location, ret, popped, scope_node);
        return;
      }
      case PM_CONSTANT_WRITE_NODE: {
        const pm_constant_write_node_t *cast = (const pm_constant_write_node_t *) node;
        pm_compile_constant_write_node(iseq, cast, 0, &location, ret, popped, scope_node);
        return;
      }
      case PM_DEF_NODE: {
        const pm_def_node_t *cast = (const pm_def_node_t *) node;
        ID method_name = pm_constant_id_lookup(scope_node, cast->name);
        pm_scope_node_t next_scope_node;
        pm_scope_node_init((const pm_node_t *) cast, &next_scope_node, scope_node);
        rb_iseq_t *method_iseq = pm_new_child_iseq(iseq, (&next_scope_node), rb_fstring(rb_id2str(method_name)), 0, (ISEQ_TYPE_METHOD), (location.line));
        pm_scope_node_destroy(&next_scope_node);
        if (cast->receiver) {
            pm_compile_node(iseq, (cast->receiver), ret, 0, scope_node);
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_definesmethod, 2, (VALUE)(rb_id2sym(method_name)), (VALUE)(method_iseq)));
        }
        else {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_definemethod, 2, (VALUE)(rb_id2sym(method_name)), (VALUE)(method_iseq)));
        }
        (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)((VALUE) method_iseq), "prism_compile.c", 8656));
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(rb_id2sym(method_name))));
        }
        return;
      }
      case PM_DEFINED_NODE: {
        const pm_defined_node_t *cast = (const pm_defined_node_t *) node;
        pm_compile_defined_expr(iseq, cast->value, &location, ret, popped, scope_node, 0);
        return;
      }
      case PM_EMBEDDED_STATEMENTS_NODE: {
        const pm_embedded_statements_node_t *cast = (const pm_embedded_statements_node_t *) node;
        if (cast->statements != ((void *)0)) {
            pm_compile_node(iseq, ((const pm_node_t *) (cast->statements)), ret, popped, scope_node);
        }
        else {
            do { int lineno = ISEQ_COMPILE_DATA(iseq)->last_line; if (lineno == 0) lineno = RB_FIX2INT(rb_iseq_first_lineno(iseq)); ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (lineno), (-1), YARVINSN_putnil, 0)); } while (0);
        }
        if (popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        return;
      }
      case PM_EMBEDDED_VARIABLE_NODE: {
        const pm_embedded_variable_node_t *cast = (const pm_embedded_variable_node_t *) node;
        pm_compile_node(iseq, (cast->variable), ret, popped, scope_node);
        return;
      }
      case PM_FALSE_NODE: {
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qfalse))));
        }
        return;
      }
      case PM_ENSURE_NODE: {
        const pm_ensure_node_t *cast = (const pm_ensure_node_t *) node;
        if (cast->statements != ((void *)0)) {
            LABEL *start = new_label_body(iseq, (location.line));
            LABEL *end = new_label_body(iseq, (location.line));
            ADD_ELEM((ret), (LINK_ELEMENT *) (start));
            LABEL *prev_end_label = ISEQ_COMPILE_DATA(iseq)->end_label;
            ISEQ_COMPILE_DATA(iseq)->end_label = end;
            pm_compile_node(iseq, ((const pm_node_t *) cast->statements), ret, popped, scope_node);
            ISEQ_COMPILE_DATA(iseq)->end_label = prev_end_label;
            ADD_ELEM((ret), (LINK_ELEMENT *) (end));
        }
        return;
      }
      case PM_ELSE_NODE: {
        const pm_else_node_t *cast = (const pm_else_node_t *) node;
        if (cast->statements != ((void *)0)) {
            pm_compile_node(iseq, ((const pm_node_t *) cast->statements), ret, popped, scope_node);
        }
        else if (!popped) {
            do { int lineno = ISEQ_COMPILE_DATA(iseq)->last_line; if (lineno == 0) lineno = RB_FIX2INT(rb_iseq_first_lineno(iseq)); ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (lineno), (-1), YARVINSN_putnil, 0)); } while (0);
        }
        return;
      }
      case PM_FLIP_FLOP_NODE: {
        const pm_flip_flop_node_t *cast = (const pm_flip_flop_node_t *) node;
        LABEL *final_label = new_label_body(iseq, (location.line));
        LABEL *then_label = new_label_body(iseq, (location.line));
        LABEL *else_label = new_label_body(iseq, (location.line));
        pm_compile_flip_flop(cast, else_label, then_label, iseq, location.line, ret, popped, scope_node);
        ADD_ELEM((ret), (LINK_ELEMENT *) (then_label));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qtrue))));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_jump, 1, (VALUE)(final_label))), ((final_label)->refcnt++));
        ADD_ELEM((ret), (LINK_ELEMENT *) (else_label));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qfalse))));
        ADD_ELEM((ret), (LINK_ELEMENT *) (final_label));
        return;
      }
      case PM_FLOAT_NODE: {
        if (!popped) {
            VALUE operand = parse_float((const pm_float_node_t *) node);
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(operand)));
        }
        return;
      }
      case PM_FOR_NODE: {
        const pm_for_node_t *cast = (const pm_for_node_t *) node;
        LABEL *retry_label = new_label_body(iseq, (location.line));
        LABEL *retry_end_l = new_label_body(iseq, (location.line));
        ADD_ELEM((ret), (LINK_ELEMENT *) (retry_label));
        pm_compile_node(iseq, (cast->collection), ret, 0, scope_node);
        pm_scope_node_t next_scope_node;
        pm_scope_node_init((const pm_node_t *) cast, &next_scope_node, scope_node);
        const rb_iseq_t *child_iseq = pm_new_child_iseq(iseq, (&next_scope_node), rb_fstring(make_name_for_block(iseq)), iseq, (ISEQ_TYPE_BLOCK), (location.line));
        pm_scope_node_destroy(&next_scope_node);
        const rb_iseq_t *prev_block = ISEQ_COMPILE_DATA(iseq)->current_block;
        ISEQ_COMPILE_DATA(iseq)->current_block = child_iseq;
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((idEach)), (VALUE)((__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))), ((child_iseq)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
        pm_compile_retry_end_label(iseq, ret, retry_end_l);
        if (popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        ISEQ_COMPILE_DATA(iseq)->current_block = prev_block;
        do { VALUE _e = __extension__ ({ const VALUE args_to_new_ary[] = {((CATCH_TYPE_BREAK)), (VALUE)((retry_label)) | 1, (VALUE)((retry_end_l)) | 1, (VALUE)((child_iseq)), (VALUE)((retry_end_l)) | 1}; if (__builtin_constant_p(5)) { __extension__ _Static_assert(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))) == (5), "rb_ary_new_from_args" ": " "numberof(args_to_new_ary) == (5)"); } rb_ary_new_from_values(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))), args_to_new_ary); }); (((retry_label)) ? ((((retry_label))->refcnt++), ((retry_label))->unremovable=1) : 0); (((retry_end_l))->refcnt++); (((retry_end_l))->refcnt++); if (RB_NIL_P(ISEQ_COMPILE_DATA(iseq)->catch_table_ary)) (rb_obj_write((VALUE)(iseq), (VALUE *)(&ISEQ_COMPILE_DATA(iseq)->catch_table_ary), (VALUE)(rb_ary_hidden_new(3)), "prism_compile.c", 8792)); rb_ary_push(ISEQ_COMPILE_DATA(iseq)->catch_table_ary, freeze_hide_obj(_e)); } while (0);
        return;
      }
      case PM_FORWARDING_ARGUMENTS_NODE:
        rb_bug("Cannot compile a ForwardingArgumentsNode directly\n");
        return;
      case PM_FORWARDING_SUPER_NODE:
        pm_compile_forwarding_super_node(iseq, (const pm_forwarding_super_node_t *) node, &location, ret, popped, scope_node);
        return;
      case PM_GLOBAL_VARIABLE_AND_WRITE_NODE: {
        const pm_global_variable_and_write_node_t *cast = (const pm_global_variable_and_write_node_t *) node;
        LABEL *end_label = new_label_body(iseq, (location.line));
        VALUE name = rb_id2sym(pm_constant_id_lookup(scope_node, cast->name));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_getglobal, 1, (VALUE)(name)));
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(end_label))), ((end_label)->refcnt++));
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        pm_compile_node(iseq, (cast->value), ret, 0, scope_node);
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setglobal, 1, (VALUE)(name)));
        ADD_ELEM((ret), (LINK_ELEMENT *) (end_label));
        return;
      }
      case PM_GLOBAL_VARIABLE_OPERATOR_WRITE_NODE: {
        const pm_global_variable_operator_write_node_t *cast = (const pm_global_variable_operator_write_node_t *) node;
        VALUE name = rb_id2sym(pm_constant_id_lookup(scope_node, cast->name));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_getglobal, 1, (VALUE)(name)));
        pm_compile_node(iseq, (cast->value), ret, 0, scope_node);
        ID method_id = pm_constant_id_lookup(scope_node, cast->binary_operator);
        int flags = (0x01 << VM_CALL_ARGS_SIMPLE_bit);
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((method_id)), (VALUE)((rb_int2num_inline(1))), (((void *)0)), (VALUE)((VALUE)(__builtin_choose_expr( __builtin_constant_p(flags), ((VALUE)(flags)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(flags)))), (((void *)0))));
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setglobal, 1, (VALUE)(name)));
        return;
      }
      case PM_GLOBAL_VARIABLE_OR_WRITE_NODE: {
        const pm_global_variable_or_write_node_t *cast = (const pm_global_variable_or_write_node_t *) node;
        LABEL *set_label = new_label_body(iseq, (location.line));
        LABEL *end_label = new_label_body(iseq, (location.line));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
        VALUE name = rb_id2sym(pm_constant_id_lookup(scope_node, cast->name));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_defined, 3, (VALUE)(__builtin_choose_expr( __builtin_constant_p(DEFINED_GVAR), ((VALUE)(DEFINED_GVAR)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(DEFINED_GVAR))), (VALUE)(name), (VALUE)(((VALUE)RUBY_Qtrue))));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(set_label))), ((set_label)->refcnt++));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_getglobal, 1, (VALUE)(name)));
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchif, 1, (VALUE)(end_label))), ((end_label)->refcnt++));
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) (set_label));
        pm_compile_node(iseq, (cast->value), ret, 0, scope_node);
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setglobal, 1, (VALUE)(name)));
        ADD_ELEM((ret), (LINK_ELEMENT *) (end_label));
        return;
      }
      case PM_GLOBAL_VARIABLE_READ_NODE: {
        const pm_global_variable_read_node_t *cast = (const pm_global_variable_read_node_t *) node;
        VALUE name = rb_id2sym(pm_constant_id_lookup(scope_node, cast->name));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_getglobal, 1, (VALUE)(name)));
        if (popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        return;
      }
      case PM_GLOBAL_VARIABLE_WRITE_NODE: {
        const pm_global_variable_write_node_t *cast = (const pm_global_variable_write_node_t *) node;
        pm_compile_node(iseq, (cast->value), ret, 0, scope_node);
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
        ID name = pm_constant_id_lookup(scope_node, cast->name);
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setglobal, 1, (VALUE)(rb_id2sym(name))));
        return;
      }
      case PM_HASH_NODE: {
        if (((((pm_node_t *)(node))->flags & (PM_NODE_FLAG_STATIC_LITERAL)) != 0)) {
            if (!popped) {
                const pm_hash_node_t *cast = (const pm_hash_node_t *) node;
                if (cast->elements.size == 0) {
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_newhash, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))));
                }
                else {
                    VALUE value = pm_static_literal_value(iseq, node, scope_node);
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_duphash, 1, (VALUE)(value)));
                    (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)(value), "prism_compile.c", 8915));
                }
            }
        }
        else {
            const pm_hash_node_t *cast = (const pm_hash_node_t *) node;
            const pm_node_list_t *elements = &cast->elements;
            if (popped) {
                for (size_t index = 0; index < elements->size; index++) {
                    pm_compile_node(iseq, (elements->nodes[index]), ret, 1, scope_node);
                }
            }
            else {
                pm_compile_hash_elements(iseq, node, elements, 0, ret, scope_node);
            }
        }
        return;
      }
      case PM_IF_NODE: {
        const pm_if_node_t *cast = (const pm_if_node_t *) node;
        pm_compile_conditional(iseq, &location, PM_IF_NODE, (const pm_node_t *) cast, cast->statements, cast->subsequent, cast->predicate, ret, popped, scope_node);
        return;
      }
      case PM_IMAGINARY_NODE: {
        if (!popped) {
            VALUE operand = parse_imaginary((const pm_imaginary_node_t *) node);
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(operand)));
        }
        return;
      }
      case PM_IMPLICIT_NODE: {
        const pm_implicit_node_t *cast = (const pm_implicit_node_t *) node;
        pm_compile_node(iseq, (cast->value), ret, popped, scope_node);
        return;
      }
      case PM_IN_NODE: {
        rb_bug("Should not ever enter an in node directly");
        return;
      }
      case PM_INDEX_OPERATOR_WRITE_NODE: {
        const pm_index_operator_write_node_t *cast = (const pm_index_operator_write_node_t *) node;
        pm_compile_index_operator_write_node(iseq, cast, &location, ret, popped, scope_node);
        return;
      }
      case PM_INDEX_AND_WRITE_NODE: {
        const pm_index_and_write_node_t *cast = (const pm_index_and_write_node_t *) node;
        pm_compile_index_control_flow_write_node(iseq, node, cast->receiver, cast->arguments, cast->block, cast->value, &location, ret, popped, scope_node);
        return;
      }
      case PM_INDEX_OR_WRITE_NODE: {
        const pm_index_or_write_node_t *cast = (const pm_index_or_write_node_t *) node;
        pm_compile_index_control_flow_write_node(iseq, node, cast->receiver, cast->arguments, cast->block, cast->value, &location, ret, popped, scope_node);
        return;
      }
      case PM_INSTANCE_VARIABLE_AND_WRITE_NODE: {
        const pm_instance_variable_and_write_node_t *cast = (const pm_instance_variable_and_write_node_t *) node;
        LABEL *end_label = new_label_body(iseq, (location.line));
        ID name_id = pm_constant_id_lookup(scope_node, cast->name);
        VALUE name = rb_id2sym(name_id);
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_getinstancevariable, 2, (VALUE)(name), (VALUE)(get_ivar_ic_value(iseq, name_id))));
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(end_label))), ((end_label)->refcnt++));
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        pm_compile_node(iseq, (cast->value), ret, 0, scope_node);
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setinstancevariable, 2, (VALUE)(name), (VALUE)(get_ivar_ic_value(iseq, name_id))));
        ADD_ELEM((ret), (LINK_ELEMENT *) (end_label));
        return;
      }
      case PM_INSTANCE_VARIABLE_OPERATOR_WRITE_NODE: {
        const pm_instance_variable_operator_write_node_t *cast = (const pm_instance_variable_operator_write_node_t *) node;
        ID name_id = pm_constant_id_lookup(scope_node, cast->name);
        VALUE name = rb_id2sym(name_id);
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_getinstancevariable, 2, (VALUE)(name), (VALUE)(get_ivar_ic_value(iseq, name_id))));
        pm_compile_node(iseq, (cast->value), ret, 0, scope_node);
        ID method_id = pm_constant_id_lookup(scope_node, cast->binary_operator);
        int flags = (0x01 << VM_CALL_ARGS_SIMPLE_bit);
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((method_id)), (VALUE)((rb_int2num_inline(1))), (((void *)0)), (VALUE)((VALUE)(__builtin_choose_expr( __builtin_constant_p(flags), ((VALUE)(flags)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(flags)))), (((void *)0))));
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setinstancevariable, 2, (VALUE)(name), (VALUE)(get_ivar_ic_value(iseq, name_id))));
        return;
      }
      case PM_INSTANCE_VARIABLE_OR_WRITE_NODE: {
        const pm_instance_variable_or_write_node_t *cast = (const pm_instance_variable_or_write_node_t *) node;
        LABEL *end_label = new_label_body(iseq, (location.line));
        ID name_id = pm_constant_id_lookup(scope_node, cast->name);
        VALUE name = rb_id2sym(name_id);
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_getinstancevariable, 2, (VALUE)(name), (VALUE)(get_ivar_ic_value(iseq, name_id))));
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchif, 1, (VALUE)(end_label))), ((end_label)->refcnt++));
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        pm_compile_node(iseq, (cast->value), ret, 0, scope_node);
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setinstancevariable, 2, (VALUE)(name), (VALUE)(get_ivar_ic_value(iseq, name_id))));
        ADD_ELEM((ret), (LINK_ELEMENT *) (end_label));
        return;
      }
      case PM_INSTANCE_VARIABLE_READ_NODE: {
        if (!popped) {
            const pm_instance_variable_read_node_t *cast = (const pm_instance_variable_read_node_t *) node;
            ID name = pm_constant_id_lookup(scope_node, cast->name);
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_getinstancevariable, 2, (VALUE)(rb_id2sym(name)), (VALUE)(get_ivar_ic_value(iseq, name))));
        }
        return;
      }
      case PM_INSTANCE_VARIABLE_WRITE_NODE: {
        const pm_instance_variable_write_node_t *cast = (const pm_instance_variable_write_node_t *) node;
        pm_compile_node(iseq, (cast->value), ret, 0, scope_node);
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
        ID name = pm_constant_id_lookup(scope_node, cast->name);
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setinstancevariable, 2, (VALUE)(rb_id2sym(name)), (VALUE)(get_ivar_ic_value(iseq, name))));
        return;
      }
      case PM_INTEGER_NODE: {
        if (!popped) {
            VALUE operand = parse_integer((const pm_integer_node_t *) node);
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(operand)));
        }
        return;
      }
      case PM_INTERPOLATED_MATCH_LAST_LINE_NODE: {
        if (((((pm_node_t *)(node))->flags & (PM_NODE_FLAG_STATIC_LITERAL)) != 0)) {
            if (!popped) {
                VALUE regexp = pm_static_literal_value(iseq, node, scope_node);
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(regexp)));
            }
        }
        else {
            pm_compile_regexp_dynamic(iseq, node, &((const pm_interpolated_match_last_line_node_t *) node)->parts, &location, ret, popped, scope_node);
        }
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_getglobal, 1, (VALUE)(rb_id2sym(idLASTLINE))));
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((idEqTilde)), (VALUE)((rb_int2num_inline(1))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
        if (popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        return;
      }
      case PM_INTERPOLATED_REGULAR_EXPRESSION_NODE: {
        if (((((pm_node_t *)(node))->flags & (PM_REGULAR_EXPRESSION_FLAGS_ONCE)) != 0)) {
            const rb_iseq_t *prevblock = ISEQ_COMPILE_DATA(iseq)->current_block;
            const rb_iseq_t *block_iseq = ((void *)0);
            int ise_index = ((iseq)->body)->ise_size++;
            pm_scope_node_t next_scope_node;
            pm_scope_node_init(node, &next_scope_node, scope_node);
            block_iseq = pm_new_child_iseq(iseq, (&next_scope_node), rb_fstring(make_name_for_block(iseq)), iseq, (ISEQ_TYPE_PLAIN), (location.line));
            pm_scope_node_destroy(&next_scope_node);
            ISEQ_COMPILE_DATA(iseq)->current_block = block_iseq;
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_once, 2, (VALUE)(block_iseq), (VALUE)(__builtin_choose_expr( __builtin_constant_p(ise_index), ((VALUE)(ise_index)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(ise_index)))));
            ISEQ_COMPILE_DATA(iseq)->current_block = prevblock;
            if (popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
            return;
        }
        if (((((pm_node_t *)(node))->flags & (PM_NODE_FLAG_STATIC_LITERAL)) != 0)) {
            if (!popped) {
                VALUE regexp = pm_static_literal_value(iseq, node, scope_node);
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(regexp)));
            }
        }
        else {
            pm_compile_regexp_dynamic(iseq, node, &((const pm_interpolated_regular_expression_node_t *) node)->parts, &location, ret, popped, scope_node);
            if (popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        }
        return;
      }
      case PM_INTERPOLATED_STRING_NODE: {
        if (((((pm_node_t *)(node))->flags & (PM_NODE_FLAG_STATIC_LITERAL)) != 0)) {
            if (!popped) {
                VALUE string = pm_static_literal_value(iseq, node, scope_node);
                if (((((pm_node_t *)(node))->flags & (PM_INTERPOLATED_STRING_NODE_FLAGS_FROZEN)) != 0)) {
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(string)));
                }
                else if (((((pm_node_t *)(node))->flags & (PM_INTERPOLATED_STRING_NODE_FLAGS_MUTABLE)) != 0)) {
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putstring, 1, (VALUE)(string)));
                }
                else {
                    ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putchilledstring, 1, (VALUE)(string)));
                }
            }
        }
        else {
            const pm_interpolated_string_node_t *cast = (const pm_interpolated_string_node_t *) node;
            int length = pm_interpolated_node_compile(iseq, &cast->parts, &location, ret, popped, scope_node, ((void *)0), ((void *)0));
            if (length > 1) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_concatstrings, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(length), ((VALUE)(length)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(length)))));
            if (popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        }
        return;
      }
      case PM_INTERPOLATED_SYMBOL_NODE: {
        const pm_interpolated_symbol_node_t *cast = (const pm_interpolated_symbol_node_t *) node;
        int length = pm_interpolated_node_compile(iseq, &cast->parts, &location, ret, popped, scope_node, ((void *)0), ((void *)0));
        if (length > 1) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_concatstrings, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(length), ((VALUE)(length)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(length)))));
        }
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_intern, 0));
        }
        else {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        }
        return;
      }
      case PM_INTERPOLATED_X_STRING_NODE: {
        const pm_interpolated_x_string_node_t *cast = (const pm_interpolated_x_string_node_t *) node;
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putself, 0));
        int length = pm_interpolated_node_compile(iseq, &cast->parts, &location, ret, 0, scope_node, ((void *)0), ((void *)0));
        if (length > 1) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_concatstrings, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(length), ((VALUE)(length)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(length)))));
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((idBackquote)), (VALUE)((rb_int2num_inline(1))), (((void *)0)), (VALUE)((VALUE)(__builtin_choose_expr( __builtin_constant_p((0x01 << VM_CALL_FCALL_bit) | (0x01 << VM_CALL_ARGS_SIMPLE_bit)), ((VALUE)((0x01 << VM_CALL_FCALL_bit) | (0x01 << VM_CALL_ARGS_SIMPLE_bit))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((0x01 << VM_CALL_FCALL_bit) | (0x01 << VM_CALL_ARGS_SIMPLE_bit))))), (((void *)0))));
        if (popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        return;
      }
      case PM_IT_LOCAL_VARIABLE_READ_NODE: {
        if (!popped) {
            pm_iseq_add_getlocal(iseq, (ret), (int) (location).line, (int) (location).node_id, (scope_node->local_table_for_iseq_size), (0));
        }
        return;
      }
      case PM_KEYWORD_HASH_NODE: {
        const pm_keyword_hash_node_t *cast = (const pm_keyword_hash_node_t *) node;
        const pm_node_list_t *elements = &cast->elements;
        const pm_node_t *element;
        for (size_t index = 0; index < (elements)->size && ((element) = (elements)->nodes[index]); index++) {
            pm_compile_node(iseq, (element), ret, popped, scope_node);
        }
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_newhash, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(elements->size * 2), ((VALUE)(elements->size * 2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(elements->size * 2)))));
        return;
      }
      case PM_LAMBDA_NODE: {
        const pm_lambda_node_t *cast = (const pm_lambda_node_t *) node;
        pm_scope_node_t next_scope_node;
        pm_scope_node_init(node, &next_scope_node, scope_node);
        int opening_lineno = pm_location_line_number(parser, &cast->opening_loc);
        const rb_iseq_t *block = pm_new_child_iseq(iseq, (&next_scope_node), rb_fstring(make_name_for_block(iseq)), iseq, (ISEQ_TYPE_BLOCK), (opening_lineno));
        pm_scope_node_destroy(&next_scope_node);
        VALUE argc = __builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((idLambda)), (VALUE)((argc)), ((block)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p((0x01 << VM_CALL_FCALL_bit)), ((VALUE)((0x01 << VM_CALL_FCALL_bit))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((0x01 << VM_CALL_FCALL_bit)))), (((void *)0))));
        (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)((VALUE) block), "prism_compile.c", 9258));
        if (popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        return;
      }
      case PM_LOCAL_VARIABLE_AND_WRITE_NODE: {
        const pm_local_variable_and_write_node_t *cast = (const pm_local_variable_and_write_node_t *) node;
        LABEL *end_label = new_label_body(iseq, (location.line));
        pm_local_index_t local_index = pm_lookup_local_index(iseq, scope_node, cast->name, cast->depth);
        pm_iseq_add_getlocal(iseq, (ret), (int) (location).line, (int) (location).node_id, (local_index.index), (local_index.level));
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(end_label))), ((end_label)->refcnt++));
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        pm_compile_node(iseq, (cast->value), ret, 0, scope_node);
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
        pm_iseq_add_setlocal(iseq, (ret), (int) (location).line, (int) (location).node_id, (local_index.index), (local_index.level));
        ADD_ELEM((ret), (LINK_ELEMENT *) (end_label));
        return;
      }
      case PM_LOCAL_VARIABLE_OPERATOR_WRITE_NODE: {
        const pm_local_variable_operator_write_node_t *cast = (const pm_local_variable_operator_write_node_t *) node;
        pm_local_index_t local_index = pm_lookup_local_index(iseq, scope_node, cast->name, cast->depth);
        pm_iseq_add_getlocal(iseq, (ret), (int) (location).line, (int) (location).node_id, (local_index.index), (local_index.level));
        pm_compile_node(iseq, (cast->value), ret, 0, scope_node);
        ID method_id = pm_constant_id_lookup(scope_node, cast->binary_operator);
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((method_id)), (VALUE)((rb_int2num_inline(1))), (((void *)0)), (VALUE)((VALUE)(__builtin_choose_expr( __builtin_constant_p((0x01 << VM_CALL_ARGS_SIMPLE_bit)), ((VALUE)((0x01 << VM_CALL_ARGS_SIMPLE_bit))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((0x01 << VM_CALL_ARGS_SIMPLE_bit))))), (((void *)0))));
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
        pm_iseq_add_setlocal(iseq, (ret), (int) (location).line, (int) (location).node_id, (local_index.index), (local_index.level));
        return;
      }
      case PM_LOCAL_VARIABLE_OR_WRITE_NODE: {
        const pm_local_variable_or_write_node_t *cast = (const pm_local_variable_or_write_node_t *) node;
        LABEL *set_label = new_label_body(iseq, (location.line));
        LABEL *end_label = new_label_body(iseq, (location.line));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qtrue))));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchunless, 1, (VALUE)(set_label))), ((set_label)->refcnt++));
        pm_local_index_t local_index = pm_lookup_local_index(iseq, scope_node, cast->name, cast->depth);
        pm_iseq_add_getlocal(iseq, (ret), (int) (location).line, (int) (location).node_id, (local_index.index), (local_index.level));
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchif, 1, (VALUE)(end_label))), ((end_label)->refcnt++));
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) (set_label));
        pm_compile_node(iseq, (cast->value), ret, 0, scope_node);
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
        pm_iseq_add_setlocal(iseq, (ret), (int) (location).line, (int) (location).node_id, (local_index.index), (local_index.level));
        ADD_ELEM((ret), (LINK_ELEMENT *) (end_label));
        return;
      }
      case PM_LOCAL_VARIABLE_READ_NODE: {
        if (!popped) {
            const pm_local_variable_read_node_t *cast = (const pm_local_variable_read_node_t *) node;
            pm_local_index_t index = pm_lookup_local_index(iseq, scope_node, cast->name, cast->depth);
            pm_iseq_add_getlocal(iseq, (ret), (int) (location).line, (int) (location).node_id, (index.index), (index.level));
        }
        return;
      }
      case PM_LOCAL_VARIABLE_WRITE_NODE: {
        const pm_local_variable_write_node_t *cast = (const pm_local_variable_write_node_t *) node;
        pm_compile_node(iseq, (cast->value), ret, 0, scope_node);
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
        pm_local_index_t index = pm_lookup_local_index(iseq, scope_node, cast->name, cast->depth);
        pm_iseq_add_setlocal(iseq, (ret), (int) (location).line, (int) (location).node_id, (index.index), (index.level));
        return;
      }
      case PM_MATCH_LAST_LINE_NODE: {
        VALUE regexp = pm_static_literal_value(iseq, node, scope_node);
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(regexp)));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_getspecial, 2, (VALUE)(__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (VALUE)(__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0)))));
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((idEqTilde)), (VALUE)((rb_int2num_inline(1))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
        if (popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        return;
      }
      case PM_MATCH_PREDICATE_NODE: {
        const pm_match_predicate_node_t *cast = (const pm_match_predicate_node_t *) node;
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
        pm_compile_node(iseq, (cast->value), ret, 0, scope_node);
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
        LABEL *matched_label = new_label_body(iseq, (location.line));
        LABEL *unmatched_label = new_label_body(iseq, (location.line));
        LABEL *done_label = new_label_body(iseq, (location.line));
        pm_compile_pattern(iseq, scope_node, cast->pattern, ret, matched_label, unmatched_label, 0, 0, 1, 2);
        ADD_ELEM((ret), (LINK_ELEMENT *) (unmatched_label));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qfalse))));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_jump, 1, (VALUE)(done_label))), ((done_label)->refcnt++));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) (matched_label));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_adjuststack, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(2), ((VALUE)(2)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(2)))));
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qtrue))));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_jump, 1, (VALUE)(done_label))), ((done_label)->refcnt++));
        ADD_ELEM((ret), (LINK_ELEMENT *) (done_label));
        return;
      }
      case PM_MATCH_REQUIRED_NODE:
        pm_compile_match_required_node(iseq, (const pm_match_required_node_t *) node, &location, ret, popped, scope_node);
        return;
      case PM_MATCH_WRITE_NODE:
        pm_compile_match_write_node(iseq, (const pm_match_write_node_t *) node, &location, ret, popped, scope_node);
        return;
      case PM_MISSING_NODE:
        rb_bug("A pm_missing_node_t should not exist in prism's AST.");
        return;
      case PM_MODULE_NODE: {
        const pm_module_node_t *cast = (const pm_module_node_t *) node;
        ID module_id = pm_constant_id_lookup(scope_node, cast->name);
        VALUE module_name = rb_str_freeze(rb_sprintf("<module:%""l""i" "\v"">", rb_id2str(module_id)));
        pm_scope_node_t next_scope_node;
        pm_scope_node_init((const pm_node_t *) cast, &next_scope_node, scope_node);
        const rb_iseq_t *module_iseq = pm_new_child_iseq(iseq, (&next_scope_node), rb_fstring(module_name), iseq, (ISEQ_TYPE_CLASS), (location.line));
        pm_scope_node_destroy(&next_scope_node);
        const int flags = VM_DEFINECLASS_TYPE_MODULE | pm_compile_class_path(iseq, cast->constant_path, &location, ret, 0, scope_node);
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_defineclass, 3, (VALUE)(rb_id2sym(module_id)), (VALUE)(module_iseq), (VALUE)(__builtin_choose_expr( __builtin_constant_p(flags), ((VALUE)(flags)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(flags)))));
        (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)((VALUE) module_iseq), "prism_compile.c", 9448));
        if (popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        return;
      }
      case PM_REQUIRED_PARAMETER_NODE: {
        const pm_required_parameter_node_t *cast = (const pm_required_parameter_node_t *) node;
        pm_local_index_t index = pm_lookup_local_index(iseq, scope_node, cast->name, 0);
        pm_iseq_add_setlocal(iseq, (ret), (int) (location).line, (int) (location).node_id, (index.index), (index.level));
        return;
      }
      case PM_MULTI_WRITE_NODE: {
        const pm_multi_write_node_t *cast = (const pm_multi_write_node_t *) node;
        LINK_ANCHOR writes[1] = {{{ISEQ_ELEMENT_ANCHOR,},&writes[0].anchor}};
        LINK_ANCHOR cleanup[1] = {{{ISEQ_ELEMENT_ANCHOR,},&cleanup[0].anchor}};
        pm_multi_target_state_t state = { 0 };
        state.position = popped ? 0 : 1;
        pm_compile_multi_target_node(iseq, node, ret, writes, cleanup, scope_node, &state);
        pm_compile_node(iseq, (cast->value), ret, 0, scope_node);
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
        APPEND_LIST((ret), (writes));
        if (!popped && state.stack_size >= 1) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_setn, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(state.stack_size), ((VALUE)(state.stack_size)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(state.stack_size)))));
        }
        pm_multi_target_state_update(&state);
        APPEND_LIST((ret), (cleanup));
        return;
      }
      case PM_NEXT_NODE:
        pm_compile_next_node(iseq, (const pm_next_node_t *) node, &location, ret, popped, scope_node);
        return;
      case PM_NIL_NODE: {
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
        }
        return;
      }
      case PM_NO_KEYWORDS_PARAMETER_NODE: {
        ((iseq)->body)->param.flags.accepts_no_kwarg = 1;
        return;
      }
      case PM_NUMBERED_REFERENCE_READ_NODE: {
        if (!popped) {
            uint32_t reference_number = ((const pm_numbered_reference_read_node_t *) node)->number;
            if (reference_number > 0) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_getspecial, 2, (VALUE)(__builtin_choose_expr( __builtin_constant_p(1), ((VALUE)(1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(1))), (VALUE)(__builtin_choose_expr( __builtin_constant_p(reference_number << 1), ((VALUE)(reference_number << 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(reference_number << 1)))));
            }
            else {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
            }
        }
        return;
      }
      case PM_OR_NODE: {
        const pm_or_node_t *cast = (const pm_or_node_t *) node;
        LABEL *end_label = new_label_body(iseq, (location.line));
        pm_compile_node(iseq, (cast->left), ret, 0, scope_node);
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_dup, 0));
        (ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_branchif, 1, (VALUE)(end_label))), ((end_label)->refcnt++));
        if (!popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        pm_compile_node(iseq, (cast->right), ret, popped, scope_node);
        ADD_ELEM((ret), (LINK_ELEMENT *) (end_label));
        return;
      }
      case PM_OPTIONAL_PARAMETER_NODE: {
        const pm_optional_parameter_node_t *cast = (const pm_optional_parameter_node_t *) node;
        pm_compile_node(iseq, (cast->value), ret, 0, scope_node);
        pm_local_index_t index = pm_lookup_local_index(iseq, scope_node, cast->name, 0);
        pm_iseq_add_setlocal(iseq, (ret), (int) (location).line, (int) (location).node_id, (index.index), (index.level));
        return;
      }
      case PM_PARENTHESES_NODE: {
        const pm_parentheses_node_t *cast = (const pm_parentheses_node_t *) node;
        if (cast->body != ((void *)0)) {
            pm_compile_node(iseq, (cast->body), ret, popped, scope_node);
        }
        else if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
        }
        return;
      }
      case PM_PRE_EXECUTION_NODE: {
        const pm_pre_execution_node_t *cast = (const pm_pre_execution_node_t *) node;
        LINK_ANCHOR *outer_pre = scope_node->pre_execution_anchor;
        ((void)0);
        LINK_ANCHOR inner_pre[1] = {{{ISEQ_ELEMENT_ANCHOR,},&inner_pre[0].anchor}};
        scope_node->pre_execution_anchor = inner_pre;
        LINK_ANCHOR inner_body[1] = {{{ISEQ_ELEMENT_ANCHOR,},&inner_body[0].anchor}};
        if (cast->statements != ((void *)0)) {
            const pm_node_list_t *body = &cast->statements->body;
            for (size_t index = 0; index < body->size; index++) {
                pm_compile_node(iseq, body->nodes[index], inner_body, 1, scope_node);
            }
        }
        if (!popped) {
            ADD_ELEM((inner_body), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
        }
        APPEND_LIST((outer_pre), (inner_pre));
        APPEND_LIST((outer_pre), (inner_body));
        scope_node->pre_execution_anchor = outer_pre;
        return;
      }
      case PM_POST_EXECUTION_NODE: {
        const rb_iseq_t *child_iseq;
        const rb_iseq_t *prevblock = ISEQ_COMPILE_DATA(iseq)->current_block;
        pm_scope_node_t next_scope_node;
        pm_scope_node_init(node, &next_scope_node, scope_node);
        child_iseq = pm_new_child_iseq(iseq, (&next_scope_node), rb_fstring(make_name_for_block(iseq)), iseq, (ISEQ_TYPE_BLOCK), (lineno));
        pm_scope_node_destroy(&next_scope_node);
        ISEQ_COMPILE_DATA(iseq)->current_block = child_iseq;
        int is_index = ((iseq)->body)->ise_size++;
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_once, 2, (VALUE)(child_iseq), (VALUE)(__builtin_choose_expr( __builtin_constant_p(is_index), ((VALUE)(is_index)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(is_index)))));
        (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)((VALUE) child_iseq), "prism_compile.c", 9634));
        if (popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        ISEQ_COMPILE_DATA(iseq)->current_block = prevblock;
        return;
      }
      case PM_RANGE_NODE: {
        const pm_range_node_t *cast = (const pm_range_node_t *) node;
        _Bool exclude_end = ((((pm_node_t *)(cast))->flags & (PM_RANGE_FLAGS_EXCLUDE_END)) != 0);
        if (pm_optimizable_range_item_p(cast->left) && pm_optimizable_range_item_p(cast->right)) {
            if (!popped) {
                const pm_node_t *left = cast->left;
                const pm_node_t *right = cast->right;
                VALUE val = rb_range_new(
                    (left && (((enum pm_node_type) (left)->type) == (PM_INTEGER_NODE))) ? parse_integer((const pm_integer_node_t *) left) : ((VALUE)RUBY_Qnil),
                    (right && (((enum pm_node_type) (right)->type) == (PM_INTEGER_NODE))) ? parse_integer((const pm_integer_node_t *) right) : ((VALUE)RUBY_Qnil),
                    exclude_end
                );
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(val)));
            }
        }
        else {
            if (cast->left != ((void *)0)) {
                pm_compile_node(iseq, (cast->left), ret, popped, scope_node);
            }
            else if (!popped) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
            }
            if (cast->right != ((void *)0)) {
                pm_compile_node(iseq, (cast->right), ret, popped, scope_node);
            }
            else if (!popped) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
            }
            if (!popped) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_newrange, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(exclude_end ? 1 : 0), ((VALUE)(exclude_end ? 1 : 0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(exclude_end ? 1 : 0)))));
            }
        }
        return;
      }
      case PM_RATIONAL_NODE: {
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(parse_rational((const pm_rational_node_t *) node))));
        }
        return;
      }
      case PM_REDO_NODE:
        pm_compile_redo_node(iseq, &location, ret, popped, scope_node);
        return;
      case PM_REGULAR_EXPRESSION_NODE: {
        if (!popped) {
            VALUE regexp = pm_static_literal_value(iseq, node, scope_node);
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(regexp)));
        }
        return;
      }
      case PM_RESCUE_NODE:
        pm_compile_rescue_node(iseq, (const pm_rescue_node_t *) node, &location, ret, popped, scope_node);
        return;
      case PM_RESCUE_MODIFIER_NODE: {
        const pm_rescue_modifier_node_t *cast = (const pm_rescue_modifier_node_t *) node;
        pm_scope_node_t rescue_scope_node;
        pm_scope_node_init((const pm_node_t *) cast, &rescue_scope_node, scope_node);
        rb_iseq_t *rescue_iseq = pm_new_child_iseq(iseq, (&rescue_scope_node), rb_fstring(rb_str_concat(((__builtin_constant_p("rescue in ") ? rbimpl_str_new_cstr : rb_str_new_cstr) ("rescue in ")), ((iseq)->body)->location.label)), iseq, (ISEQ_TYPE_RESCUE), (pm_node_line_number(parser, cast->rescue_expression)));
        pm_scope_node_destroy(&rescue_scope_node);
        LABEL *lstart = new_label_body(iseq, (location.line));
        LABEL *lend = new_label_body(iseq, (location.line));
        LABEL *lcont = new_label_body(iseq, (location.line));
        lstart->rescued = LABEL_RESCUE_BEG;
        lend->rescued = LABEL_RESCUE_END;
        ADD_ELEM((ret), (LINK_ELEMENT *) (lstart));
        pm_compile_node(iseq, (cast->expression), ret, 0, scope_node);
        ADD_ELEM((ret), (LINK_ELEMENT *) (lend));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_nop, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) (lcont));
        if (popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        do { VALUE _e = __extension__ ({ const VALUE args_to_new_ary[] = {((CATCH_TYPE_RESCUE)), (VALUE)((lstart)) | 1, (VALUE)((lend)) | 1, (VALUE)((rescue_iseq)), (VALUE)((lcont)) | 1}; if (__builtin_constant_p(5)) { __extension__ _Static_assert(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))) == (5), "rb_ary_new_from_args" ": " "numberof(args_to_new_ary) == (5)"); } rb_ary_new_from_values(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))), args_to_new_ary); }); (((lstart)) ? ((((lstart))->refcnt++), ((lstart))->unremovable=1) : 0); (((lend))->refcnt++); (((lcont))->refcnt++); if (RB_NIL_P(ISEQ_COMPILE_DATA(iseq)->catch_table_ary)) (rb_obj_write((VALUE)(iseq), (VALUE *)(&ISEQ_COMPILE_DATA(iseq)->catch_table_ary), (VALUE)(rb_ary_hidden_new(3)), "prism_compile.c", 9741)); rb_ary_push(ISEQ_COMPILE_DATA(iseq)->catch_table_ary, freeze_hide_obj(_e)); } while (0);
        do { VALUE _e = __extension__ ({ const VALUE args_to_new_ary[] = {((CATCH_TYPE_RETRY)), (VALUE)((lend)) | 1, (VALUE)((lcont)) | 1, (VALUE)((((void *)0))), (VALUE)((lstart)) | 1}; if (__builtin_constant_p(5)) { __extension__ _Static_assert(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))) == (5), "rb_ary_new_from_args" ": " "numberof(args_to_new_ary) == (5)"); } rb_ary_new_from_values(((int)(sizeof(args_to_new_ary) / sizeof((args_to_new_ary)[0]))), args_to_new_ary); }); (((lend)) ? ((((lend))->refcnt++), ((lend))->unremovable=1) : 0); (((lcont))->refcnt++); (((lstart))->refcnt++); if (RB_NIL_P(ISEQ_COMPILE_DATA(iseq)->catch_table_ary)) (rb_obj_write((VALUE)(iseq), (VALUE *)(&ISEQ_COMPILE_DATA(iseq)->catch_table_ary), (VALUE)(rb_ary_hidden_new(3)), "prism_compile.c", 9742)); rb_ary_push(ISEQ_COMPILE_DATA(iseq)->catch_table_ary, freeze_hide_obj(_e)); } while (0);
        return;
      }
      case PM_RETURN_NODE:
        pm_compile_return_node(iseq, (const pm_return_node_t *) node, &location, ret, popped, scope_node);
        return;
      case PM_RETRY_NODE: {
        if (((iseq)->body)->type == ISEQ_TYPE_RESCUE) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_throw, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(RUBY_TAG_RETRY), ((VALUE)(RUBY_TAG_RETRY)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(RUBY_TAG_RETRY)))));
            if (popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        }
        else {
            append_compile_error(iseq, location.line, "Invalid retry");
            return;
        }
        return;
      }
      case PM_SCOPE_NODE:
        pm_compile_scope_node(iseq, (pm_scope_node_t *) node, &location, ret, popped);
        return;
      case PM_SELF_NODE: {
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putself, 0));
        }
        return;
      }
      case PM_SHAREABLE_CONSTANT_NODE: {
        const pm_shareable_constant_node_t *cast = (const pm_shareable_constant_node_t *) node;
        pm_node_flags_t shareability = (cast->base.flags & (PM_SHAREABLE_CONSTANT_NODE_FLAGS_LITERAL | PM_SHAREABLE_CONSTANT_NODE_FLAGS_EXPERIMENTAL_EVERYTHING | PM_SHAREABLE_CONSTANT_NODE_FLAGS_EXPERIMENTAL_COPY));
        switch (((enum pm_node_type) (cast->write)->type)) {
          case PM_CONSTANT_WRITE_NODE:
            pm_compile_constant_write_node(iseq, (const pm_constant_write_node_t *) cast->write, shareability, &location, ret, popped, scope_node);
            break;
          case PM_CONSTANT_AND_WRITE_NODE:
            pm_compile_constant_and_write_node(iseq, (const pm_constant_and_write_node_t *) cast->write, shareability, &location, ret, popped, scope_node);
            break;
          case PM_CONSTANT_OR_WRITE_NODE:
            pm_compile_constant_or_write_node(iseq, (const pm_constant_or_write_node_t *) cast->write, shareability, &location, ret, popped, scope_node);
            break;
          case PM_CONSTANT_OPERATOR_WRITE_NODE:
            pm_compile_constant_operator_write_node(iseq, (const pm_constant_operator_write_node_t *) cast->write, shareability, &location, ret, popped, scope_node);
            break;
          case PM_CONSTANT_PATH_WRITE_NODE:
            pm_compile_constant_path_write_node(iseq, (const pm_constant_path_write_node_t *) cast->write, shareability, &location, ret, popped, scope_node);
            break;
          case PM_CONSTANT_PATH_AND_WRITE_NODE:
            pm_compile_constant_path_and_write_node(iseq, (const pm_constant_path_and_write_node_t *) cast->write, shareability, &location, ret, popped, scope_node);
            break;
          case PM_CONSTANT_PATH_OR_WRITE_NODE:
            pm_compile_constant_path_or_write_node(iseq, (const pm_constant_path_or_write_node_t *) cast->write, shareability, &location, ret, popped, scope_node);
            break;
          case PM_CONSTANT_PATH_OPERATOR_WRITE_NODE:
            pm_compile_constant_path_operator_write_node(iseq, (const pm_constant_path_operator_write_node_t *) cast->write, shareability, &location, ret, popped, scope_node);
            break;
          default:
            rb_bug("Unexpected node type for shareable constant write: %s", pm_node_type_to_str(((enum pm_node_type) (cast->write)->type)));
            break;
        }
        return;
      }
      case PM_SINGLETON_CLASS_NODE: {
        const pm_singleton_class_node_t *cast = (const pm_singleton_class_node_t *) node;
        pm_scope_node_t next_scope_node;
        pm_scope_node_init((const pm_node_t *) cast, &next_scope_node, scope_node);
        const rb_iseq_t *child_iseq = pm_new_child_iseq(iseq, (&next_scope_node), rb_fstring(rb_fstring_new(("singleton class"), ((sizeof("singleton class" "") / sizeof("singleton class" ""[0])) - 1))), 0, (ISEQ_TYPE_CLASS), (location.line));
        pm_scope_node_destroy(&next_scope_node);
        pm_compile_node(iseq, (cast->expression), ret, 0, scope_node);
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
        ID singletonclass;
        do { static ID rbimpl_id; (singletonclass) = rbimpl_intern_const(&rbimpl_id, ("singletonclass")); } while (0);
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_defineclass, 3, (VALUE)(rb_id2sym(singletonclass)), (VALUE)(child_iseq), (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_DEFINECLASS_TYPE_SINGLETON_CLASS), ((VALUE)(VM_DEFINECLASS_TYPE_SINGLETON_CLASS)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_DEFINECLASS_TYPE_SINGLETON_CLASS)))));
        if (popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        (rb_obj_written((VALUE)(iseq), (VALUE)(((VALUE)RUBY_Qundef)), (VALUE)((VALUE) child_iseq), "prism_compile.c", 9834));
        return;
      }
      case PM_SOURCE_ENCODING_NODE: {
        if (!popped) {
            VALUE value = pm_static_literal_value(iseq, node, scope_node);
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(value)));
        }
        return;
      }
      case PM_SOURCE_FILE_NODE: {
        if (!popped) {
            const pm_source_file_node_t *cast = (const pm_source_file_node_t *) node;
            VALUE string = pm_source_file_value(cast, scope_node);
            if (((((pm_node_t *)(cast))->flags & (PM_STRING_FLAGS_FROZEN)) != 0)) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(string)));
            }
            else if (((((pm_node_t *)(cast))->flags & (PM_STRING_FLAGS_MUTABLE)) != 0)) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putstring, 1, (VALUE)(string)));
            }
            else {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putchilledstring, 1, (VALUE)(string)));
            }
        }
        return;
      }
      case PM_SOURCE_LINE_NODE: {
        if (!popped) {
            VALUE value = pm_static_literal_value(iseq, node, scope_node);
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(value)));
        }
        return;
      }
      case PM_SPLAT_NODE: {
        const pm_splat_node_t *cast = (const pm_splat_node_t *) node;
        if (cast->expression) {
            pm_compile_node(iseq, (cast->expression), ret, popped, scope_node);
        }
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_splatarray, 1, (VALUE)(((VALUE)RUBY_Qtrue))));
        }
        return;
      }
      case PM_STATEMENTS_NODE: {
        const pm_statements_node_t *cast = (const pm_statements_node_t *) node;
        const pm_node_list_t *body = &cast->body;
        if (body->size > 0) {
            for (size_t index = 0; index < body->size - 1; index++) {
                pm_compile_node(iseq, (body->nodes[index]), ret, 1, scope_node);
            }
            pm_compile_node(iseq, (body->nodes[body->size - 1]), ret, popped, scope_node);
        }
        else {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putnil, 0));
        }
        return;
      }
      case PM_STRING_NODE: {
        if (!popped) {
            const pm_string_node_t *cast = (const pm_string_node_t *) node;
            VALUE value = parse_static_literal_string(iseq, scope_node, node, &cast->unescaped);
            if (((((pm_node_t *)(node))->flags & (PM_STRING_FLAGS_FROZEN)) != 0)) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(value)));
            }
            else if (((((pm_node_t *)(node))->flags & (PM_STRING_FLAGS_MUTABLE)) != 0)) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putstring, 1, (VALUE)(value)));
            }
            else {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putchilledstring, 1, (VALUE)(value)));
            }
        }
        return;
      }
      case PM_SUPER_NODE:
        pm_compile_super_node(iseq, (const pm_super_node_t *) node, &location, ret, popped, scope_node);
        return;
      case PM_SYMBOL_NODE: {
        if (!popped) {
            VALUE value = pm_static_literal_value(iseq, node, scope_node);
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(value)));
        }
        return;
      }
      case PM_TRUE_NODE: {
        if (!popped) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(((VALUE)RUBY_Qtrue))));
        }
        return;
      }
      case PM_UNDEF_NODE: {
        const pm_undef_node_t *cast = (const pm_undef_node_t *) node;
        const pm_node_list_t *names = &cast->names;
        for (size_t index = 0; index < names->size; index++) {
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_VMCORE), ((VALUE)(VM_SPECIAL_OBJECT_VMCORE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_VMCORE)))));
            ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putspecialobject, 1, (VALUE)(__builtin_choose_expr( __builtin_constant_p(VM_SPECIAL_OBJECT_CBASE), ((VALUE)(VM_SPECIAL_OBJECT_CBASE)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(VM_SPECIAL_OBJECT_CBASE)))));
            pm_compile_node(iseq, (names->nodes[index]), ret, 0, scope_node);
            ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((id_core_undef_method)), (VALUE)((rb_int2num_inline(2))), (((void *)0)), (VALUE)((VALUE)__builtin_choose_expr( __builtin_constant_p(0), ((VALUE)(0)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(0))), (((void *)0))));
            if (index < names->size - 1) {
                ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
            }
        }
        if (popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        return;
      }
      case PM_UNLESS_NODE: {
        const pm_unless_node_t *cast = (const pm_unless_node_t *) node;
        const pm_statements_node_t *statements = ((void *)0);
        if (cast->else_clause != ((void *)0)) {
            statements = ((const pm_else_node_t *) cast->else_clause)->statements;
        }
        pm_compile_conditional(iseq, &location, PM_UNLESS_NODE, (const pm_node_t *) cast, statements, (const pm_node_t *) cast->statements, cast->predicate, ret, popped, scope_node);
        return;
      }
      case PM_UNTIL_NODE: {
        const pm_until_node_t *cast = (const pm_until_node_t *) node;
        pm_compile_loop(iseq, &location, cast->base.flags, PM_UNTIL_NODE, (const pm_node_t *) cast, cast->statements, cast->predicate, ret, popped, scope_node);
        return;
      }
      case PM_WHILE_NODE: {
        const pm_while_node_t *cast = (const pm_while_node_t *) node;
        pm_compile_loop(iseq, &location, cast->base.flags, PM_WHILE_NODE, (const pm_node_t *) cast, cast->statements, cast->predicate, ret, popped, scope_node);
        return;
      }
      case PM_X_STRING_NODE: {
        const pm_x_string_node_t *cast = (const pm_x_string_node_t *) node;
        VALUE value = parse_static_literal_string(iseq, scope_node, node, &cast->unescaped);
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putself, 0));
        ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_putobject, 1, (VALUE)(value)));
        ADD_ELEM(((ret)), (LINK_ELEMENT *) new_insn_send(iseq, (int) (location).line, (int) (location).node_id, ((idBackquote)), (VALUE)((rb_int2num_inline(1))), (((void *)0)), (VALUE)((VALUE)(__builtin_choose_expr( __builtin_constant_p((0x01 << VM_CALL_FCALL_bit) | (0x01 << VM_CALL_ARGS_SIMPLE_bit)), ((VALUE)((0x01 << VM_CALL_FCALL_bit) | (0x01 << VM_CALL_ARGS_SIMPLE_bit))) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX((0x01 << VM_CALL_FCALL_bit) | (0x01 << VM_CALL_ARGS_SIMPLE_bit))))), (((void *)0))));
        if (popped) ADD_ELEM((ret), (LINK_ELEMENT *) new_insn_body(iseq, (int) (location).line, (int) (location).node_id, YARVINSN_pop, 0));
        return;
      }
      case PM_YIELD_NODE:
        pm_compile_yield_node(iseq, (const pm_yield_node_t *) node, &location, ret, popped, scope_node);
        return;
      default:
        rb_raise(rb_eNotImpError, "node type %s not implemented", pm_node_type_to_str(((enum pm_node_type) (node)->type)));
        return;
    }
}
static inline _Bool
pm_iseq_pre_execution_p(rb_iseq_t *iseq)
{
    switch (((iseq)->body)->type) {
      case ISEQ_TYPE_TOP:
      case ISEQ_TYPE_EVAL:
      case ISEQ_TYPE_MAIN:
        return 1;
      default:
        return 0;
    }
}
VALUE
pm_iseq_compile_node(rb_iseq_t *iseq, pm_scope_node_t *node)
{
    LINK_ANCHOR ret[1] = {{{ISEQ_ELEMENT_ANCHOR,},&ret[0].anchor}};
    if (pm_iseq_pre_execution_p(iseq)) {
        LINK_ANCHOR pre[1] = {{{ISEQ_ELEMENT_ANCHOR,},&pre[0].anchor}};
        node->pre_execution_anchor = pre;
        LINK_ANCHOR body[1] = {{{ISEQ_ELEMENT_ANCHOR,},&body[0].anchor}};
        pm_compile_node(iseq, (const pm_node_t *) node, body, 0, node);
        APPEND_LIST((ret), (pre));
        APPEND_LIST((ret), (body));
    }
    else {
        pm_compile_node(iseq, (const pm_node_t *) node, ret, 0, node);
    }
    if (!(iseq_setup_insn(iseq, ret))) {((void)0);return 0;};
    return iseq_setup(iseq, ret);
}
void
pm_parse_result_free(pm_parse_result_t *result)
{
    if (result->node.ast_node != ((void *)0)) {
        pm_node_destroy(&result->parser, result->node.ast_node);
    }
    if (result->parsed) {
        ruby_xfree(result->node.constants);
        pm_scope_node_destroy(&result->node);
    }
    pm_parser_free(&result->parser);
    pm_string_free(&result->input);
    pm_options_free(&result->options);
}
typedef struct {
    pm_diagnostic_t *error;
    int32_t line;
    uint32_t column_start;
    uint32_t column_end;
} pm_parse_error_t;
typedef struct {
    const char *number_prefix;
    const char *blank_prefix;
    const char *divider;
    size_t blank_prefix_length;
    size_t divider_length;
} pm_parse_error_format_t;
static inline pm_parse_error_t *
pm_parse_errors_format_sort(const pm_parser_t *parser, const pm_list_t *error_list, const pm_newline_list_t *newline_list) {
    pm_parse_error_t *errors = ruby_xcalloc(error_list->size, sizeof(pm_parse_error_t));
    if (errors == ((void *)0)) return ((void *)0);
    int32_t start_line = parser->start_line;
    for (pm_diagnostic_t *error = (pm_diagnostic_t *) error_list->head; error != ((void *)0); error = (pm_diagnostic_t *) error->node.next) {
        pm_line_column_t start = pm_newline_list_line_column(newline_list, error->location.start, start_line);
        pm_line_column_t end = pm_newline_list_line_column(newline_list, error->location.end, start_line);
        size_t index = 0;
        while (
            (index < error_list->size) &&
            (errors[index].error != ((void *)0)) &&
            (
                (errors[index].line < start.line) ||
                ((errors[index].line == start.line) && (errors[index].column_start < start.column))
            )
        ) index++;
        if (index + 1 < error_list->size) {
            memmove(&errors[index + 1], &errors[index], sizeof(pm_parse_error_t) * (error_list->size - index - 1));
        }
        uint32_t column_end;
        if (start.line == end.line) {
            column_end = end.column;
        } else {
            column_end = (uint32_t) (newline_list->offsets[start.line - start_line + 1] - newline_list->offsets[start.line - start_line] - 1);
        }
        if (start.column == column_end) column_end++;
        errors[index] = (pm_parse_error_t) {
            .error = error,
            .line = start.line,
            .column_start = start.column,
            .column_end = column_end
        };
    }
    return errors;
}
static inline void
pm_parse_errors_format_line(const pm_parser_t *parser, const pm_newline_list_t *newline_list, const char *number_prefix, int32_t line, uint32_t column_start, uint32_t column_end, pm_buffer_t *buffer) {
    int32_t line_delta = line - parser->start_line;
    ((void) (0));
    size_t index = (size_t) line_delta;
    ((void) (0));
    const uint8_t *start = &parser->start[newline_list->offsets[index]];
    const uint8_t *end;
    if (index >= newline_list->size - 1) {
        end = parser->end;
    } else {
        end = &parser->start[newline_list->offsets[index + 1]];
    }
    pm_buffer_append_format(buffer, number_prefix, line);
    _Bool truncate_end = 0;
    if ((column_end != 0) && ((end - (start + column_end)) >= 30)) {
        end = start + column_end + 30;
        truncate_end = 1;
    }
    if (column_start >= 30) {
        pm_buffer_append_string(buffer, "... ", 4);
        start += column_start;
    }
    pm_buffer_append_string(buffer, (const char *) start, (size_t) (end - start));
    if (truncate_end) {
        pm_buffer_append_string(buffer, " ...\n", 5);
    } else if (end == parser->end && end[-1] != '\n') {
        pm_buffer_append_string(buffer, "\n", 1);
    }
}
static void
pm_parse_errors_format(const pm_parser_t *parser, const pm_list_t *error_list, pm_buffer_t *buffer, _Bool colorize, _Bool inline_messages) {
    ((void) (0));
    const int32_t start_line = parser->start_line;
    const pm_newline_list_t *newline_list = &parser->newline_list;
    pm_parse_error_t *errors = pm_parse_errors_format_sort(parser, error_list, newline_list);
    if (errors == ((void *)0)) return;
    pm_parse_error_format_t error_format;
    int32_t first_line_number = errors[0].line;
    int32_t last_line_number = errors[error_list->size - 1].line;
    if (first_line_number < 0) first_line_number = (-first_line_number) * 10;
    if (last_line_number < 0) last_line_number = (-last_line_number) * 10;
    int32_t max_line_number = first_line_number > last_line_number ? first_line_number : last_line_number;
    if (max_line_number < 10) {
        if (colorize) {
            error_format = (pm_parse_error_format_t) {
                .number_prefix = "\033[38;5;102m" "%1" "i" " | " "\033[m",
                .blank_prefix = "\033[38;5;102m" "  | " "\033[m",
                .divider = "\033[38;5;102m" "  ~~~~~" "\033[m" "\n"
            };
        } else {
            error_format = (pm_parse_error_format_t) {
                .number_prefix = "%1" "i" " | ",
                .blank_prefix = "  | ",
                .divider = "  ~~~~~\n"
            };
        }
    } else if (max_line_number < 100) {
        if (colorize) {
            error_format = (pm_parse_error_format_t) {
                .number_prefix = "\033[38;5;102m" "%2" "i" " | " "\033[m",
                .blank_prefix = "\033[38;5;102m" "   | " "\033[m",
                .divider = "\033[38;5;102m" "  ~~~~~~" "\033[m" "\n"
            };
        } else {
            error_format = (pm_parse_error_format_t) {
                .number_prefix = "%2" "i" " | ",
                .blank_prefix = "   | ",
                .divider = "  ~~~~~~\n"
            };
        }
    } else if (max_line_number < 1000) {
        if (colorize) {
            error_format = (pm_parse_error_format_t) {
                .number_prefix = "\033[38;5;102m" "%3" "i" " | " "\033[m",
                .blank_prefix = "\033[38;5;102m" "    | " "\033[m",
                .divider = "\033[38;5;102m" "  ~~~~~~~" "\033[m" "\n"
            };
        } else {
            error_format = (pm_parse_error_format_t) {
                .number_prefix = "%3" "i" " | ",
                .blank_prefix = "    | ",
                .divider = "  ~~~~~~~\n"
            };
        }
    } else if (max_line_number < 10000) {
        if (colorize) {
            error_format = (pm_parse_error_format_t) {
                .number_prefix = "\033[38;5;102m" "%4" "i" " | " "\033[m",
                .blank_prefix = "\033[38;5;102m" "     | " "\033[m",
                .divider = "\033[38;5;102m" "  ~~~~~~~~" "\033[m" "\n"
            };
        } else {
            error_format = (pm_parse_error_format_t) {
                .number_prefix = "%4" "i" " | ",
                .blank_prefix = "     | ",
                .divider = "  ~~~~~~~~\n"
            };
        }
    } else {
        if (colorize) {
            error_format = (pm_parse_error_format_t) {
                .number_prefix = "\033[38;5;102m" "%5" "i" " | " "\033[m",
                .blank_prefix = "\033[38;5;102m" "      | " "\033[m",
                .divider = "\033[38;5;102m" "  ~~~~~~~~" "\033[m" "\n"
            };
        } else {
            error_format = (pm_parse_error_format_t) {
                .number_prefix = "%5" "i" " | ",
                .blank_prefix = "      | ",
                .divider = "  ~~~~~~~~\n"
            };
        }
    }
    error_format.blank_prefix_length = strlen(error_format.blank_prefix);
    error_format.divider_length = strlen(error_format.divider);
    int32_t last_line = parser->start_line - 1;
    uint32_t last_column_start = 0;
    const pm_encoding_t *encoding = parser->encoding;
    for (size_t index = 0; index < error_list->size; index++) {
        pm_parse_error_t *error = &errors[index];
        if (error->line - last_line > 1) {
            if (error->line - last_line > 2) {
                if ((index != 0) && (error->line - last_line > 3)) {
                    pm_buffer_append_string(buffer, error_format.divider, error_format.divider_length);
                }
                pm_buffer_append_string(buffer, "  ", 2);
                pm_parse_errors_format_line(parser, newline_list, error_format.number_prefix, error->line - 2, 0, 0, buffer);
            }
            pm_buffer_append_string(buffer, "  ", 2);
            pm_parse_errors_format_line(parser, newline_list, error_format.number_prefix, error->line - 1, 0, 0, buffer);
        }
        if ((index == 0) || (error->line != last_line)) {
            if (colorize) {
                pm_buffer_append_string(buffer, "\033[1;31m" "> " "\033[m", 12);
            } else {
                pm_buffer_append_string(buffer, "> ", 2);
            }
            last_column_start = error->column_start;
            uint32_t column_end = error->column_end;
            for (size_t next_index = index + 1; next_index < error_list->size; next_index++) {
                if (errors[next_index].line != error->line) break;
                if (errors[next_index].column_end > column_end) column_end = errors[next_index].column_end;
            }
            pm_parse_errors_format_line(parser, newline_list, error_format.number_prefix, error->line, error->column_start, column_end, buffer);
        }
        const uint8_t *start = &parser->start[newline_list->offsets[error->line - start_line]];
        if (start == parser->end) pm_buffer_append_byte(buffer, '\n');
        pm_buffer_append_string(buffer, "  ", 2);
        pm_buffer_append_string(buffer, error_format.blank_prefix, error_format.blank_prefix_length);
        size_t column = 0;
        if (last_column_start >= 30) {
            pm_buffer_append_string(buffer, "    ", 4);
            column = last_column_start;
        }
        while (column < error->column_start) {
            pm_buffer_append_byte(buffer, ' ');
            size_t char_width = encoding->char_width(start + column, parser->end - (start + column));
            column += (char_width == 0 ? 1 : char_width);
        }
        if (colorize) pm_buffer_append_string(buffer, "\033[1;31m", 7);
        pm_buffer_append_byte(buffer, '^');
        size_t char_width = encoding->char_width(start + column, parser->end - (start + column));
        column += (char_width == 0 ? 1 : char_width);
        while (column < error->column_end) {
            pm_buffer_append_byte(buffer, '~');
            size_t char_width = encoding->char_width(start + column, parser->end - (start + column));
            column += (char_width == 0 ? 1 : char_width);
        }
        if (colorize) pm_buffer_append_string(buffer, "\033[m", 3);
        if (inline_messages) {
            pm_buffer_append_byte(buffer, ' ');
            ((void) (0));
            const char *message = error->error->message;
            pm_buffer_append_string(buffer, message, strlen(message));
        }
        pm_buffer_append_byte(buffer, '\n');
        last_line = error->line;
        int32_t next_line = (index == error_list->size - 1) ? (((int32_t) newline_list->size) + parser->start_line) : errors[index + 1].line;
        if (next_line - last_line > 1) {
            pm_buffer_append_string(buffer, "  ", 2);
            pm_parse_errors_format_line(parser, newline_list, error_format.number_prefix, ++last_line, 0, 0, buffer);
        }
        if (next_line - last_line > 1) {
            pm_buffer_append_string(buffer, "  ", 2);
            pm_parse_errors_format_line(parser, newline_list, error_format.number_prefix, ++last_line, 0, 0, buffer);
        }
    }
    ruby_xfree(errors);
}
static _Bool
pm_parse_process_error_utf8_p(const pm_parser_t *parser, const pm_location_t *location)
{
    const size_t start_line = pm_newline_list_line_column(&parser->newline_list, location->start, 1).line;
    const size_t end_line = pm_newline_list_line_column(&parser->newline_list, location->end, 1).line;
    const uint8_t *start = parser->start + parser->newline_list.offsets[start_line - 1];
    const uint8_t *end = ((end_line == parser->newline_list.size) ? parser->end : (parser->start + parser->newline_list.offsets[end_line]));
    size_t width;
    while (start < end) {
        if ((width = pm_encoding_utf_8_char_width(start, end - start)) == 0) return 0;
        start += width;
    }
    return 1;
}
static VALUE
pm_parse_process_error(const pm_parse_result_t *result)
{
    const pm_parser_t *parser = &result->parser;
    const pm_diagnostic_t *head = (const pm_diagnostic_t *) parser->error_list.head;
    _Bool valid_utf8 = 1;
    pm_buffer_t buffer = { 0 };
    const pm_string_t *filepath = &parser->filepath;
    for (const pm_diagnostic_t *error = head; error != ((void *)0); error = (const pm_diagnostic_t *) error->node.next) {
        switch (error->level) {
          case PM_ERROR_LEVEL_SYNTAX:
            if (valid_utf8 && !pm_parse_process_error_utf8_p(parser, &error->location)) {
                valid_utf8 = 0;
            }
            break;
          case PM_ERROR_LEVEL_ARGUMENT: {
            int32_t line_number = (int32_t) pm_location_line_number(parser, &error->location);
            pm_buffer_append_format(
                &buffer,
                "%.*s:%" "i" ": %s",
                (int) pm_string_length(filepath),
                pm_string_source(filepath),
                line_number,
                error->message
            );
            if (pm_parse_process_error_utf8_p(parser, &error->location)) {
                pm_buffer_append_byte(&buffer, '\n');
                pm_list_node_t *list_node = (pm_list_node_t *) error;
                pm_list_t error_list = { .size = 1, .head = list_node, .tail = list_node };
                pm_parse_errors_format(parser, &error_list, &buffer, rb_stderr_tty_p(), 0);
            }
            VALUE value = rb_exc_new(rb_eArgError, pm_buffer_value(&buffer), pm_buffer_length(&buffer));
            pm_buffer_free(&buffer);
            return value;
          }
          case PM_ERROR_LEVEL_LOAD: {
            VALUE message = ((__builtin_constant_p(error->message) ? rbimpl_enc_str_new_cstr : rb_enc_str_new_cstr) ((error->message), (rb_locale_encoding())));
            VALUE value = rb_exc_new_str(rb_eLoadError, message);
            rb_ivar_set(value, rb_intern_const("@path"), ((VALUE)RUBY_Qnil));
            return value;
          }
        }
    }
    pm_buffer_append_format(
        &buffer,
        "%.*s:%" "i" ": syntax error%s found\n",
        (int) pm_string_length(filepath),
        pm_string_source(filepath),
        (int32_t) pm_location_line_number(parser, &head->location),
        (parser->error_list.size > 1) ? "s" : ""
    );
    if (valid_utf8) {
        pm_parse_errors_format(parser, &parser->error_list, &buffer, rb_stderr_tty_p(), 1);
    }
    else {
        for (const pm_diagnostic_t *error = head; error != ((void *)0); error = (const pm_diagnostic_t *) error->node.next) {
            if (error != head) pm_buffer_append_byte(&buffer, '\n');
            pm_buffer_append_format(&buffer, "%.*s:%" "i" ": %s", (int) pm_string_length(filepath), pm_string_source(filepath), (int32_t) pm_location_line_number(parser, &error->location), error->message);
        }
    }
    VALUE message = ((__builtin_constant_p(pm_buffer_value(&buffer)) && __builtin_constant_p(pm_buffer_length(&buffer)) ? rb_enc_str_new_static: rb_enc_str_new) ((pm_buffer_value(&buffer)), (pm_buffer_length(&buffer)), (result->node.encoding)));
    VALUE error = rb_exc_new_str(rb_eSyntaxError, message);
    rb_encoding *filepath_encoding = result->node.filepath_encoding != ((void *)0) ? result->node.filepath_encoding : rb_utf8_encoding();
    VALUE path = ((__builtin_constant_p((const char *) pm_string_source(filepath)) && __builtin_constant_p(pm_string_length(filepath)) ? rb_enc_str_new_static: rb_enc_str_new) (((const char *) pm_string_source(filepath)), (pm_string_length(filepath)), (filepath_encoding)));
    rb_ivar_set(error, rb_intern_const("@path"), path);
    pm_buffer_free(&buffer);
    return error;
}
static VALUE
pm_parse_process(pm_parse_result_t *result, pm_node_t *node, VALUE *script_lines)
{
    pm_parser_t *parser = &result->parser;
    pm_scope_node_t *scope_node = &result->node;
    rb_encoding *filepath_encoding = scope_node->filepath_encoding;
    int coverage_enabled = scope_node->coverage_enabled;
    pm_scope_node_init(node, scope_node, ((void *)0));
    scope_node->filepath_encoding = filepath_encoding;
    scope_node->encoding = rb_enc_find(parser->encoding->name);
    if (!scope_node->encoding) rb_bug("Encoding not found %s!", parser->encoding->name);
    scope_node->coverage_enabled = coverage_enabled;
    if (script_lines != ((void *)0)) {
        *script_lines = rb_ary_new_capa(parser->newline_list.size);
        for (size_t index = 0; index < parser->newline_list.size; index++) {
            size_t offset = parser->newline_list.offsets[index];
            size_t length = index == parser->newline_list.size - 1 ? ((size_t) (parser->end - (parser->start + offset))) : (parser->newline_list.offsets[index + 1] - offset);
            rb_ary_push(*script_lines, ((__builtin_constant_p((const char *) parser->start + offset) && __builtin_constant_p(length) ? rb_enc_str_new_static: rb_enc_str_new) (((const char *) parser->start + offset), (length), (scope_node->encoding))));
        }
        scope_node->script_lines = script_lines;
    }
    const pm_diagnostic_t *warning;
    const char *warning_filepath = (const char *) pm_string_source(&parser->filepath);
    for (warning = (const pm_diagnostic_t *) parser->warning_list.head; warning != ((void *)0); warning = (const pm_diagnostic_t *) warning->node.next) {
        int line = pm_location_line_number(parser, &warning->location);
        if (warning->level == PM_WARNING_LEVEL_VERBOSE) {
            rb_enc_compile_warning(scope_node->encoding, warning_filepath, line, "%s", warning->message);
        }
        else {
            rb_enc_compile_warn(scope_node->encoding, warning_filepath, line, "%s", warning->message);
        }
    }
    if (parser->error_list.size > 0) {
        VALUE error = pm_parse_process_error(result);
        return error;
    }
    scope_node->parser = parser;
    scope_node->constants = ruby_xcalloc(parser->constant_pool.size, sizeof(ID));
    for (uint32_t index = 0; index < parser->constant_pool.size; index++) {
        pm_constant_t *constant = &parser->constant_pool.constants[index];
        scope_node->constants[index] = rb_intern3((const char *) constant->start, constant->length, scope_node->encoding);
    }
    scope_node->index_lookup_table = rb_st_init_numtable();
    pm_constant_id_list_t *locals = &scope_node->locals;
    for (size_t index = 0; index < locals->size; index++) {
        rb_st_insert(scope_node->index_lookup_table, locals->ids[index], index);
    }
    result->parsed = 1;
    return ((VALUE)RUBY_Qnil);
}
static void
pm_options_frozen_string_literal_init(pm_options_t *options)
{
    int frozen_string_literal = rb_iseq_opt_frozen_string_literal();
    switch (frozen_string_literal) {
      case -1:
        break;
      case 0:
        pm_options_frozen_string_literal_set(options, 0);
        break;
      case 1:
        pm_options_frozen_string_literal_set(options, 1);
        break;
      default:
        rb_bug("pm_options_frozen_string_literal_init: invalid frozen_string_literal=%d", frozen_string_literal);
        break;
    }
}
static inline VALUE
pm_parse_file_script_lines(const pm_scope_node_t *scope_node, const pm_parser_t *parser)
{
    const pm_newline_list_t *newline_list = &parser->newline_list;
    const char *start = (const char *) parser->start;
    const char *end = (const char *) parser->end;
    size_t last_offset = newline_list->offsets[newline_list->size - 1];
    _Bool last_push = start + last_offset != end;
    VALUE lines = rb_ary_new_capa(newline_list->size - (last_push ? 0 : 1));
    for (size_t index = 0; index < newline_list->size - 1; index++) {
        size_t offset = newline_list->offsets[index];
        size_t length = newline_list->offsets[index + 1] - offset;
        rb_ary_push(lines, ((__builtin_constant_p(start + offset) && __builtin_constant_p(length) ? rb_enc_str_new_static: rb_enc_str_new) ((start + offset), (length), (scope_node->encoding))));
    }
    if (last_push) {
        rb_ary_push(lines, ((__builtin_constant_p(start + last_offset) && __builtin_constant_p(end - (start + last_offset)) ? rb_enc_str_new_static: rb_enc_str_new) ((start + last_offset), (end - (start + last_offset)), (scope_node->encoding))));
    }
    return lines;
}
static pm_string_init_result_t
pm_read_file(pm_string_t *string, const char *filepath)
{
    const int open_mode = 00 | 04000;
    int fd = open(filepath, open_mode);
    if (fd == -1) {
        return PM_STRING_INIT_ERROR_GENERIC;
    }
    struct stat sb;
    if (fstat(fd, &sb) == -1) {
        close(fd);
        return PM_STRING_INIT_ERROR_GENERIC;
    }
    if (((((sb.st_mode)) & 0170000) == (0040000))) {
        close(fd);
        return PM_STRING_INIT_ERROR_DIRECTORY;
    }
    if (((((sb.st_mode)) & 0170000) == (0010000)) || ((((sb.st_mode)) & 0170000) == (0020000))) {
        VALUE io = rb_io_fdopen((int) fd, open_mode, filepath);
        rb_io_wait(io, rb_int2num_inline(RUBY_IO_READABLE), ((VALUE)RUBY_Qnil));
        VALUE contents = rb_funcall(io, (__builtin_constant_p("read") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("read")); }) : (rb_intern)("read")), 0);
        if (!RB_TYPE_P(contents, RUBY_T_STRING)) {
            return PM_STRING_INIT_ERROR_GENERIC;
        }
        long len = RSTRING_LEN(contents);
        if (len < 0) {
            return PM_STRING_INIT_ERROR_GENERIC;
        }
        size_t length = (size_t) len;
        uint8_t *source = malloc(length);
        ruby_nonempty_memcpy(source, RSTRING_PTR(contents), length);
        *string = (pm_string_t) { .type = PM_STRING_OWNED, .source = source, .length = length };
        return PM_STRING_INIT_SUCCESS;
    }
    size_t size = (size_t) sb.st_size;
    uint8_t *source = ((void *)0);
    if (size == 0) {
        close(fd);
        const uint8_t source[] = "";
        *string = (pm_string_t) { .type = PM_STRING_CONSTANT, .source = source, .length = 0 };
        return PM_STRING_INIT_SUCCESS;
    }
    source = mmap(((void *)0), size, 0x1, 0x02, fd, 0);
    if (source == ((void *) -1)) {
        close(fd);
        return PM_STRING_INIT_ERROR_GENERIC;
    }
    close(fd);
    *string = (pm_string_t) { .type = PM_STRING_MAPPED, .source = source, .length = size };
    return PM_STRING_INIT_SUCCESS;
}
VALUE
pm_load_file(pm_parse_result_t *result, VALUE filepath, _Bool load_error)
{
    pm_string_init_result_t init_result = pm_read_file(&result->input, RSTRING_PTR(filepath));
    if (init_result == PM_STRING_INIT_SUCCESS) {
        pm_options_frozen_string_literal_init(&result->options);
        return ((VALUE)RUBY_Qnil);
    }
    int err;
    if (init_result == PM_STRING_INIT_ERROR_DIRECTORY) {
        err = 21;
    } else {
        err = (*rb_errno_ptr());
    }
    VALUE error;
    if (load_error) {
        VALUE message = ((__builtin_constant_p(strerror(err)) ? rbimpl_str_buf_new_cstr : rb_str_buf_new_cstr) (strerror(err)));
        ((__builtin_constant_p(" -- ") ? rbimpl_str_cat_cstr : rb_str_cat_cstr) ((message), (" -- ")));
        rb_str_append(message, filepath);
        error = rb_exc_new_str(rb_eLoadError, message);
        rb_ivar_set(error, rb_intern_const("@path"), filepath);
    } else {
        error = rb_syserr_new(err, RSTRING_PTR(filepath));
        (*__extension__ ({ volatile VALUE *rb_gc_guarded_ptr = &(filepath); __asm__("" : : "m"(rb_gc_guarded_ptr)); rb_gc_guarded_ptr; }));
    }
    return error;
}
VALUE
pm_parse_file(pm_parse_result_t *result, VALUE filepath, VALUE *script_lines)
{
    result->node.filepath_encoding = rb_enc_get(filepath);
    pm_options_filepath_set(&result->options, RSTRING_PTR(filepath));
    (*__extension__ ({ volatile VALUE *rb_gc_guarded_ptr = &(filepath); __asm__("" : : "m"(rb_gc_guarded_ptr)); rb_gc_guarded_ptr; }));
    pm_parser_init(&result->parser, pm_string_source(&result->input), pm_string_length(&result->input), &result->options);
    pm_node_t *node = pm_parse(&result->parser);
    VALUE error = pm_parse_process(result, node, script_lines);
    ID id_script_lines = (__builtin_constant_p("SCRIPT_LINES__") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("SCRIPT_LINES__")); }) : (rb_intern)("SCRIPT_LINES__"));
    if (rb_const_defined_at(rb_cObject, id_script_lines)) {
        VALUE constant_script_lines = rb_const_get_at(rb_cObject, id_script_lines);
        if (RB_TYPE_P(constant_script_lines, RUBY_T_HASH)) {
            rb_hash_aset(constant_script_lines, filepath, pm_parse_file_script_lines(&result->node, &result->parser));
        }
    }
    return error;
}
VALUE
pm_load_parse_file(pm_parse_result_t *result, VALUE filepath, VALUE *script_lines)
{
    VALUE error = pm_load_file(result, filepath, 0);
    if (RB_NIL_P(error)) {
        error = pm_parse_file(result, filepath, script_lines);
    }
    return error;
}
VALUE
pm_parse_string(pm_parse_result_t *result, VALUE source, VALUE filepath, VALUE *script_lines)
{
    rb_encoding *encoding = rb_enc_get(source);
    if (!rb_enc_asciicompat(encoding)) {
        return ((__builtin_constant_p("invalid source encoding") ? rbimpl_exc_new_cstr : rb_exc_new_cstr) ((rb_eArgError), ("invalid source encoding")));
    }
    pm_options_frozen_string_literal_init(&result->options);
    pm_string_constant_init(&result->input, RSTRING_PTR(source), RSTRING_LEN(source));
    pm_options_encoding_set(&result->options, rb_enc_name(encoding));
    result->node.filepath_encoding = rb_enc_get(filepath);
    pm_options_filepath_set(&result->options, RSTRING_PTR(filepath));
    (*__extension__ ({ volatile VALUE *rb_gc_guarded_ptr = &(filepath); __asm__("" : : "m"(rb_gc_guarded_ptr)); rb_gc_guarded_ptr; }));
    pm_parser_init(&result->parser, pm_string_source(&result->input), pm_string_length(&result->input), &result->options);
    pm_node_t *node = pm_parse(&result->parser);
    return pm_parse_process(result, node, script_lines);
}
static char *
pm_parse_stdin_fgets(char *string, int size, void *stream)
{
    ((void)0);
    VALUE line = rb_funcall((VALUE) stream, (__builtin_constant_p("gets") ? __extension__ ({ static ID rbimpl_id; rbimpl_intern_const(&rbimpl_id, ("gets")); }) : (rb_intern)("gets")), 1, __builtin_choose_expr( __builtin_constant_p(size - 1), ((VALUE)(size - 1)) << 1 | RUBY_FIXNUM_FLAG, RB_INT2FIX(size - 1)));
    if (RB_NIL_P(line)) {
        return ((void *)0);
    }
    const char *cstr = RSTRING_PTR(line);
    long length = RSTRING_LEN(line);
    ruby_nonempty_memcpy(string, cstr, length);
    string[length] = '\0';
    return string;
}
void rb_reset_argf_lineno(long n);
VALUE
pm_parse_stdin(pm_parse_result_t *result)
{
    pm_options_frozen_string_literal_init(&result->options);
    pm_buffer_t buffer;
    pm_node_t *node = pm_parse_stream(&result->parser, &buffer, (void *) rb_stdin, pm_parse_stdin_fgets, &result->options);
    pm_string_owned_init(&result->input, (uint8_t *) pm_buffer_value(&buffer), pm_buffer_length(&buffer));
    rb_reset_argf_lineno(0);
    return pm_parse_process(result, node, ((void *)0));
}
